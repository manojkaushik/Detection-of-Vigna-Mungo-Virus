{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3. yellow_mosaic_virus_vigna_mungo_leaves_CNN_6_imgSize_128.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUNl7NCehXPt"
      },
      "source": [
        "**CNN_1:** implementation on original leaf images\n",
        "\n",
        "size change of images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqAMVXxmhGpo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "8b76be6c-32e8-401a-857b-ab3cc797000a"
      },
      "source": [
        "# https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaDzDcvsnH77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "985d676f-dba4-4366-bd2c-5e49119c114d"
      },
      "source": [
        "# baseline model with dropout and data augmentation on the cifar10 dataset\n",
        "\n",
        "# Note: colab has changed the tensorflow version from 27 March 2020\n",
        "# %tensorflow_version 1.x\n",
        "\n",
        "import sys\n",
        "import os\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "import glob\n",
        "import numpy as np\n",
        "import cv2\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "from keras.callbacks import CSVLogger\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.models import load_model\n",
        "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "EPOCSH = 2000\n",
        "img_size = 128\n",
        "\n",
        "pathModelSave = \"/content/drive/My Drive/SavedModels/model_cnn_6_ori_imgsize_\"+str(img_size)+\"_.hdf5\"\n",
        "pathToSaveCSV_ori = \"/content/drive/My Drive/SavedModels/CSV_6_imgSize_\"+str(img_size)+\"_ori.csv\"\n",
        "\n",
        "pathModelSave_seg = \"/content/drive/My Drive/SavedModels/model_cnn_6_seg_img_\"+str(img_size)+\"_.hdf5\"\n",
        "pathToSaveCSV_seg = \"/content/drive/My Drive/SavedModels/CSV_6_imgSize_seg_\"+str(img_size)+\"_.csv\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xP7tSCPLnWk3"
      },
      "source": [
        "# load train and test dataset\n",
        "\n",
        "def prepare_data(path, img_size):\n",
        "\n",
        "    X = []\n",
        "    Y = []\n",
        "    filenames = [img for img in glob.glob(path)]\n",
        "\n",
        "    count = 0\n",
        "    for i in tqdm(filenames):\n",
        "      count = count + 1\n",
        "      split = i.split(os.sep)[-3]\n",
        "      if split != \"alien_test\":\n",
        "        img = cv2.imread(i)\n",
        "        img = cv2.resize(img, dsize=(img_size, img_size))\n",
        "        X.append(img)\n",
        "        split2 = i.split(os.sep)[-2]\n",
        "        if split2 == \"Healthy\":\n",
        "          Y.append(0)\n",
        "        elif split2 == \"Mild\":\n",
        "          Y.append(1)\n",
        "        elif split2 == \"Severe\":\n",
        "          Y.append(2)\n",
        "    print('\\n\\n total images are:', count)\n",
        "\n",
        "    # hot encoding\n",
        "    # Y = to_categorical(Y)\n",
        "    X = np.asarray(X)\n",
        "    \n",
        "    return X, Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNhbWZ5dFaEy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "2294d0fd-ffeb-4f68-a34a-e18727886042"
      },
      "source": [
        "X_ori, Y_ori = prepare_data('/content/drive/My Drive/datasets/vigna_mungo_leaves/*/*/*', img_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 201/201 [02:49<00:00,  1.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " total images are: 201\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJhwa9qgnOhv"
      },
      "source": [
        "# scale pixels\n",
        "def prep_pixels(trainX, testX):\n",
        "\t# convert from integers to floats\n",
        "\ttrain_norm = trainX.astype('float32')\n",
        "\ttest_norm = testX.astype('float32')\n",
        "\t# normalize to range 0-1\n",
        "\ttrain_norm = train_norm / 255.0\n",
        "\ttest_norm = test_norm / 255.0\n",
        "\t# return normalized images\n",
        "\treturn train_norm, test_norm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1O9za1q51gY",
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "1a592650-44f7-422b-c1e6-3a66c92cbb27"
      },
      "source": [
        "#@title Default title text\n",
        "# define cnn model\n",
        "def define_model():\n",
        "\tkernel = (3, 3)\n",
        "\tfirst_conv  = 32\n",
        "\tsecond_conv = first_conv * 2\n",
        "\tthird_conv  = second_conv * 2\n",
        "\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(first_conv, kernel, activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(img_size, img_size, 3)))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\t\n",
        "\tmodel.add(Conv2D(first_conv, kernel, activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\t\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Conv2D(second_conv, kernel, activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\t\n",
        "\tmodel.add(Conv2D(second_conv, kernel, activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\t\n",
        "\tmodel.add(Dropout(0.3))\n",
        "\tmodel.add(Conv2D(third_conv, kernel, activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\t\n",
        "\tmodel.add(Conv2D(third_conv, kernel, activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\t\n",
        "\tmodel.add(Dropout(0.4))\n",
        "\tmodel.add(Flatten())\n",
        " \n",
        "\tmodel.add(Dense(third_conv, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(BatchNormalization())\n",
        " \n",
        "\tmodel.add(Dropout(0.5))\n",
        "\tmodel.add(Dense(3, activation='softmax'))\n",
        " \n",
        "\t# compile model\n",
        "\topt = SGD(lr=0.001, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\tmodel.summary()\n",
        "\treturn model\n",
        "\n",
        "# define model\n",
        "model = define_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 128, 128, 32)      896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 128, 128, 32)      128       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 128, 128, 32)      9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 128, 128, 32)      128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64, 64, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 64, 64, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 64, 64, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 64, 64, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 64, 64, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 32, 32, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 32, 32, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               4194432   \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 4,484,131\n",
            "Trainable params: 4,482,979\n",
            "Non-trainable params: 1,152\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMQhN-pTGOsL"
      },
      "source": [
        "# load dataset\n",
        "trainX, testX_, trainY, testY_ = train_test_split(X_ori, Y_ori, test_size=0.2, random_state = 0)\n",
        "trainX, testX = prep_pixels(trainX, testX_)\n",
        "\n",
        "# hot encoding\n",
        "trainY = to_categorical(trainY)\n",
        "testY = to_categorical(testY_)\n",
        "\n",
        "datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
        "it_train = datagen.flow(trainX, trainY, batch_size = 8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35RB7i6r6WU8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a0689f36-a48a-45e7-9135-8d0f3242e407"
      },
      "source": [
        "%%time\n",
        "# fit model\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "checkpoint = ModelCheckpoint(pathModelSave, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "# early = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')\n",
        "csv_logger_ori = CSVLogger(pathToSaveCSV_ori, append=False, separator=',')\n",
        "\n",
        "steps = int(trainX.shape[0] / 32)\n",
        "history_ori = model.fit_generator(\n",
        "    it_train, \n",
        "    steps_per_epoch = steps, \n",
        "    epochs=EPOCSH, \n",
        "    callbacks = [checkpoint, csv_logger_ori], \n",
        "    validation_data = (testX, testY), \n",
        "    verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2000\n",
            "5/5 [==============================] - 3s 504ms/step - loss: 1.5459 - accuracy: 0.4500 - val_loss: 5.6436 - val_accuracy: 0.3171\n",
            "Epoch 2/2000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:707: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
            "  'skipping.' % (self.monitor), RuntimeWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 1s 228ms/step - loss: 1.3882 - accuracy: 0.4750 - val_loss: 3.6817 - val_accuracy: 0.3171\n",
            "Epoch 3/2000\n",
            "5/5 [==============================] - 1s 228ms/step - loss: 1.4016 - accuracy: 0.5000 - val_loss: 2.6155 - val_accuracy: 0.3171\n",
            "Epoch 4/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.8974 - accuracy: 0.5500 - val_loss: 3.0874 - val_accuracy: 0.3171\n",
            "Epoch 5/2000\n",
            "5/5 [==============================] - 1s 227ms/step - loss: 1.1544 - accuracy: 0.4750 - val_loss: 3.6203 - val_accuracy: 0.3171\n",
            "Epoch 6/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 1.0276 - accuracy: 0.4750 - val_loss: 4.8446 - val_accuracy: 0.3171\n",
            "Epoch 7/2000\n",
            "5/5 [==============================] - 1s 227ms/step - loss: 1.3011 - accuracy: 0.5500 - val_loss: 6.2800 - val_accuracy: 0.3171\n",
            "Epoch 8/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.6253 - accuracy: 0.6750 - val_loss: 4.8337 - val_accuracy: 0.3171\n",
            "Epoch 9/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 1.0719 - accuracy: 0.6750 - val_loss: 4.0557 - val_accuracy: 0.3171\n",
            "Epoch 10/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.5120 - accuracy: 0.8000 - val_loss: 3.4549 - val_accuracy: 0.3171\n",
            "Epoch 11/2000\n",
            "5/5 [==============================] - 1s 226ms/step - loss: 0.8645 - accuracy: 0.6500 - val_loss: 2.1562 - val_accuracy: 0.3171\n",
            "Epoch 12/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.6908 - accuracy: 0.7250 - val_loss: 1.5836 - val_accuracy: 0.3171\n",
            "Epoch 13/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.6641 - accuracy: 0.6750 - val_loss: 1.4354 - val_accuracy: 0.3171\n",
            "Epoch 14/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 1.1240 - accuracy: 0.7750 - val_loss: 1.4708 - val_accuracy: 0.3171\n",
            "Epoch 15/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.5559 - accuracy: 0.8250 - val_loss: 1.4600 - val_accuracy: 0.3171\n",
            "Epoch 16/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.3864 - accuracy: 0.8000 - val_loss: 1.2600 - val_accuracy: 0.3171\n",
            "Epoch 17/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.2129 - accuracy: 0.9500 - val_loss: 1.0294 - val_accuracy: 0.4390\n",
            "Epoch 18/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.3370 - accuracy: 0.9000 - val_loss: 1.2603 - val_accuracy: 0.3415\n",
            "Epoch 19/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.9926 - accuracy: 0.6500 - val_loss: 1.7843 - val_accuracy: 0.3171\n",
            "Epoch 20/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.5517 - accuracy: 0.7250 - val_loss: 1.6309 - val_accuracy: 0.3171\n",
            "Epoch 21/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.6566 - accuracy: 0.7250 - val_loss: 1.0478 - val_accuracy: 0.3659\n",
            "Epoch 22/2000\n",
            "5/5 [==============================] - 1s 228ms/step - loss: 0.5412 - accuracy: 0.8250 - val_loss: 0.7657 - val_accuracy: 0.6341\n",
            "Epoch 23/2000\n",
            "5/5 [==============================] - 1s 228ms/step - loss: 0.6533 - accuracy: 0.7000 - val_loss: 0.7300 - val_accuracy: 0.6829\n",
            "Epoch 24/2000\n",
            "5/5 [==============================] - 1s 228ms/step - loss: 0.8866 - accuracy: 0.7750 - val_loss: 0.8689 - val_accuracy: 0.6341\n",
            "Epoch 25/2000\n",
            "5/5 [==============================] - 1s 225ms/step - loss: 0.6896 - accuracy: 0.7250 - val_loss: 0.8518 - val_accuracy: 0.7073\n",
            "Epoch 26/2000\n",
            "5/5 [==============================] - 1s 226ms/step - loss: 0.4716 - accuracy: 0.8250 - val_loss: 0.6885 - val_accuracy: 0.6829\n",
            "Epoch 27/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.3765 - accuracy: 0.7750 - val_loss: 0.6592 - val_accuracy: 0.8049\n",
            "Epoch 28/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.6453 - accuracy: 0.8500 - val_loss: 0.6766 - val_accuracy: 0.7805\n",
            "Epoch 29/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1787 - accuracy: 0.9500 - val_loss: 0.7030 - val_accuracy: 0.7561\n",
            "Epoch 30/2000\n",
            "5/5 [==============================] - 1s 228ms/step - loss: 0.3069 - accuracy: 0.9500 - val_loss: 0.9396 - val_accuracy: 0.5854\n",
            "Epoch 31/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.6162 - accuracy: 0.8000 - val_loss: 1.4931 - val_accuracy: 0.5854\n",
            "Epoch 32/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.8232 - accuracy: 0.7500 - val_loss: 1.8718 - val_accuracy: 0.5122\n",
            "Epoch 33/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.3195 - accuracy: 0.8500 - val_loss: 2.1333 - val_accuracy: 0.5610\n",
            "Epoch 34/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.3632 - accuracy: 0.8750 - val_loss: 2.7397 - val_accuracy: 0.4390\n",
            "Epoch 35/2000\n",
            "5/5 [==============================] - 1s 228ms/step - loss: 0.2020 - accuracy: 0.9250 - val_loss: 3.3079 - val_accuracy: 0.4390\n",
            "Epoch 36/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.3592 - accuracy: 0.8250 - val_loss: 3.9201 - val_accuracy: 0.4146\n",
            "Epoch 37/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.4276 - accuracy: 0.8250 - val_loss: 4.3388 - val_accuracy: 0.4146\n",
            "Epoch 38/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.2748 - accuracy: 0.8750 - val_loss: 4.9072 - val_accuracy: 0.4146\n",
            "Epoch 39/2000\n",
            "5/5 [==============================] - 1s 228ms/step - loss: 0.4582 - accuracy: 0.8250 - val_loss: 5.1690 - val_accuracy: 0.3902\n",
            "Epoch 40/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.3389 - accuracy: 0.9250 - val_loss: 4.9402 - val_accuracy: 0.6098\n",
            "Epoch 41/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.2647 - accuracy: 0.9250 - val_loss: 4.8464 - val_accuracy: 0.6341\n",
            "Epoch 42/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.1652 - accuracy: 0.9250 - val_loss: 4.9362 - val_accuracy: 0.5854\n",
            "Epoch 43/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.3603 - accuracy: 0.9250 - val_loss: 5.1619 - val_accuracy: 0.5854\n",
            "Epoch 44/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.3178 - accuracy: 0.9250 - val_loss: 5.8627 - val_accuracy: 0.5366\n",
            "Epoch 45/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.3542 - accuracy: 0.9000 - val_loss: 6.8515 - val_accuracy: 0.4878\n",
            "Epoch 46/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.5026 - accuracy: 0.8000 - val_loss: 7.8400 - val_accuracy: 0.4146\n",
            "Epoch 47/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.8033 - accuracy: 0.7750 - val_loss: 9.3630 - val_accuracy: 0.4146\n",
            "Epoch 48/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.6098 - accuracy: 0.8250 - val_loss: 10.8010 - val_accuracy: 0.3659\n",
            "Epoch 49/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.4403 - accuracy: 0.8500 - val_loss: 11.5108 - val_accuracy: 0.4146\n",
            "Epoch 50/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.2767 - accuracy: 0.9000 - val_loss: 12.0096 - val_accuracy: 0.3902\n",
            "Epoch 51/2000\n",
            "5/5 [==============================] - 1s 228ms/step - loss: 0.4822 - accuracy: 0.7750 - val_loss: 12.1361 - val_accuracy: 0.3415\n",
            "Epoch 52/2000\n",
            "5/5 [==============================] - 1s 228ms/step - loss: 0.4506 - accuracy: 0.9000 - val_loss: 11.3814 - val_accuracy: 0.2683\n",
            "Epoch 53/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.5989 - accuracy: 0.8500 - val_loss: 11.5844 - val_accuracy: 0.2683\n",
            "Epoch 54/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.2961 - accuracy: 0.9000 - val_loss: 11.7840 - val_accuracy: 0.3415\n",
            "Epoch 55/2000\n",
            "5/5 [==============================] - 1s 226ms/step - loss: 0.5341 - accuracy: 0.8250 - val_loss: 13.4748 - val_accuracy: 0.2683\n",
            "Epoch 56/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.3984 - accuracy: 0.8500 - val_loss: 15.4301 - val_accuracy: 0.3171\n",
            "Epoch 57/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.5218 - accuracy: 0.8000 - val_loss: 16.6385 - val_accuracy: 0.3171\n",
            "Epoch 58/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.5341 - accuracy: 0.8000 - val_loss: 16.4810 - val_accuracy: 0.3415\n",
            "Epoch 59/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.7163 - accuracy: 0.7500 - val_loss: 17.1870 - val_accuracy: 0.3171\n",
            "Epoch 60/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.5089 - accuracy: 0.8500 - val_loss: 17.0015 - val_accuracy: 0.3415\n",
            "Epoch 61/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1803 - accuracy: 0.9750 - val_loss: 17.4953 - val_accuracy: 0.3659\n",
            "Epoch 62/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.3597 - accuracy: 0.8500 - val_loss: 17.4348 - val_accuracy: 0.3415\n",
            "Epoch 63/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2158 - accuracy: 0.9500 - val_loss: 17.3441 - val_accuracy: 0.3171\n",
            "Epoch 64/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.6122 - accuracy: 0.8250 - val_loss: 15.6105 - val_accuracy: 0.3415\n",
            "Epoch 65/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.4591 - accuracy: 0.9000 - val_loss: 15.1991 - val_accuracy: 0.3415\n",
            "Epoch 66/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.1890 - accuracy: 0.9250 - val_loss: 15.3841 - val_accuracy: 0.3171\n",
            "Epoch 67/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.5664 - accuracy: 0.9000 - val_loss: 16.2064 - val_accuracy: 0.3415\n",
            "Epoch 68/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.5713 - accuracy: 0.8500 - val_loss: 14.8064 - val_accuracy: 0.4390\n",
            "Epoch 69/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.3150 - accuracy: 0.8750 - val_loss: 12.7962 - val_accuracy: 0.4634\n",
            "Epoch 70/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.8238 - accuracy: 0.7750 - val_loss: 10.9052 - val_accuracy: 0.4634\n",
            "Epoch 71/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.5306 - accuracy: 0.7000 - val_loss: 10.5040 - val_accuracy: 0.4390\n",
            "Epoch 72/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.2450 - accuracy: 0.9000 - val_loss: 10.5247 - val_accuracy: 0.3659\n",
            "Epoch 73/2000\n",
            "5/5 [==============================] - 1s 227ms/step - loss: 0.5706 - accuracy: 0.8500 - val_loss: 12.7924 - val_accuracy: 0.3902\n",
            "Epoch 74/2000\n",
            "5/5 [==============================] - 1s 228ms/step - loss: 0.2837 - accuracy: 0.8750 - val_loss: 15.0126 - val_accuracy: 0.3902\n",
            "Epoch 75/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.5794 - accuracy: 0.6750 - val_loss: 15.9470 - val_accuracy: 0.3659\n",
            "Epoch 76/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.2729 - accuracy: 0.9500 - val_loss: 15.3761 - val_accuracy: 0.4146\n",
            "Epoch 77/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.5306 - accuracy: 0.8000 - val_loss: 12.6033 - val_accuracy: 0.4634\n",
            "Epoch 78/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.4185 - accuracy: 0.7750 - val_loss: 10.6044 - val_accuracy: 0.5366\n",
            "Epoch 79/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.1406 - accuracy: 0.9500 - val_loss: 13.7399 - val_accuracy: 0.4390\n",
            "Epoch 80/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.2716 - accuracy: 0.9250 - val_loss: 14.8031 - val_accuracy: 0.3659\n",
            "Epoch 81/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.2352 - accuracy: 0.9000 - val_loss: 14.3757 - val_accuracy: 0.4146\n",
            "Epoch 82/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.3430 - accuracy: 0.8750 - val_loss: 13.3403 - val_accuracy: 0.3902\n",
            "Epoch 83/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.3294 - accuracy: 0.8750 - val_loss: 10.4624 - val_accuracy: 0.4634\n",
            "Epoch 84/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.3240 - accuracy: 0.9000 - val_loss: 9.0474 - val_accuracy: 0.5122\n",
            "Epoch 85/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.2498 - accuracy: 0.9000 - val_loss: 9.9752 - val_accuracy: 0.5854\n",
            "Epoch 86/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.4828 - accuracy: 0.8500 - val_loss: 6.2634 - val_accuracy: 0.6098\n",
            "Epoch 87/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.2643 - accuracy: 0.8500 - val_loss: 8.0563 - val_accuracy: 0.6585\n",
            "Epoch 88/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.4387 - accuracy: 0.8750 - val_loss: 11.3982 - val_accuracy: 0.6341\n",
            "Epoch 89/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.2287 - accuracy: 0.9250 - val_loss: 11.0044 - val_accuracy: 0.6341\n",
            "Epoch 90/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.3803 - accuracy: 0.8750 - val_loss: 9.6170 - val_accuracy: 0.6098\n",
            "Epoch 91/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.3059 - accuracy: 0.9250 - val_loss: 7.5920 - val_accuracy: 0.5854\n",
            "Epoch 92/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.4783 - accuracy: 0.8500 - val_loss: 4.1521 - val_accuracy: 0.5854\n",
            "Epoch 93/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.4384 - accuracy: 0.8750 - val_loss: 3.2405 - val_accuracy: 0.5366\n",
            "Epoch 94/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.2835 - accuracy: 0.8750 - val_loss: 3.3735 - val_accuracy: 0.4634\n",
            "Epoch 95/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.2911 - accuracy: 0.9000 - val_loss: 3.8126 - val_accuracy: 0.6341\n",
            "Epoch 96/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.4245 - accuracy: 0.8750 - val_loss: 7.9150 - val_accuracy: 0.6585\n",
            "Epoch 97/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.2136 - accuracy: 0.9250 - val_loss: 9.2496 - val_accuracy: 0.6585\n",
            "Epoch 98/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.2879 - accuracy: 0.9000 - val_loss: 8.1968 - val_accuracy: 0.6585\n",
            "Epoch 99/2000\n",
            "5/5 [==============================] - 1s 227ms/step - loss: 0.2163 - accuracy: 0.9250 - val_loss: 6.4026 - val_accuracy: 0.6341\n",
            "Epoch 100/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.2492 - accuracy: 0.8750 - val_loss: 4.8006 - val_accuracy: 0.6341\n",
            "Epoch 101/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1495 - accuracy: 0.9500 - val_loss: 4.2078 - val_accuracy: 0.6341\n",
            "Epoch 102/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.2808 - accuracy: 0.8500 - val_loss: 4.4522 - val_accuracy: 0.6829\n",
            "Epoch 103/2000\n",
            "5/5 [==============================] - 1s 227ms/step - loss: 0.2471 - accuracy: 0.9000 - val_loss: 4.4086 - val_accuracy: 0.7561\n",
            "Epoch 104/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2383 - accuracy: 0.9000 - val_loss: 4.3659 - val_accuracy: 0.7561\n",
            "Epoch 105/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.3279 - accuracy: 0.8750 - val_loss: 3.7143 - val_accuracy: 0.7561\n",
            "Epoch 106/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.2981 - accuracy: 0.9250 - val_loss: 2.0858 - val_accuracy: 0.7561\n",
            "Epoch 107/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.3640 - accuracy: 0.8500 - val_loss: 2.3011 - val_accuracy: 0.7073\n",
            "Epoch 108/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.4347 - accuracy: 0.8500 - val_loss: 5.4845 - val_accuracy: 0.7561\n",
            "Epoch 109/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2571 - accuracy: 0.9000 - val_loss: 7.8647 - val_accuracy: 0.6585\n",
            "Epoch 110/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.6383 - accuracy: 0.7500 - val_loss: 8.3065 - val_accuracy: 0.6341\n",
            "Epoch 111/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2758 - accuracy: 0.9250 - val_loss: 6.5998 - val_accuracy: 0.6585\n",
            "Epoch 112/2000\n",
            "5/5 [==============================] - 1s 228ms/step - loss: 0.0746 - accuracy: 1.0000 - val_loss: 3.0119 - val_accuracy: 0.6585\n",
            "Epoch 113/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.2881 - accuracy: 0.8250 - val_loss: 2.6007 - val_accuracy: 0.7073\n",
            "Epoch 114/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.3955 - accuracy: 0.9250 - val_loss: 3.6568 - val_accuracy: 0.7561\n",
            "Epoch 115/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.2064 - accuracy: 0.9250 - val_loss: 4.6676 - val_accuracy: 0.7073\n",
            "Epoch 116/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.4017 - accuracy: 0.8750 - val_loss: 3.3725 - val_accuracy: 0.7317\n",
            "Epoch 117/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1859 - accuracy: 0.9500 - val_loss: 1.7866 - val_accuracy: 0.7561\n",
            "Epoch 118/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.3799 - accuracy: 0.8750 - val_loss: 1.4143 - val_accuracy: 0.7805\n",
            "Epoch 119/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.2047 - accuracy: 0.9500 - val_loss: 1.2568 - val_accuracy: 0.8293\n",
            "Epoch 120/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.5344 - accuracy: 0.8250 - val_loss: 1.8374 - val_accuracy: 0.8293\n",
            "Epoch 121/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.4737 - accuracy: 0.8000 - val_loss: 2.0054 - val_accuracy: 0.7561\n",
            "Epoch 122/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2678 - accuracy: 0.8750 - val_loss: 1.7452 - val_accuracy: 0.7805\n",
            "Epoch 123/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1081 - accuracy: 0.9750 - val_loss: 1.3357 - val_accuracy: 0.8537\n",
            "Epoch 124/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.3035 - accuracy: 0.9250 - val_loss: 0.6545 - val_accuracy: 0.8780\n",
            "Epoch 125/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.5243 - accuracy: 0.8500 - val_loss: 0.9782 - val_accuracy: 0.9024\n",
            "Epoch 126/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.2356 - accuracy: 0.9250 - val_loss: 1.0294 - val_accuracy: 0.9024\n",
            "Epoch 127/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.2240 - accuracy: 0.9250 - val_loss: 0.6195 - val_accuracy: 0.9268\n",
            "Epoch 128/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.1184 - accuracy: 0.9750 - val_loss: 0.7059 - val_accuracy: 0.9024\n",
            "Epoch 129/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2725 - accuracy: 0.9500 - val_loss: 0.3935 - val_accuracy: 0.9268\n",
            "Epoch 130/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.3881 - accuracy: 0.8750 - val_loss: 0.6473 - val_accuracy: 0.8780\n",
            "Epoch 131/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.4427 - accuracy: 0.8500 - val_loss: 0.8696 - val_accuracy: 0.8780\n",
            "Epoch 132/2000\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.3438 - accuracy: 0.9250 - val_loss: 0.5194 - val_accuracy: 0.9024\n",
            "Epoch 133/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.2327 - accuracy: 0.9250 - val_loss: 0.5064 - val_accuracy: 0.9024\n",
            "Epoch 134/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.4463 - accuracy: 0.8500 - val_loss: 0.3276 - val_accuracy: 0.9268\n",
            "Epoch 135/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.4420 - accuracy: 0.8500 - val_loss: 0.2846 - val_accuracy: 0.9512\n",
            "Epoch 136/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2412 - accuracy: 0.9250 - val_loss: 0.4582 - val_accuracy: 0.9024\n",
            "Epoch 137/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.2801 - accuracy: 0.8750 - val_loss: 0.5831 - val_accuracy: 0.9268\n",
            "Epoch 138/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1586 - accuracy: 0.9750 - val_loss: 0.5302 - val_accuracy: 0.9268\n",
            "Epoch 139/2000\n",
            "5/5 [==============================] - 1s 243ms/step - loss: 0.3286 - accuracy: 0.8250 - val_loss: 0.5909 - val_accuracy: 0.9268\n",
            "Epoch 140/2000\n",
            "5/5 [==============================] - 1s 295ms/step - loss: 0.3657 - accuracy: 0.9000 - val_loss: 0.9662 - val_accuracy: 0.8780\n",
            "Epoch 141/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1589 - accuracy: 0.9750 - val_loss: 0.9460 - val_accuracy: 0.8780\n",
            "Epoch 142/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2805 - accuracy: 0.8500 - val_loss: 1.1141 - val_accuracy: 0.8780\n",
            "Epoch 143/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.3546 - accuracy: 0.9000 - val_loss: 0.7687 - val_accuracy: 0.9024\n",
            "Epoch 144/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1358 - accuracy: 0.9500 - val_loss: 0.5328 - val_accuracy: 0.9024\n",
            "Epoch 145/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1482 - accuracy: 0.9000 - val_loss: 0.2845 - val_accuracy: 0.9024\n",
            "Epoch 146/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1559 - accuracy: 0.9500 - val_loss: 0.1564 - val_accuracy: 0.9512\n",
            "Epoch 147/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.3388 - accuracy: 0.8750 - val_loss: 0.1877 - val_accuracy: 0.9268\n",
            "Epoch 148/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.4776 - accuracy: 0.9250 - val_loss: 0.2429 - val_accuracy: 0.9024\n",
            "Epoch 149/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.2625 - accuracy: 0.9000 - val_loss: 0.3477 - val_accuracy: 0.9024\n",
            "Epoch 150/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.3044 - accuracy: 0.8500 - val_loss: 0.1914 - val_accuracy: 0.9512\n",
            "Epoch 151/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.2175 - accuracy: 0.9750 - val_loss: 0.2675 - val_accuracy: 0.9268\n",
            "Epoch 152/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.2458 - accuracy: 0.8750 - val_loss: 0.2461 - val_accuracy: 0.9512\n",
            "Epoch 153/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1787 - accuracy: 0.9250 - val_loss: 0.2845 - val_accuracy: 0.9268\n",
            "Epoch 154/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.3576 - accuracy: 0.8250 - val_loss: 0.1608 - val_accuracy: 0.9512\n",
            "Epoch 155/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.2683 - accuracy: 0.8750 - val_loss: 0.5554 - val_accuracy: 0.9024\n",
            "Epoch 156/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.3479 - accuracy: 0.9250 - val_loss: 0.5710 - val_accuracy: 0.9268\n",
            "Epoch 157/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1365 - accuracy: 0.9250 - val_loss: 0.5809 - val_accuracy: 0.9024\n",
            "Epoch 158/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.3681 - accuracy: 0.8750 - val_loss: 0.5086 - val_accuracy: 0.8780\n",
            "Epoch 159/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.3401 - accuracy: 0.8750 - val_loss: 0.4444 - val_accuracy: 0.9268\n",
            "Epoch 160/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.2589 - accuracy: 0.9000 - val_loss: 0.7041 - val_accuracy: 0.8780\n",
            "Epoch 161/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.1489 - accuracy: 0.9500 - val_loss: 0.6666 - val_accuracy: 0.9024\n",
            "Epoch 162/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.1566 - accuracy: 0.9500 - val_loss: 0.5779 - val_accuracy: 0.9024\n",
            "Epoch 163/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.4932 - accuracy: 0.8000 - val_loss: 0.5957 - val_accuracy: 0.9512\n",
            "Epoch 164/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.1513 - accuracy: 0.9500 - val_loss: 0.8145 - val_accuracy: 0.9268\n",
            "Epoch 165/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.2950 - accuracy: 0.8750 - val_loss: 1.1509 - val_accuracy: 0.7073\n",
            "Epoch 166/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.4163 - accuracy: 0.8250 - val_loss: 1.3720 - val_accuracy: 0.6341\n",
            "Epoch 167/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.3428 - accuracy: 0.8750 - val_loss: 0.9157 - val_accuracy: 0.9024\n",
            "Epoch 168/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0649 - accuracy: 0.9750 - val_loss: 0.4451 - val_accuracy: 0.9268\n",
            "Epoch 169/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2178 - accuracy: 0.9250 - val_loss: 0.6342 - val_accuracy: 0.9268\n",
            "Epoch 170/2000\n",
            "5/5 [==============================] - 1s 249ms/step - loss: 0.2930 - accuracy: 0.9000 - val_loss: 0.6347 - val_accuracy: 0.9268\n",
            "Epoch 171/2000\n",
            "5/5 [==============================] - 1s 248ms/step - loss: 0.4635 - accuracy: 0.8500 - val_loss: 0.3451 - val_accuracy: 0.9024\n",
            "Epoch 172/2000\n",
            "5/5 [==============================] - 1s 251ms/step - loss: 0.2689 - accuracy: 0.9000 - val_loss: 0.6188 - val_accuracy: 0.9268\n",
            "Epoch 173/2000\n",
            "5/5 [==============================] - 1s 249ms/step - loss: 0.0990 - accuracy: 0.9750 - val_loss: 0.6558 - val_accuracy: 0.8780\n",
            "Epoch 174/2000\n",
            "5/5 [==============================] - 1s 247ms/step - loss: 0.1875 - accuracy: 0.9250 - val_loss: 0.6311 - val_accuracy: 0.8780\n",
            "Epoch 175/2000\n",
            "5/5 [==============================] - 1s 246ms/step - loss: 0.3753 - accuracy: 0.8750 - val_loss: 0.6192 - val_accuracy: 0.8780\n",
            "Epoch 176/2000\n",
            "5/5 [==============================] - 1s 250ms/step - loss: 0.3941 - accuracy: 0.8500 - val_loss: 0.6209 - val_accuracy: 0.9268\n",
            "Epoch 177/2000\n",
            "5/5 [==============================] - 1s 245ms/step - loss: 0.3991 - accuracy: 0.8750 - val_loss: 0.6768 - val_accuracy: 0.9268\n",
            "Epoch 178/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.3375 - accuracy: 0.9250 - val_loss: 0.9390 - val_accuracy: 0.8780\n",
            "Epoch 179/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.3273 - accuracy: 0.8250 - val_loss: 0.7701 - val_accuracy: 0.9268\n",
            "Epoch 180/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.2237 - accuracy: 0.8750 - val_loss: 0.7950 - val_accuracy: 0.9268\n",
            "Epoch 181/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1430 - accuracy: 0.9750 - val_loss: 0.9890 - val_accuracy: 0.9268\n",
            "Epoch 182/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.2558 - accuracy: 0.8750 - val_loss: 0.9754 - val_accuracy: 0.9268\n",
            "Epoch 183/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1868 - accuracy: 0.9000 - val_loss: 0.7584 - val_accuracy: 0.9024\n",
            "Epoch 184/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.2885 - accuracy: 0.8750 - val_loss: 0.6766 - val_accuracy: 0.9268\n",
            "Epoch 185/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.2752 - accuracy: 0.9250 - val_loss: 0.7103 - val_accuracy: 0.8780\n",
            "Epoch 186/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.3729 - accuracy: 0.8250 - val_loss: 0.5958 - val_accuracy: 0.9268\n",
            "Epoch 187/2000\n",
            "5/5 [==============================] - 1s 228ms/step - loss: 0.2817 - accuracy: 0.9000 - val_loss: 0.7327 - val_accuracy: 0.9024\n",
            "Epoch 188/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.4252 - accuracy: 0.8500 - val_loss: 0.6746 - val_accuracy: 0.9024\n",
            "Epoch 189/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1465 - accuracy: 0.9500 - val_loss: 0.5152 - val_accuracy: 0.9268\n",
            "Epoch 190/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2214 - accuracy: 0.9500 - val_loss: 0.6787 - val_accuracy: 0.9024\n",
            "Epoch 191/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.4749 - accuracy: 0.8500 - val_loss: 0.6722 - val_accuracy: 0.9024\n",
            "Epoch 192/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.6691 - accuracy: 0.8250 - val_loss: 0.5681 - val_accuracy: 0.9024\n",
            "Epoch 193/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1553 - accuracy: 0.9750 - val_loss: 0.6496 - val_accuracy: 0.9024\n",
            "Epoch 194/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.2027 - accuracy: 0.9000 - val_loss: 0.9154 - val_accuracy: 0.9512\n",
            "Epoch 195/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.2396 - accuracy: 0.9250 - val_loss: 1.0497 - val_accuracy: 0.7805\n",
            "Epoch 196/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.3027 - accuracy: 0.9000 - val_loss: 0.8978 - val_accuracy: 0.6829\n",
            "Epoch 197/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.2277 - accuracy: 0.9250 - val_loss: 0.5931 - val_accuracy: 0.9024\n",
            "Epoch 198/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.4199 - accuracy: 0.8250 - val_loss: 0.7067 - val_accuracy: 0.8049\n",
            "Epoch 199/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1274 - accuracy: 1.0000 - val_loss: 0.3604 - val_accuracy: 0.9024\n",
            "Epoch 200/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.3996 - accuracy: 0.9000 - val_loss: 0.5403 - val_accuracy: 0.9268\n",
            "Epoch 201/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2795 - accuracy: 0.8500 - val_loss: 0.4087 - val_accuracy: 0.9268\n",
            "Epoch 202/2000\n",
            "5/5 [==============================] - 1s 228ms/step - loss: 0.2374 - accuracy: 0.9000 - val_loss: 0.2325 - val_accuracy: 0.9268\n",
            "Epoch 203/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2825 - accuracy: 0.9500 - val_loss: 0.2672 - val_accuracy: 0.9024\n",
            "Epoch 204/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1893 - accuracy: 0.9250 - val_loss: 0.2741 - val_accuracy: 0.9024\n",
            "Epoch 205/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1494 - accuracy: 0.9250 - val_loss: 0.2421 - val_accuracy: 0.9512\n",
            "Epoch 206/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.3169 - accuracy: 0.9500 - val_loss: 0.3444 - val_accuracy: 0.9512\n",
            "Epoch 207/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1677 - accuracy: 0.9250 - val_loss: 0.4893 - val_accuracy: 0.9512\n",
            "Epoch 208/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0913 - accuracy: 1.0000 - val_loss: 0.5767 - val_accuracy: 0.9512\n",
            "Epoch 209/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.2658 - accuracy: 0.9250 - val_loss: 0.4916 - val_accuracy: 0.9512\n",
            "Epoch 210/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.2192 - accuracy: 0.9000 - val_loss: 0.1570 - val_accuracy: 0.9756\n",
            "Epoch 211/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.2641 - accuracy: 0.9000 - val_loss: 0.3098 - val_accuracy: 0.9512\n",
            "Epoch 212/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1983 - accuracy: 0.9000 - val_loss: 0.2734 - val_accuracy: 0.9512\n",
            "Epoch 213/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.2175 - accuracy: 0.9500 - val_loss: 0.3065 - val_accuracy: 0.9268\n",
            "Epoch 214/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.3187 - accuracy: 0.9000 - val_loss: 0.3991 - val_accuracy: 0.9268\n",
            "Epoch 215/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.1348 - accuracy: 0.9500 - val_loss: 0.4388 - val_accuracy: 0.9268\n",
            "Epoch 216/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1590 - accuracy: 0.9500 - val_loss: 0.4739 - val_accuracy: 0.9024\n",
            "Epoch 217/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2251 - accuracy: 0.8750 - val_loss: 0.4273 - val_accuracy: 0.9268\n",
            "Epoch 218/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.1524 - accuracy: 0.9500 - val_loss: 0.5854 - val_accuracy: 0.9512\n",
            "Epoch 219/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.2649 - accuracy: 0.8500 - val_loss: 0.6331 - val_accuracy: 0.9268\n",
            "Epoch 220/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.3695 - accuracy: 0.8750 - val_loss: 0.6774 - val_accuracy: 0.9268\n",
            "Epoch 221/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1097 - accuracy: 0.9750 - val_loss: 0.6511 - val_accuracy: 0.9024\n",
            "Epoch 222/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2090 - accuracy: 0.9500 - val_loss: 0.6151 - val_accuracy: 0.9268\n",
            "Epoch 223/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1236 - accuracy: 0.9500 - val_loss: 0.1343 - val_accuracy: 0.9512\n",
            "Epoch 224/2000\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.3045 - accuracy: 0.9000 - val_loss: 0.1794 - val_accuracy: 0.9512\n",
            "Epoch 225/2000\n",
            "5/5 [==============================] - 1s 241ms/step - loss: 0.2206 - accuracy: 0.9000 - val_loss: 0.3861 - val_accuracy: 0.9268\n",
            "Epoch 226/2000\n",
            "5/5 [==============================] - 1s 243ms/step - loss: 0.0821 - accuracy: 1.0000 - val_loss: 0.6078 - val_accuracy: 0.9268\n",
            "Epoch 227/2000\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 0.2931 - accuracy: 0.9500 - val_loss: 0.3443 - val_accuracy: 0.9268\n",
            "Epoch 228/2000\n",
            "5/5 [==============================] - 1s 241ms/step - loss: 0.3940 - accuracy: 0.8250 - val_loss: 0.9194 - val_accuracy: 0.7805\n",
            "Epoch 229/2000\n",
            "5/5 [==============================] - 1s 241ms/step - loss: 0.2424 - accuracy: 0.9000 - val_loss: 1.7936 - val_accuracy: 0.6341\n",
            "Epoch 230/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1806 - accuracy: 0.9500 - val_loss: 1.1704 - val_accuracy: 0.7073\n",
            "Epoch 231/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.2507 - accuracy: 0.9250 - val_loss: 0.3954 - val_accuracy: 0.9512\n",
            "Epoch 232/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1421 - accuracy: 0.9250 - val_loss: 0.1314 - val_accuracy: 0.9512\n",
            "Epoch 233/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.3868 - accuracy: 0.8750 - val_loss: 0.0753 - val_accuracy: 0.9756\n",
            "Epoch 234/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1607 - accuracy: 0.9750 - val_loss: 0.2656 - val_accuracy: 0.9024\n",
            "Epoch 235/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.1460 - accuracy: 0.9500 - val_loss: 0.6213 - val_accuracy: 0.9024\n",
            "Epoch 236/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.3554 - accuracy: 0.8250 - val_loss: 0.3437 - val_accuracy: 0.9268\n",
            "Epoch 237/2000\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.1354 - accuracy: 0.9500 - val_loss: 0.1812 - val_accuracy: 0.9756\n",
            "Epoch 238/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0815 - accuracy: 0.9500 - val_loss: 0.2219 - val_accuracy: 0.9512\n",
            "Epoch 239/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1341 - accuracy: 0.9500 - val_loss: 0.4778 - val_accuracy: 0.9024\n",
            "Epoch 240/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1674 - accuracy: 0.9500 - val_loss: 0.4502 - val_accuracy: 0.8780\n",
            "Epoch 241/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.0975 - accuracy: 0.9750 - val_loss: 0.5384 - val_accuracy: 0.9268\n",
            "Epoch 242/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0991 - accuracy: 0.9500 - val_loss: 0.6368 - val_accuracy: 0.9268\n",
            "Epoch 243/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1115 - accuracy: 0.9750 - val_loss: 0.7040 - val_accuracy: 0.9268\n",
            "Epoch 244/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2052 - accuracy: 0.9000 - val_loss: 0.2121 - val_accuracy: 0.9512\n",
            "Epoch 245/2000\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.3215 - accuracy: 0.9000 - val_loss: 0.3302 - val_accuracy: 0.9024\n",
            "Epoch 246/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.1275 - accuracy: 0.9500 - val_loss: 1.3500 - val_accuracy: 0.6585\n",
            "Epoch 247/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.3656 - accuracy: 0.9000 - val_loss: 0.2568 - val_accuracy: 0.9268\n",
            "Epoch 248/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.2741 - accuracy: 0.9250 - val_loss: 0.2182 - val_accuracy: 0.9512\n",
            "Epoch 249/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0828 - accuracy: 0.9750 - val_loss: 0.5121 - val_accuracy: 0.8537\n",
            "Epoch 250/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1252 - accuracy: 0.9750 - val_loss: 0.5087 - val_accuracy: 0.9024\n",
            "Epoch 251/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1693 - accuracy: 0.9250 - val_loss: 0.4537 - val_accuracy: 0.9024\n",
            "Epoch 252/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.4200 - accuracy: 0.8250 - val_loss: 0.3727 - val_accuracy: 0.9268\n",
            "Epoch 253/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2840 - accuracy: 0.8750 - val_loss: 0.2735 - val_accuracy: 0.9268\n",
            "Epoch 254/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.3611 - accuracy: 0.9250 - val_loss: 1.0308 - val_accuracy: 0.6585\n",
            "Epoch 255/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.2196 - accuracy: 0.9250 - val_loss: 1.5307 - val_accuracy: 0.6341\n",
            "Epoch 256/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.3855 - accuracy: 0.9000 - val_loss: 1.1046 - val_accuracy: 0.6829\n",
            "Epoch 257/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1916 - accuracy: 0.9000 - val_loss: 1.2428 - val_accuracy: 0.6829\n",
            "Epoch 258/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1079 - accuracy: 0.9500 - val_loss: 1.0185 - val_accuracy: 0.6829\n",
            "Epoch 259/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1213 - accuracy: 0.9500 - val_loss: 0.5980 - val_accuracy: 0.8049\n",
            "Epoch 260/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1381 - accuracy: 0.9750 - val_loss: 0.4567 - val_accuracy: 0.8780\n",
            "Epoch 261/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1072 - accuracy: 0.9750 - val_loss: 0.2570 - val_accuracy: 0.9024\n",
            "Epoch 262/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.2462 - accuracy: 0.9000 - val_loss: 0.3115 - val_accuracy: 0.9024\n",
            "Epoch 263/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0891 - accuracy: 0.9500 - val_loss: 0.1796 - val_accuracy: 0.9512\n",
            "Epoch 264/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2009 - accuracy: 0.9250 - val_loss: 0.2560 - val_accuracy: 0.9512\n",
            "Epoch 265/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1492 - accuracy: 0.9500 - val_loss: 0.3456 - val_accuracy: 0.9512\n",
            "Epoch 266/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.3635 - accuracy: 0.8500 - val_loss: 0.4412 - val_accuracy: 0.9512\n",
            "Epoch 267/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1607 - accuracy: 0.9000 - val_loss: 0.4907 - val_accuracy: 0.9512\n",
            "Epoch 268/2000\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.2728 - accuracy: 0.9750 - val_loss: 0.6692 - val_accuracy: 0.9268\n",
            "Epoch 269/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.2181 - accuracy: 0.9250 - val_loss: 0.5925 - val_accuracy: 0.9512\n",
            "Epoch 270/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1168 - accuracy: 0.9500 - val_loss: 0.6064 - val_accuracy: 0.9268\n",
            "Epoch 271/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1781 - accuracy: 0.9250 - val_loss: 0.6363 - val_accuracy: 0.9268\n",
            "Epoch 272/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.3241 - accuracy: 0.9500 - val_loss: 0.2508 - val_accuracy: 0.9024\n",
            "Epoch 273/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.3306 - accuracy: 0.8250 - val_loss: 0.2802 - val_accuracy: 0.9512\n",
            "Epoch 274/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0845 - accuracy: 0.9750 - val_loss: 0.5240 - val_accuracy: 0.9512\n",
            "Epoch 275/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0810 - accuracy: 0.9750 - val_loss: 0.5642 - val_accuracy: 0.9268\n",
            "Epoch 276/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.1824 - accuracy: 0.9000 - val_loss: 0.5859 - val_accuracy: 0.8780\n",
            "Epoch 277/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.2183 - accuracy: 0.9250 - val_loss: 0.3496 - val_accuracy: 0.9268\n",
            "Epoch 278/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1802 - accuracy: 0.9500 - val_loss: 0.3316 - val_accuracy: 0.9268\n",
            "Epoch 279/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.5149 - accuracy: 0.8500 - val_loss: 0.1718 - val_accuracy: 0.9512\n",
            "Epoch 280/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.1464 - accuracy: 0.9250 - val_loss: 0.1653 - val_accuracy: 0.9512\n",
            "Epoch 281/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.2614 - accuracy: 0.9000 - val_loss: 0.5874 - val_accuracy: 0.9268\n",
            "Epoch 282/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1705 - accuracy: 0.9500 - val_loss: 0.8240 - val_accuracy: 0.7073\n",
            "Epoch 283/2000\n",
            "5/5 [==============================] - 1s 228ms/step - loss: 0.2666 - accuracy: 0.9500 - val_loss: 0.6806 - val_accuracy: 0.9512\n",
            "Epoch 284/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2424 - accuracy: 0.9250 - val_loss: 0.3535 - val_accuracy: 0.9512\n",
            "Epoch 285/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2235 - accuracy: 0.9000 - val_loss: 0.4941 - val_accuracy: 0.9512\n",
            "Epoch 286/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1259 - accuracy: 0.9500 - val_loss: 0.5967 - val_accuracy: 0.8049\n",
            "Epoch 287/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1298 - accuracy: 0.9250 - val_loss: 0.1985 - val_accuracy: 0.9024\n",
            "Epoch 288/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1562 - accuracy: 0.9750 - val_loss: 0.1465 - val_accuracy: 0.9512\n",
            "Epoch 289/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.1598 - accuracy: 0.9500 - val_loss: 0.1854 - val_accuracy: 0.9512\n",
            "Epoch 290/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1995 - accuracy: 0.9500 - val_loss: 0.2138 - val_accuracy: 0.9512\n",
            "Epoch 291/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.2599 - accuracy: 0.9250 - val_loss: 0.5684 - val_accuracy: 0.8049\n",
            "Epoch 292/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2196 - accuracy: 0.9500 - val_loss: 0.4975 - val_accuracy: 0.8049\n",
            "Epoch 293/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0800 - accuracy: 0.9750 - val_loss: 0.2966 - val_accuracy: 0.9024\n",
            "Epoch 294/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.1584 - accuracy: 0.9500 - val_loss: 0.2194 - val_accuracy: 0.9512\n",
            "Epoch 295/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1581 - accuracy: 0.9500 - val_loss: 0.1760 - val_accuracy: 0.9512\n",
            "Epoch 296/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.2072 - accuracy: 0.9500 - val_loss: 0.1998 - val_accuracy: 0.9268\n",
            "Epoch 297/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1625 - accuracy: 0.9750 - val_loss: 0.1627 - val_accuracy: 0.9268\n",
            "Epoch 298/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1925 - accuracy: 0.9000 - val_loss: 0.1682 - val_accuracy: 0.9268\n",
            "Epoch 299/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.2836 - accuracy: 0.9250 - val_loss: 0.1830 - val_accuracy: 0.9512\n",
            "Epoch 300/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1529 - accuracy: 0.9750 - val_loss: 0.3057 - val_accuracy: 0.9024\n",
            "Epoch 301/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0552 - accuracy: 1.0000 - val_loss: 0.5237 - val_accuracy: 0.7805\n",
            "Epoch 302/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.5434 - accuracy: 0.8750 - val_loss: 0.3378 - val_accuracy: 0.9024\n",
            "Epoch 303/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.2480 - accuracy: 0.9250 - val_loss: 0.1875 - val_accuracy: 0.9512\n",
            "Epoch 304/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.2880 - accuracy: 0.8750 - val_loss: 0.3949 - val_accuracy: 0.9512\n",
            "Epoch 305/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1832 - accuracy: 0.9750 - val_loss: 0.2270 - val_accuracy: 0.9024\n",
            "Epoch 306/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2209 - accuracy: 0.8750 - val_loss: 0.2591 - val_accuracy: 0.9268\n",
            "Epoch 307/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1307 - accuracy: 0.9500 - val_loss: 0.2272 - val_accuracy: 0.9268\n",
            "Epoch 308/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.2860 - accuracy: 0.8750 - val_loss: 0.1271 - val_accuracy: 0.9512\n",
            "Epoch 309/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1013 - accuracy: 0.9750 - val_loss: 0.5073 - val_accuracy: 0.9512\n",
            "Epoch 310/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1765 - accuracy: 0.9250 - val_loss: 0.1644 - val_accuracy: 0.9512\n",
            "Epoch 311/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2096 - accuracy: 0.9250 - val_loss: 0.3657 - val_accuracy: 0.9756\n",
            "Epoch 312/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.4502 - accuracy: 0.8750 - val_loss: 0.2955 - val_accuracy: 0.9512\n",
            "Epoch 313/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1355 - accuracy: 0.9250 - val_loss: 0.1383 - val_accuracy: 0.9756\n",
            "Epoch 314/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1281 - accuracy: 0.9750 - val_loss: 0.1662 - val_accuracy: 0.9268\n",
            "Epoch 315/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.3039 - accuracy: 0.9000 - val_loss: 0.5295 - val_accuracy: 0.8049\n",
            "Epoch 316/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.7329 - accuracy: 0.8500 - val_loss: 0.3811 - val_accuracy: 0.8780\n",
            "Epoch 317/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1245 - accuracy: 0.9750 - val_loss: 0.7990 - val_accuracy: 0.9268\n",
            "Epoch 318/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1568 - accuracy: 0.9250 - val_loss: 1.0739 - val_accuracy: 0.7805\n",
            "Epoch 319/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.2409 - accuracy: 0.9250 - val_loss: 0.9851 - val_accuracy: 0.9268\n",
            "Epoch 320/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1654 - accuracy: 0.9500 - val_loss: 0.8126 - val_accuracy: 0.9268\n",
            "Epoch 321/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.2655 - accuracy: 0.9000 - val_loss: 0.1741 - val_accuracy: 0.9268\n",
            "Epoch 322/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.3039 - accuracy: 0.9000 - val_loss: 0.5700 - val_accuracy: 0.9268\n",
            "Epoch 323/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1451 - accuracy: 0.9750 - val_loss: 1.6253 - val_accuracy: 0.6341\n",
            "Epoch 324/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.4221 - accuracy: 0.8500 - val_loss: 1.6481 - val_accuracy: 0.6341\n",
            "Epoch 325/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1077 - accuracy: 0.9750 - val_loss: 0.2761 - val_accuracy: 0.9024\n",
            "Epoch 326/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0956 - accuracy: 1.0000 - val_loss: 0.1127 - val_accuracy: 0.9756\n",
            "Epoch 327/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.3599 - accuracy: 0.8250 - val_loss: 0.0827 - val_accuracy: 0.9756\n",
            "Epoch 328/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.3376 - accuracy: 0.9000 - val_loss: 0.5698 - val_accuracy: 0.9268\n",
            "Epoch 329/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0751 - accuracy: 0.9750 - val_loss: 0.7022 - val_accuracy: 0.9268\n",
            "Epoch 330/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1365 - accuracy: 0.9750 - val_loss: 0.7587 - val_accuracy: 0.9268\n",
            "Epoch 331/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2311 - accuracy: 0.9000 - val_loss: 0.4970 - val_accuracy: 0.9268\n",
            "Epoch 332/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.2093 - accuracy: 0.9500 - val_loss: 0.3912 - val_accuracy: 0.9512\n",
            "Epoch 333/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1557 - accuracy: 0.9250 - val_loss: 0.6297 - val_accuracy: 0.9512\n",
            "Epoch 334/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.2281 - accuracy: 0.9250 - val_loss: 0.7517 - val_accuracy: 0.9512\n",
            "Epoch 335/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1342 - accuracy: 0.9500 - val_loss: 0.5997 - val_accuracy: 0.9024\n",
            "Epoch 336/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1344 - accuracy: 0.9250 - val_loss: 0.4578 - val_accuracy: 0.9024\n",
            "Epoch 337/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.2071 - accuracy: 0.9250 - val_loss: 0.8541 - val_accuracy: 0.9024\n",
            "Epoch 338/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.2159 - accuracy: 0.9500 - val_loss: 0.7413 - val_accuracy: 0.9268\n",
            "Epoch 339/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1250 - accuracy: 0.9500 - val_loss: 0.2164 - val_accuracy: 0.9268\n",
            "Epoch 340/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.2853 - accuracy: 0.8750 - val_loss: 0.2123 - val_accuracy: 0.9268\n",
            "Epoch 341/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2339 - accuracy: 0.9250 - val_loss: 0.7537 - val_accuracy: 0.8780\n",
            "Epoch 342/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.2421 - accuracy: 0.9000 - val_loss: 0.7344 - val_accuracy: 0.8780\n",
            "Epoch 343/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.1646 - accuracy: 0.9500 - val_loss: 0.3803 - val_accuracy: 0.9268\n",
            "Epoch 344/2000\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 0.1395 - accuracy: 0.9500 - val_loss: 0.1967 - val_accuracy: 0.9268\n",
            "Epoch 345/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.1148 - accuracy: 0.9500 - val_loss: 0.2386 - val_accuracy: 0.9512\n",
            "Epoch 346/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1755 - accuracy: 0.9500 - val_loss: 0.4883 - val_accuracy: 0.9268\n",
            "Epoch 347/2000\n",
            "5/5 [==============================] - 1s 228ms/step - loss: 0.1335 - accuracy: 0.9500 - val_loss: 0.4681 - val_accuracy: 0.8780\n",
            "Epoch 348/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.2810 - accuracy: 0.9500 - val_loss: 0.3983 - val_accuracy: 0.8780\n",
            "Epoch 349/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.2007 - accuracy: 0.9250 - val_loss: 0.4043 - val_accuracy: 0.9268\n",
            "Epoch 350/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1599 - accuracy: 0.9500 - val_loss: 0.4587 - val_accuracy: 0.9268\n",
            "Epoch 351/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.2935 - accuracy: 0.9000 - val_loss: 0.5461 - val_accuracy: 0.9024\n",
            "Epoch 352/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1621 - accuracy: 0.9750 - val_loss: 0.4635 - val_accuracy: 0.9024\n",
            "Epoch 353/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1925 - accuracy: 0.9250 - val_loss: 0.1679 - val_accuracy: 0.9512\n",
            "Epoch 354/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0542 - accuracy: 1.0000 - val_loss: 0.1775 - val_accuracy: 0.9512\n",
            "Epoch 355/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.3819 - accuracy: 0.8750 - val_loss: 0.2209 - val_accuracy: 0.9024\n",
            "Epoch 356/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1390 - accuracy: 0.9250 - val_loss: 0.6447 - val_accuracy: 0.7317\n",
            "Epoch 357/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.2396 - accuracy: 0.9500 - val_loss: 0.6129 - val_accuracy: 0.7317\n",
            "Epoch 358/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1751 - accuracy: 0.9500 - val_loss: 0.3468 - val_accuracy: 0.8780\n",
            "Epoch 359/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1236 - accuracy: 0.9500 - val_loss: 0.2245 - val_accuracy: 0.9268\n",
            "Epoch 360/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0602 - accuracy: 1.0000 - val_loss: 0.2113 - val_accuracy: 0.9268\n",
            "Epoch 361/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.0819 - accuracy: 0.9750 - val_loss: 0.2031 - val_accuracy: 0.9268\n",
            "Epoch 362/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0683 - accuracy: 1.0000 - val_loss: 0.2423 - val_accuracy: 0.9268\n",
            "Epoch 363/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1419 - accuracy: 0.9500 - val_loss: 0.3320 - val_accuracy: 0.9512\n",
            "Epoch 364/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0679 - accuracy: 0.9750 - val_loss: 0.4663 - val_accuracy: 0.9512\n",
            "Epoch 365/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.6147 - accuracy: 0.7500 - val_loss: 0.2609 - val_accuracy: 0.9024\n",
            "Epoch 366/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.4062 - accuracy: 0.9250 - val_loss: 0.3459 - val_accuracy: 0.8780\n",
            "Epoch 367/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.2082 - accuracy: 0.9250 - val_loss: 0.7141 - val_accuracy: 0.9024\n",
            "Epoch 368/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.2514 - accuracy: 0.9000 - val_loss: 0.2645 - val_accuracy: 0.9512\n",
            "Epoch 369/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.2421 - accuracy: 0.8500 - val_loss: 0.7086 - val_accuracy: 0.9268\n",
            "Epoch 370/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.1432 - accuracy: 0.9500 - val_loss: 0.7211 - val_accuracy: 0.9268\n",
            "Epoch 371/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.2624 - accuracy: 0.9500 - val_loss: 0.6103 - val_accuracy: 0.9268\n",
            "Epoch 372/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.5196 - accuracy: 0.8750 - val_loss: 0.6670 - val_accuracy: 0.8780\n",
            "Epoch 373/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1689 - accuracy: 0.9500 - val_loss: 0.1242 - val_accuracy: 0.9512\n",
            "Epoch 374/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0977 - accuracy: 1.0000 - val_loss: 0.1244 - val_accuracy: 0.9756\n",
            "Epoch 375/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.2622 - accuracy: 0.9250 - val_loss: 0.4080 - val_accuracy: 0.9512\n",
            "Epoch 376/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.4727 - accuracy: 0.8000 - val_loss: 1.5498 - val_accuracy: 0.6585\n",
            "Epoch 377/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.6958 - accuracy: 0.7500 - val_loss: 1.6281 - val_accuracy: 0.6585\n",
            "Epoch 378/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.5694 - accuracy: 0.7750 - val_loss: 1.4642 - val_accuracy: 0.6829\n",
            "Epoch 379/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.4116 - accuracy: 0.8500 - val_loss: 1.4963 - val_accuracy: 0.6341\n",
            "Epoch 380/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.5986 - accuracy: 0.7750 - val_loss: 1.2160 - val_accuracy: 0.6585\n",
            "Epoch 381/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.3955 - accuracy: 0.8750 - val_loss: 0.9963 - val_accuracy: 0.6829\n",
            "Epoch 382/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.2218 - accuracy: 0.9500 - val_loss: 1.4005 - val_accuracy: 0.6829\n",
            "Epoch 383/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.3883 - accuracy: 0.8000 - val_loss: 1.6591 - val_accuracy: 0.6341\n",
            "Epoch 384/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.5352 - accuracy: 0.7750 - val_loss: 1.5068 - val_accuracy: 0.6341\n",
            "Epoch 385/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.4734 - accuracy: 0.8000 - val_loss: 1.2162 - val_accuracy: 0.6341\n",
            "Epoch 386/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.2480 - accuracy: 0.8750 - val_loss: 0.6278 - val_accuracy: 0.6341\n",
            "Epoch 387/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.2734 - accuracy: 0.9000 - val_loss: 0.6843 - val_accuracy: 0.5854\n",
            "Epoch 388/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.3130 - accuracy: 0.8750 - val_loss: 0.6675 - val_accuracy: 0.5854\n",
            "Epoch 389/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.2712 - accuracy: 0.8500 - val_loss: 0.5934 - val_accuracy: 0.6585\n",
            "Epoch 390/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.2539 - accuracy: 0.9000 - val_loss: 1.4817 - val_accuracy: 0.6829\n",
            "Epoch 391/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.3795 - accuracy: 0.8500 - val_loss: 1.6245 - val_accuracy: 0.6829\n",
            "Epoch 392/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.2192 - accuracy: 0.9000 - val_loss: 1.5728 - val_accuracy: 0.7805\n",
            "Epoch 393/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0990 - accuracy: 1.0000 - val_loss: 1.0281 - val_accuracy: 0.8780\n",
            "Epoch 394/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1430 - accuracy: 0.9750 - val_loss: 0.8616 - val_accuracy: 0.9268\n",
            "Epoch 395/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.2662 - accuracy: 0.9500 - val_loss: 0.6784 - val_accuracy: 0.9512\n",
            "Epoch 396/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1622 - accuracy: 0.9500 - val_loss: 0.4614 - val_accuracy: 0.9268\n",
            "Epoch 397/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.3211 - accuracy: 0.8500 - val_loss: 0.2747 - val_accuracy: 0.9268\n",
            "Epoch 398/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1826 - accuracy: 0.9250 - val_loss: 0.4470 - val_accuracy: 0.9512\n",
            "Epoch 399/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.4954 - accuracy: 0.8250 - val_loss: 0.6737 - val_accuracy: 0.9512\n",
            "Epoch 400/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.3055 - accuracy: 0.8750 - val_loss: 0.4375 - val_accuracy: 0.8293\n",
            "Epoch 401/2000\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.3040 - accuracy: 0.8750 - val_loss: 0.3879 - val_accuracy: 0.8537\n",
            "Epoch 402/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.2859 - accuracy: 0.8250 - val_loss: 0.8481 - val_accuracy: 0.9268\n",
            "Epoch 403/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.4330 - accuracy: 0.8750 - val_loss: 1.5198 - val_accuracy: 0.9024\n",
            "Epoch 404/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1218 - accuracy: 0.9750 - val_loss: 1.4444 - val_accuracy: 0.9268\n",
            "Epoch 405/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.2003 - accuracy: 0.9000 - val_loss: 1.3518 - val_accuracy: 0.9268\n",
            "Epoch 406/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2070 - accuracy: 0.9750 - val_loss: 1.2836 - val_accuracy: 0.9024\n",
            "Epoch 407/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1309 - accuracy: 0.9750 - val_loss: 1.2210 - val_accuracy: 0.9024\n",
            "Epoch 408/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.2968 - accuracy: 0.8750 - val_loss: 0.9914 - val_accuracy: 0.9512\n",
            "Epoch 409/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.3719 - accuracy: 0.8000 - val_loss: 0.9449 - val_accuracy: 0.9512\n",
            "Epoch 410/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1449 - accuracy: 0.9750 - val_loss: 1.1697 - val_accuracy: 0.9024\n",
            "Epoch 411/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.3443 - accuracy: 0.8750 - val_loss: 1.1591 - val_accuracy: 0.8780\n",
            "Epoch 412/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.2552 - accuracy: 0.9000 - val_loss: 1.3768 - val_accuracy: 0.8049\n",
            "Epoch 413/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0787 - accuracy: 1.0000 - val_loss: 1.4483 - val_accuracy: 0.6098\n",
            "Epoch 414/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.2469 - accuracy: 0.9250 - val_loss: 1.2746 - val_accuracy: 0.7805\n",
            "Epoch 415/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1810 - accuracy: 0.9250 - val_loss: 1.2179 - val_accuracy: 0.8049\n",
            "Epoch 416/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.3463 - accuracy: 0.8750 - val_loss: 1.3810 - val_accuracy: 0.8780\n",
            "Epoch 417/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.2967 - accuracy: 0.8750 - val_loss: 1.2607 - val_accuracy: 0.7805\n",
            "Epoch 418/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.2775 - accuracy: 0.8750 - val_loss: 0.6957 - val_accuracy: 0.7317\n",
            "Epoch 419/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.3687 - accuracy: 0.8250 - val_loss: 1.5147 - val_accuracy: 0.8293\n",
            "Epoch 420/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.2473 - accuracy: 0.9500 - val_loss: 1.2516 - val_accuracy: 0.9268\n",
            "Epoch 421/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1573 - accuracy: 0.9500 - val_loss: 1.0077 - val_accuracy: 0.9512\n",
            "Epoch 422/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.1437 - accuracy: 0.9750 - val_loss: 0.9645 - val_accuracy: 0.9512\n",
            "Epoch 423/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.2300 - accuracy: 0.9000 - val_loss: 0.8531 - val_accuracy: 0.9512\n",
            "Epoch 424/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.2204 - accuracy: 0.9250 - val_loss: 0.9319 - val_accuracy: 0.9268\n",
            "Epoch 425/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.2031 - accuracy: 0.9000 - val_loss: 1.1265 - val_accuracy: 0.9268\n",
            "Epoch 426/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0928 - accuracy: 1.0000 - val_loss: 1.3278 - val_accuracy: 0.9268\n",
            "Epoch 427/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.3778 - accuracy: 0.8500 - val_loss: 1.1267 - val_accuracy: 0.8293\n",
            "Epoch 428/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1382 - accuracy: 0.9250 - val_loss: 0.4146 - val_accuracy: 0.8293\n",
            "Epoch 429/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1708 - accuracy: 0.9500 - val_loss: 0.5079 - val_accuracy: 0.7805\n",
            "Epoch 430/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1577 - accuracy: 0.9500 - val_loss: 0.6491 - val_accuracy: 0.7561\n",
            "Epoch 431/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.2086 - accuracy: 0.9250 - val_loss: 0.6919 - val_accuracy: 0.7073\n",
            "Epoch 432/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.4158 - accuracy: 0.8500 - val_loss: 0.6213 - val_accuracy: 0.7561\n",
            "Epoch 433/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.3257 - accuracy: 0.9000 - val_loss: 0.5445 - val_accuracy: 0.7561\n",
            "Epoch 434/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.3624 - accuracy: 0.8750 - val_loss: 0.5356 - val_accuracy: 0.7561\n",
            "Epoch 435/2000\n",
            "5/5 [==============================] - 1s 244ms/step - loss: 0.1338 - accuracy: 0.9500 - val_loss: 0.6496 - val_accuracy: 0.6098\n",
            "Epoch 436/2000\n",
            "5/5 [==============================] - 1s 252ms/step - loss: 0.4095 - accuracy: 0.8500 - val_loss: 0.3368 - val_accuracy: 0.8537\n",
            "Epoch 437/2000\n",
            "5/5 [==============================] - 1s 251ms/step - loss: 0.3068 - accuracy: 0.9250 - val_loss: 0.4109 - val_accuracy: 0.8293\n",
            "Epoch 438/2000\n",
            "5/5 [==============================] - 1s 250ms/step - loss: 0.2049 - accuracy: 0.9000 - val_loss: 0.3321 - val_accuracy: 0.8537\n",
            "Epoch 439/2000\n",
            "5/5 [==============================] - 1s 247ms/step - loss: 0.2794 - accuracy: 0.9000 - val_loss: 0.6722 - val_accuracy: 0.8780\n",
            "Epoch 440/2000\n",
            "5/5 [==============================] - 1s 249ms/step - loss: 0.4698 - accuracy: 0.7750 - val_loss: 0.5341 - val_accuracy: 0.8537\n",
            "Epoch 441/2000\n",
            "5/5 [==============================] - 1s 250ms/step - loss: 0.2961 - accuracy: 0.9000 - val_loss: 0.3325 - val_accuracy: 0.8293\n",
            "Epoch 442/2000\n",
            "5/5 [==============================] - 1s 247ms/step - loss: 0.1968 - accuracy: 0.9250 - val_loss: 0.2681 - val_accuracy: 0.9268\n",
            "Epoch 443/2000\n",
            "5/5 [==============================] - 1s 241ms/step - loss: 0.1569 - accuracy: 0.9500 - val_loss: 0.1930 - val_accuracy: 0.9512\n",
            "Epoch 444/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.2253 - accuracy: 0.9250 - val_loss: 0.3625 - val_accuracy: 0.9268\n",
            "Epoch 445/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1322 - accuracy: 0.9500 - val_loss: 0.7132 - val_accuracy: 0.7317\n",
            "Epoch 446/2000\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.3344 - accuracy: 0.8750 - val_loss: 0.9748 - val_accuracy: 0.7805\n",
            "Epoch 447/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.2148 - accuracy: 0.9000 - val_loss: 0.3814 - val_accuracy: 0.9512\n",
            "Epoch 448/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.1778 - accuracy: 0.9750 - val_loss: 0.3247 - val_accuracy: 0.9512\n",
            "Epoch 449/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.6643 - accuracy: 0.8000 - val_loss: 0.3159 - val_accuracy: 0.9512\n",
            "Epoch 450/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.2534 - accuracy: 0.9250 - val_loss: 0.3740 - val_accuracy: 0.9268\n",
            "Epoch 451/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.2818 - accuracy: 0.8750 - val_loss: 0.6956 - val_accuracy: 0.9024\n",
            "Epoch 452/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.6414 - accuracy: 0.8250 - val_loss: 0.8536 - val_accuracy: 0.8780\n",
            "Epoch 453/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1772 - accuracy: 0.9000 - val_loss: 0.8565 - val_accuracy: 0.7317\n",
            "Epoch 454/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1960 - accuracy: 0.9500 - val_loss: 0.6924 - val_accuracy: 0.7561\n",
            "Epoch 455/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.2114 - accuracy: 0.9250 - val_loss: 0.4097 - val_accuracy: 0.8537\n",
            "Epoch 456/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1327 - accuracy: 0.9750 - val_loss: 0.2420 - val_accuracy: 0.9024\n",
            "Epoch 457/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.3655 - accuracy: 0.8750 - val_loss: 0.1885 - val_accuracy: 0.9512\n",
            "Epoch 458/2000\n",
            "5/5 [==============================] - 1s 228ms/step - loss: 0.0733 - accuracy: 0.9750 - val_loss: 0.1810 - val_accuracy: 0.9756\n",
            "Epoch 459/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1055 - accuracy: 1.0000 - val_loss: 0.1826 - val_accuracy: 0.9756\n",
            "Epoch 460/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.4047 - accuracy: 0.8750 - val_loss: 0.2517 - val_accuracy: 0.9512\n",
            "Epoch 461/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.2541 - accuracy: 0.8250 - val_loss: 0.2484 - val_accuracy: 0.9268\n",
            "Epoch 462/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1267 - accuracy: 0.9500 - val_loss: 0.3651 - val_accuracy: 0.8780\n",
            "Epoch 463/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1648 - accuracy: 0.9250 - val_loss: 0.5521 - val_accuracy: 0.8537\n",
            "Epoch 464/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.4807 - accuracy: 0.8500 - val_loss: 0.3251 - val_accuracy: 0.8537\n",
            "Epoch 465/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.2179 - accuracy: 0.9250 - val_loss: 0.3146 - val_accuracy: 0.8537\n",
            "Epoch 466/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1785 - accuracy: 0.9500 - val_loss: 0.5231 - val_accuracy: 0.8780\n",
            "Epoch 467/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.2100 - accuracy: 0.9250 - val_loss: 1.2061 - val_accuracy: 0.9268\n",
            "Epoch 468/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1306 - accuracy: 0.9250 - val_loss: 1.0549 - val_accuracy: 0.9024\n",
            "Epoch 469/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2924 - accuracy: 0.8750 - val_loss: 0.1629 - val_accuracy: 0.9512\n",
            "Epoch 470/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1073 - accuracy: 0.9750 - val_loss: 0.1903 - val_accuracy: 0.9268\n",
            "Epoch 471/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1691 - accuracy: 0.9250 - val_loss: 0.2076 - val_accuracy: 0.9512\n",
            "Epoch 472/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.1781 - accuracy: 0.9500 - val_loss: 1.0408 - val_accuracy: 0.9268\n",
            "Epoch 473/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1829 - accuracy: 0.9000 - val_loss: 0.9881 - val_accuracy: 0.9268\n",
            "Epoch 474/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1687 - accuracy: 0.9250 - val_loss: 0.8898 - val_accuracy: 0.9268\n",
            "Epoch 475/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.3110 - accuracy: 0.8500 - val_loss: 0.8220 - val_accuracy: 0.9268\n",
            "Epoch 476/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.2080 - accuracy: 0.9500 - val_loss: 0.1631 - val_accuracy: 0.9512\n",
            "Epoch 477/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.1815 - accuracy: 0.9250 - val_loss: 0.1784 - val_accuracy: 0.9756\n",
            "Epoch 478/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.1430 - accuracy: 0.9500 - val_loss: 0.8316 - val_accuracy: 0.9024\n",
            "Epoch 479/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0839 - accuracy: 0.9500 - val_loss: 0.9782 - val_accuracy: 0.9024\n",
            "Epoch 480/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.3062 - accuracy: 0.9000 - val_loss: 0.3661 - val_accuracy: 0.8537\n",
            "Epoch 481/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1758 - accuracy: 0.9500 - val_loss: 0.9708 - val_accuracy: 0.7561\n",
            "Epoch 482/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.3825 - accuracy: 0.8500 - val_loss: 1.0320 - val_accuracy: 0.7317\n",
            "Epoch 483/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.2348 - accuracy: 0.9250 - val_loss: 0.9710 - val_accuracy: 0.8537\n",
            "Epoch 484/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.2624 - accuracy: 0.9000 - val_loss: 0.2420 - val_accuracy: 0.9024\n",
            "Epoch 485/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1118 - accuracy: 0.9750 - val_loss: 0.1981 - val_accuracy: 0.9512\n",
            "Epoch 486/2000\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 0.1071 - accuracy: 0.9750 - val_loss: 0.2454 - val_accuracy: 0.9268\n",
            "Epoch 487/2000\n",
            "5/5 [==============================] - 1s 241ms/step - loss: 0.2365 - accuracy: 0.9250 - val_loss: 1.7951 - val_accuracy: 0.7561\n",
            "Epoch 488/2000\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 0.1253 - accuracy: 0.9750 - val_loss: 2.5918 - val_accuracy: 0.7317\n",
            "Epoch 489/2000\n",
            "5/5 [==============================] - 1s 242ms/step - loss: 0.3677 - accuracy: 0.9250 - val_loss: 0.7106 - val_accuracy: 0.9268\n",
            "Epoch 490/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.2586 - accuracy: 0.8750 - val_loss: 0.2629 - val_accuracy: 0.9024\n",
            "Epoch 491/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.2063 - accuracy: 0.9250 - val_loss: 0.2892 - val_accuracy: 0.9024\n",
            "Epoch 492/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.1763 - accuracy: 0.9250 - val_loss: 0.8533 - val_accuracy: 0.9268\n",
            "Epoch 493/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1681 - accuracy: 0.9250 - val_loss: 1.4659 - val_accuracy: 0.9268\n",
            "Epoch 494/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2788 - accuracy: 0.9000 - val_loss: 2.0277 - val_accuracy: 0.9024\n",
            "Epoch 495/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.1857 - accuracy: 0.8750 - val_loss: 1.3659 - val_accuracy: 0.9268\n",
            "Epoch 496/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1407 - accuracy: 0.9500 - val_loss: 1.2565 - val_accuracy: 0.9268\n",
            "Epoch 497/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1227 - accuracy: 0.9750 - val_loss: 1.6603 - val_accuracy: 0.8780\n",
            "Epoch 498/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.1529 - accuracy: 0.9250 - val_loss: 1.8234 - val_accuracy: 0.8780\n",
            "Epoch 499/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1361 - accuracy: 0.9500 - val_loss: 1.6060 - val_accuracy: 0.8537\n",
            "Epoch 500/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1595 - accuracy: 0.9500 - val_loss: 1.2042 - val_accuracy: 0.9024\n",
            "Epoch 501/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1117 - accuracy: 0.9500 - val_loss: 0.3937 - val_accuracy: 0.8049\n",
            "Epoch 502/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.2090 - accuracy: 0.9250 - val_loss: 0.3904 - val_accuracy: 0.8293\n",
            "Epoch 503/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.1755 - accuracy: 0.9000 - val_loss: 0.3876 - val_accuracy: 0.8780\n",
            "Epoch 504/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.3732 - accuracy: 0.9000 - val_loss: 0.6973 - val_accuracy: 0.9268\n",
            "Epoch 505/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.2126 - accuracy: 0.9000 - val_loss: 1.1099 - val_accuracy: 0.9268\n",
            "Epoch 506/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.2491 - accuracy: 0.9000 - val_loss: 1.3114 - val_accuracy: 0.9268\n",
            "Epoch 507/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.2940 - accuracy: 0.8750 - val_loss: 1.1252 - val_accuracy: 0.9024\n",
            "Epoch 508/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1237 - accuracy: 0.9500 - val_loss: 1.2252 - val_accuracy: 0.8537\n",
            "Epoch 509/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1627 - accuracy: 0.9750 - val_loss: 1.1522 - val_accuracy: 0.8293\n",
            "Epoch 510/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1230 - accuracy: 0.9250 - val_loss: 0.9152 - val_accuracy: 0.8780\n",
            "Epoch 511/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0630 - accuracy: 1.0000 - val_loss: 0.7424 - val_accuracy: 0.9024\n",
            "Epoch 512/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1725 - accuracy: 0.9250 - val_loss: 0.7780 - val_accuracy: 0.9024\n",
            "Epoch 513/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1578 - accuracy: 0.9000 - val_loss: 0.9620 - val_accuracy: 0.9268\n",
            "Epoch 514/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.2890 - accuracy: 0.8750 - val_loss: 1.1199 - val_accuracy: 0.9268\n",
            "Epoch 515/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1891 - accuracy: 0.9250 - val_loss: 0.6806 - val_accuracy: 0.9024\n",
            "Epoch 516/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.2030 - accuracy: 0.9000 - val_loss: 0.8110 - val_accuracy: 0.9268\n",
            "Epoch 517/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0420 - accuracy: 1.0000 - val_loss: 1.2075 - val_accuracy: 0.9268\n",
            "Epoch 518/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0812 - accuracy: 0.9750 - val_loss: 1.0548 - val_accuracy: 0.9268\n",
            "Epoch 519/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.5377 - accuracy: 0.8000 - val_loss: 0.7357 - val_accuracy: 0.9512\n",
            "Epoch 520/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.2289 - accuracy: 0.9000 - val_loss: 0.4278 - val_accuracy: 0.9512\n",
            "Epoch 521/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.3847 - accuracy: 0.8500 - val_loss: 1.2147 - val_accuracy: 0.8537\n",
            "Epoch 522/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.2546 - accuracy: 0.9000 - val_loss: 1.2728 - val_accuracy: 0.9024\n",
            "Epoch 523/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0882 - accuracy: 0.9750 - val_loss: 1.2310 - val_accuracy: 0.8780\n",
            "Epoch 524/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1310 - accuracy: 0.9500 - val_loss: 1.1508 - val_accuracy: 0.9024\n",
            "Epoch 525/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.3298 - accuracy: 0.9250 - val_loss: 1.0058 - val_accuracy: 0.8537\n",
            "Epoch 526/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.2917 - accuracy: 0.9000 - val_loss: 1.0819 - val_accuracy: 0.8049\n",
            "Epoch 527/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.2434 - accuracy: 0.9000 - val_loss: 1.1269 - val_accuracy: 0.9024\n",
            "Epoch 528/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1806 - accuracy: 0.9000 - val_loss: 0.9879 - val_accuracy: 0.9024\n",
            "Epoch 529/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.3496 - accuracy: 0.9000 - val_loss: 0.5628 - val_accuracy: 0.9024\n",
            "Epoch 530/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.1247 - accuracy: 0.9500 - val_loss: 0.3419 - val_accuracy: 0.9268\n",
            "Epoch 531/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0803 - accuracy: 1.0000 - val_loss: 0.5352 - val_accuracy: 0.9268\n",
            "Epoch 532/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1077 - accuracy: 0.9750 - val_loss: 0.3177 - val_accuracy: 0.9268\n",
            "Epoch 533/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1194 - accuracy: 0.9500 - val_loss: 0.2894 - val_accuracy: 0.9024\n",
            "Epoch 534/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1654 - accuracy: 0.8500 - val_loss: 0.3720 - val_accuracy: 0.9268\n",
            "Epoch 535/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.1075 - accuracy: 0.9500 - val_loss: 0.5717 - val_accuracy: 0.9024\n",
            "Epoch 536/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1486 - accuracy: 0.9250 - val_loss: 0.3994 - val_accuracy: 0.9268\n",
            "Epoch 537/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0894 - accuracy: 0.9750 - val_loss: 0.2330 - val_accuracy: 0.9268\n",
            "Epoch 538/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1061 - accuracy: 0.9750 - val_loss: 0.2588 - val_accuracy: 0.9268\n",
            "Epoch 539/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.0834 - accuracy: 0.9500 - val_loss: 0.1995 - val_accuracy: 0.9268\n",
            "Epoch 540/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1701 - accuracy: 0.9250 - val_loss: 0.2908 - val_accuracy: 0.9512\n",
            "Epoch 541/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1583 - accuracy: 0.9750 - val_loss: 0.1322 - val_accuracy: 0.9512\n",
            "Epoch 542/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1212 - accuracy: 0.9750 - val_loss: 0.8769 - val_accuracy: 0.9268\n",
            "Epoch 543/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.0450 - accuracy: 0.9750 - val_loss: 1.0112 - val_accuracy: 0.9024\n",
            "Epoch 544/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.1463 - accuracy: 0.9250 - val_loss: 1.0458 - val_accuracy: 0.8780\n",
            "Epoch 545/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2004 - accuracy: 0.9250 - val_loss: 0.8051 - val_accuracy: 0.9268\n",
            "Epoch 546/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.0606 - accuracy: 1.0000 - val_loss: 0.4524 - val_accuracy: 0.9268\n",
            "Epoch 547/2000\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.1576 - accuracy: 0.9250 - val_loss: 0.3828 - val_accuracy: 0.9268\n",
            "Epoch 548/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.2300 - accuracy: 0.8750 - val_loss: 1.1999 - val_accuracy: 0.9268\n",
            "Epoch 549/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1694 - accuracy: 0.9000 - val_loss: 1.8409 - val_accuracy: 0.8780\n",
            "Epoch 550/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2625 - accuracy: 0.9500 - val_loss: 1.0010 - val_accuracy: 0.9268\n",
            "Epoch 551/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1642 - accuracy: 0.9500 - val_loss: 0.2399 - val_accuracy: 0.9512\n",
            "Epoch 552/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.3506 - accuracy: 0.8500 - val_loss: 0.1701 - val_accuracy: 0.9756\n",
            "Epoch 553/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1350 - accuracy: 0.9250 - val_loss: 0.2678 - val_accuracy: 0.9268\n",
            "Epoch 554/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.2616 - accuracy: 0.9000 - val_loss: 1.1215 - val_accuracy: 0.9268\n",
            "Epoch 555/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.2141 - accuracy: 0.9250 - val_loss: 1.1177 - val_accuracy: 0.9268\n",
            "Epoch 556/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1733 - accuracy: 0.9250 - val_loss: 0.7623 - val_accuracy: 0.9268\n",
            "Epoch 557/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0817 - accuracy: 0.9750 - val_loss: 0.1297 - val_accuracy: 0.9756\n",
            "Epoch 558/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1646 - accuracy: 0.9250 - val_loss: 0.5322 - val_accuracy: 0.9756\n",
            "Epoch 559/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.3060 - accuracy: 0.9000 - val_loss: 0.4861 - val_accuracy: 0.9512\n",
            "Epoch 560/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1448 - accuracy: 0.9750 - val_loss: 0.0794 - val_accuracy: 0.9512\n",
            "Epoch 561/2000\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.2150 - accuracy: 0.9500 - val_loss: 0.4226 - val_accuracy: 0.9512\n",
            "Epoch 562/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1488 - accuracy: 0.9500 - val_loss: 0.0858 - val_accuracy: 0.9756\n",
            "Epoch 563/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1736 - accuracy: 0.9000 - val_loss: 0.6462 - val_accuracy: 0.9512\n",
            "Epoch 564/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1174 - accuracy: 0.9500 - val_loss: 1.4281 - val_accuracy: 0.9024\n",
            "Epoch 565/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0879 - accuracy: 0.9500 - val_loss: 1.3324 - val_accuracy: 0.8780\n",
            "Epoch 566/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.1738 - accuracy: 0.9250 - val_loss: 1.2535 - val_accuracy: 0.8780\n",
            "Epoch 567/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.3335 - accuracy: 0.8250 - val_loss: 1.1546 - val_accuracy: 0.9024\n",
            "Epoch 568/2000\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 0.1838 - accuracy: 0.9250 - val_loss: 1.1140 - val_accuracy: 0.9268\n",
            "Epoch 569/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1801 - accuracy: 0.9000 - val_loss: 0.6509 - val_accuracy: 0.9268\n",
            "Epoch 570/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1567 - accuracy: 0.9250 - val_loss: 0.6766 - val_accuracy: 0.9512\n",
            "Epoch 571/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.2667 - accuracy: 0.9500 - val_loss: 1.4011 - val_accuracy: 0.9512\n",
            "Epoch 572/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0847 - accuracy: 0.9750 - val_loss: 1.1100 - val_accuracy: 0.9268\n",
            "Epoch 573/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0933 - accuracy: 0.9750 - val_loss: 0.8492 - val_accuracy: 0.9268\n",
            "Epoch 574/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1518 - accuracy: 0.9500 - val_loss: 1.3294 - val_accuracy: 0.9268\n",
            "Epoch 575/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0405 - accuracy: 1.0000 - val_loss: 1.4427 - val_accuracy: 0.9024\n",
            "Epoch 576/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1168 - accuracy: 0.9250 - val_loss: 1.5206 - val_accuracy: 0.8537\n",
            "Epoch 577/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0951 - accuracy: 1.0000 - val_loss: 1.3729 - val_accuracy: 0.8780\n",
            "Epoch 578/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1727 - accuracy: 0.9500 - val_loss: 0.8231 - val_accuracy: 0.9268\n",
            "Epoch 579/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.0606 - accuracy: 1.0000 - val_loss: 0.7385 - val_accuracy: 0.9512\n",
            "Epoch 580/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.2373 - accuracy: 0.9000 - val_loss: 0.7588 - val_accuracy: 0.9268\n",
            "Epoch 581/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1680 - accuracy: 0.9000 - val_loss: 0.5558 - val_accuracy: 0.9268\n",
            "Epoch 582/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0798 - accuracy: 0.9750 - val_loss: 0.7798 - val_accuracy: 0.8780\n",
            "Epoch 583/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.2766 - accuracy: 0.9500 - val_loss: 0.8405 - val_accuracy: 0.9268\n",
            "Epoch 584/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1381 - accuracy: 0.9750 - val_loss: 0.8331 - val_accuracy: 0.9268\n",
            "Epoch 585/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1220 - accuracy: 0.9500 - val_loss: 0.5086 - val_accuracy: 0.9024\n",
            "Epoch 586/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2792 - accuracy: 0.8750 - val_loss: 0.1949 - val_accuracy: 0.9512\n",
            "Epoch 587/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.2087 - accuracy: 0.9000 - val_loss: 0.0652 - val_accuracy: 0.9756\n",
            "Epoch 588/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0614 - accuracy: 1.0000 - val_loss: 0.0769 - val_accuracy: 0.9756\n",
            "Epoch 589/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1664 - accuracy: 0.9000 - val_loss: 0.0784 - val_accuracy: 0.9756\n",
            "Epoch 590/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1234 - accuracy: 0.9750 - val_loss: 0.0779 - val_accuracy: 0.9756\n",
            "Epoch 591/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1185 - accuracy: 0.9500 - val_loss: 0.5752 - val_accuracy: 0.9268\n",
            "Epoch 592/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.2634 - accuracy: 0.9000 - val_loss: 0.9641 - val_accuracy: 0.9268\n",
            "Epoch 593/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0695 - accuracy: 1.0000 - val_loss: 0.9692 - val_accuracy: 0.9268\n",
            "Epoch 594/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1951 - accuracy: 0.9500 - val_loss: 0.9042 - val_accuracy: 0.9268\n",
            "Epoch 595/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0871 - accuracy: 0.9750 - val_loss: 0.5402 - val_accuracy: 0.9268\n",
            "Epoch 596/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1379 - accuracy: 0.9750 - val_loss: 0.3087 - val_accuracy: 0.9268\n",
            "Epoch 597/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1545 - accuracy: 0.9250 - val_loss: 0.5829 - val_accuracy: 0.9268\n",
            "Epoch 598/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1959 - accuracy: 0.9250 - val_loss: 0.9731 - val_accuracy: 0.9024\n",
            "Epoch 599/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1202 - accuracy: 0.9750 - val_loss: 0.3005 - val_accuracy: 0.9268\n",
            "Epoch 600/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0691 - accuracy: 0.9750 - val_loss: 0.1113 - val_accuracy: 0.9512\n",
            "Epoch 601/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.2365 - accuracy: 0.9500 - val_loss: 0.1108 - val_accuracy: 0.9512\n",
            "Epoch 602/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1550 - accuracy: 0.9500 - val_loss: 0.3008 - val_accuracy: 0.9268\n",
            "Epoch 603/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0614 - accuracy: 1.0000 - val_loss: 0.4185 - val_accuracy: 0.9268\n",
            "Epoch 604/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1043 - accuracy: 0.9750 - val_loss: 0.8942 - val_accuracy: 0.9268\n",
            "Epoch 605/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 1.2398 - val_accuracy: 0.9024\n",
            "Epoch 606/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1159 - accuracy: 0.9500 - val_loss: 1.1629 - val_accuracy: 0.9268\n",
            "Epoch 607/2000\n",
            "5/5 [==============================] - 1s 228ms/step - loss: 0.2504 - accuracy: 0.8500 - val_loss: 0.1463 - val_accuracy: 0.9756\n",
            "Epoch 608/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1520 - accuracy: 0.9500 - val_loss: 0.3339 - val_accuracy: 0.8537\n",
            "Epoch 609/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.3050 - accuracy: 0.9500 - val_loss: 0.3500 - val_accuracy: 0.8293\n",
            "Epoch 610/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.3944 - accuracy: 0.8000 - val_loss: 0.1526 - val_accuracy: 0.9512\n",
            "Epoch 611/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1026 - accuracy: 0.9750 - val_loss: 0.2739 - val_accuracy: 0.9268\n",
            "Epoch 612/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1803 - accuracy: 0.9500 - val_loss: 1.3823 - val_accuracy: 0.9268\n",
            "Epoch 613/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0877 - accuracy: 0.9750 - val_loss: 1.7123 - val_accuracy: 0.8293\n",
            "Epoch 614/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.2718 - accuracy: 0.9250 - val_loss: 1.6733 - val_accuracy: 0.8537\n",
            "Epoch 615/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.1728 - accuracy: 0.9750 - val_loss: 0.6593 - val_accuracy: 0.9268\n",
            "Epoch 616/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.1226 - accuracy: 0.9500 - val_loss: 0.3371 - val_accuracy: 0.9024\n",
            "Epoch 617/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0654 - accuracy: 1.0000 - val_loss: 0.3623 - val_accuracy: 0.7805\n",
            "Epoch 618/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1030 - accuracy: 0.9500 - val_loss: 0.8198 - val_accuracy: 0.7317\n",
            "Epoch 619/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1537 - accuracy: 0.9250 - val_loss: 0.9212 - val_accuracy: 0.7805\n",
            "Epoch 620/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1351 - accuracy: 0.9500 - val_loss: 0.1946 - val_accuracy: 0.9512\n",
            "Epoch 621/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0875 - accuracy: 0.9750 - val_loss: 0.1499 - val_accuracy: 0.9512\n",
            "Epoch 622/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 0.1333 - val_accuracy: 0.9756\n",
            "Epoch 623/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1015 - accuracy: 0.9750 - val_loss: 0.1325 - val_accuracy: 0.9512\n",
            "Epoch 624/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1148 - accuracy: 0.9500 - val_loss: 0.4015 - val_accuracy: 0.8780\n",
            "Epoch 625/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.2777 - accuracy: 0.9250 - val_loss: 0.4395 - val_accuracy: 0.8780\n",
            "Epoch 626/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1170 - accuracy: 0.9250 - val_loss: 0.1350 - val_accuracy: 0.9512\n",
            "Epoch 627/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.2821 - accuracy: 0.9000 - val_loss: 0.1086 - val_accuracy: 0.9756\n",
            "Epoch 628/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0872 - accuracy: 0.9500 - val_loss: 0.1326 - val_accuracy: 0.9512\n",
            "Epoch 629/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1044 - accuracy: 0.9500 - val_loss: 0.4984 - val_accuracy: 0.9024\n",
            "Epoch 630/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0548 - accuracy: 1.0000 - val_loss: 0.9344 - val_accuracy: 0.8780\n",
            "Epoch 631/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.1392 - accuracy: 0.9500 - val_loss: 1.0430 - val_accuracy: 0.9024\n",
            "Epoch 632/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.2574 - accuracy: 0.9000 - val_loss: 0.2514 - val_accuracy: 0.9024\n",
            "Epoch 633/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1144 - accuracy: 0.9750 - val_loss: 1.3570 - val_accuracy: 0.6829\n",
            "Epoch 634/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.2700 - accuracy: 0.9000 - val_loss: 1.5308 - val_accuracy: 0.7317\n",
            "Epoch 635/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.2029 - accuracy: 0.9500 - val_loss: 1.2515 - val_accuracy: 0.7805\n",
            "Epoch 636/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.2422 - accuracy: 0.9250 - val_loss: 1.0750 - val_accuracy: 0.8780\n",
            "Epoch 637/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1104 - accuracy: 0.9750 - val_loss: 0.4844 - val_accuracy: 0.9024\n",
            "Epoch 638/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0475 - accuracy: 1.0000 - val_loss: 0.0983 - val_accuracy: 0.9512\n",
            "Epoch 639/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1667 - accuracy: 0.9250 - val_loss: 0.1600 - val_accuracy: 0.9512\n",
            "Epoch 640/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.3255 - accuracy: 0.9000 - val_loss: 0.7634 - val_accuracy: 0.8537\n",
            "Epoch 641/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.3507 - accuracy: 0.8250 - val_loss: 0.4805 - val_accuracy: 0.8293\n",
            "Epoch 642/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1189 - accuracy: 0.9500 - val_loss: 0.2848 - val_accuracy: 0.9268\n",
            "Epoch 643/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.1091 - accuracy: 0.9500 - val_loss: 0.3487 - val_accuracy: 0.8293\n",
            "Epoch 644/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.4213 - accuracy: 0.8500 - val_loss: 0.1896 - val_accuracy: 0.9512\n",
            "Epoch 645/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1029 - accuracy: 0.9750 - val_loss: 1.3223 - val_accuracy: 0.8049\n",
            "Epoch 646/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1939 - accuracy: 0.8500 - val_loss: 1.8498 - val_accuracy: 0.7073\n",
            "Epoch 647/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1228 - accuracy: 0.9750 - val_loss: 1.2959 - val_accuracy: 0.7317\n",
            "Epoch 648/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.2014 - accuracy: 0.9000 - val_loss: 1.6291 - val_accuracy: 0.6098\n",
            "Epoch 649/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.2285 - accuracy: 0.9000 - val_loss: 0.5511 - val_accuracy: 0.9268\n",
            "Epoch 650/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1281 - accuracy: 0.9750 - val_loss: 0.2010 - val_accuracy: 0.9268\n",
            "Epoch 651/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1827 - accuracy: 0.9000 - val_loss: 0.6028 - val_accuracy: 0.9024\n",
            "Epoch 652/2000\n",
            "5/5 [==============================] - 1s 241ms/step - loss: 0.1000 - accuracy: 0.9750 - val_loss: 0.5876 - val_accuracy: 0.9024\n",
            "Epoch 653/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.1071 - accuracy: 0.9500 - val_loss: 0.2540 - val_accuracy: 0.9512\n",
            "Epoch 654/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.1185 - accuracy: 0.9250 - val_loss: 0.2494 - val_accuracy: 0.9512\n",
            "Epoch 655/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.1343 - accuracy: 0.9750 - val_loss: 0.3290 - val_accuracy: 0.9268\n",
            "Epoch 656/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.3917 - accuracy: 0.8500 - val_loss: 0.4321 - val_accuracy: 0.8293\n",
            "Epoch 657/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1168 - accuracy: 0.9250 - val_loss: 0.3625 - val_accuracy: 0.8780\n",
            "Epoch 658/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0816 - accuracy: 0.9750 - val_loss: 0.4597 - val_accuracy: 0.8780\n",
            "Epoch 659/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1876 - accuracy: 0.9250 - val_loss: 0.7596 - val_accuracy: 0.8780\n",
            "Epoch 660/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.4384 - accuracy: 0.8750 - val_loss: 0.0558 - val_accuracy: 0.9756\n",
            "Epoch 661/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.2042 - accuracy: 0.9250 - val_loss: 0.0913 - val_accuracy: 0.9756\n",
            "Epoch 662/2000\n",
            "5/5 [==============================] - 1s 228ms/step - loss: 0.2760 - accuracy: 0.8750 - val_loss: 0.0878 - val_accuracy: 0.9756\n",
            "Epoch 663/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1986 - accuracy: 0.9000 - val_loss: 0.1049 - val_accuracy: 1.0000\n",
            "Epoch 664/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0873 - accuracy: 0.9750 - val_loss: 0.6501 - val_accuracy: 0.7561\n",
            "Epoch 665/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1454 - accuracy: 0.9500 - val_loss: 1.6287 - val_accuracy: 0.5854\n",
            "Epoch 666/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0987 - accuracy: 0.9750 - val_loss: 2.4805 - val_accuracy: 0.5854\n",
            "Epoch 667/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0913 - accuracy: 0.9750 - val_loss: 2.9522 - val_accuracy: 0.5854\n",
            "Epoch 668/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.1329 - accuracy: 0.9250 - val_loss: 2.0090 - val_accuracy: 0.6585\n",
            "Epoch 669/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.2464 - accuracy: 0.9500 - val_loss: 0.5525 - val_accuracy: 0.8049\n",
            "Epoch 670/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0825 - accuracy: 0.9750 - val_loss: 0.3012 - val_accuracy: 0.9024\n",
            "Epoch 671/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0783 - accuracy: 0.9750 - val_loss: 0.2669 - val_accuracy: 0.9024\n",
            "Epoch 672/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1039 - accuracy: 0.9750 - val_loss: 0.5601 - val_accuracy: 0.9268\n",
            "Epoch 673/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1191 - accuracy: 0.9750 - val_loss: 0.4493 - val_accuracy: 0.9024\n",
            "Epoch 674/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.2541 - accuracy: 0.9000 - val_loss: 0.1417 - val_accuracy: 0.9512\n",
            "Epoch 675/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.4182 - accuracy: 0.8750 - val_loss: 0.4362 - val_accuracy: 0.8049\n",
            "Epoch 676/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0812 - accuracy: 1.0000 - val_loss: 0.6760 - val_accuracy: 0.7805\n",
            "Epoch 677/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.2226 - accuracy: 0.9000 - val_loss: 1.7429 - val_accuracy: 0.6098\n",
            "Epoch 678/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0811 - accuracy: 0.9750 - val_loss: 2.8433 - val_accuracy: 0.4634\n",
            "Epoch 679/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.2627 - accuracy: 0.8750 - val_loss: 0.4401 - val_accuracy: 0.8293\n",
            "Epoch 680/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1354 - accuracy: 0.9500 - val_loss: 0.2256 - val_accuracy: 0.9268\n",
            "Epoch 681/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2268 - accuracy: 0.9000 - val_loss: 0.1793 - val_accuracy: 0.9756\n",
            "Epoch 682/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0822 - accuracy: 0.9750 - val_loss: 0.3717 - val_accuracy: 0.8537\n",
            "Epoch 683/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1714 - accuracy: 0.9000 - val_loss: 0.4492 - val_accuracy: 0.8293\n",
            "Epoch 684/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.3214 - accuracy: 0.9000 - val_loss: 0.5587 - val_accuracy: 0.7561\n",
            "Epoch 685/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1679 - accuracy: 0.9500 - val_loss: 0.8550 - val_accuracy: 0.6341\n",
            "Epoch 686/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.1155 - accuracy: 0.9500 - val_loss: 0.9950 - val_accuracy: 0.5366\n",
            "Epoch 687/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.4666 - accuracy: 0.8500 - val_loss: 1.1555 - val_accuracy: 0.5854\n",
            "Epoch 688/2000\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.0685 - accuracy: 0.9750 - val_loss: 0.9056 - val_accuracy: 0.8537\n",
            "Epoch 689/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0955 - accuracy: 0.9750 - val_loss: 0.8649 - val_accuracy: 0.9024\n",
            "Epoch 690/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.0859 - accuracy: 0.9750 - val_loss: 1.0850 - val_accuracy: 0.8780\n",
            "Epoch 691/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1215 - accuracy: 0.9500 - val_loss: 1.2323 - val_accuracy: 0.9024\n",
            "Epoch 692/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.3630 - accuracy: 0.9250 - val_loss: 2.8903 - val_accuracy: 0.5854\n",
            "Epoch 693/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1199 - accuracy: 0.9500 - val_loss: 1.3651 - val_accuracy: 0.8537\n",
            "Epoch 694/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.1808 - accuracy: 0.9000 - val_loss: 0.1381 - val_accuracy: 0.9756\n",
            "Epoch 695/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1158 - accuracy: 0.9750 - val_loss: 0.2578 - val_accuracy: 0.9268\n",
            "Epoch 696/2000\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.2335 - accuracy: 0.8750 - val_loss: 1.4593 - val_accuracy: 0.8049\n",
            "Epoch 697/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1549 - accuracy: 0.9500 - val_loss: 2.7021 - val_accuracy: 0.6098\n",
            "Epoch 698/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.1924 - accuracy: 0.9250 - val_loss: 1.6102 - val_accuracy: 0.7805\n",
            "Epoch 699/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1197 - accuracy: 0.9500 - val_loss: 0.7809 - val_accuracy: 0.8537\n",
            "Epoch 700/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0674 - accuracy: 1.0000 - val_loss: 0.7590 - val_accuracy: 0.8537\n",
            "Epoch 701/2000\n",
            "5/5 [==============================] - 1s 247ms/step - loss: 0.0778 - accuracy: 0.9750 - val_loss: 0.6586 - val_accuracy: 0.8780\n",
            "Epoch 702/2000\n",
            "5/5 [==============================] - 1s 252ms/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 0.5311 - val_accuracy: 0.8780\n",
            "Epoch 703/2000\n",
            "5/5 [==============================] - 1s 251ms/step - loss: 0.1367 - accuracy: 0.9250 - val_loss: 0.0562 - val_accuracy: 0.9512\n",
            "Epoch 704/2000\n",
            "5/5 [==============================] - 1s 251ms/step - loss: 0.1311 - accuracy: 0.9500 - val_loss: 0.0466 - val_accuracy: 1.0000\n",
            "Epoch 705/2000\n",
            "5/5 [==============================] - 1s 252ms/step - loss: 0.3479 - accuracy: 0.8750 - val_loss: 0.1071 - val_accuracy: 0.9756\n",
            "Epoch 706/2000\n",
            "5/5 [==============================] - 1s 251ms/step - loss: 0.1603 - accuracy: 0.9250 - val_loss: 0.1984 - val_accuracy: 0.9268\n",
            "Epoch 707/2000\n",
            "5/5 [==============================] - 1s 251ms/step - loss: 0.1464 - accuracy: 0.9000 - val_loss: 1.7994 - val_accuracy: 0.5610\n",
            "Epoch 708/2000\n",
            "5/5 [==============================] - 1s 252ms/step - loss: 0.2968 - accuracy: 0.8750 - val_loss: 3.1297 - val_accuracy: 0.2683\n",
            "Epoch 709/2000\n",
            "5/5 [==============================] - 1s 241ms/step - loss: 0.3664 - accuracy: 0.8750 - val_loss: 1.1430 - val_accuracy: 0.7073\n",
            "Epoch 710/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1076 - accuracy: 0.9500 - val_loss: 0.1837 - val_accuracy: 0.9268\n",
            "Epoch 711/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.3471 - accuracy: 0.8750 - val_loss: 0.3601 - val_accuracy: 0.8049\n",
            "Epoch 712/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1919 - accuracy: 0.9250 - val_loss: 1.0229 - val_accuracy: 0.6829\n",
            "Epoch 713/2000\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.3158 - accuracy: 0.9000 - val_loss: 1.7261 - val_accuracy: 0.5366\n",
            "Epoch 714/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.2430 - accuracy: 0.9250 - val_loss: 2.0701 - val_accuracy: 0.4634\n",
            "Epoch 715/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.1162 - accuracy: 1.0000 - val_loss: 2.8944 - val_accuracy: 0.3902\n",
            "Epoch 716/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1195 - accuracy: 0.9500 - val_loss: 3.3822 - val_accuracy: 0.1951\n",
            "Epoch 717/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0832 - accuracy: 0.9750 - val_loss: 2.7446 - val_accuracy: 0.2927\n",
            "Epoch 718/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.2060 - accuracy: 0.8750 - val_loss: 2.7471 - val_accuracy: 0.3415\n",
            "Epoch 719/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0774 - accuracy: 0.9500 - val_loss: 2.3482 - val_accuracy: 0.6341\n",
            "Epoch 720/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1670 - accuracy: 0.9250 - val_loss: 2.4890 - val_accuracy: 0.6341\n",
            "Epoch 721/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0829 - accuracy: 0.9750 - val_loss: 2.7242 - val_accuracy: 0.6341\n",
            "Epoch 722/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.3521 - accuracy: 0.8500 - val_loss: 2.8526 - val_accuracy: 0.5610\n",
            "Epoch 723/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1377 - accuracy: 0.9500 - val_loss: 2.1239 - val_accuracy: 0.5610\n",
            "Epoch 724/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.2194 - accuracy: 0.9250 - val_loss: 1.5708 - val_accuracy: 0.6585\n",
            "Epoch 725/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.4921 - accuracy: 0.8500 - val_loss: 1.4458 - val_accuracy: 0.6829\n",
            "Epoch 726/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1857 - accuracy: 0.9500 - val_loss: 1.6340 - val_accuracy: 0.5610\n",
            "Epoch 727/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1425 - accuracy: 0.9500 - val_loss: 4.2317 - val_accuracy: 0.5366\n",
            "Epoch 728/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1405 - accuracy: 0.9250 - val_loss: 3.4693 - val_accuracy: 0.6098\n",
            "Epoch 729/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1811 - accuracy: 0.9000 - val_loss: 0.1743 - val_accuracy: 0.9512\n",
            "Epoch 730/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.1690 - accuracy: 0.9250 - val_loss: 0.3874 - val_accuracy: 0.8537\n",
            "Epoch 731/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.1696 - accuracy: 0.9250 - val_loss: 0.1391 - val_accuracy: 0.9512\n",
            "Epoch 732/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1663 - accuracy: 0.9250 - val_loss: 0.8601 - val_accuracy: 0.8780\n",
            "Epoch 733/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1605 - accuracy: 0.9500 - val_loss: 0.2191 - val_accuracy: 0.9268\n",
            "Epoch 734/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1320 - accuracy: 0.9250 - val_loss: 0.1948 - val_accuracy: 0.9268\n",
            "Epoch 735/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1979 - accuracy: 0.9250 - val_loss: 0.3958 - val_accuracy: 0.8780\n",
            "Epoch 736/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1425 - accuracy: 0.9500 - val_loss: 0.2621 - val_accuracy: 0.9268\n",
            "Epoch 737/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1300 - accuracy: 0.9500 - val_loss: 1.5912 - val_accuracy: 0.8780\n",
            "Epoch 738/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.1974 - accuracy: 0.9500 - val_loss: 0.2358 - val_accuracy: 0.9512\n",
            "Epoch 739/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0580 - accuracy: 0.9750 - val_loss: 0.4927 - val_accuracy: 0.7073\n",
            "Epoch 740/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0577 - accuracy: 1.0000 - val_loss: 0.3413 - val_accuracy: 0.9268\n",
            "Epoch 741/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.0861 - accuracy: 0.9750 - val_loss: 0.2089 - val_accuracy: 0.9512\n",
            "Epoch 742/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.2349 - accuracy: 0.9000 - val_loss: 0.0749 - val_accuracy: 0.9756\n",
            "Epoch 743/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1198 - accuracy: 0.9500 - val_loss: 0.1676 - val_accuracy: 0.9512\n",
            "Epoch 744/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1434 - accuracy: 0.9500 - val_loss: 0.4064 - val_accuracy: 0.9024\n",
            "Epoch 745/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1752 - accuracy: 0.8500 - val_loss: 0.6678 - val_accuracy: 0.9268\n",
            "Epoch 746/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1219 - accuracy: 0.9750 - val_loss: 0.0867 - val_accuracy: 0.9756\n",
            "Epoch 747/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0732 - accuracy: 0.9750 - val_loss: 0.2123 - val_accuracy: 0.9512\n",
            "Epoch 748/2000\n",
            "5/5 [==============================] - 1s 242ms/step - loss: 0.1146 - accuracy: 0.9500 - val_loss: 0.1484 - val_accuracy: 0.9512\n",
            "Epoch 749/2000\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 0.0715 - accuracy: 0.9750 - val_loss: 0.1240 - val_accuracy: 0.9268\n",
            "Epoch 750/2000\n",
            "5/5 [==============================] - 1s 241ms/step - loss: 0.0894 - accuracy: 0.9750 - val_loss: 0.5362 - val_accuracy: 0.9024\n",
            "Epoch 751/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.0747 - accuracy: 1.0000 - val_loss: 0.4607 - val_accuracy: 0.8780\n",
            "Epoch 752/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0537 - accuracy: 1.0000 - val_loss: 0.3052 - val_accuracy: 0.8780\n",
            "Epoch 753/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0594 - accuracy: 1.0000 - val_loss: 0.1886 - val_accuracy: 0.9024\n",
            "Epoch 754/2000\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.4062 - accuracy: 0.8500 - val_loss: 0.3238 - val_accuracy: 0.9268\n",
            "Epoch 755/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0401 - accuracy: 1.0000 - val_loss: 0.7174 - val_accuracy: 0.8537\n",
            "Epoch 756/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1766 - accuracy: 0.9500 - val_loss: 0.6210 - val_accuracy: 0.8780\n",
            "Epoch 757/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.2459 - accuracy: 0.9000 - val_loss: 0.8818 - val_accuracy: 0.8780\n",
            "Epoch 758/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 1.1522 - val_accuracy: 0.7073\n",
            "Epoch 759/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2734 - accuracy: 0.9250 - val_loss: 0.9383 - val_accuracy: 0.7805\n",
            "Epoch 760/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1248 - accuracy: 0.9500 - val_loss: 0.7245 - val_accuracy: 0.9024\n",
            "Epoch 761/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.3315 - accuracy: 0.9250 - val_loss: 1.4832 - val_accuracy: 0.7561\n",
            "Epoch 762/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0913 - accuracy: 0.9750 - val_loss: 1.8242 - val_accuracy: 0.7073\n",
            "Epoch 763/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0933 - accuracy: 0.9750 - val_loss: 0.8894 - val_accuracy: 0.8537\n",
            "Epoch 764/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1794 - accuracy: 0.9250 - val_loss: 0.5577 - val_accuracy: 0.9268\n",
            "Epoch 765/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0413 - accuracy: 1.0000 - val_loss: 0.2297 - val_accuracy: 0.9268\n",
            "Epoch 766/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0253 - accuracy: 1.0000 - val_loss: 0.2178 - val_accuracy: 0.9268\n",
            "Epoch 767/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1594 - accuracy: 0.9500 - val_loss: 0.3718 - val_accuracy: 0.9268\n",
            "Epoch 768/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0437 - accuracy: 1.0000 - val_loss: 0.5377 - val_accuracy: 0.9024\n",
            "Epoch 769/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.1135 - accuracy: 0.9750 - val_loss: 0.1060 - val_accuracy: 0.9756\n",
            "Epoch 770/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0828 - accuracy: 0.9750 - val_loss: 0.1098 - val_accuracy: 0.9756\n",
            "Epoch 771/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0666 - accuracy: 1.0000 - val_loss: 0.1060 - val_accuracy: 0.9756\n",
            "Epoch 772/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.1881 - val_accuracy: 0.9268\n",
            "Epoch 773/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0741 - accuracy: 0.9500 - val_loss: 0.3054 - val_accuracy: 0.9268\n",
            "Epoch 774/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1088 - accuracy: 0.9750 - val_loss: 0.1118 - val_accuracy: 0.9512\n",
            "Epoch 775/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1673 - accuracy: 0.9250 - val_loss: 0.0952 - val_accuracy: 0.9512\n",
            "Epoch 776/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0542 - accuracy: 0.9750 - val_loss: 0.1544 - val_accuracy: 0.9756\n",
            "Epoch 777/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0737 - accuracy: 0.9750 - val_loss: 0.2310 - val_accuracy: 0.9268\n",
            "Epoch 778/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0498 - accuracy: 0.9750 - val_loss: 0.9493 - val_accuracy: 0.7317\n",
            "Epoch 779/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.2072 - accuracy: 0.9250 - val_loss: 1.1124 - val_accuracy: 0.8537\n",
            "Epoch 780/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.1863 - accuracy: 0.9250 - val_loss: 0.5128 - val_accuracy: 0.9268\n",
            "Epoch 781/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.1057 - accuracy: 0.9250 - val_loss: 0.2968 - val_accuracy: 0.9268\n",
            "Epoch 782/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1373 - accuracy: 0.9500 - val_loss: 0.1194 - val_accuracy: 0.9756\n",
            "Epoch 783/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1374 - accuracy: 0.9500 - val_loss: 0.0866 - val_accuracy: 0.9756\n",
            "Epoch 784/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1351 - accuracy: 0.9250 - val_loss: 0.7829 - val_accuracy: 0.8780\n",
            "Epoch 785/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1533 - accuracy: 0.9500 - val_loss: 0.9578 - val_accuracy: 0.8293\n",
            "Epoch 786/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.4262 - accuracy: 0.8500 - val_loss: 0.2217 - val_accuracy: 0.9268\n",
            "Epoch 787/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1196 - accuracy: 0.9000 - val_loss: 0.1549 - val_accuracy: 0.9512\n",
            "Epoch 788/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1387 - accuracy: 0.9750 - val_loss: 0.2113 - val_accuracy: 0.9512\n",
            "Epoch 789/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0822 - accuracy: 0.9750 - val_loss: 0.1176 - val_accuracy: 0.9512\n",
            "Epoch 790/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0528 - accuracy: 1.0000 - val_loss: 0.1094 - val_accuracy: 0.9512\n",
            "Epoch 791/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1594 - accuracy: 0.9750 - val_loss: 0.0872 - val_accuracy: 0.9512\n",
            "Epoch 792/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0816 - accuracy: 0.9750 - val_loss: 0.7759 - val_accuracy: 0.9024\n",
            "Epoch 793/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0460 - accuracy: 1.0000 - val_loss: 1.1835 - val_accuracy: 0.7561\n",
            "Epoch 794/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1767 - accuracy: 0.9500 - val_loss: 1.1745 - val_accuracy: 0.8780\n",
            "Epoch 795/2000\n",
            "5/5 [==============================] - 1s 228ms/step - loss: 0.1329 - accuracy: 0.9500 - val_loss: 0.8252 - val_accuracy: 0.9024\n",
            "Epoch 796/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1560 - accuracy: 0.9750 - val_loss: 0.8714 - val_accuracy: 0.9024\n",
            "Epoch 797/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.2563 - accuracy: 0.9750 - val_loss: 0.3443 - val_accuracy: 0.9268\n",
            "Epoch 798/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0263 - accuracy: 1.0000 - val_loss: 0.0842 - val_accuracy: 0.9512\n",
            "Epoch 799/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0509 - accuracy: 1.0000 - val_loss: 0.0628 - val_accuracy: 0.9756\n",
            "Epoch 800/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.0992 - accuracy: 0.9750 - val_loss: 0.0535 - val_accuracy: 0.9756\n",
            "Epoch 801/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1661 - accuracy: 0.9500 - val_loss: 0.3351 - val_accuracy: 0.9024\n",
            "Epoch 802/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1212 - accuracy: 0.9250 - val_loss: 0.2387 - val_accuracy: 0.9024\n",
            "Epoch 803/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1237 - accuracy: 0.9500 - val_loss: 0.0653 - val_accuracy: 0.9512\n",
            "Epoch 804/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.2115 - accuracy: 0.9250 - val_loss: 0.0431 - val_accuracy: 1.0000\n",
            "Epoch 805/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1130 - accuracy: 0.9750 - val_loss: 0.0470 - val_accuracy: 1.0000\n",
            "Epoch 806/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1023 - accuracy: 0.9500 - val_loss: 0.8791 - val_accuracy: 0.8293\n",
            "Epoch 807/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1261 - accuracy: 0.9750 - val_loss: 0.3102 - val_accuracy: 0.9268\n",
            "Epoch 808/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1045 - accuracy: 0.9500 - val_loss: 0.4320 - val_accuracy: 0.9268\n",
            "Epoch 809/2000\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.1151 - accuracy: 0.9250 - val_loss: 0.4142 - val_accuracy: 0.8780\n",
            "Epoch 810/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 0.0759 - val_accuracy: 0.9512\n",
            "Epoch 811/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2310 - accuracy: 0.9250 - val_loss: 0.0482 - val_accuracy: 0.9756\n",
            "Epoch 812/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0726 - accuracy: 0.9750 - val_loss: 0.0556 - val_accuracy: 0.9756\n",
            "Epoch 813/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0833 - accuracy: 0.9750 - val_loss: 0.0607 - val_accuracy: 0.9756\n",
            "Epoch 814/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1566 - accuracy: 0.9000 - val_loss: 0.3231 - val_accuracy: 0.9268\n",
            "Epoch 815/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1060 - accuracy: 0.9500 - val_loss: 0.3601 - val_accuracy: 0.8780\n",
            "Epoch 816/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.1668 - accuracy: 0.9500 - val_loss: 0.1141 - val_accuracy: 0.9512\n",
            "Epoch 817/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0528 - accuracy: 1.0000 - val_loss: 0.2118 - val_accuracy: 0.9512\n",
            "Epoch 818/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0736 - accuracy: 0.9750 - val_loss: 0.3350 - val_accuracy: 0.9268\n",
            "Epoch 819/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.3971 - accuracy: 0.8750 - val_loss: 1.0313 - val_accuracy: 0.9268\n",
            "Epoch 820/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2053 - accuracy: 0.9250 - val_loss: 4.0501 - val_accuracy: 0.6341\n",
            "Epoch 821/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.3525 - accuracy: 0.9250 - val_loss: 1.3732 - val_accuracy: 0.6829\n",
            "Epoch 822/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.2137 - accuracy: 0.9500 - val_loss: 1.2026 - val_accuracy: 0.6585\n",
            "Epoch 823/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.2641 - accuracy: 0.9250 - val_loss: 0.9367 - val_accuracy: 0.6341\n",
            "Epoch 824/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1362 - accuracy: 0.9500 - val_loss: 3.1725 - val_accuracy: 0.5854\n",
            "Epoch 825/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1877 - accuracy: 0.9750 - val_loss: 3.5909 - val_accuracy: 0.5610\n",
            "Epoch 826/2000\n",
            "5/5 [==============================] - 1s 227ms/step - loss: 0.2189 - accuracy: 0.9250 - val_loss: 1.8218 - val_accuracy: 0.5610\n",
            "Epoch 827/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.0873 - accuracy: 0.9500 - val_loss: 1.0613 - val_accuracy: 0.6341\n",
            "Epoch 828/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1087 - accuracy: 0.9500 - val_loss: 1.7767 - val_accuracy: 0.5610\n",
            "Epoch 829/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1282 - accuracy: 0.9750 - val_loss: 1.9481 - val_accuracy: 0.6098\n",
            "Epoch 830/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0975 - accuracy: 1.0000 - val_loss: 1.9510 - val_accuracy: 0.6341\n",
            "Epoch 831/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.3192 - accuracy: 0.9000 - val_loss: 2.3261 - val_accuracy: 0.6098\n",
            "Epoch 832/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0612 - accuracy: 0.9750 - val_loss: 2.5239 - val_accuracy: 0.4634\n",
            "Epoch 833/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 2.4277 - val_accuracy: 0.4878\n",
            "Epoch 834/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0677 - accuracy: 1.0000 - val_loss: 2.0593 - val_accuracy: 0.6098\n",
            "Epoch 835/2000\n",
            "5/5 [==============================] - 1s 228ms/step - loss: 0.1397 - accuracy: 0.9500 - val_loss: 1.9296 - val_accuracy: 0.7073\n",
            "Epoch 836/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0888 - accuracy: 0.9500 - val_loss: 1.1725 - val_accuracy: 0.8293\n",
            "Epoch 837/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1503 - accuracy: 0.9250 - val_loss: 0.8412 - val_accuracy: 0.9268\n",
            "Epoch 838/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1936 - accuracy: 0.9500 - val_loss: 1.4210 - val_accuracy: 0.8293\n",
            "Epoch 839/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1799 - accuracy: 0.9500 - val_loss: 1.6181 - val_accuracy: 0.8293\n",
            "Epoch 840/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0912 - accuracy: 0.9500 - val_loss: 0.5708 - val_accuracy: 0.9756\n",
            "Epoch 841/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0751 - accuracy: 0.9750 - val_loss: 0.4118 - val_accuracy: 0.9756\n",
            "Epoch 842/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1473 - accuracy: 0.9500 - val_loss: 0.5380 - val_accuracy: 0.9268\n",
            "Epoch 843/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.1266 - accuracy: 0.9750 - val_loss: 0.6738 - val_accuracy: 0.9268\n",
            "Epoch 844/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0621 - accuracy: 0.9750 - val_loss: 0.8703 - val_accuracy: 0.9268\n",
            "Epoch 845/2000\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 0.1321 - accuracy: 0.9750 - val_loss: 1.2990 - val_accuracy: 0.7805\n",
            "Epoch 846/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.1457 - accuracy: 0.9500 - val_loss: 1.5358 - val_accuracy: 0.7317\n",
            "Epoch 847/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0400 - accuracy: 1.0000 - val_loss: 1.0982 - val_accuracy: 0.8293\n",
            "Epoch 848/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1526 - accuracy: 0.9500 - val_loss: 0.1805 - val_accuracy: 0.9268\n",
            "Epoch 849/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0484 - accuracy: 0.9750 - val_loss: 0.0584 - val_accuracy: 0.9756\n",
            "Epoch 850/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0492 - accuracy: 1.0000 - val_loss: 0.0859 - val_accuracy: 0.9756\n",
            "Epoch 851/2000\n",
            "5/5 [==============================] - 1s 227ms/step - loss: 0.0891 - accuracy: 0.9750 - val_loss: 0.0625 - val_accuracy: 0.9756\n",
            "Epoch 852/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.1285 - accuracy: 0.9500 - val_loss: 0.0787 - val_accuracy: 0.9756\n",
            "Epoch 853/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.2011 - accuracy: 0.9500 - val_loss: 0.0818 - val_accuracy: 0.9756\n",
            "Epoch 854/2000\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.1739 - accuracy: 0.9500 - val_loss: 0.0524 - val_accuracy: 0.9756\n",
            "Epoch 855/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1206 - accuracy: 0.9500 - val_loss: 0.0513 - val_accuracy: 1.0000\n",
            "Epoch 856/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.1238 - accuracy: 0.9250 - val_loss: 0.0679 - val_accuracy: 0.9512\n",
            "Epoch 857/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1842 - accuracy: 0.9250 - val_loss: 0.0705 - val_accuracy: 0.9756\n",
            "Epoch 858/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0808 - accuracy: 0.9500 - val_loss: 0.0762 - val_accuracy: 0.9756\n",
            "Epoch 859/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2774 - accuracy: 0.9250 - val_loss: 0.0603 - val_accuracy: 0.9756\n",
            "Epoch 860/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.1100 - accuracy: 0.9500 - val_loss: 0.0749 - val_accuracy: 0.9512\n",
            "Epoch 861/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.0599 - val_accuracy: 0.9756\n",
            "Epoch 862/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 0.1186 - val_accuracy: 0.9512\n",
            "Epoch 863/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1813 - accuracy: 0.9250 - val_loss: 0.2622 - val_accuracy: 0.9024\n",
            "Epoch 864/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1156 - accuracy: 0.9500 - val_loss: 0.1283 - val_accuracy: 0.9512\n",
            "Epoch 865/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0956 - accuracy: 0.9500 - val_loss: 0.0914 - val_accuracy: 0.9512\n",
            "Epoch 866/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.2232 - accuracy: 0.9500 - val_loss: 0.0824 - val_accuracy: 0.9756\n",
            "Epoch 867/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.1861 - accuracy: 0.9250 - val_loss: 0.0835 - val_accuracy: 0.9756\n",
            "Epoch 868/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1024 - accuracy: 0.9750 - val_loss: 0.0822 - val_accuracy: 0.9512\n",
            "Epoch 869/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0572 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.8780\n",
            "Epoch 870/2000\n",
            "5/5 [==============================] - 1s 228ms/step - loss: 0.0663 - accuracy: 0.9750 - val_loss: 0.3704 - val_accuracy: 0.8780\n",
            "Epoch 871/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.0631 - accuracy: 0.9750 - val_loss: 0.3681 - val_accuracy: 0.9268\n",
            "Epoch 872/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.1915 - accuracy: 0.9250 - val_loss: 1.2192 - val_accuracy: 0.7805\n",
            "Epoch 873/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1353 - accuracy: 0.9250 - val_loss: 1.3652 - val_accuracy: 0.8049\n",
            "Epoch 874/2000\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 0.0633 - accuracy: 0.9500 - val_loss: 0.3936 - val_accuracy: 0.9268\n",
            "Epoch 875/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.3015 - accuracy: 0.8500 - val_loss: 0.2560 - val_accuracy: 0.9512\n",
            "Epoch 876/2000\n",
            "5/5 [==============================] - 1s 228ms/step - loss: 0.1705 - accuracy: 0.9250 - val_loss: 0.0679 - val_accuracy: 1.0000\n",
            "Epoch 877/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0491 - accuracy: 1.0000 - val_loss: 0.1153 - val_accuracy: 0.9512\n",
            "Epoch 878/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1286 - accuracy: 0.9500 - val_loss: 0.1389 - val_accuracy: 0.9268\n",
            "Epoch 879/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0411 - accuracy: 1.0000 - val_loss: 0.0470 - val_accuracy: 1.0000\n",
            "Epoch 880/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0972 - accuracy: 0.9500 - val_loss: 0.0378 - val_accuracy: 1.0000\n",
            "Epoch 881/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0976 - accuracy: 0.9500 - val_loss: 0.2604 - val_accuracy: 0.9268\n",
            "Epoch 882/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.2222 - accuracy: 0.9500 - val_loss: 0.8794 - val_accuracy: 0.8780\n",
            "Epoch 883/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.3083 - accuracy: 0.9250 - val_loss: 0.8449 - val_accuracy: 0.8780\n",
            "Epoch 884/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.0880 - accuracy: 0.9500 - val_loss: 0.7213 - val_accuracy: 0.9024\n",
            "Epoch 885/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0717 - accuracy: 1.0000 - val_loss: 0.6697 - val_accuracy: 0.9268\n",
            "Epoch 886/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1799 - accuracy: 0.9250 - val_loss: 0.4138 - val_accuracy: 0.9268\n",
            "Epoch 887/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 0.3013 - val_accuracy: 0.9268\n",
            "Epoch 888/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0932 - accuracy: 0.9750 - val_loss: 0.5425 - val_accuracy: 0.9024\n",
            "Epoch 889/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0750 - accuracy: 0.9750 - val_loss: 0.6267 - val_accuracy: 0.9024\n",
            "Epoch 890/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0607 - accuracy: 0.9750 - val_loss: 0.6925 - val_accuracy: 0.9024\n",
            "Epoch 891/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0538 - accuracy: 1.0000 - val_loss: 0.6073 - val_accuracy: 0.9024\n",
            "Epoch 892/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 0.9512\n",
            "Epoch 893/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0454 - accuracy: 0.9750 - val_loss: 0.1319 - val_accuracy: 0.9756\n",
            "Epoch 894/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1923 - accuracy: 0.9500 - val_loss: 0.3080 - val_accuracy: 0.9024\n",
            "Epoch 895/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.5080 - accuracy: 0.9250 - val_loss: 0.0456 - val_accuracy: 1.0000\n",
            "Epoch 896/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0307 - accuracy: 0.9750 - val_loss: 0.0441 - val_accuracy: 1.0000\n",
            "Epoch 897/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 0.0560 - val_accuracy: 1.0000\n",
            "Epoch 898/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0531 - accuracy: 0.9750 - val_loss: 0.1027 - val_accuracy: 0.9512\n",
            "Epoch 899/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1931 - accuracy: 0.9250 - val_loss: 0.6837 - val_accuracy: 0.8780\n",
            "Epoch 900/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1056 - accuracy: 0.9750 - val_loss: 2.0799 - val_accuracy: 0.7561\n",
            "Epoch 901/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.0526 - accuracy: 0.9750 - val_loss: 1.3708 - val_accuracy: 0.8049\n",
            "Epoch 902/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 1.0274 - val_accuracy: 0.8780\n",
            "Epoch 903/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2891 - accuracy: 0.9500 - val_loss: 0.7768 - val_accuracy: 0.8780\n",
            "Epoch 904/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0402 - accuracy: 0.9750 - val_loss: 0.0678 - val_accuracy: 0.9512\n",
            "Epoch 905/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0728 - accuracy: 0.9750 - val_loss: 0.0648 - val_accuracy: 1.0000\n",
            "Epoch 906/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.3546 - accuracy: 0.9000 - val_loss: 0.0996 - val_accuracy: 0.9756\n",
            "Epoch 907/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0335 - accuracy: 1.0000 - val_loss: 0.3404 - val_accuracy: 0.9024\n",
            "Epoch 908/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0707 - accuracy: 0.9750 - val_loss: 0.5144 - val_accuracy: 0.8780\n",
            "Epoch 909/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0938 - accuracy: 0.9750 - val_loss: 0.5998 - val_accuracy: 0.8537\n",
            "Epoch 910/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1477 - accuracy: 0.9750 - val_loss: 0.4250 - val_accuracy: 0.8780\n",
            "Epoch 911/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0678 - accuracy: 0.9750 - val_loss: 0.4113 - val_accuracy: 0.9024\n",
            "Epoch 912/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.2705 - accuracy: 0.8500 - val_loss: 0.4068 - val_accuracy: 0.9268\n",
            "Epoch 913/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0516 - accuracy: 1.0000 - val_loss: 0.3369 - val_accuracy: 0.8049\n",
            "Epoch 914/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.3086 - accuracy: 0.8750 - val_loss: 0.9889 - val_accuracy: 0.9024\n",
            "Epoch 915/2000\n",
            "5/5 [==============================] - 1s 228ms/step - loss: 0.2157 - accuracy: 0.9250 - val_loss: 2.0207 - val_accuracy: 0.7317\n",
            "Epoch 916/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 0.9528 - val_accuracy: 0.8293\n",
            "Epoch 917/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.0353 - accuracy: 1.0000 - val_loss: 0.5522 - val_accuracy: 0.7805\n",
            "Epoch 918/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.4299 - accuracy: 0.8750 - val_loss: 0.9931 - val_accuracy: 0.5122\n",
            "Epoch 919/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1665 - accuracy: 0.9750 - val_loss: 0.5874 - val_accuracy: 0.6341\n",
            "Epoch 920/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.0855 - accuracy: 0.9750 - val_loss: 0.4815 - val_accuracy: 0.7073\n",
            "Epoch 921/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1569 - accuracy: 0.9250 - val_loss: 0.4025 - val_accuracy: 0.8537\n",
            "Epoch 922/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2852 - accuracy: 0.9000 - val_loss: 0.9092 - val_accuracy: 0.7073\n",
            "Epoch 923/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0552 - accuracy: 0.9750 - val_loss: 0.1528 - val_accuracy: 0.9756\n",
            "Epoch 924/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.1837 - accuracy: 0.9500 - val_loss: 0.1541 - val_accuracy: 0.9268\n",
            "Epoch 925/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.3529 - accuracy: 0.9000 - val_loss: 0.3445 - val_accuracy: 0.9512\n",
            "Epoch 926/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0472 - accuracy: 1.0000 - val_loss: 0.6165 - val_accuracy: 0.9268\n",
            "Epoch 927/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1197 - accuracy: 0.9500 - val_loss: 1.4236 - val_accuracy: 0.8537\n",
            "Epoch 928/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0743 - accuracy: 0.9500 - val_loss: 1.3054 - val_accuracy: 0.7317\n",
            "Epoch 929/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.2308 - accuracy: 0.9500 - val_loss: 1.1309 - val_accuracy: 0.6585\n",
            "Epoch 930/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1638 - accuracy: 0.9250 - val_loss: 1.3782 - val_accuracy: 0.6585\n",
            "Epoch 931/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.0573 - accuracy: 0.9750 - val_loss: 2.1929 - val_accuracy: 0.6829\n",
            "Epoch 932/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1590 - accuracy: 0.9500 - val_loss: 2.0086 - val_accuracy: 0.6098\n",
            "Epoch 933/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1732 - accuracy: 0.9500 - val_loss: 0.8479 - val_accuracy: 0.8537\n",
            "Epoch 934/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0780 - accuracy: 0.9750 - val_loss: 0.2781 - val_accuracy: 0.9512\n",
            "Epoch 935/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0542 - accuracy: 0.9750 - val_loss: 0.5262 - val_accuracy: 0.7561\n",
            "Epoch 936/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.5993 - accuracy: 0.8500 - val_loss: 0.6057 - val_accuracy: 0.7073\n",
            "Epoch 937/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0798 - accuracy: 0.9750 - val_loss: 0.3354 - val_accuracy: 0.9024\n",
            "Epoch 938/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0761 - accuracy: 0.9750 - val_loss: 0.1405 - val_accuracy: 0.9512\n",
            "Epoch 939/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0551 - accuracy: 0.9750 - val_loss: 0.5932 - val_accuracy: 0.9024\n",
            "Epoch 940/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.6202 - val_accuracy: 0.9024\n",
            "Epoch 941/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.1282 - accuracy: 0.9500 - val_loss: 0.5534 - val_accuracy: 0.9268\n",
            "Epoch 942/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.1134 - accuracy: 0.9750 - val_loss: 0.6258 - val_accuracy: 0.9024\n",
            "Epoch 943/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1223 - accuracy: 0.9500 - val_loss: 0.7366 - val_accuracy: 0.9024\n",
            "Epoch 944/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1162 - accuracy: 0.9750 - val_loss: 0.3314 - val_accuracy: 0.9024\n",
            "Epoch 945/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0815 - accuracy: 0.9750 - val_loss: 0.2770 - val_accuracy: 0.9024\n",
            "Epoch 946/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 0.1779 - val_accuracy: 0.9268\n",
            "Epoch 947/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0684 - accuracy: 0.9500 - val_loss: 0.0876 - val_accuracy: 0.9512\n",
            "Epoch 948/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0775 - accuracy: 1.0000 - val_loss: 0.1466 - val_accuracy: 0.9512\n",
            "Epoch 949/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 0.3872 - val_accuracy: 0.9512\n",
            "Epoch 950/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.5591 - val_accuracy: 0.9024\n",
            "Epoch 951/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0922 - accuracy: 0.9750 - val_loss: 0.4282 - val_accuracy: 0.9268\n",
            "Epoch 952/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0619 - accuracy: 1.0000 - val_loss: 0.1689 - val_accuracy: 0.9268\n",
            "Epoch 953/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1298 - accuracy: 0.9500 - val_loss: 0.0744 - val_accuracy: 0.9756\n",
            "Epoch 954/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0644 - accuracy: 0.9750 - val_loss: 0.0759 - val_accuracy: 0.9756\n",
            "Epoch 955/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1131 - accuracy: 0.9250 - val_loss: 0.3830 - val_accuracy: 0.9268\n",
            "Epoch 956/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0507 - accuracy: 1.0000 - val_loss: 0.7277 - val_accuracy: 0.9268\n",
            "Epoch 957/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0695 - accuracy: 1.0000 - val_loss: 0.8895 - val_accuracy: 0.9268\n",
            "Epoch 958/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1552 - accuracy: 0.9500 - val_loss: 1.3108 - val_accuracy: 0.9268\n",
            "Epoch 959/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.2128 - accuracy: 0.9000 - val_loss: 0.1486 - val_accuracy: 1.0000\n",
            "Epoch 960/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.3636 - accuracy: 0.8750 - val_loss: 0.2532 - val_accuracy: 0.9512\n",
            "Epoch 961/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.1966 - accuracy: 0.9500 - val_loss: 0.2328 - val_accuracy: 0.9024\n",
            "Epoch 962/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1636 - accuracy: 0.9750 - val_loss: 1.6388 - val_accuracy: 0.8537\n",
            "Epoch 963/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.1465 - accuracy: 0.9500 - val_loss: 0.1263 - val_accuracy: 0.9512\n",
            "Epoch 964/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1961 - accuracy: 0.8750 - val_loss: 0.0847 - val_accuracy: 0.9512\n",
            "Epoch 965/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0424 - accuracy: 1.0000 - val_loss: 0.3193 - val_accuracy: 0.9024\n",
            "Epoch 966/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0459 - accuracy: 1.0000 - val_loss: 0.9653 - val_accuracy: 0.9024\n",
            "Epoch 967/2000\n",
            "5/5 [==============================] - 1s 246ms/step - loss: 0.0874 - accuracy: 0.9750 - val_loss: 1.0173 - val_accuracy: 0.9024\n",
            "Epoch 968/2000\n",
            "5/5 [==============================] - 1s 246ms/step - loss: 0.0921 - accuracy: 0.9750 - val_loss: 0.8802 - val_accuracy: 0.9024\n",
            "Epoch 969/2000\n",
            "5/5 [==============================] - 1s 248ms/step - loss: 0.0674 - accuracy: 0.9750 - val_loss: 0.5473 - val_accuracy: 0.9268\n",
            "Epoch 970/2000\n",
            "5/5 [==============================] - 1s 249ms/step - loss: 0.0675 - accuracy: 0.9750 - val_loss: 0.3437 - val_accuracy: 0.9268\n",
            "Epoch 971/2000\n",
            "5/5 [==============================] - 1s 246ms/step - loss: 0.1099 - accuracy: 0.9500 - val_loss: 0.2538 - val_accuracy: 0.9512\n",
            "Epoch 972/2000\n",
            "5/5 [==============================] - 1s 247ms/step - loss: 0.1053 - accuracy: 0.9500 - val_loss: 0.4595 - val_accuracy: 0.9268\n",
            "Epoch 973/2000\n",
            "5/5 [==============================] - 1s 250ms/step - loss: 0.0721 - accuracy: 0.9750 - val_loss: 0.8051 - val_accuracy: 0.8293\n",
            "Epoch 974/2000\n",
            "5/5 [==============================] - 1s 245ms/step - loss: 0.0598 - accuracy: 0.9750 - val_loss: 0.7475 - val_accuracy: 0.8049\n",
            "Epoch 975/2000\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.1297 - accuracy: 0.9500 - val_loss: 0.6141 - val_accuracy: 0.8293\n",
            "Epoch 976/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0908 - accuracy: 0.9750 - val_loss: 0.5944 - val_accuracy: 0.8293\n",
            "Epoch 977/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0855 - accuracy: 1.0000 - val_loss: 0.5801 - val_accuracy: 0.8293\n",
            "Epoch 978/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0903 - accuracy: 0.9500 - val_loss: 0.6332 - val_accuracy: 0.8049\n",
            "Epoch 979/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1649 - accuracy: 0.9500 - val_loss: 0.9295 - val_accuracy: 0.8293\n",
            "Epoch 980/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0870 - accuracy: 0.9750 - val_loss: 1.3328 - val_accuracy: 0.8293\n",
            "Epoch 981/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0271 - accuracy: 1.0000 - val_loss: 1.0307 - val_accuracy: 0.8780\n",
            "Epoch 982/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1105 - accuracy: 0.9750 - val_loss: 0.5096 - val_accuracy: 0.9268\n",
            "Epoch 983/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0393 - accuracy: 1.0000 - val_loss: 0.3241 - val_accuracy: 0.9024\n",
            "Epoch 984/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0712 - accuracy: 0.9750 - val_loss: 1.0698 - val_accuracy: 0.8049\n",
            "Epoch 985/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0533 - accuracy: 1.0000 - val_loss: 1.4903 - val_accuracy: 0.7805\n",
            "Epoch 986/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0584 - accuracy: 0.9750 - val_loss: 1.2317 - val_accuracy: 0.8049\n",
            "Epoch 987/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0755 - accuracy: 0.9750 - val_loss: 0.6098 - val_accuracy: 0.8537\n",
            "Epoch 988/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0575 - accuracy: 0.9750 - val_loss: 0.2076 - val_accuracy: 0.9268\n",
            "Epoch 989/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2863 - accuracy: 0.9250 - val_loss: 0.8982 - val_accuracy: 0.8537\n",
            "Epoch 990/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 1.0014 - val_accuracy: 0.8537\n",
            "Epoch 991/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.2370 - accuracy: 0.9250 - val_loss: 0.9024 - val_accuracy: 0.9024\n",
            "Epoch 992/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2447 - accuracy: 0.9250 - val_loss: 1.1073 - val_accuracy: 0.7805\n",
            "Epoch 993/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.3318 - accuracy: 0.9000 - val_loss: 1.0035 - val_accuracy: 0.6585\n",
            "Epoch 994/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.2230 - accuracy: 0.9250 - val_loss: 0.2943 - val_accuracy: 0.9512\n",
            "Epoch 995/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1663 - accuracy: 0.9500 - val_loss: 0.4177 - val_accuracy: 0.9024\n",
            "Epoch 996/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0830 - accuracy: 0.9750 - val_loss: 0.3106 - val_accuracy: 0.9024\n",
            "Epoch 997/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1386 - accuracy: 0.9250 - val_loss: 0.3121 - val_accuracy: 0.9024\n",
            "Epoch 998/2000\n",
            "5/5 [==============================] - 1s 228ms/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 0.2245 - val_accuracy: 0.9268\n",
            "Epoch 999/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0444 - accuracy: 1.0000 - val_loss: 0.1813 - val_accuracy: 0.9268\n",
            "Epoch 1000/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1262 - accuracy: 0.9500 - val_loss: 0.1953 - val_accuracy: 0.9024\n",
            "Epoch 1001/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 0.2114 - val_accuracy: 0.9024\n",
            "Epoch 1002/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.1126 - accuracy: 0.9750 - val_loss: 0.2849 - val_accuracy: 0.9268\n",
            "Epoch 1003/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0908 - accuracy: 0.9750 - val_loss: 0.1157 - val_accuracy: 0.9756\n",
            "Epoch 1004/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1471 - accuracy: 0.9750 - val_loss: 0.1549 - val_accuracy: 0.9512\n",
            "Epoch 1005/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0521 - accuracy: 0.9750 - val_loss: 0.2488 - val_accuracy: 0.9268\n",
            "Epoch 1006/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1067 - accuracy: 0.9500 - val_loss: 0.4402 - val_accuracy: 0.9268\n",
            "Epoch 1007/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.0380 - accuracy: 1.0000 - val_loss: 1.0824 - val_accuracy: 0.9024\n",
            "Epoch 1008/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 1.1599 - val_accuracy: 0.9024\n",
            "Epoch 1009/2000\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.1561 - accuracy: 0.9500 - val_loss: 0.7503 - val_accuracy: 0.9268\n",
            "Epoch 1010/2000\n",
            "5/5 [==============================] - 1s 242ms/step - loss: 0.0642 - accuracy: 0.9750 - val_loss: 0.7122 - val_accuracy: 0.9268\n",
            "Epoch 1011/2000\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 0.1922 - accuracy: 0.9250 - val_loss: 0.3317 - val_accuracy: 0.9512\n",
            "Epoch 1012/2000\n",
            "5/5 [==============================] - 1s 242ms/step - loss: 0.0464 - accuracy: 1.0000 - val_loss: 0.3887 - val_accuracy: 0.9512\n",
            "Epoch 1013/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 0.7632 - val_accuracy: 0.9512\n",
            "Epoch 1014/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.0637 - accuracy: 0.9750 - val_loss: 0.9295 - val_accuracy: 0.9512\n",
            "Epoch 1015/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1509 - accuracy: 0.9250 - val_loss: 0.2404 - val_accuracy: 0.9268\n",
            "Epoch 1016/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.1162 - val_accuracy: 0.9512\n",
            "Epoch 1017/2000\n",
            "5/5 [==============================] - 1s 227ms/step - loss: 0.1243 - accuracy: 0.9500 - val_loss: 0.1148 - val_accuracy: 0.9512\n",
            "Epoch 1018/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.0417 - accuracy: 1.0000 - val_loss: 0.1290 - val_accuracy: 0.9512\n",
            "Epoch 1019/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.0870 - accuracy: 0.9750 - val_loss: 0.1769 - val_accuracy: 0.9268\n",
            "Epoch 1020/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.1170 - accuracy: 0.9250 - val_loss: 0.3624 - val_accuracy: 0.8537\n",
            "Epoch 1021/2000\n",
            "5/5 [==============================] - 1s 228ms/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 0.5509 - val_accuracy: 0.8537\n",
            "Epoch 1022/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.2654 - accuracy: 0.8500 - val_loss: 0.2253 - val_accuracy: 0.9268\n",
            "Epoch 1023/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.1275 - accuracy: 0.9750 - val_loss: 0.2658 - val_accuracy: 0.8780\n",
            "Epoch 1024/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1792 - accuracy: 0.9250 - val_loss: 0.1085 - val_accuracy: 0.9756\n",
            "Epoch 1025/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2791 - accuracy: 0.9250 - val_loss: 0.3870 - val_accuracy: 0.7805\n",
            "Epoch 1026/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.2159 - accuracy: 0.9000 - val_loss: 0.4222 - val_accuracy: 0.7073\n",
            "Epoch 1027/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2268 - accuracy: 0.9250 - val_loss: 0.1562 - val_accuracy: 0.9024\n",
            "Epoch 1028/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 1.3314 - val_accuracy: 0.8780\n",
            "Epoch 1029/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1384 - accuracy: 0.9250 - val_loss: 0.8147 - val_accuracy: 0.8537\n",
            "Epoch 1030/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.1121 - accuracy: 0.9750 - val_loss: 0.5497 - val_accuracy: 0.8780\n",
            "Epoch 1031/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.3808 - accuracy: 0.8250 - val_loss: 0.5836 - val_accuracy: 0.9268\n",
            "Epoch 1032/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0331 - accuracy: 1.0000 - val_loss: 1.6448 - val_accuracy: 0.7561\n",
            "Epoch 1033/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0602 - accuracy: 1.0000 - val_loss: 2.1759 - val_accuracy: 0.6585\n",
            "Epoch 1034/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0524 - accuracy: 0.9750 - val_loss: 1.9486 - val_accuracy: 0.7561\n",
            "Epoch 1035/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0983 - accuracy: 0.9500 - val_loss: 1.5212 - val_accuracy: 0.8537\n",
            "Epoch 1036/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1131 - accuracy: 0.9500 - val_loss: 1.1941 - val_accuracy: 0.9512\n",
            "Epoch 1037/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0898 - accuracy: 0.9500 - val_loss: 0.6720 - val_accuracy: 0.9756\n",
            "Epoch 1038/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0999 - accuracy: 0.9500 - val_loss: 0.8697 - val_accuracy: 0.9024\n",
            "Epoch 1039/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 0.7512 - val_accuracy: 0.9024\n",
            "Epoch 1040/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.9396 - val_accuracy: 0.9024\n",
            "Epoch 1041/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 1.1292 - val_accuracy: 0.8780\n",
            "Epoch 1042/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0355 - accuracy: 1.0000 - val_loss: 0.9674 - val_accuracy: 0.9268\n",
            "Epoch 1043/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0998 - accuracy: 0.9250 - val_loss: 0.1495 - val_accuracy: 0.9268\n",
            "Epoch 1044/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0625 - accuracy: 0.9750 - val_loss: 0.0816 - val_accuracy: 0.9756\n",
            "Epoch 1045/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.4411 - accuracy: 0.8750 - val_loss: 0.3058 - val_accuracy: 0.9024\n",
            "Epoch 1046/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 0.6358 - val_accuracy: 0.8049\n",
            "Epoch 1047/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1411 - accuracy: 0.9750 - val_loss: 0.8752 - val_accuracy: 0.7561\n",
            "Epoch 1048/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.2953 - accuracy: 0.9000 - val_loss: 0.3999 - val_accuracy: 0.8293\n",
            "Epoch 1049/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.1381 - accuracy: 0.9500 - val_loss: 0.0866 - val_accuracy: 0.9756\n",
            "Epoch 1050/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2610 - accuracy: 0.8750 - val_loss: 0.1004 - val_accuracy: 0.9512\n",
            "Epoch 1051/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 0.2467 - val_accuracy: 0.8537\n",
            "Epoch 1052/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0928 - accuracy: 0.9750 - val_loss: 0.1986 - val_accuracy: 0.9268\n",
            "Epoch 1053/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1561 - accuracy: 0.9500 - val_loss: 0.2040 - val_accuracy: 0.9268\n",
            "Epoch 1054/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0882 - accuracy: 0.9750 - val_loss: 0.3997 - val_accuracy: 0.8049\n",
            "Epoch 1055/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0554 - accuracy: 1.0000 - val_loss: 0.2051 - val_accuracy: 0.8780\n",
            "Epoch 1056/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 0.2766 - val_accuracy: 0.9024\n",
            "Epoch 1057/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0984 - accuracy: 0.9750 - val_loss: 0.4472 - val_accuracy: 0.9512\n",
            "Epoch 1058/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0504 - accuracy: 0.9750 - val_loss: 0.2074 - val_accuracy: 0.9512\n",
            "Epoch 1059/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0847 - accuracy: 0.9750 - val_loss: 0.0766 - val_accuracy: 0.9512\n",
            "Epoch 1060/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.0694 - accuracy: 0.9750 - val_loss: 0.1299 - val_accuracy: 0.9024\n",
            "Epoch 1061/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.1936 - accuracy: 0.9500 - val_loss: 0.1541 - val_accuracy: 0.9512\n",
            "Epoch 1062/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0520 - accuracy: 1.0000 - val_loss: 0.1161 - val_accuracy: 0.9512\n",
            "Epoch 1063/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0805 - accuracy: 0.9750 - val_loss: 0.1050 - val_accuracy: 0.9756\n",
            "Epoch 1064/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0394 - accuracy: 0.9750 - val_loss: 0.1326 - val_accuracy: 0.9512\n",
            "Epoch 1065/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0757 - accuracy: 1.0000 - val_loss: 0.2216 - val_accuracy: 0.9512\n",
            "Epoch 1066/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.0586 - accuracy: 0.9750 - val_loss: 0.4749 - val_accuracy: 0.8049\n",
            "Epoch 1067/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0994 - accuracy: 0.9500 - val_loss: 0.4520 - val_accuracy: 0.8293\n",
            "Epoch 1068/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0910 - accuracy: 0.9750 - val_loss: 0.3983 - val_accuracy: 0.8537\n",
            "Epoch 1069/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0273 - accuracy: 1.0000 - val_loss: 0.3732 - val_accuracy: 0.8780\n",
            "Epoch 1070/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.1160 - accuracy: 0.9500 - val_loss: 0.3140 - val_accuracy: 0.9024\n",
            "Epoch 1071/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 0.3733 - val_accuracy: 0.9268\n",
            "Epoch 1072/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1088 - accuracy: 0.9500 - val_loss: 0.0770 - val_accuracy: 0.9756\n",
            "Epoch 1073/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.3577 - accuracy: 0.8750 - val_loss: 0.0848 - val_accuracy: 0.9756\n",
            "Epoch 1074/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0414 - accuracy: 0.9750 - val_loss: 0.0758 - val_accuracy: 0.9756\n",
            "Epoch 1075/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0574 - accuracy: 0.9750 - val_loss: 0.1074 - val_accuracy: 0.9512\n",
            "Epoch 1076/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0617 - accuracy: 0.9750 - val_loss: 0.4794 - val_accuracy: 0.9024\n",
            "Epoch 1077/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0907 - accuracy: 0.9500 - val_loss: 0.7164 - val_accuracy: 0.9024\n",
            "Epoch 1078/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.7708 - val_accuracy: 0.8780\n",
            "Epoch 1079/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0528 - accuracy: 0.9750 - val_loss: 0.8394 - val_accuracy: 0.8293\n",
            "Epoch 1080/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0708 - accuracy: 0.9500 - val_loss: 0.7389 - val_accuracy: 0.8780\n",
            "Epoch 1081/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1459 - accuracy: 0.9750 - val_loss: 0.8781 - val_accuracy: 0.8780\n",
            "Epoch 1082/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0655 - accuracy: 0.9750 - val_loss: 0.8617 - val_accuracy: 0.8537\n",
            "Epoch 1083/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.3342 - accuracy: 0.9000 - val_loss: 0.2042 - val_accuracy: 0.9268\n",
            "Epoch 1084/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0735 - accuracy: 0.9750 - val_loss: 0.2505 - val_accuracy: 0.9024\n",
            "Epoch 1085/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.2762 - accuracy: 0.9000 - val_loss: 0.8026 - val_accuracy: 0.8537\n",
            "Epoch 1086/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.0572 - accuracy: 0.9750 - val_loss: 0.8963 - val_accuracy: 0.7805\n",
            "Epoch 1087/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.1175 - accuracy: 0.9500 - val_loss: 0.6299 - val_accuracy: 0.8780\n",
            "Epoch 1088/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0998 - accuracy: 0.9500 - val_loss: 0.5925 - val_accuracy: 0.9268\n",
            "Epoch 1089/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1602 - accuracy: 0.9750 - val_loss: 0.8657 - val_accuracy: 0.8780\n",
            "Epoch 1090/2000\n",
            "5/5 [==============================] - 1s 228ms/step - loss: 0.0379 - accuracy: 1.0000 - val_loss: 0.9223 - val_accuracy: 0.8537\n",
            "Epoch 1091/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.3090 - accuracy: 0.9250 - val_loss: 0.8227 - val_accuracy: 0.9024\n",
            "Epoch 1092/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1275 - accuracy: 0.9250 - val_loss: 0.1283 - val_accuracy: 0.9512\n",
            "Epoch 1093/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0864 - accuracy: 0.9750 - val_loss: 0.1867 - val_accuracy: 0.9268\n",
            "Epoch 1094/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.8524 - val_accuracy: 0.8293\n",
            "Epoch 1095/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1001 - accuracy: 0.9750 - val_loss: 1.1737 - val_accuracy: 0.8049\n",
            "Epoch 1096/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.2119 - accuracy: 0.8750 - val_loss: 0.5151 - val_accuracy: 0.9024\n",
            "Epoch 1097/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1221 - accuracy: 0.9250 - val_loss: 0.1223 - val_accuracy: 0.9512\n",
            "Epoch 1098/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0966 - accuracy: 0.9750 - val_loss: 0.1478 - val_accuracy: 0.9756\n",
            "Epoch 1099/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0377 - accuracy: 0.9750 - val_loss: 0.1892 - val_accuracy: 0.9268\n",
            "Epoch 1100/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1018 - accuracy: 0.9500 - val_loss: 0.2169 - val_accuracy: 0.9024\n",
            "Epoch 1101/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0543 - accuracy: 1.0000 - val_loss: 0.2213 - val_accuracy: 0.8780\n",
            "Epoch 1102/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1126 - accuracy: 0.9500 - val_loss: 0.1931 - val_accuracy: 0.9024\n",
            "Epoch 1103/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0539 - accuracy: 0.9750 - val_loss: 0.4998 - val_accuracy: 0.8780\n",
            "Epoch 1104/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0344 - accuracy: 1.0000 - val_loss: 1.0283 - val_accuracy: 0.7317\n",
            "Epoch 1105/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0725 - accuracy: 0.9750 - val_loss: 0.6957 - val_accuracy: 0.8780\n",
            "Epoch 1106/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.2075 - accuracy: 0.9250 - val_loss: 0.2343 - val_accuracy: 0.9268\n",
            "Epoch 1107/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0839 - accuracy: 0.9750 - val_loss: 0.0700 - val_accuracy: 0.9756\n",
            "Epoch 1108/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0346 - accuracy: 1.0000 - val_loss: 0.0687 - val_accuracy: 0.9756\n",
            "Epoch 1109/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0816 - accuracy: 0.9500 - val_loss: 0.1482 - val_accuracy: 0.9512\n",
            "Epoch 1110/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 0.2291 - val_accuracy: 0.9268\n",
            "Epoch 1111/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0602 - accuracy: 0.9750 - val_loss: 0.2880 - val_accuracy: 0.9268\n",
            "Epoch 1112/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0490 - accuracy: 1.0000 - val_loss: 0.2938 - val_accuracy: 0.9268\n",
            "Epoch 1113/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0334 - accuracy: 1.0000 - val_loss: 0.2564 - val_accuracy: 0.9268\n",
            "Epoch 1114/2000\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.0530 - accuracy: 0.9750 - val_loss: 0.2209 - val_accuracy: 0.9268\n",
            "Epoch 1115/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1440 - accuracy: 0.9750 - val_loss: 0.3642 - val_accuracy: 0.9268\n",
            "Epoch 1116/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0729 - accuracy: 0.9750 - val_loss: 0.4675 - val_accuracy: 0.9268\n",
            "Epoch 1117/2000\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.0343 - accuracy: 0.9750 - val_loss: 0.2614 - val_accuracy: 0.9512\n",
            "Epoch 1118/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0356 - accuracy: 1.0000 - val_loss: 0.0915 - val_accuracy: 0.9756\n",
            "Epoch 1119/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1103 - accuracy: 0.9500 - val_loss: 0.1399 - val_accuracy: 0.9512\n",
            "Epoch 1120/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.3601 - val_accuracy: 0.9024\n",
            "Epoch 1121/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2820 - accuracy: 0.9250 - val_loss: 0.5923 - val_accuracy: 0.8537\n",
            "Epoch 1122/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0580 - accuracy: 0.9500 - val_loss: 0.5070 - val_accuracy: 0.9024\n",
            "Epoch 1123/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1336 - accuracy: 0.9750 - val_loss: 0.3828 - val_accuracy: 0.9512\n",
            "Epoch 1124/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.2695 - accuracy: 0.9750 - val_loss: 0.5669 - val_accuracy: 0.9024\n",
            "Epoch 1125/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1158 - accuracy: 0.9250 - val_loss: 0.3309 - val_accuracy: 0.8780\n",
            "Epoch 1126/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0571 - accuracy: 0.9750 - val_loss: 0.2746 - val_accuracy: 0.9268\n",
            "Epoch 1127/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0590 - accuracy: 0.9750 - val_loss: 0.2128 - val_accuracy: 0.9512\n",
            "Epoch 1128/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0376 - accuracy: 0.9750 - val_loss: 0.4363 - val_accuracy: 0.8293\n",
            "Epoch 1129/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 0.7506 - val_accuracy: 0.7317\n",
            "Epoch 1130/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.8927 - val_accuracy: 0.6829\n",
            "Epoch 1131/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0577 - accuracy: 0.9750 - val_loss: 0.9748 - val_accuracy: 0.6829\n",
            "Epoch 1132/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1607 - accuracy: 0.9750 - val_loss: 0.9192 - val_accuracy: 0.6829\n",
            "Epoch 1133/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.7865 - val_accuracy: 0.7317\n",
            "Epoch 1134/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0832 - accuracy: 0.9750 - val_loss: 0.5889 - val_accuracy: 0.8293\n",
            "Epoch 1135/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.0301 - accuracy: 0.9750 - val_loss: 0.3087 - val_accuracy: 0.9024\n",
            "Epoch 1136/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1254 - accuracy: 0.9250 - val_loss: 0.2646 - val_accuracy: 0.8780\n",
            "Epoch 1137/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0614 - accuracy: 1.0000 - val_loss: 0.4515 - val_accuracy: 0.8780\n",
            "Epoch 1138/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.2506 - accuracy: 0.9250 - val_loss: 0.6119 - val_accuracy: 0.8293\n",
            "Epoch 1139/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.5280 - val_accuracy: 0.8780\n",
            "Epoch 1140/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0723 - accuracy: 0.9500 - val_loss: 0.4057 - val_accuracy: 0.8780\n",
            "Epoch 1141/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1138 - accuracy: 0.9500 - val_loss: 0.1690 - val_accuracy: 0.9756\n",
            "Epoch 1142/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1251 - accuracy: 0.9250 - val_loss: 0.0954 - val_accuracy: 1.0000\n",
            "Epoch 1143/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.2787 - accuracy: 0.9500 - val_loss: 0.2093 - val_accuracy: 0.9512\n",
            "Epoch 1144/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1154 - accuracy: 0.9750 - val_loss: 0.5565 - val_accuracy: 0.9268\n",
            "Epoch 1145/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0529 - accuracy: 0.9750 - val_loss: 0.6790 - val_accuracy: 0.8780\n",
            "Epoch 1146/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.5679 - accuracy: 0.8500 - val_loss: 0.0519 - val_accuracy: 1.0000\n",
            "Epoch 1147/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.0729 - val_accuracy: 0.9756\n",
            "Epoch 1148/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1597 - accuracy: 0.8750 - val_loss: 0.2893 - val_accuracy: 0.9268\n",
            "Epoch 1149/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0942 - accuracy: 0.9750 - val_loss: 0.6077 - val_accuracy: 0.8780\n",
            "Epoch 1150/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1287 - accuracy: 0.9250 - val_loss: 0.6324 - val_accuracy: 0.9024\n",
            "Epoch 1151/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0545 - accuracy: 0.9750 - val_loss: 0.4557 - val_accuracy: 0.9268\n",
            "Epoch 1152/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0459 - accuracy: 1.0000 - val_loss: 0.1572 - val_accuracy: 0.9512\n",
            "Epoch 1153/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.1056 - accuracy: 0.9750 - val_loss: 0.1113 - val_accuracy: 1.0000\n",
            "Epoch 1154/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0396 - accuracy: 1.0000 - val_loss: 0.0708 - val_accuracy: 1.0000\n",
            "Epoch 1155/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0898 - accuracy: 0.9750 - val_loss: 0.3691 - val_accuracy: 0.9268\n",
            "Epoch 1156/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.5737 - val_accuracy: 0.8537\n",
            "Epoch 1157/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 0.7461 - val_accuracy: 0.8537\n",
            "Epoch 1158/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.7293 - val_accuracy: 0.8537\n",
            "Epoch 1159/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0265 - accuracy: 0.9750 - val_loss: 0.6527 - val_accuracy: 0.8537\n",
            "Epoch 1160/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.6191 - val_accuracy: 0.8293\n",
            "Epoch 1161/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.6432 - val_accuracy: 0.8049\n",
            "Epoch 1162/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0452 - accuracy: 1.0000 - val_loss: 0.7583 - val_accuracy: 0.8780\n",
            "Epoch 1163/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.3140 - accuracy: 0.8750 - val_loss: 0.0546 - val_accuracy: 1.0000\n",
            "Epoch 1164/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0369 - accuracy: 1.0000 - val_loss: 0.1245 - val_accuracy: 0.9268\n",
            "Epoch 1165/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1090 - accuracy: 0.9250 - val_loss: 0.0527 - val_accuracy: 1.0000\n",
            "Epoch 1166/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.1694 - accuracy: 0.9250 - val_loss: 0.0580 - val_accuracy: 0.9512\n",
            "Epoch 1167/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0351 - accuracy: 1.0000 - val_loss: 0.4534 - val_accuracy: 0.9024\n",
            "Epoch 1168/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0503 - accuracy: 1.0000 - val_loss: 0.5022 - val_accuracy: 0.9024\n",
            "Epoch 1169/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1314 - accuracy: 0.9250 - val_loss: 0.1507 - val_accuracy: 0.9268\n",
            "Epoch 1170/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0473 - accuracy: 0.9750 - val_loss: 0.0746 - val_accuracy: 1.0000\n",
            "Epoch 1171/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.4859 - accuracy: 0.9000 - val_loss: 0.5855 - val_accuracy: 0.7561\n",
            "Epoch 1172/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.2167 - accuracy: 0.9000 - val_loss: 0.2301 - val_accuracy: 0.9024\n",
            "Epoch 1173/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2358 - accuracy: 0.9000 - val_loss: 0.5172 - val_accuracy: 0.8293\n",
            "Epoch 1174/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0719 - accuracy: 0.9750 - val_loss: 1.4055 - val_accuracy: 0.6585\n",
            "Epoch 1175/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1733 - accuracy: 0.9500 - val_loss: 1.8337 - val_accuracy: 0.6341\n",
            "Epoch 1176/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1449 - accuracy: 0.9500 - val_loss: 1.4005 - val_accuracy: 0.6585\n",
            "Epoch 1177/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1233 - accuracy: 0.9500 - val_loss: 0.4778 - val_accuracy: 0.7805\n",
            "Epoch 1178/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.2634 - accuracy: 0.9500 - val_loss: 0.4713 - val_accuracy: 0.7073\n",
            "Epoch 1179/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0379 - accuracy: 1.0000 - val_loss: 0.6395 - val_accuracy: 0.6585\n",
            "Epoch 1180/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2055 - accuracy: 0.9250 - val_loss: 1.0268 - val_accuracy: 0.6829\n",
            "Epoch 1181/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0939 - accuracy: 0.9250 - val_loss: 1.9547 - val_accuracy: 0.5610\n",
            "Epoch 1182/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 3.0245 - val_accuracy: 0.4146\n",
            "Epoch 1183/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1533 - accuracy: 0.9250 - val_loss: 2.5495 - val_accuracy: 0.6341\n",
            "Epoch 1184/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.1315 - accuracy: 0.9750 - val_loss: 1.4107 - val_accuracy: 0.7805\n",
            "Epoch 1185/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0994 - accuracy: 0.9500 - val_loss: 0.2196 - val_accuracy: 0.9512\n",
            "Epoch 1186/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0772 - accuracy: 0.9750 - val_loss: 0.1388 - val_accuracy: 1.0000\n",
            "Epoch 1187/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0580 - accuracy: 0.9750 - val_loss: 0.1294 - val_accuracy: 1.0000\n",
            "Epoch 1188/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0568 - accuracy: 0.9750 - val_loss: 0.3682 - val_accuracy: 0.9512\n",
            "Epoch 1189/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2960 - accuracy: 0.9500 - val_loss: 0.1296 - val_accuracy: 0.9756\n",
            "Epoch 1190/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0379 - accuracy: 1.0000 - val_loss: 0.2103 - val_accuracy: 0.9756\n",
            "Epoch 1191/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0838 - accuracy: 0.9750 - val_loss: 0.3678 - val_accuracy: 0.9268\n",
            "Epoch 1192/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1157 - accuracy: 0.9250 - val_loss: 0.6429 - val_accuracy: 0.9024\n",
            "Epoch 1193/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.1358 - accuracy: 0.9250 - val_loss: 1.0297 - val_accuracy: 0.8780\n",
            "Epoch 1194/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.4139 - val_accuracy: 0.8293\n",
            "Epoch 1195/2000\n",
            "5/5 [==============================] - 1s 228ms/step - loss: 0.0956 - accuracy: 0.9750 - val_loss: 0.4899 - val_accuracy: 0.8293\n",
            "Epoch 1196/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0514 - accuracy: 0.9750 - val_loss: 0.3628 - val_accuracy: 0.8537\n",
            "Epoch 1197/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0383 - accuracy: 0.9750 - val_loss: 0.3147 - val_accuracy: 0.9024\n",
            "Epoch 1198/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1397 - accuracy: 0.9500 - val_loss: 0.2934 - val_accuracy: 0.9024\n",
            "Epoch 1199/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0605 - accuracy: 0.9750 - val_loss: 0.4172 - val_accuracy: 0.9268\n",
            "Epoch 1200/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.4603 - val_accuracy: 0.9512\n",
            "Epoch 1201/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1224 - accuracy: 0.9250 - val_loss: 0.3678 - val_accuracy: 0.9512\n",
            "Epoch 1202/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0599 - accuracy: 0.9750 - val_loss: 0.5953 - val_accuracy: 0.9024\n",
            "Epoch 1203/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1055 - accuracy: 0.9750 - val_loss: 0.8121 - val_accuracy: 0.9024\n",
            "Epoch 1204/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1884 - accuracy: 0.9500 - val_loss: 0.2698 - val_accuracy: 0.9756\n",
            "Epoch 1205/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0966 - accuracy: 0.9500 - val_loss: 0.5276 - val_accuracy: 0.9756\n",
            "Epoch 1206/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0532 - accuracy: 0.9750 - val_loss: 1.5563 - val_accuracy: 0.8293\n",
            "Epoch 1207/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1183 - accuracy: 0.9750 - val_loss: 1.6283 - val_accuracy: 0.8780\n",
            "Epoch 1208/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0375 - accuracy: 1.0000 - val_loss: 0.2648 - val_accuracy: 0.9756\n",
            "Epoch 1209/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.2082 - accuracy: 0.8750 - val_loss: 0.0644 - val_accuracy: 0.9756\n",
            "Epoch 1210/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0596 - accuracy: 1.0000 - val_loss: 0.2945 - val_accuracy: 0.8293\n",
            "Epoch 1211/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.2952 - accuracy: 0.9250 - val_loss: 0.2102 - val_accuracy: 0.9268\n",
            "Epoch 1212/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 0.2300 - val_accuracy: 0.9024\n",
            "Epoch 1213/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1344 - accuracy: 0.9250 - val_loss: 0.3174 - val_accuracy: 0.8537\n",
            "Epoch 1214/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0771 - accuracy: 0.9750 - val_loss: 0.1706 - val_accuracy: 0.9024\n",
            "Epoch 1215/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2317 - accuracy: 0.9250 - val_loss: 0.0565 - val_accuracy: 0.9756\n",
            "Epoch 1216/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1427 - accuracy: 0.9500 - val_loss: 0.0462 - val_accuracy: 0.9756\n",
            "Epoch 1217/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.1361 - accuracy: 0.9500 - val_loss: 0.0459 - val_accuracy: 1.0000\n",
            "Epoch 1218/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0858 - accuracy: 0.9500 - val_loss: 0.0654 - val_accuracy: 0.9512\n",
            "Epoch 1219/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0600 - accuracy: 0.9750 - val_loss: 0.0331 - val_accuracy: 1.0000\n",
            "Epoch 1220/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0659 - accuracy: 0.9750 - val_loss: 0.0520 - val_accuracy: 0.9756\n",
            "Epoch 1221/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0279 - accuracy: 1.0000 - val_loss: 0.0624 - val_accuracy: 0.9756\n",
            "Epoch 1222/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0916 - accuracy: 0.9750 - val_loss: 0.0538 - val_accuracy: 1.0000\n",
            "Epoch 1223/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0680 - accuracy: 0.9750 - val_loss: 0.2652 - val_accuracy: 0.9024\n",
            "Epoch 1224/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.1023 - accuracy: 0.9750 - val_loss: 0.4763 - val_accuracy: 0.8537\n",
            "Epoch 1225/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2642 - accuracy: 0.9000 - val_loss: 0.6424 - val_accuracy: 0.8293\n",
            "Epoch 1226/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1435 - accuracy: 0.9500 - val_loss: 0.5097 - val_accuracy: 0.9024\n",
            "Epoch 1227/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1180 - accuracy: 0.9500 - val_loss: 0.0695 - val_accuracy: 1.0000\n",
            "Epoch 1228/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0955 - accuracy: 0.9750 - val_loss: 0.0637 - val_accuracy: 1.0000\n",
            "Epoch 1229/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.0449 - accuracy: 1.0000 - val_loss: 0.1088 - val_accuracy: 0.9756\n",
            "Epoch 1230/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0429 - accuracy: 0.9750 - val_loss: 0.4397 - val_accuracy: 0.9512\n",
            "Epoch 1231/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0664 - accuracy: 0.9500 - val_loss: 0.6058 - val_accuracy: 0.9268\n",
            "Epoch 1232/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1023 - accuracy: 0.9500 - val_loss: 0.0784 - val_accuracy: 0.9756\n",
            "Epoch 1233/2000\n",
            "5/5 [==============================] - 1s 241ms/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 1.0000\n",
            "Epoch 1234/2000\n",
            "5/5 [==============================] - 1s 245ms/step - loss: 0.0666 - accuracy: 0.9750 - val_loss: 0.0641 - val_accuracy: 0.9756\n",
            "Epoch 1235/2000\n",
            "5/5 [==============================] - 1s 248ms/step - loss: 0.1827 - accuracy: 0.9500 - val_loss: 0.1072 - val_accuracy: 0.9512\n",
            "Epoch 1236/2000\n",
            "5/5 [==============================] - 1s 249ms/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.1301 - val_accuracy: 0.9268\n",
            "Epoch 1237/2000\n",
            "5/5 [==============================] - 1s 250ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 0.0925 - val_accuracy: 0.9512\n",
            "Epoch 1238/2000\n",
            "5/5 [==============================] - 1s 248ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.0802 - val_accuracy: 0.9512\n",
            "Epoch 1239/2000\n",
            "5/5 [==============================] - 1s 248ms/step - loss: 0.0626 - accuracy: 0.9750 - val_loss: 0.1750 - val_accuracy: 0.9268\n",
            "Epoch 1240/2000\n",
            "5/5 [==============================] - 1s 250ms/step - loss: 0.0526 - accuracy: 1.0000 - val_loss: 0.2742 - val_accuracy: 0.9268\n",
            "Epoch 1241/2000\n",
            "5/5 [==============================] - 1s 245ms/step - loss: 0.0618 - accuracy: 0.9750 - val_loss: 0.1112 - val_accuracy: 0.9512\n",
            "Epoch 1242/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0273 - accuracy: 1.0000 - val_loss: 0.0482 - val_accuracy: 0.9756\n",
            "Epoch 1243/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0561 - accuracy: 0.9750 - val_loss: 0.0378 - val_accuracy: 1.0000\n",
            "Epoch 1244/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0770 - accuracy: 0.9750 - val_loss: 0.0345 - val_accuracy: 1.0000\n",
            "Epoch 1245/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0819 - accuracy: 0.9750 - val_loss: 0.0774 - val_accuracy: 0.9756\n",
            "Epoch 1246/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0354 - accuracy: 1.0000 - val_loss: 0.1218 - val_accuracy: 0.9512\n",
            "Epoch 1247/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 0.1586 - val_accuracy: 0.9268\n",
            "Epoch 1248/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1224 - accuracy: 0.9500 - val_loss: 0.4047 - val_accuracy: 0.9024\n",
            "Epoch 1249/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2882 - accuracy: 0.9000 - val_loss: 0.1195 - val_accuracy: 0.9268\n",
            "Epoch 1250/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0754 - accuracy: 0.9750 - val_loss: 0.3334 - val_accuracy: 0.9268\n",
            "Epoch 1251/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1441 - accuracy: 0.9750 - val_loss: 0.4758 - val_accuracy: 0.8537\n",
            "Epoch 1252/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0364 - accuracy: 1.0000 - val_loss: 0.1243 - val_accuracy: 0.9512\n",
            "Epoch 1253/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0386 - accuracy: 1.0000 - val_loss: 0.1376 - val_accuracy: 0.9268\n",
            "Epoch 1254/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1263 - accuracy: 0.9750 - val_loss: 0.2386 - val_accuracy: 0.9024\n",
            "Epoch 1255/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.2546 - accuracy: 0.9250 - val_loss: 0.3351 - val_accuracy: 0.7805\n",
            "Epoch 1256/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0529 - accuracy: 1.0000 - val_loss: 0.4568 - val_accuracy: 0.6829\n",
            "Epoch 1257/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.7999 - val_accuracy: 0.6098\n",
            "Epoch 1258/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0582 - accuracy: 0.9750 - val_loss: 1.4677 - val_accuracy: 0.5366\n",
            "Epoch 1259/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0571 - accuracy: 0.9750 - val_loss: 1.2204 - val_accuracy: 0.6098\n",
            "Epoch 1260/2000\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.0566 - accuracy: 1.0000 - val_loss: 0.7085 - val_accuracy: 0.6341\n",
            "Epoch 1261/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.1736 - accuracy: 0.9500 - val_loss: 0.3762 - val_accuracy: 0.7561\n",
            "Epoch 1262/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.3563 - val_accuracy: 0.9024\n",
            "Epoch 1263/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.1011 - accuracy: 0.9750 - val_loss: 0.0683 - val_accuracy: 1.0000\n",
            "Epoch 1264/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0468 - accuracy: 0.9750 - val_loss: 0.0390 - val_accuracy: 1.0000\n",
            "Epoch 1265/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0345 - accuracy: 0.9750 - val_loss: 0.0363 - val_accuracy: 1.0000\n",
            "Epoch 1266/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0522 - accuracy: 0.9750 - val_loss: 0.4403 - val_accuracy: 0.9024\n",
            "Epoch 1267/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0440 - accuracy: 1.0000 - val_loss: 1.2127 - val_accuracy: 0.7561\n",
            "Epoch 1268/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.1109 - accuracy: 0.9750 - val_loss: 1.6604 - val_accuracy: 0.6585\n",
            "Epoch 1269/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0245 - accuracy: 1.0000 - val_loss: 0.9966 - val_accuracy: 0.8049\n",
            "Epoch 1270/2000\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.9245 - val_accuracy: 0.8049\n",
            "Epoch 1271/2000\n",
            "5/5 [==============================] - 1s 241ms/step - loss: 0.3893 - accuracy: 0.9000 - val_loss: 1.3102 - val_accuracy: 0.8049\n",
            "Epoch 1272/2000\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 0.0855 - accuracy: 0.9500 - val_loss: 1.3676 - val_accuracy: 0.8049\n",
            "Epoch 1273/2000\n",
            "5/5 [==============================] - 1s 241ms/step - loss: 0.0238 - accuracy: 1.0000 - val_loss: 1.2212 - val_accuracy: 0.7805\n",
            "Epoch 1274/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.9969 - val_accuracy: 0.8049\n",
            "Epoch 1275/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0710 - accuracy: 0.9750 - val_loss: 1.0418 - val_accuracy: 0.7805\n",
            "Epoch 1276/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0540 - accuracy: 0.9500 - val_loss: 1.2061 - val_accuracy: 0.7561\n",
            "Epoch 1277/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.2161 - accuracy: 0.9500 - val_loss: 1.5140 - val_accuracy: 0.7561\n",
            "Epoch 1278/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0499 - accuracy: 0.9750 - val_loss: 1.0916 - val_accuracy: 0.7317\n",
            "Epoch 1279/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.3666 - accuracy: 0.9250 - val_loss: 0.8404 - val_accuracy: 0.8049\n",
            "Epoch 1280/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1339 - accuracy: 0.9750 - val_loss: 1.7600 - val_accuracy: 0.6829\n",
            "Epoch 1281/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0675 - accuracy: 1.0000 - val_loss: 0.4440 - val_accuracy: 0.9268\n",
            "Epoch 1282/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0918 - accuracy: 0.9500 - val_loss: 1.3166 - val_accuracy: 0.7561\n",
            "Epoch 1283/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0530 - accuracy: 0.9500 - val_loss: 1.5739 - val_accuracy: 0.6341\n",
            "Epoch 1284/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.8079 - val_accuracy: 0.5366\n",
            "Epoch 1285/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0465 - accuracy: 0.9750 - val_loss: 2.0691 - val_accuracy: 0.4878\n",
            "Epoch 1286/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 2.2211 - val_accuracy: 0.4146\n",
            "Epoch 1287/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1126 - accuracy: 0.9750 - val_loss: 1.5553 - val_accuracy: 0.5122\n",
            "Epoch 1288/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0650 - accuracy: 0.9750 - val_loss: 1.4360 - val_accuracy: 0.5122\n",
            "Epoch 1289/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0595 - accuracy: 0.9750 - val_loss: 1.2030 - val_accuracy: 0.5366\n",
            "Epoch 1290/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0650 - accuracy: 0.9750 - val_loss: 1.4680 - val_accuracy: 0.5122\n",
            "Epoch 1291/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0775 - accuracy: 0.9750 - val_loss: 1.5031 - val_accuracy: 0.4878\n",
            "Epoch 1292/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0661 - accuracy: 0.9750 - val_loss: 1.0724 - val_accuracy: 0.5610\n",
            "Epoch 1293/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0963 - accuracy: 0.9750 - val_loss: 0.7340 - val_accuracy: 0.6829\n",
            "Epoch 1294/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.1708 - accuracy: 0.8750 - val_loss: 0.7802 - val_accuracy: 0.7073\n",
            "Epoch 1295/2000\n",
            "5/5 [==============================] - 1s 228ms/step - loss: 0.2484 - accuracy: 0.9500 - val_loss: 0.7483 - val_accuracy: 0.7561\n",
            "Epoch 1296/2000\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.1332 - accuracy: 0.9250 - val_loss: 0.5982 - val_accuracy: 0.8537\n",
            "Epoch 1297/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0876 - accuracy: 0.9250 - val_loss: 1.2619 - val_accuracy: 0.8049\n",
            "Epoch 1298/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 1.6262 - val_accuracy: 0.7073\n",
            "Epoch 1299/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 1.3987 - val_accuracy: 0.7561\n",
            "Epoch 1300/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.9679 - val_accuracy: 0.8049\n",
            "Epoch 1301/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0487 - accuracy: 1.0000 - val_loss: 0.4542 - val_accuracy: 0.9024\n",
            "Epoch 1302/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0580 - accuracy: 0.9750 - val_loss: 0.2765 - val_accuracy: 0.9024\n",
            "Epoch 1303/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 0.5194 - val_accuracy: 0.8780\n",
            "Epoch 1304/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0279 - accuracy: 1.0000 - val_loss: 0.5892 - val_accuracy: 0.9024\n",
            "Epoch 1305/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1133 - accuracy: 0.9750 - val_loss: 0.5543 - val_accuracy: 0.9268\n",
            "Epoch 1306/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.4973 - val_accuracy: 0.9268\n",
            "Epoch 1307/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.1474 - accuracy: 0.9250 - val_loss: 0.0756 - val_accuracy: 0.9756\n",
            "Epoch 1308/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.3049 - accuracy: 0.9250 - val_loss: 0.5447 - val_accuracy: 0.9512\n",
            "Epoch 1309/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0396 - accuracy: 1.0000 - val_loss: 1.1558 - val_accuracy: 0.8049\n",
            "Epoch 1310/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.4544 - accuracy: 0.8750 - val_loss: 0.8922 - val_accuracy: 0.8780\n",
            "Epoch 1311/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0404 - accuracy: 0.9750 - val_loss: 0.6804 - val_accuracy: 0.8537\n",
            "Epoch 1312/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.1566 - accuracy: 0.9250 - val_loss: 0.3108 - val_accuracy: 0.8780\n",
            "Epoch 1313/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1297 - accuracy: 0.9500 - val_loss: 0.1622 - val_accuracy: 0.9512\n",
            "Epoch 1314/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.1351 - accuracy: 0.9000 - val_loss: 0.3945 - val_accuracy: 0.9268\n",
            "Epoch 1315/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.2023 - accuracy: 0.9500 - val_loss: 0.1153 - val_accuracy: 0.9512\n",
            "Epoch 1316/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.1764 - accuracy: 0.9750 - val_loss: 0.2567 - val_accuracy: 0.8780\n",
            "Epoch 1317/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.3026 - accuracy: 0.9000 - val_loss: 0.3176 - val_accuracy: 0.8780\n",
            "Epoch 1318/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.1079 - accuracy: 0.9500 - val_loss: 0.3443 - val_accuracy: 0.8780\n",
            "Epoch 1319/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1754 - accuracy: 0.9250 - val_loss: 0.2903 - val_accuracy: 0.9268\n",
            "Epoch 1320/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0803 - accuracy: 0.9250 - val_loss: 0.0833 - val_accuracy: 1.0000\n",
            "Epoch 1321/2000\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.1058 - accuracy: 0.9750 - val_loss: 0.1443 - val_accuracy: 0.9268\n",
            "Epoch 1322/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0856 - accuracy: 0.9500 - val_loss: 0.1014 - val_accuracy: 0.9512\n",
            "Epoch 1323/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0858 - accuracy: 0.9500 - val_loss: 0.0620 - val_accuracy: 1.0000\n",
            "Epoch 1324/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0631 - accuracy: 0.9750 - val_loss: 0.0253 - val_accuracy: 1.0000\n",
            "Epoch 1325/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.1503 - accuracy: 0.9000 - val_loss: 0.0248 - val_accuracy: 1.0000\n",
            "Epoch 1326/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0556 - accuracy: 0.9750 - val_loss: 0.1281 - val_accuracy: 0.9268\n",
            "Epoch 1327/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1656 - accuracy: 0.9250 - val_loss: 0.2234 - val_accuracy: 0.8780\n",
            "Epoch 1328/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0364 - accuracy: 1.0000 - val_loss: 0.3673 - val_accuracy: 0.8049\n",
            "Epoch 1329/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.3027 - val_accuracy: 0.8537\n",
            "Epoch 1330/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.2153 - val_accuracy: 0.8537\n",
            "Epoch 1331/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0645 - accuracy: 0.9500 - val_loss: 0.0928 - val_accuracy: 1.0000\n",
            "Epoch 1332/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0535 - accuracy: 0.9750 - val_loss: 0.0338 - val_accuracy: 1.0000\n",
            "Epoch 1333/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 0.0359 - val_accuracy: 1.0000\n",
            "Epoch 1334/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 0.0862 - val_accuracy: 1.0000\n",
            "Epoch 1335/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0647 - accuracy: 1.0000 - val_loss: 0.2466 - val_accuracy: 0.8780\n",
            "Epoch 1336/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0508 - accuracy: 0.9750 - val_loss: 0.3165 - val_accuracy: 0.8537\n",
            "Epoch 1337/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 0.3301 - val_accuracy: 0.8537\n",
            "Epoch 1338/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0696 - accuracy: 0.9750 - val_loss: 0.5118 - val_accuracy: 0.7805\n",
            "Epoch 1339/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1430 - accuracy: 0.9750 - val_loss: 0.4864 - val_accuracy: 0.8049\n",
            "Epoch 1340/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.4874 - val_accuracy: 0.8293\n",
            "Epoch 1341/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0619 - accuracy: 0.9750 - val_loss: 0.3351 - val_accuracy: 0.9512\n",
            "Epoch 1342/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0664 - accuracy: 0.9750 - val_loss: 0.0846 - val_accuracy: 0.9512\n",
            "Epoch 1343/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 0.1180 - val_accuracy: 0.9512\n",
            "Epoch 1344/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0660 - accuracy: 1.0000 - val_loss: 0.0595 - val_accuracy: 1.0000\n",
            "Epoch 1345/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 0.0679 - val_accuracy: 0.9756\n",
            "Epoch 1346/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0657 - accuracy: 0.9750 - val_loss: 0.3914 - val_accuracy: 0.9268\n",
            "Epoch 1347/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.0871 - accuracy: 0.9500 - val_loss: 0.6372 - val_accuracy: 0.9024\n",
            "Epoch 1348/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0562 - accuracy: 0.9750 - val_loss: 0.3746 - val_accuracy: 0.9512\n",
            "Epoch 1349/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.1924 - val_accuracy: 0.9756\n",
            "Epoch 1350/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0585 - accuracy: 0.9750 - val_loss: 0.1022 - val_accuracy: 0.9756\n",
            "Epoch 1351/2000\n",
            "5/5 [==============================] - 1s 228ms/step - loss: 0.0735 - accuracy: 0.9750 - val_loss: 0.0457 - val_accuracy: 1.0000\n",
            "Epoch 1352/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0441 - accuracy: 0.9750 - val_loss: 0.1499 - val_accuracy: 0.9024\n",
            "Epoch 1353/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.0443 - accuracy: 1.0000 - val_loss: 0.1745 - val_accuracy: 0.9024\n",
            "Epoch 1354/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1179 - accuracy: 0.9750 - val_loss: 0.1583 - val_accuracy: 0.9024\n",
            "Epoch 1355/2000\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.1012 - accuracy: 0.9750 - val_loss: 0.1913 - val_accuracy: 0.9268\n",
            "Epoch 1356/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1285 - accuracy: 0.9500 - val_loss: 0.1153 - val_accuracy: 0.9512\n",
            "Epoch 1357/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 0.0871 - val_accuracy: 0.9512\n",
            "Epoch 1358/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1059 - accuracy: 0.9750 - val_loss: 0.1234 - val_accuracy: 0.9512\n",
            "Epoch 1359/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 0.1568 - val_accuracy: 0.9268\n",
            "Epoch 1360/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0245 - accuracy: 1.0000 - val_loss: 0.1408 - val_accuracy: 0.9512\n",
            "Epoch 1361/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0978 - accuracy: 0.9750 - val_loss: 0.1392 - val_accuracy: 0.9512\n",
            "Epoch 1362/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.2974 - accuracy: 0.9250 - val_loss: 0.0863 - val_accuracy: 0.9512\n",
            "Epoch 1363/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1875 - accuracy: 0.9750 - val_loss: 0.4597 - val_accuracy: 0.8293\n",
            "Epoch 1364/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0391 - accuracy: 1.0000 - val_loss: 3.0783 - val_accuracy: 0.6585\n",
            "Epoch 1365/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0461 - accuracy: 0.9750 - val_loss: 2.9867 - val_accuracy: 0.5854\n",
            "Epoch 1366/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.2663 - accuracy: 0.9500 - val_loss: 2.9026 - val_accuracy: 0.7073\n",
            "Epoch 1367/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1103 - accuracy: 0.9750 - val_loss: 1.2016 - val_accuracy: 0.7561\n",
            "Epoch 1368/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 1.1332 - val_accuracy: 0.8049\n",
            "Epoch 1369/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.4286 - accuracy: 0.8750 - val_loss: 4.1030 - val_accuracy: 0.5610\n",
            "Epoch 1370/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.2942 - accuracy: 0.9000 - val_loss: 1.0860 - val_accuracy: 0.7805\n",
            "Epoch 1371/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0804 - accuracy: 0.9750 - val_loss: 0.6800 - val_accuracy: 0.8293\n",
            "Epoch 1372/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1479 - accuracy: 0.9750 - val_loss: 0.7003 - val_accuracy: 0.7561\n",
            "Epoch 1373/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0595 - accuracy: 0.9750 - val_loss: 1.0082 - val_accuracy: 0.6098\n",
            "Epoch 1374/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.3893 - accuracy: 0.9250 - val_loss: 0.2332 - val_accuracy: 0.8780\n",
            "Epoch 1375/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.4998 - accuracy: 0.8500 - val_loss: 0.2879 - val_accuracy: 0.8537\n",
            "Epoch 1376/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.1323 - accuracy: 0.9500 - val_loss: 1.1445 - val_accuracy: 0.8537\n",
            "Epoch 1377/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.4134 - accuracy: 0.7750 - val_loss: 0.3742 - val_accuracy: 0.8537\n",
            "Epoch 1378/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1789 - accuracy: 0.9250 - val_loss: 0.2862 - val_accuracy: 0.8780\n",
            "Epoch 1379/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1664 - accuracy: 0.9500 - val_loss: 0.1619 - val_accuracy: 0.9512\n",
            "Epoch 1380/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.1255 - accuracy: 0.9500 - val_loss: 0.1622 - val_accuracy: 0.9512\n",
            "Epoch 1381/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0449 - accuracy: 1.0000 - val_loss: 0.2534 - val_accuracy: 0.9268\n",
            "Epoch 1382/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0597 - accuracy: 1.0000 - val_loss: 0.2613 - val_accuracy: 0.9024\n",
            "Epoch 1383/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 0.2321 - val_accuracy: 0.9024\n",
            "Epoch 1384/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0685 - accuracy: 0.9750 - val_loss: 0.1608 - val_accuracy: 0.9756\n",
            "Epoch 1385/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0600 - accuracy: 0.9750 - val_loss: 0.1121 - val_accuracy: 1.0000\n",
            "Epoch 1386/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0734 - accuracy: 0.9750 - val_loss: 0.0841 - val_accuracy: 0.9756\n",
            "Epoch 1387/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.2596 - accuracy: 0.9250 - val_loss: 0.0715 - val_accuracy: 0.9756\n",
            "Epoch 1388/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.1909 - accuracy: 0.9500 - val_loss: 0.0786 - val_accuracy: 1.0000\n",
            "Epoch 1389/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0431 - accuracy: 1.0000 - val_loss: 0.0825 - val_accuracy: 1.0000\n",
            "Epoch 1390/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0525 - accuracy: 0.9750 - val_loss: 0.0946 - val_accuracy: 1.0000\n",
            "Epoch 1391/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0431 - accuracy: 1.0000 - val_loss: 0.0652 - val_accuracy: 1.0000\n",
            "Epoch 1392/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.0844 - val_accuracy: 0.9512\n",
            "Epoch 1393/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 0.1082 - val_accuracy: 0.9512\n",
            "Epoch 1394/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1079 - accuracy: 0.9750 - val_loss: 0.0605 - val_accuracy: 1.0000\n",
            "Epoch 1395/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0871 - accuracy: 0.9500 - val_loss: 0.0772 - val_accuracy: 0.9756\n",
            "Epoch 1396/2000\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.0554 - accuracy: 0.9750 - val_loss: 0.0758 - val_accuracy: 0.9756\n",
            "Epoch 1397/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0567 - accuracy: 1.0000 - val_loss: 0.0850 - val_accuracy: 1.0000\n",
            "Epoch 1398/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1421 - accuracy: 0.9750 - val_loss: 0.5592 - val_accuracy: 0.9024\n",
            "Epoch 1399/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0710 - accuracy: 0.9750 - val_loss: 1.1341 - val_accuracy: 0.8293\n",
            "Epoch 1400/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 1.2831 - val_accuracy: 0.8537\n",
            "Epoch 1401/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0885 - accuracy: 0.9500 - val_loss: 0.5828 - val_accuracy: 0.9512\n",
            "Epoch 1402/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 0.1475 - val_accuracy: 0.9756\n",
            "Epoch 1403/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0962 - accuracy: 0.9750 - val_loss: 0.3666 - val_accuracy: 0.9268\n",
            "Epoch 1404/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 0.5168 - val_accuracy: 0.9024\n",
            "Epoch 1405/2000\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.0787 - accuracy: 0.9750 - val_loss: 0.7176 - val_accuracy: 0.8537\n",
            "Epoch 1406/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.1546 - accuracy: 0.9750 - val_loss: 0.7720 - val_accuracy: 0.8537\n",
            "Epoch 1407/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 0.8662 - val_accuracy: 0.8049\n",
            "Epoch 1408/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.2024 - accuracy: 0.9000 - val_loss: 0.6841 - val_accuracy: 0.8293\n",
            "Epoch 1409/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: 0.5105 - val_accuracy: 0.8780\n",
            "Epoch 1410/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0469 - accuracy: 0.9750 - val_loss: 0.4714 - val_accuracy: 0.9024\n",
            "Epoch 1411/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0659 - accuracy: 0.9750 - val_loss: 0.5348 - val_accuracy: 0.9024\n",
            "Epoch 1412/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1203 - accuracy: 0.9750 - val_loss: 0.7171 - val_accuracy: 0.9268\n",
            "Epoch 1413/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1697 - accuracy: 0.9250 - val_loss: 0.5788 - val_accuracy: 0.9512\n",
            "Epoch 1414/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0676 - accuracy: 0.9750 - val_loss: 0.3402 - val_accuracy: 0.9512\n",
            "Epoch 1415/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0768 - accuracy: 0.9750 - val_loss: 0.7905 - val_accuracy: 0.9268\n",
            "Epoch 1416/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.0494 - accuracy: 0.9750 - val_loss: 1.2643 - val_accuracy: 0.9024\n",
            "Epoch 1417/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 0.9485 - val_accuracy: 0.9024\n",
            "Epoch 1418/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1202 - accuracy: 0.9750 - val_loss: 0.5661 - val_accuracy: 0.9268\n",
            "Epoch 1419/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0261 - accuracy: 1.0000 - val_loss: 0.1378 - val_accuracy: 0.9756\n",
            "Epoch 1420/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.0565 - val_accuracy: 1.0000\n",
            "Epoch 1421/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1249 - accuracy: 0.9250 - val_loss: 0.1306 - val_accuracy: 0.9756\n",
            "Epoch 1422/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0417 - accuracy: 1.0000 - val_loss: 0.7726 - val_accuracy: 0.9268\n",
            "Epoch 1423/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0390 - accuracy: 1.0000 - val_loss: 0.9355 - val_accuracy: 0.8780\n",
            "Epoch 1424/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0997 - accuracy: 0.9750 - val_loss: 0.9364 - val_accuracy: 0.9024\n",
            "Epoch 1425/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0379 - accuracy: 1.0000 - val_loss: 0.8525 - val_accuracy: 0.9268\n",
            "Epoch 1426/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0492 - accuracy: 0.9750 - val_loss: 0.9588 - val_accuracy: 0.9024\n",
            "Epoch 1427/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0245 - accuracy: 1.0000 - val_loss: 1.1294 - val_accuracy: 0.9024\n",
            "Epoch 1428/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0263 - accuracy: 1.0000 - val_loss: 1.2349 - val_accuracy: 0.8293\n",
            "Epoch 1429/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0327 - accuracy: 1.0000 - val_loss: 1.0366 - val_accuracy: 0.9268\n",
            "Epoch 1430/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0878 - accuracy: 0.9500 - val_loss: 2.1816 - val_accuracy: 0.7317\n",
            "Epoch 1431/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0844 - accuracy: 0.9750 - val_loss: 2.2086 - val_accuracy: 0.8537\n",
            "Epoch 1432/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1909 - accuracy: 0.8500 - val_loss: 0.4839 - val_accuracy: 0.9512\n",
            "Epoch 1433/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.0374 - accuracy: 1.0000 - val_loss: 0.3432 - val_accuracy: 0.9756\n",
            "Epoch 1434/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1210 - accuracy: 0.9750 - val_loss: 0.5318 - val_accuracy: 0.9512\n",
            "Epoch 1435/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0998 - accuracy: 0.9750 - val_loss: 0.7037 - val_accuracy: 0.9024\n",
            "Epoch 1436/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0400 - accuracy: 1.0000 - val_loss: 0.6464 - val_accuracy: 0.8049\n",
            "Epoch 1437/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0415 - accuracy: 1.0000 - val_loss: 0.5315 - val_accuracy: 0.8780\n",
            "Epoch 1438/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1808 - accuracy: 0.9250 - val_loss: 0.4640 - val_accuracy: 0.9024\n",
            "Epoch 1439/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 0.4685 - val_accuracy: 0.8537\n",
            "Epoch 1440/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0416 - accuracy: 1.0000 - val_loss: 0.5343 - val_accuracy: 0.8293\n",
            "Epoch 1441/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1276 - accuracy: 0.9500 - val_loss: 0.4405 - val_accuracy: 0.9268\n",
            "Epoch 1442/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.3271 - val_accuracy: 0.9512\n",
            "Epoch 1443/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1719 - accuracy: 0.9500 - val_loss: 0.4326 - val_accuracy: 0.9268\n",
            "Epoch 1444/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.5443 - val_accuracy: 0.8293\n",
            "Epoch 1445/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0827 - accuracy: 0.9500 - val_loss: 0.4870 - val_accuracy: 0.8537\n",
            "Epoch 1446/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1946 - accuracy: 0.9250 - val_loss: 0.3193 - val_accuracy: 0.8780\n",
            "Epoch 1447/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.3631 - val_accuracy: 0.8537\n",
            "Epoch 1448/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0372 - accuracy: 1.0000 - val_loss: 0.5425 - val_accuracy: 0.7317\n",
            "Epoch 1449/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.3064 - accuracy: 0.9250 - val_loss: 0.5856 - val_accuracy: 0.7561\n",
            "Epoch 1450/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0493 - accuracy: 0.9750 - val_loss: 0.6128 - val_accuracy: 0.8049\n",
            "Epoch 1451/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1939 - accuracy: 0.9500 - val_loss: 0.7081 - val_accuracy: 0.9268\n",
            "Epoch 1452/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1461 - accuracy: 0.9500 - val_loss: 1.0664 - val_accuracy: 0.8537\n",
            "Epoch 1453/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1185 - accuracy: 0.9500 - val_loss: 1.1475 - val_accuracy: 0.9268\n",
            "Epoch 1454/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1114 - accuracy: 0.9750 - val_loss: 1.2618 - val_accuracy: 0.8537\n",
            "Epoch 1455/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 1.4059 - val_accuracy: 0.8049\n",
            "Epoch 1456/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0487 - accuracy: 0.9750 - val_loss: 1.4229 - val_accuracy: 0.7805\n",
            "Epoch 1457/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0664 - accuracy: 0.9750 - val_loss: 1.3383 - val_accuracy: 0.8293\n",
            "Epoch 1458/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1564 - accuracy: 0.9500 - val_loss: 0.7261 - val_accuracy: 0.9268\n",
            "Epoch 1459/2000\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.0549 - accuracy: 0.9750 - val_loss: 0.1870 - val_accuracy: 0.9268\n",
            "Epoch 1460/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.1006 - accuracy: 0.9500 - val_loss: 0.3903 - val_accuracy: 0.9512\n",
            "Epoch 1461/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0784 - accuracy: 0.9500 - val_loss: 1.0594 - val_accuracy: 0.7805\n",
            "Epoch 1462/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.6287 - val_accuracy: 0.6098\n",
            "Epoch 1463/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1449 - accuracy: 0.9250 - val_loss: 1.5028 - val_accuracy: 0.7317\n",
            "Epoch 1464/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.9974 - val_accuracy: 0.8537\n",
            "Epoch 1465/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.8239 - val_accuracy: 0.9024\n",
            "Epoch 1466/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1047 - accuracy: 0.9500 - val_loss: 0.7677 - val_accuracy: 0.9024\n",
            "Epoch 1467/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1349 - accuracy: 0.9500 - val_loss: 1.2488 - val_accuracy: 0.8780\n",
            "Epoch 1468/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0965 - accuracy: 0.9500 - val_loss: 0.5634 - val_accuracy: 0.9024\n",
            "Epoch 1469/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0233 - accuracy: 1.0000 - val_loss: 0.1352 - val_accuracy: 0.9512\n",
            "Epoch 1470/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1939 - accuracy: 0.9000 - val_loss: 0.1550 - val_accuracy: 0.9512\n",
            "Epoch 1471/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1065 - accuracy: 0.9500 - val_loss: 0.0934 - val_accuracy: 0.9756\n",
            "Epoch 1472/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0511 - accuracy: 1.0000 - val_loss: 0.1391 - val_accuracy: 0.9512\n",
            "Epoch 1473/2000\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 0.0444 - accuracy: 1.0000 - val_loss: 0.2213 - val_accuracy: 0.9512\n",
            "Epoch 1474/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1252 - accuracy: 0.9750 - val_loss: 0.2793 - val_accuracy: 0.9268\n",
            "Epoch 1475/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1661 - accuracy: 0.9500 - val_loss: 0.2280 - val_accuracy: 0.9024\n",
            "Epoch 1476/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1040 - accuracy: 0.9500 - val_loss: 0.4668 - val_accuracy: 0.7561\n",
            "Epoch 1477/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.1463 - accuracy: 0.9250 - val_loss: 0.7991 - val_accuracy: 0.5610\n",
            "Epoch 1478/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1275 - accuracy: 0.9500 - val_loss: 0.3555 - val_accuracy: 0.9268\n",
            "Epoch 1479/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0450 - accuracy: 0.9750 - val_loss: 0.4816 - val_accuracy: 0.8537\n",
            "Epoch 1480/2000\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.0405 - accuracy: 0.9750 - val_loss: 0.7586 - val_accuracy: 0.7805\n",
            "Epoch 1481/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1377 - accuracy: 0.9500 - val_loss: 0.7285 - val_accuracy: 0.8537\n",
            "Epoch 1482/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0735 - accuracy: 0.9750 - val_loss: 0.7346 - val_accuracy: 0.8537\n",
            "Epoch 1483/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1250 - accuracy: 0.9250 - val_loss: 0.5613 - val_accuracy: 0.8780\n",
            "Epoch 1484/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 0.6408 - val_accuracy: 0.8780\n",
            "Epoch 1485/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.0413 - accuracy: 0.9750 - val_loss: 0.9430 - val_accuracy: 0.8780\n",
            "Epoch 1486/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.8600 - val_accuracy: 0.8293\n",
            "Epoch 1487/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0722 - accuracy: 0.9750 - val_loss: 0.8254 - val_accuracy: 0.8537\n",
            "Epoch 1488/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.8416 - val_accuracy: 0.8537\n",
            "Epoch 1489/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0687 - accuracy: 0.9500 - val_loss: 0.8975 - val_accuracy: 0.8780\n",
            "Epoch 1490/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0394 - accuracy: 0.9750 - val_loss: 0.9078 - val_accuracy: 0.9024\n",
            "Epoch 1491/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1469 - accuracy: 0.9500 - val_loss: 1.0769 - val_accuracy: 0.9756\n",
            "Epoch 1492/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0561 - accuracy: 0.9750 - val_loss: 0.3329 - val_accuracy: 0.9756\n",
            "Epoch 1493/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1729 - accuracy: 0.9250 - val_loss: 0.0435 - val_accuracy: 1.0000\n",
            "Epoch 1494/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0409 - accuracy: 0.9750 - val_loss: 0.1653 - val_accuracy: 0.9756\n",
            "Epoch 1495/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 0.5459 - val_accuracy: 0.9756\n",
            "Epoch 1496/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.3842 - accuracy: 0.9250 - val_loss: 0.7910 - val_accuracy: 0.9756\n",
            "Epoch 1497/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0670 - accuracy: 0.9750 - val_loss: 1.5624 - val_accuracy: 0.7073\n",
            "Epoch 1498/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1642 - accuracy: 0.9500 - val_loss: 0.9370 - val_accuracy: 0.8537\n",
            "Epoch 1499/2000\n",
            "5/5 [==============================] - 1s 246ms/step - loss: 0.1807 - accuracy: 0.9250 - val_loss: 0.1200 - val_accuracy: 1.0000\n",
            "Epoch 1500/2000\n",
            "5/5 [==============================] - 1s 248ms/step - loss: 0.1278 - accuracy: 0.9500 - val_loss: 0.1647 - val_accuracy: 0.9756\n",
            "Epoch 1501/2000\n",
            "5/5 [==============================] - 1s 251ms/step - loss: 0.0263 - accuracy: 1.0000 - val_loss: 0.1902 - val_accuracy: 0.9512\n",
            "Epoch 1502/2000\n",
            "5/5 [==============================] - 1s 246ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.7988 - val_accuracy: 0.8780\n",
            "Epoch 1503/2000\n",
            "5/5 [==============================] - 1s 248ms/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 1.3117 - val_accuracy: 0.8293\n",
            "Epoch 1504/2000\n",
            "5/5 [==============================] - 1s 248ms/step - loss: 0.1267 - accuracy: 0.9500 - val_loss: 1.1907 - val_accuracy: 0.8537\n",
            "Epoch 1505/2000\n",
            "5/5 [==============================] - 1s 250ms/step - loss: 0.0454 - accuracy: 1.0000 - val_loss: 1.1167 - val_accuracy: 0.8780\n",
            "Epoch 1506/2000\n",
            "5/5 [==============================] - 1s 246ms/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 0.8522 - val_accuracy: 0.8780\n",
            "Epoch 1507/2000\n",
            "5/5 [==============================] - 1s 243ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 0.7378 - val_accuracy: 0.8780\n",
            "Epoch 1508/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0644 - accuracy: 0.9500 - val_loss: 0.5891 - val_accuracy: 0.9268\n",
            "Epoch 1509/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 0.3744 - val_accuracy: 0.9268\n",
            "Epoch 1510/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0449 - accuracy: 1.0000 - val_loss: 0.3526 - val_accuracy: 0.9268\n",
            "Epoch 1511/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0884 - accuracy: 0.9750 - val_loss: 0.0419 - val_accuracy: 1.0000\n",
            "Epoch 1512/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0368 - accuracy: 1.0000 - val_loss: 0.0450 - val_accuracy: 1.0000\n",
            "Epoch 1513/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.0305 - val_accuracy: 1.0000\n",
            "Epoch 1514/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0511 - accuracy: 0.9750 - val_loss: 0.2936 - val_accuracy: 0.9756\n",
            "Epoch 1515/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0648 - accuracy: 1.0000 - val_loss: 0.7005 - val_accuracy: 0.9268\n",
            "Epoch 1516/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.0438 - val_accuracy: 0.9024\n",
            "Epoch 1517/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.0785 - accuracy: 0.9750 - val_loss: 0.5903 - val_accuracy: 0.9024\n",
            "Epoch 1518/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 0.4019 - val_accuracy: 0.9268\n",
            "Epoch 1519/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0675 - accuracy: 0.9750 - val_loss: 0.0187 - val_accuracy: 1.0000\n",
            "Epoch 1520/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 0.0579 - val_accuracy: 0.9756\n",
            "Epoch 1521/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0860 - accuracy: 0.9750 - val_loss: 0.0236 - val_accuracy: 1.0000\n",
            "Epoch 1522/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 0.9238 - val_accuracy: 0.8780\n",
            "Epoch 1523/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.2137 - accuracy: 0.9250 - val_loss: 0.8535 - val_accuracy: 0.8293\n",
            "Epoch 1524/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.0716 - accuracy: 0.9500 - val_loss: 0.5935 - val_accuracy: 0.8537\n",
            "Epoch 1525/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.1145 - accuracy: 0.9250 - val_loss: 0.0980 - val_accuracy: 0.9512\n",
            "Epoch 1526/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1444 - accuracy: 0.9500 - val_loss: 0.3686 - val_accuracy: 0.9268\n",
            "Epoch 1527/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.0740 - accuracy: 0.9500 - val_loss: 0.8031 - val_accuracy: 0.9268\n",
            "Epoch 1528/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1033 - accuracy: 0.9500 - val_loss: 1.2260 - val_accuracy: 0.8049\n",
            "Epoch 1529/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.1213 - accuracy: 0.9500 - val_loss: 1.3536 - val_accuracy: 0.7805\n",
            "Epoch 1530/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0593 - accuracy: 0.9750 - val_loss: 1.4400 - val_accuracy: 0.7805\n",
            "Epoch 1531/2000\n",
            "5/5 [==============================] - 1s 243ms/step - loss: 0.2069 - accuracy: 0.9000 - val_loss: 1.1341 - val_accuracy: 0.7805\n",
            "Epoch 1532/2000\n",
            "5/5 [==============================] - 1s 245ms/step - loss: 0.0962 - accuracy: 0.9500 - val_loss: 1.2894 - val_accuracy: 0.7073\n",
            "Epoch 1533/2000\n",
            "5/5 [==============================] - 1s 243ms/step - loss: 0.0744 - accuracy: 0.9750 - val_loss: 1.6459 - val_accuracy: 0.5610\n",
            "Epoch 1534/2000\n",
            "5/5 [==============================] - 1s 243ms/step - loss: 0.0416 - accuracy: 1.0000 - val_loss: 2.1837 - val_accuracy: 0.5610\n",
            "Epoch 1535/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0660 - accuracy: 0.9750 - val_loss: 2.1444 - val_accuracy: 0.5366\n",
            "Epoch 1536/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1352 - accuracy: 0.9750 - val_loss: 1.3380 - val_accuracy: 0.6098\n",
            "Epoch 1537/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0982 - accuracy: 0.9750 - val_loss: 0.6080 - val_accuracy: 0.8780\n",
            "Epoch 1538/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1156 - accuracy: 0.9750 - val_loss: 0.1746 - val_accuracy: 0.9512\n",
            "Epoch 1539/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.0964 - accuracy: 0.9750 - val_loss: 0.1347 - val_accuracy: 0.9756\n",
            "Epoch 1540/2000\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.0442 - accuracy: 1.0000 - val_loss: 0.6190 - val_accuracy: 0.9024\n",
            "Epoch 1541/2000\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.2314 - accuracy: 0.9250 - val_loss: 0.6542 - val_accuracy: 0.8780\n",
            "Epoch 1542/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.2933 - val_accuracy: 0.9024\n",
            "Epoch 1543/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0707 - accuracy: 0.9750 - val_loss: 0.1927 - val_accuracy: 0.9512\n",
            "Epoch 1544/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.2365 - val_accuracy: 0.9024\n",
            "Epoch 1545/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.0655 - accuracy: 0.9750 - val_loss: 0.2056 - val_accuracy: 0.9268\n",
            "Epoch 1546/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0971 - accuracy: 0.9750 - val_loss: 0.2171 - val_accuracy: 0.9268\n",
            "Epoch 1547/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0451 - accuracy: 0.9750 - val_loss: 0.1880 - val_accuracy: 0.9268\n",
            "Epoch 1548/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1359 - accuracy: 0.9500 - val_loss: 0.0658 - val_accuracy: 1.0000\n",
            "Epoch 1549/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0986 - accuracy: 0.9500 - val_loss: 0.0543 - val_accuracy: 1.0000\n",
            "Epoch 1550/2000\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.0966 - accuracy: 0.9750 - val_loss: 0.2711 - val_accuracy: 0.9268\n",
            "Epoch 1551/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1227 - accuracy: 0.9750 - val_loss: 1.0260 - val_accuracy: 0.7317\n",
            "Epoch 1552/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1582 - accuracy: 0.9000 - val_loss: 0.1832 - val_accuracy: 0.9268\n",
            "Epoch 1553/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 0.1911 - val_accuracy: 0.9024\n",
            "Epoch 1554/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.1761 - accuracy: 0.9500 - val_loss: 0.6668 - val_accuracy: 0.8049\n",
            "Epoch 1555/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.5625 - accuracy: 0.8000 - val_loss: 1.1643 - val_accuracy: 0.6098\n",
            "Epoch 1556/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.3905 - accuracy: 0.8250 - val_loss: 1.7517 - val_accuracy: 0.7317\n",
            "Epoch 1557/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0882 - accuracy: 0.9750 - val_loss: 4.0938 - val_accuracy: 0.8293\n",
            "Epoch 1558/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.2359 - accuracy: 0.9250 - val_loss: 4.4123 - val_accuracy: 0.6098\n",
            "Epoch 1559/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1563 - accuracy: 0.9250 - val_loss: 2.9958 - val_accuracy: 0.6829\n",
            "Epoch 1560/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1932 - accuracy: 0.9250 - val_loss: 1.7683 - val_accuracy: 0.8537\n",
            "Epoch 1561/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.1529 - accuracy: 0.9500 - val_loss: 1.4270 - val_accuracy: 0.7073\n",
            "Epoch 1562/2000\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.1792 - accuracy: 0.9500 - val_loss: 0.7996 - val_accuracy: 0.6341\n",
            "Epoch 1563/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0991 - accuracy: 0.9500 - val_loss: 0.7598 - val_accuracy: 0.6341\n",
            "Epoch 1564/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.1150 - accuracy: 0.9500 - val_loss: 0.6219 - val_accuracy: 0.7317\n",
            "Epoch 1565/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.2303 - accuracy: 0.9500 - val_loss: 0.5689 - val_accuracy: 0.7561\n",
            "Epoch 1566/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0380 - accuracy: 1.0000 - val_loss: 0.5286 - val_accuracy: 0.7561\n",
            "Epoch 1567/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.2055 - accuracy: 0.9000 - val_loss: 0.2763 - val_accuracy: 0.8780\n",
            "Epoch 1568/2000\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.0467 - accuracy: 0.9750 - val_loss: 0.1956 - val_accuracy: 0.9512\n",
            "Epoch 1569/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.2022 - accuracy: 0.9250 - val_loss: 0.1808 - val_accuracy: 0.9512\n",
            "Epoch 1570/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0770 - accuracy: 0.9750 - val_loss: 0.1478 - val_accuracy: 1.0000\n",
            "Epoch 1571/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1879 - accuracy: 0.9250 - val_loss: 0.1456 - val_accuracy: 0.9512\n",
            "Epoch 1572/2000\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.1027 - accuracy: 0.9500 - val_loss: 0.1616 - val_accuracy: 0.9268\n",
            "Epoch 1573/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0381 - accuracy: 1.0000 - val_loss: 0.1560 - val_accuracy: 0.9512\n",
            "Epoch 1574/2000\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.3031 - accuracy: 0.9000 - val_loss: 0.0928 - val_accuracy: 0.9756\n",
            "Epoch 1575/2000\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 0.0795 - val_accuracy: 0.9756\n",
            "Epoch 1576/2000\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.2499 - accuracy: 0.9250 - val_loss: 0.1058 - val_accuracy: 0.9756\n",
            "Epoch 1577/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0976 - accuracy: 0.9250 - val_loss: 0.2995 - val_accuracy: 0.8780\n",
            "Epoch 1578/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.3047 - accuracy: 0.8750 - val_loss: 0.7428 - val_accuracy: 0.8293\n",
            "Epoch 1579/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1974 - accuracy: 0.9000 - val_loss: 1.0481 - val_accuracy: 0.6829\n",
            "Epoch 1580/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.3474 - accuracy: 0.9000 - val_loss: 1.2301 - val_accuracy: 0.7073\n",
            "Epoch 1581/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0321 - accuracy: 0.9750 - val_loss: 0.5491 - val_accuracy: 0.8293\n",
            "Epoch 1582/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.2780 - accuracy: 0.8750 - val_loss: 0.9622 - val_accuracy: 0.5854\n",
            "Epoch 1583/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.2133 - accuracy: 0.9000 - val_loss: 1.0554 - val_accuracy: 0.6585\n",
            "Epoch 1584/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0811 - accuracy: 0.9500 - val_loss: 1.0267 - val_accuracy: 0.7317\n",
            "Epoch 1585/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.3048 - accuracy: 0.9250 - val_loss: 0.8556 - val_accuracy: 0.7805\n",
            "Epoch 1586/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.2211 - accuracy: 0.9000 - val_loss: 0.6106 - val_accuracy: 0.7805\n",
            "Epoch 1587/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1204 - accuracy: 0.9250 - val_loss: 0.2227 - val_accuracy: 0.9268\n",
            "Epoch 1588/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1539 - accuracy: 0.9250 - val_loss: 0.0796 - val_accuracy: 1.0000\n",
            "Epoch 1589/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0722 - accuracy: 0.9750 - val_loss: 0.1119 - val_accuracy: 0.9756\n",
            "Epoch 1590/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0573 - accuracy: 1.0000 - val_loss: 0.1476 - val_accuracy: 0.9756\n",
            "Epoch 1591/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.1467 - accuracy: 0.9500 - val_loss: 0.1832 - val_accuracy: 0.9024\n",
            "Epoch 1592/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0751 - accuracy: 0.9750 - val_loss: 0.4459 - val_accuracy: 0.9024\n",
            "Epoch 1593/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2069 - accuracy: 0.9250 - val_loss: 0.3536 - val_accuracy: 0.9024\n",
            "Epoch 1594/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1033 - accuracy: 0.9500 - val_loss: 0.4205 - val_accuracy: 0.8780\n",
            "Epoch 1595/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1977 - accuracy: 0.9500 - val_loss: 0.3908 - val_accuracy: 0.8780\n",
            "Epoch 1596/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 0.5878 - val_accuracy: 0.8780\n",
            "Epoch 1597/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1385 - accuracy: 0.9250 - val_loss: 0.7763 - val_accuracy: 0.8049\n",
            "Epoch 1598/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0858 - accuracy: 0.9500 - val_loss: 0.9572 - val_accuracy: 0.7561\n",
            "Epoch 1599/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.2621 - accuracy: 0.9000 - val_loss: 0.1597 - val_accuracy: 0.9512\n",
            "Epoch 1600/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0913 - accuracy: 0.9750 - val_loss: 0.1699 - val_accuracy: 0.9756\n",
            "Epoch 1601/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.2324 - accuracy: 0.9250 - val_loss: 2.3250 - val_accuracy: 0.6829\n",
            "Epoch 1602/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1315 - accuracy: 0.9500 - val_loss: 2.7816 - val_accuracy: 0.5854\n",
            "Epoch 1603/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0849 - accuracy: 0.9500 - val_loss: 1.6800 - val_accuracy: 0.6585\n",
            "Epoch 1604/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0771 - accuracy: 1.0000 - val_loss: 1.1751 - val_accuracy: 0.8293\n",
            "Epoch 1605/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1070 - accuracy: 0.9750 - val_loss: 2.1155 - val_accuracy: 0.6585\n",
            "Epoch 1606/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.1844 - accuracy: 0.9250 - val_loss: 4.3997 - val_accuracy: 0.5854\n",
            "Epoch 1607/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0976 - accuracy: 0.9750 - val_loss: 5.4144 - val_accuracy: 0.5122\n",
            "Epoch 1608/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.3420 - accuracy: 0.9250 - val_loss: 5.1197 - val_accuracy: 0.5366\n",
            "Epoch 1609/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.1975 - accuracy: 0.9250 - val_loss: 3.9759 - val_accuracy: 0.6585\n",
            "Epoch 1610/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1112 - accuracy: 0.9500 - val_loss: 2.2679 - val_accuracy: 0.7317\n",
            "Epoch 1611/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 1.7720 - val_accuracy: 0.8049\n",
            "Epoch 1612/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0686 - accuracy: 0.9750 - val_loss: 1.6726 - val_accuracy: 0.8049\n",
            "Epoch 1613/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0974 - accuracy: 0.9250 - val_loss: 0.9719 - val_accuracy: 0.8293\n",
            "Epoch 1614/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1074 - accuracy: 0.9500 - val_loss: 0.6136 - val_accuracy: 0.8537\n",
            "Epoch 1615/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.2047 - accuracy: 0.9000 - val_loss: 1.3970 - val_accuracy: 0.8293\n",
            "Epoch 1616/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0969 - accuracy: 0.9500 - val_loss: 1.5109 - val_accuracy: 0.8049\n",
            "Epoch 1617/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0872 - accuracy: 0.9750 - val_loss: 1.5891 - val_accuracy: 0.8049\n",
            "Epoch 1618/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1220 - accuracy: 0.9500 - val_loss: 0.9129 - val_accuracy: 0.8537\n",
            "Epoch 1619/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0533 - accuracy: 0.9750 - val_loss: 0.2746 - val_accuracy: 0.9268\n",
            "Epoch 1620/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.0443 - val_accuracy: 1.0000\n",
            "Epoch 1621/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1203 - accuracy: 0.9500 - val_loss: 0.0405 - val_accuracy: 1.0000\n",
            "Epoch 1622/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.2288 - val_accuracy: 0.9268\n",
            "Epoch 1623/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0655 - accuracy: 1.0000 - val_loss: 0.5195 - val_accuracy: 0.8780\n",
            "Epoch 1624/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1333 - accuracy: 0.9500 - val_loss: 0.7943 - val_accuracy: 0.7805\n",
            "Epoch 1625/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0836 - accuracy: 0.9500 - val_loss: 0.4518 - val_accuracy: 0.8293\n",
            "Epoch 1626/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1140 - accuracy: 0.9500 - val_loss: 0.8527 - val_accuracy: 0.8537\n",
            "Epoch 1627/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0954 - accuracy: 0.9750 - val_loss: 4.2755 - val_accuracy: 0.5854\n",
            "Epoch 1628/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.1094 - accuracy: 0.9750 - val_loss: 3.6264 - val_accuracy: 0.5610\n",
            "Epoch 1629/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0495 - accuracy: 0.9750 - val_loss: 3.0917 - val_accuracy: 0.5122\n",
            "Epoch 1630/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1262 - accuracy: 0.9500 - val_loss: 2.0887 - val_accuracy: 0.6341\n",
            "Epoch 1631/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1098 - accuracy: 0.9750 - val_loss: 1.4212 - val_accuracy: 0.7073\n",
            "Epoch 1632/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1543 - accuracy: 0.9500 - val_loss: 0.2493 - val_accuracy: 0.9024\n",
            "Epoch 1633/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.0830 - accuracy: 0.9750 - val_loss: 0.3519 - val_accuracy: 0.8293\n",
            "Epoch 1634/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1823 - accuracy: 0.9500 - val_loss: 0.4031 - val_accuracy: 0.8537\n",
            "Epoch 1635/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1456 - accuracy: 0.9000 - val_loss: 2.6997 - val_accuracy: 0.6829\n",
            "Epoch 1636/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.2911 - accuracy: 0.9000 - val_loss: 4.5282 - val_accuracy: 0.4878\n",
            "Epoch 1637/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.1251 - accuracy: 0.9500 - val_loss: 1.6814 - val_accuracy: 0.5854\n",
            "Epoch 1638/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.2066 - accuracy: 0.9000 - val_loss: 0.5253 - val_accuracy: 0.8293\n",
            "Epoch 1639/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1375 - accuracy: 0.9250 - val_loss: 1.0588 - val_accuracy: 0.7317\n",
            "Epoch 1640/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1953 - accuracy: 0.9000 - val_loss: 0.5592 - val_accuracy: 0.7317\n",
            "Epoch 1641/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0626 - accuracy: 1.0000 - val_loss: 0.5623 - val_accuracy: 0.8049\n",
            "Epoch 1642/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1645 - accuracy: 0.9500 - val_loss: 2.2041 - val_accuracy: 0.7073\n",
            "Epoch 1643/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 3.3583 - val_accuracy: 0.6585\n",
            "Epoch 1644/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0925 - accuracy: 0.9750 - val_loss: 1.2168 - val_accuracy: 0.7561\n",
            "Epoch 1645/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.1018 - accuracy: 0.9750 - val_loss: 1.2423 - val_accuracy: 0.6829\n",
            "Epoch 1646/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.0474 - accuracy: 0.9750 - val_loss: 1.7727 - val_accuracy: 0.7073\n",
            "Epoch 1647/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0524 - accuracy: 1.0000 - val_loss: 1.4002 - val_accuracy: 0.7317\n",
            "Epoch 1648/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 1.7678 - val_accuracy: 0.6829\n",
            "Epoch 1649/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 2.2806 - val_accuracy: 0.6829\n",
            "Epoch 1650/2000\n",
            "5/5 [==============================] - 1s 228ms/step - loss: 0.0556 - accuracy: 0.9750 - val_loss: 2.7081 - val_accuracy: 0.6585\n",
            "Epoch 1651/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.0346 - accuracy: 1.0000 - val_loss: 4.6711 - val_accuracy: 0.5854\n",
            "Epoch 1652/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.1787 - accuracy: 0.9000 - val_loss: 5.4782 - val_accuracy: 0.5854\n",
            "Epoch 1653/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.0773 - accuracy: 0.9500 - val_loss: 1.7183 - val_accuracy: 0.7073\n",
            "Epoch 1654/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 1.8053 - val_accuracy: 0.7561\n",
            "Epoch 1655/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0595 - accuracy: 0.9750 - val_loss: 1.7438 - val_accuracy: 0.7073\n",
            "Epoch 1656/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0430 - accuracy: 1.0000 - val_loss: 1.6780 - val_accuracy: 0.7073\n",
            "Epoch 1657/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 2.5125 - val_accuracy: 0.7317\n",
            "Epoch 1658/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 3.5479 - val_accuracy: 0.7073\n",
            "Epoch 1659/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.2701 - accuracy: 0.9500 - val_loss: 3.4421 - val_accuracy: 0.6829\n",
            "Epoch 1660/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0725 - accuracy: 0.9750 - val_loss: 2.1016 - val_accuracy: 0.7317\n",
            "Epoch 1661/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 1.5610 - val_accuracy: 0.7073\n",
            "Epoch 1662/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.0843 - accuracy: 0.9750 - val_loss: 1.2406 - val_accuracy: 0.7561\n",
            "Epoch 1663/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1002 - accuracy: 0.9500 - val_loss: 1.8844 - val_accuracy: 0.7073\n",
            "Epoch 1664/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 4.3341 - val_accuracy: 0.5854\n",
            "Epoch 1665/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0652 - accuracy: 1.0000 - val_loss: 5.9183 - val_accuracy: 0.5122\n",
            "Epoch 1666/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0814 - accuracy: 0.9500 - val_loss: 7.3239 - val_accuracy: 0.5366\n",
            "Epoch 1667/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0878 - accuracy: 0.9500 - val_loss: 7.2555 - val_accuracy: 0.5610\n",
            "Epoch 1668/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1113 - accuracy: 0.9500 - val_loss: 4.8046 - val_accuracy: 0.7073\n",
            "Epoch 1669/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.1675 - accuracy: 0.9500 - val_loss: 1.7283 - val_accuracy: 0.7805\n",
            "Epoch 1670/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 0.0801 - val_accuracy: 0.9756\n",
            "Epoch 1671/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 0.1241 - val_accuracy: 0.9268\n",
            "Epoch 1672/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2197 - accuracy: 0.9500 - val_loss: 0.1618 - val_accuracy: 0.9512\n",
            "Epoch 1673/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1350 - accuracy: 0.9500 - val_loss: 3.2249 - val_accuracy: 0.7073\n",
            "Epoch 1674/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 5.4050 - val_accuracy: 0.6585\n",
            "Epoch 1675/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 2.8808 - val_accuracy: 0.6098\n",
            "Epoch 1676/2000\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 0.1328 - accuracy: 0.9500 - val_loss: 1.2466 - val_accuracy: 0.7561\n",
            "Epoch 1677/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0536 - accuracy: 1.0000 - val_loss: 0.7780 - val_accuracy: 0.8049\n",
            "Epoch 1678/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1125 - accuracy: 0.9750 - val_loss: 1.6996 - val_accuracy: 0.7805\n",
            "Epoch 1679/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1410 - accuracy: 0.9250 - val_loss: 2.6363 - val_accuracy: 0.5610\n",
            "Epoch 1680/2000\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.3866 - accuracy: 0.8500 - val_loss: 2.1984 - val_accuracy: 0.5610\n",
            "Epoch 1681/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0919 - accuracy: 0.9750 - val_loss: 0.3376 - val_accuracy: 0.9268\n",
            "Epoch 1682/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1414 - accuracy: 0.9500 - val_loss: 0.0782 - val_accuracy: 0.9756\n",
            "Epoch 1683/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1546 - accuracy: 0.9500 - val_loss: 0.2693 - val_accuracy: 0.9268\n",
            "Epoch 1684/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1078 - accuracy: 0.9500 - val_loss: 0.5251 - val_accuracy: 0.9024\n",
            "Epoch 1685/2000\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.1015 - accuracy: 0.9500 - val_loss: 0.7441 - val_accuracy: 0.9024\n",
            "Epoch 1686/2000\n",
            "5/5 [==============================] - 1s 228ms/step - loss: 0.1519 - accuracy: 0.9250 - val_loss: 0.6721 - val_accuracy: 0.8293\n",
            "Epoch 1687/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0542 - accuracy: 1.0000 - val_loss: 0.6063 - val_accuracy: 0.8780\n",
            "Epoch 1688/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0461 - accuracy: 1.0000 - val_loss: 0.5735 - val_accuracy: 0.9024\n",
            "Epoch 1689/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.6899 - val_accuracy: 0.8537\n",
            "Epoch 1690/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0503 - accuracy: 0.9750 - val_loss: 0.9676 - val_accuracy: 0.8049\n",
            "Epoch 1691/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0631 - accuracy: 0.9750 - val_loss: 0.3843 - val_accuracy: 0.8537\n",
            "Epoch 1692/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0311 - accuracy: 1.0000 - val_loss: 0.3697 - val_accuracy: 0.8780\n",
            "Epoch 1693/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.4987 - val_accuracy: 0.8537\n",
            "Epoch 1694/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.8905 - val_accuracy: 0.8049\n",
            "Epoch 1695/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0341 - accuracy: 0.9750 - val_loss: 0.5924 - val_accuracy: 0.8537\n",
            "Epoch 1696/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.4282 - val_accuracy: 0.8780\n",
            "Epoch 1697/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0548 - accuracy: 0.9750 - val_loss: 0.0652 - val_accuracy: 0.9756\n",
            "Epoch 1698/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0347 - accuracy: 1.0000 - val_loss: 0.0355 - val_accuracy: 1.0000\n",
            "Epoch 1699/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.2002 - accuracy: 0.9500 - val_loss: 0.0541 - val_accuracy: 1.0000\n",
            "Epoch 1700/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0434 - accuracy: 1.0000 - val_loss: 0.0270 - val_accuracy: 1.0000\n",
            "Epoch 1701/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.1560 - accuracy: 0.9250 - val_loss: 0.2193 - val_accuracy: 0.9512\n",
            "Epoch 1702/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0516 - accuracy: 1.0000 - val_loss: 0.4854 - val_accuracy: 0.9268\n",
            "Epoch 1703/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0496 - accuracy: 0.9750 - val_loss: 0.5889 - val_accuracy: 0.9024\n",
            "Epoch 1704/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.4958 - val_accuracy: 0.9024\n",
            "Epoch 1705/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.4806 - val_accuracy: 0.8293\n",
            "Epoch 1706/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0624 - accuracy: 0.9750 - val_loss: 0.3283 - val_accuracy: 0.8293\n",
            "Epoch 1707/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1076 - accuracy: 0.9750 - val_loss: 0.0362 - val_accuracy: 1.0000\n",
            "Epoch 1708/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 0.0489 - val_accuracy: 1.0000\n",
            "Epoch 1709/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0804 - accuracy: 0.9750 - val_loss: 0.0263 - val_accuracy: 1.0000\n",
            "Epoch 1710/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0442 - accuracy: 0.9750 - val_loss: 0.0946 - val_accuracy: 0.9756\n",
            "Epoch 1711/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1001 - accuracy: 0.9500 - val_loss: 0.0841 - val_accuracy: 0.9512\n",
            "Epoch 1712/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1155 - accuracy: 0.9000 - val_loss: 0.0395 - val_accuracy: 1.0000\n",
            "Epoch 1713/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1568 - accuracy: 0.9500 - val_loss: 0.0647 - val_accuracy: 0.9756\n",
            "Epoch 1714/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0762 - accuracy: 0.9750 - val_loss: 0.0252 - val_accuracy: 1.0000\n",
            "Epoch 1715/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.1853 - accuracy: 0.9000 - val_loss: 0.0670 - val_accuracy: 0.9512\n",
            "Epoch 1716/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0466 - accuracy: 0.9750 - val_loss: 0.2593 - val_accuracy: 0.9024\n",
            "Epoch 1717/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1109 - accuracy: 0.9500 - val_loss: 0.3236 - val_accuracy: 0.9024\n",
            "Epoch 1718/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0572 - accuracy: 0.9750 - val_loss: 0.0722 - val_accuracy: 0.9512\n",
            "Epoch 1719/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0862 - accuracy: 0.9750 - val_loss: 0.1815 - val_accuracy: 0.9268\n",
            "Epoch 1720/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0335 - accuracy: 1.0000 - val_loss: 3.7249 - val_accuracy: 0.5122\n",
            "Epoch 1721/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.2080 - accuracy: 0.9250 - val_loss: 0.1761 - val_accuracy: 0.9268\n",
            "Epoch 1722/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2283 - accuracy: 0.8750 - val_loss: 0.4119 - val_accuracy: 0.8293\n",
            "Epoch 1723/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.3370 - accuracy: 0.9250 - val_loss: 1.3038 - val_accuracy: 0.8537\n",
            "Epoch 1724/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.2071 - accuracy: 0.9250 - val_loss: 0.5903 - val_accuracy: 0.8049\n",
            "Epoch 1725/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0516 - accuracy: 1.0000 - val_loss: 0.3103 - val_accuracy: 0.8537\n",
            "Epoch 1726/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.2844 - accuracy: 0.9250 - val_loss: 0.1585 - val_accuracy: 0.9268\n",
            "Epoch 1727/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0598 - accuracy: 0.9750 - val_loss: 0.1263 - val_accuracy: 0.9512\n",
            "Epoch 1728/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1115 - accuracy: 0.9500 - val_loss: 0.1491 - val_accuracy: 0.9512\n",
            "Epoch 1729/2000\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.2573 - accuracy: 0.9250 - val_loss: 0.3939 - val_accuracy: 0.8537\n",
            "Epoch 1730/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2332 - accuracy: 0.9250 - val_loss: 0.2064 - val_accuracy: 0.9268\n",
            "Epoch 1731/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1561 - accuracy: 0.9250 - val_loss: 0.1396 - val_accuracy: 0.9024\n",
            "Epoch 1732/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0577 - accuracy: 1.0000 - val_loss: 0.1607 - val_accuracy: 0.9268\n",
            "Epoch 1733/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.2283 - accuracy: 0.9500 - val_loss: 0.1576 - val_accuracy: 0.9024\n",
            "Epoch 1734/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.2191 - accuracy: 0.9250 - val_loss: 0.1799 - val_accuracy: 0.9024\n",
            "Epoch 1735/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.2550 - accuracy: 0.9000 - val_loss: 0.1198 - val_accuracy: 0.9512\n",
            "Epoch 1736/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1392 - accuracy: 0.9500 - val_loss: 0.1126 - val_accuracy: 0.9512\n",
            "Epoch 1737/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0273 - accuracy: 1.0000 - val_loss: 0.2460 - val_accuracy: 0.9024\n",
            "Epoch 1738/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1230 - accuracy: 0.9500 - val_loss: 0.1728 - val_accuracy: 0.9268\n",
            "Epoch 1739/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 0.0629 - val_accuracy: 0.9756\n",
            "Epoch 1740/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0835 - accuracy: 0.9500 - val_loss: 0.0657 - val_accuracy: 0.9756\n",
            "Epoch 1741/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1374 - accuracy: 0.9250 - val_loss: 0.3534 - val_accuracy: 0.9268\n",
            "Epoch 1742/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.2533 - accuracy: 0.9250 - val_loss: 0.2501 - val_accuracy: 0.9024\n",
            "Epoch 1743/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.3978 - val_accuracy: 0.8537\n",
            "Epoch 1744/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.3483 - accuracy: 0.9000 - val_loss: 0.3632 - val_accuracy: 0.8537\n",
            "Epoch 1745/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1032 - accuracy: 0.9000 - val_loss: 0.3430 - val_accuracy: 0.8293\n",
            "Epoch 1746/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.8642 - val_accuracy: 0.8293\n",
            "Epoch 1747/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1124 - accuracy: 0.9500 - val_loss: 0.9462 - val_accuracy: 0.8293\n",
            "Epoch 1748/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0452 - accuracy: 1.0000 - val_loss: 0.4965 - val_accuracy: 0.8537\n",
            "Epoch 1749/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 0.3927 - val_accuracy: 0.9268\n",
            "Epoch 1750/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.2299 - accuracy: 0.9250 - val_loss: 0.7189 - val_accuracy: 0.7561\n",
            "Epoch 1751/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0306 - accuracy: 0.9750 - val_loss: 0.9138 - val_accuracy: 0.6585\n",
            "Epoch 1752/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0855 - accuracy: 0.9500 - val_loss: 0.9228 - val_accuracy: 0.6341\n",
            "Epoch 1753/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 0.6067 - val_accuracy: 0.7317\n",
            "Epoch 1754/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1008 - accuracy: 0.9750 - val_loss: 0.7263 - val_accuracy: 0.8780\n",
            "Epoch 1755/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.9872 - val_accuracy: 0.8780\n",
            "Epoch 1756/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1045 - accuracy: 0.9250 - val_loss: 0.8639 - val_accuracy: 0.8780\n",
            "Epoch 1757/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.1359 - accuracy: 0.9500 - val_loss: 2.1502 - val_accuracy: 0.7561\n",
            "Epoch 1758/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1602 - accuracy: 0.9750 - val_loss: 3.3729 - val_accuracy: 0.6585\n",
            "Epoch 1759/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1009 - accuracy: 0.9500 - val_loss: 1.1929 - val_accuracy: 0.8293\n",
            "Epoch 1760/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0523 - accuracy: 0.9750 - val_loss: 0.4338 - val_accuracy: 0.9512\n",
            "Epoch 1761/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0362 - accuracy: 1.0000 - val_loss: 0.5842 - val_accuracy: 0.9268\n",
            "Epoch 1762/2000\n",
            "5/5 [==============================] - 1s 227ms/step - loss: 0.1473 - accuracy: 0.9500 - val_loss: 1.1596 - val_accuracy: 0.7805\n",
            "Epoch 1763/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.1192 - accuracy: 0.9500 - val_loss: 2.4727 - val_accuracy: 0.7561\n",
            "Epoch 1764/2000\n",
            "5/5 [==============================] - 1s 243ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 4.5512 - val_accuracy: 0.6098\n",
            "Epoch 1765/2000\n",
            "5/5 [==============================] - 1s 246ms/step - loss: 0.0767 - accuracy: 0.9750 - val_loss: 6.8868 - val_accuracy: 0.5854\n",
            "Epoch 1766/2000\n",
            "5/5 [==============================] - 1s 250ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 8.3829 - val_accuracy: 0.5854\n",
            "Epoch 1767/2000\n",
            "5/5 [==============================] - 1s 248ms/step - loss: 0.0437 - accuracy: 0.9750 - val_loss: 8.6277 - val_accuracy: 0.5366\n",
            "Epoch 1768/2000\n",
            "5/5 [==============================] - 1s 253ms/step - loss: 0.1654 - accuracy: 0.9500 - val_loss: 6.9165 - val_accuracy: 0.5854\n",
            "Epoch 1769/2000\n",
            "5/5 [==============================] - 1s 247ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 5.8844 - val_accuracy: 0.5854\n",
            "Epoch 1770/2000\n",
            "5/5 [==============================] - 1s 249ms/step - loss: 0.0502 - accuracy: 0.9750 - val_loss: 2.2262 - val_accuracy: 0.7317\n",
            "Epoch 1771/2000\n",
            "5/5 [==============================] - 1s 250ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 0.2075 - val_accuracy: 0.9268\n",
            "Epoch 1772/2000\n",
            "5/5 [==============================] - 1s 245ms/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 0.0942 - val_accuracy: 0.9756\n",
            "Epoch 1773/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0487 - accuracy: 0.9750 - val_loss: 0.0856 - val_accuracy: 0.9756\n",
            "Epoch 1774/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.0665 - val_accuracy: 0.9756\n",
            "Epoch 1775/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0342 - accuracy: 1.0000 - val_loss: 0.0531 - val_accuracy: 0.9756\n",
            "Epoch 1776/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.1354 - accuracy: 0.9750 - val_loss: 0.0873 - val_accuracy: 0.9756\n",
            "Epoch 1777/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.0540 - accuracy: 1.0000 - val_loss: 0.1629 - val_accuracy: 0.9268\n",
            "Epoch 1778/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.1881 - val_accuracy: 0.9268\n",
            "Epoch 1779/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.2788 - accuracy: 0.9500 - val_loss: 0.0855 - val_accuracy: 0.9756\n",
            "Epoch 1780/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0633 - accuracy: 0.9750 - val_loss: 0.0555 - val_accuracy: 0.9756\n",
            "Epoch 1781/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.1528 - val_accuracy: 0.9512\n",
            "Epoch 1782/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.2446 - val_accuracy: 0.9268\n",
            "Epoch 1783/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.2762 - accuracy: 0.8750 - val_loss: 0.2979 - val_accuracy: 0.9024\n",
            "Epoch 1784/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1208 - accuracy: 0.9500 - val_loss: 0.2581 - val_accuracy: 0.9024\n",
            "Epoch 1785/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.3189 - accuracy: 0.9500 - val_loss: 0.4329 - val_accuracy: 0.9024\n",
            "Epoch 1786/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0448 - accuracy: 1.0000 - val_loss: 1.3323 - val_accuracy: 0.8049\n",
            "Epoch 1787/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1486 - accuracy: 0.9750 - val_loss: 0.2616 - val_accuracy: 0.9268\n",
            "Epoch 1788/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2458 - accuracy: 0.9750 - val_loss: 0.0518 - val_accuracy: 0.9756\n",
            "Epoch 1789/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0365 - accuracy: 0.9750 - val_loss: 0.2427 - val_accuracy: 0.8780\n",
            "Epoch 1790/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.3681 - val_accuracy: 0.8049\n",
            "Epoch 1791/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.4453 - val_accuracy: 0.8049\n",
            "Epoch 1792/2000\n",
            "5/5 [==============================] - 1s 244ms/step - loss: 0.1799 - accuracy: 0.9500 - val_loss: 0.1479 - val_accuracy: 0.9512\n",
            "Epoch 1793/2000\n",
            "5/5 [==============================] - 1s 242ms/step - loss: 0.0337 - accuracy: 1.0000 - val_loss: 0.0690 - val_accuracy: 0.9512\n",
            "Epoch 1794/2000\n",
            "5/5 [==============================] - 1s 241ms/step - loss: 0.1281 - accuracy: 0.9500 - val_loss: 0.0648 - val_accuracy: 0.9756\n",
            "Epoch 1795/2000\n",
            "5/5 [==============================] - 1s 240ms/step - loss: 0.0403 - accuracy: 1.0000 - val_loss: 0.0696 - val_accuracy: 0.9512\n",
            "Epoch 1796/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.1296 - accuracy: 0.9500 - val_loss: 0.0487 - val_accuracy: 1.0000\n",
            "Epoch 1797/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0989 - accuracy: 0.9500 - val_loss: 0.1122 - val_accuracy: 0.9512\n",
            "Epoch 1798/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.7411 - val_accuracy: 0.8537\n",
            "Epoch 1799/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.2422 - accuracy: 0.9000 - val_loss: 0.1587 - val_accuracy: 0.9512\n",
            "Epoch 1800/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1396 - accuracy: 0.9750 - val_loss: 0.2457 - val_accuracy: 0.9024\n",
            "Epoch 1801/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1513 - accuracy: 0.9500 - val_loss: 0.2974 - val_accuracy: 0.9024\n",
            "Epoch 1802/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.0760 - accuracy: 0.9750 - val_loss: 0.4809 - val_accuracy: 0.8293\n",
            "Epoch 1803/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1655 - accuracy: 0.9500 - val_loss: 0.1590 - val_accuracy: 0.9268\n",
            "Epoch 1804/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.0526 - accuracy: 1.0000 - val_loss: 0.0847 - val_accuracy: 0.9756\n",
            "Epoch 1805/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0394 - accuracy: 0.9750 - val_loss: 0.0898 - val_accuracy: 0.9756\n",
            "Epoch 1806/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0460 - accuracy: 0.9750 - val_loss: 0.1164 - val_accuracy: 0.9512\n",
            "Epoch 1807/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1717 - accuracy: 0.9500 - val_loss: 0.1348 - val_accuracy: 0.9512\n",
            "Epoch 1808/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0430 - accuracy: 1.0000 - val_loss: 0.2086 - val_accuracy: 0.8780\n",
            "Epoch 1809/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.2834 - accuracy: 0.9000 - val_loss: 0.1448 - val_accuracy: 0.9512\n",
            "Epoch 1810/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.2661 - val_accuracy: 0.8537\n",
            "Epoch 1811/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0344 - accuracy: 1.0000 - val_loss: 0.1126 - val_accuracy: 0.9756\n",
            "Epoch 1812/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0519 - accuracy: 0.9750 - val_loss: 0.0625 - val_accuracy: 0.9756\n",
            "Epoch 1813/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0831 - accuracy: 0.9750 - val_loss: 0.1020 - val_accuracy: 0.9756\n",
            "Epoch 1814/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0321 - accuracy: 1.0000 - val_loss: 0.1991 - val_accuracy: 0.9024\n",
            "Epoch 1815/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0279 - accuracy: 1.0000 - val_loss: 0.1793 - val_accuracy: 0.9268\n",
            "Epoch 1816/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1453 - accuracy: 0.9750 - val_loss: 0.2477 - val_accuracy: 0.9268\n",
            "Epoch 1817/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0743 - accuracy: 0.9750 - val_loss: 0.3502 - val_accuracy: 0.8537\n",
            "Epoch 1818/2000\n",
            "5/5 [==============================] - 1s 226ms/step - loss: 0.0684 - accuracy: 1.0000 - val_loss: 0.1166 - val_accuracy: 0.9756\n",
            "Epoch 1819/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.1116 - accuracy: 0.9500 - val_loss: 0.0739 - val_accuracy: 0.9756\n",
            "Epoch 1820/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.1188 - accuracy: 0.9500 - val_loss: 0.1417 - val_accuracy: 0.9268\n",
            "Epoch 1821/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0604 - accuracy: 0.9750 - val_loss: 1.3056 - val_accuracy: 0.7561\n",
            "Epoch 1822/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0674 - accuracy: 1.0000 - val_loss: 3.7259 - val_accuracy: 0.6829\n",
            "Epoch 1823/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0623 - accuracy: 0.9750 - val_loss: 7.2199 - val_accuracy: 0.6098\n",
            "Epoch 1824/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1641 - accuracy: 0.8750 - val_loss: 7.2838 - val_accuracy: 0.5854\n",
            "Epoch 1825/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 4.9364 - val_accuracy: 0.7317\n",
            "Epoch 1826/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0644 - accuracy: 0.9750 - val_loss: 5.7039 - val_accuracy: 0.6829\n",
            "Epoch 1827/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0672 - accuracy: 0.9500 - val_loss: 7.3051 - val_accuracy: 0.6341\n",
            "Epoch 1828/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0343 - accuracy: 0.9750 - val_loss: 3.4849 - val_accuracy: 0.7317\n",
            "Epoch 1829/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.0791 - accuracy: 0.9750 - val_loss: 0.2002 - val_accuracy: 0.9268\n",
            "Epoch 1830/2000\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.0457 - accuracy: 0.9750 - val_loss: 0.0569 - val_accuracy: 0.9756\n",
            "Epoch 1831/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.0918 - accuracy: 0.9750 - val_loss: 0.2318 - val_accuracy: 0.9512\n",
            "Epoch 1832/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0783 - accuracy: 0.9500 - val_loss: 0.2167 - val_accuracy: 0.9512\n",
            "Epoch 1833/2000\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.0555 - accuracy: 0.9750 - val_loss: 0.2384 - val_accuracy: 0.9512\n",
            "Epoch 1834/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.3170 - val_accuracy: 0.9512\n",
            "Epoch 1835/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0768 - accuracy: 0.9750 - val_loss: 0.1001 - val_accuracy: 0.9512\n",
            "Epoch 1836/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1473 - accuracy: 0.9250 - val_loss: 0.0275 - val_accuracy: 0.9756\n",
            "Epoch 1837/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0383 - accuracy: 0.9750 - val_loss: 0.0232 - val_accuracy: 1.0000\n",
            "Epoch 1838/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0303 - accuracy: 0.9750 - val_loss: 0.0259 - val_accuracy: 1.0000\n",
            "Epoch 1839/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0851 - accuracy: 0.9500 - val_loss: 0.0657 - val_accuracy: 0.9756\n",
            "Epoch 1840/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0532 - accuracy: 1.0000 - val_loss: 0.1026 - val_accuracy: 0.9756\n",
            "Epoch 1841/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 0.1596 - val_accuracy: 0.9268\n",
            "Epoch 1842/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.2040 - val_accuracy: 0.9268\n",
            "Epoch 1843/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1756 - accuracy: 0.9250 - val_loss: 0.1114 - val_accuracy: 0.9756\n",
            "Epoch 1844/2000\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.1064 - accuracy: 0.9750 - val_loss: 0.0640 - val_accuracy: 0.9756\n",
            "Epoch 1845/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1021 - accuracy: 0.9750 - val_loss: 0.0414 - val_accuracy: 0.9756\n",
            "Epoch 1846/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 0.0325 - val_accuracy: 1.0000\n",
            "Epoch 1847/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.0345 - val_accuracy: 1.0000\n",
            "Epoch 1848/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.1399 - accuracy: 0.9500 - val_loss: 0.0890 - val_accuracy: 0.9756\n",
            "Epoch 1849/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0439 - accuracy: 0.9750 - val_loss: 0.0975 - val_accuracy: 0.9512\n",
            "Epoch 1850/2000\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.0293 - val_accuracy: 1.0000\n",
            "Epoch 1851/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0278 - accuracy: 1.0000 - val_loss: 0.0317 - val_accuracy: 1.0000\n",
            "Epoch 1852/2000\n",
            "5/5 [==============================] - 1s 239ms/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.0359 - val_accuracy: 1.0000\n",
            "Epoch 1853/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0441 - accuracy: 1.0000 - val_loss: 0.0305 - val_accuracy: 1.0000\n",
            "Epoch 1854/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0604 - accuracy: 0.9500 - val_loss: 0.0236 - val_accuracy: 1.0000\n",
            "Epoch 1855/2000\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.0979 - accuracy: 0.9500 - val_loss: 0.1133 - val_accuracy: 0.9268\n",
            "Epoch 1856/2000\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.0605 - accuracy: 0.9750 - val_loss: 0.2020 - val_accuracy: 0.9268\n",
            "Epoch 1857/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.2221 - accuracy: 0.9500 - val_loss: 0.1051 - val_accuracy: 0.9512\n",
            "Epoch 1858/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0315 - val_accuracy: 0.9756\n",
            "Epoch 1859/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.0331 - val_accuracy: 1.0000\n",
            "Epoch 1860/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.0262 - accuracy: 1.0000 - val_loss: 0.0346 - val_accuracy: 1.0000\n",
            "Epoch 1861/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1990 - accuracy: 0.9500 - val_loss: 0.0276 - val_accuracy: 1.0000\n",
            "Epoch 1862/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0674 - accuracy: 0.9750 - val_loss: 0.0551 - val_accuracy: 0.9756\n",
            "Epoch 1863/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0897 - accuracy: 0.9750 - val_loss: 0.0616 - val_accuracy: 1.0000\n",
            "Epoch 1864/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1409 - accuracy: 0.9750 - val_loss: 0.2732 - val_accuracy: 0.8780\n",
            "Epoch 1865/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1751 - accuracy: 0.9000 - val_loss: 0.5335 - val_accuracy: 0.8293\n",
            "Epoch 1866/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.4632 - val_accuracy: 0.8293\n",
            "Epoch 1867/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.1107 - accuracy: 0.9750 - val_loss: 0.5023 - val_accuracy: 0.9024\n",
            "Epoch 1868/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.0429 - accuracy: 0.9750 - val_loss: 0.4581 - val_accuracy: 0.8049\n",
            "Epoch 1869/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1581 - accuracy: 0.9250 - val_loss: 0.4942 - val_accuracy: 0.8293\n",
            "Epoch 1870/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0392 - accuracy: 1.0000 - val_loss: 0.5935 - val_accuracy: 0.8049\n",
            "Epoch 1871/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 1.4049 - val_accuracy: 0.8293\n",
            "Epoch 1872/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.1789 - accuracy: 0.9500 - val_loss: 1.3890 - val_accuracy: 0.8537\n",
            "Epoch 1873/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0692 - accuracy: 0.9750 - val_loss: 0.5747 - val_accuracy: 0.9024\n",
            "Epoch 1874/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0976 - accuracy: 0.9750 - val_loss: 0.4134 - val_accuracy: 0.9268\n",
            "Epoch 1875/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0337 - accuracy: 0.9750 - val_loss: 0.3274 - val_accuracy: 0.9512\n",
            "Epoch 1876/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.0444 - accuracy: 1.0000 - val_loss: 0.2227 - val_accuracy: 0.9024\n",
            "Epoch 1877/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 0.0935 - val_accuracy: 0.9756\n",
            "Epoch 1878/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 0.0988 - val_accuracy: 0.9512\n",
            "Epoch 1879/2000\n",
            "5/5 [==============================] - 1s 228ms/step - loss: 0.2730 - accuracy: 0.9000 - val_loss: 0.1556 - val_accuracy: 0.9024\n",
            "Epoch 1880/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1716 - accuracy: 0.9250 - val_loss: 0.2430 - val_accuracy: 0.9024\n",
            "Epoch 1881/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0472 - accuracy: 0.9750 - val_loss: 0.3152 - val_accuracy: 0.8537\n",
            "Epoch 1882/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.4734 - accuracy: 0.8500 - val_loss: 0.0891 - val_accuracy: 0.9756\n",
            "Epoch 1883/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.1099 - val_accuracy: 0.9512\n",
            "Epoch 1884/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2401 - accuracy: 0.9250 - val_loss: 0.1597 - val_accuracy: 0.9512\n",
            "Epoch 1885/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0532 - accuracy: 1.0000 - val_loss: 0.1629 - val_accuracy: 0.9512\n",
            "Epoch 1886/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 0.5117 - val_accuracy: 0.8293\n",
            "Epoch 1887/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0442 - accuracy: 1.0000 - val_loss: 0.7976 - val_accuracy: 0.8293\n",
            "Epoch 1888/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.0922 - accuracy: 0.9750 - val_loss: 0.6959 - val_accuracy: 0.8293\n",
            "Epoch 1889/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0393 - accuracy: 1.0000 - val_loss: 0.1503 - val_accuracy: 0.9756\n",
            "Epoch 1890/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0722 - accuracy: 0.9750 - val_loss: 0.1215 - val_accuracy: 0.9756\n",
            "Epoch 1891/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.1932 - accuracy: 0.9250 - val_loss: 0.1013 - val_accuracy: 0.9756\n",
            "Epoch 1892/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0374 - accuracy: 1.0000 - val_loss: 0.3167 - val_accuracy: 0.9024\n",
            "Epoch 1893/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0520 - accuracy: 0.9500 - val_loss: 0.4172 - val_accuracy: 0.8049\n",
            "Epoch 1894/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.3290 - accuracy: 0.9250 - val_loss: 0.0370 - val_accuracy: 1.0000\n",
            "Epoch 1895/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.3632 - accuracy: 0.9250 - val_loss: 0.1643 - val_accuracy: 0.9512\n",
            "Epoch 1896/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1159 - accuracy: 0.9500 - val_loss: 0.0560 - val_accuracy: 0.9756\n",
            "Epoch 1897/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0588 - accuracy: 0.9750 - val_loss: 0.4495 - val_accuracy: 0.8780\n",
            "Epoch 1898/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0743 - accuracy: 0.9750 - val_loss: 0.6620 - val_accuracy: 0.8537\n",
            "Epoch 1899/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1087 - accuracy: 0.9500 - val_loss: 0.2311 - val_accuracy: 0.9268\n",
            "Epoch 1900/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 0.0961 - val_accuracy: 0.9512\n",
            "Epoch 1901/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 1.0000\n",
            "Epoch 1902/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 1.0000\n",
            "Epoch 1903/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2872 - accuracy: 0.8750 - val_loss: 0.1781 - val_accuracy: 0.9268\n",
            "Epoch 1904/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0649 - accuracy: 1.0000 - val_loss: 0.6702 - val_accuracy: 0.8293\n",
            "Epoch 1905/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0978 - accuracy: 0.9250 - val_loss: 1.0346 - val_accuracy: 0.8293\n",
            "Epoch 1906/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.0587 - accuracy: 0.9500 - val_loss: 0.2978 - val_accuracy: 0.9024\n",
            "Epoch 1907/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0855 - accuracy: 0.9500 - val_loss: 0.3252 - val_accuracy: 0.9268\n",
            "Epoch 1908/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0813 - accuracy: 0.9500 - val_loss: 0.2658 - val_accuracy: 0.9268\n",
            "Epoch 1909/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.2222 - accuracy: 0.9250 - val_loss: 0.1455 - val_accuracy: 0.9024\n",
            "Epoch 1910/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.1106 - accuracy: 0.9500 - val_loss: 1.4602 - val_accuracy: 0.8293\n",
            "Epoch 1911/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0949 - accuracy: 0.9500 - val_loss: 0.2367 - val_accuracy: 0.9024\n",
            "Epoch 1912/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0631 - accuracy: 0.9750 - val_loss: 0.1225 - val_accuracy: 0.9268\n",
            "Epoch 1913/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1962 - accuracy: 0.9500 - val_loss: 0.0468 - val_accuracy: 1.0000\n",
            "Epoch 1914/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.0603 - accuracy: 1.0000 - val_loss: 0.0550 - val_accuracy: 1.0000\n",
            "Epoch 1915/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0433 - accuracy: 1.0000 - val_loss: 0.0808 - val_accuracy: 1.0000\n",
            "Epoch 1916/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2278 - accuracy: 0.9500 - val_loss: 0.0716 - val_accuracy: 1.0000\n",
            "Epoch 1917/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1306 - accuracy: 0.9500 - val_loss: 0.1297 - val_accuracy: 0.9268\n",
            "Epoch 1918/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0571 - accuracy: 0.9750 - val_loss: 0.1537 - val_accuracy: 0.9268\n",
            "Epoch 1919/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 0.2092 - val_accuracy: 0.9024\n",
            "Epoch 1920/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0849 - accuracy: 0.9500 - val_loss: 0.7107 - val_accuracy: 0.8537\n",
            "Epoch 1921/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0247 - accuracy: 1.0000 - val_loss: 1.0554 - val_accuracy: 0.8293\n",
            "Epoch 1922/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0406 - accuracy: 0.9750 - val_loss: 0.6702 - val_accuracy: 0.9024\n",
            "Epoch 1923/2000\n",
            "5/5 [==============================] - 1s 229ms/step - loss: 0.0539 - accuracy: 1.0000 - val_loss: 0.2879 - val_accuracy: 0.9512\n",
            "Epoch 1924/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0836 - accuracy: 0.9750 - val_loss: 0.4286 - val_accuracy: 0.9268\n",
            "Epoch 1925/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.9846 - val_accuracy: 0.8780\n",
            "Epoch 1926/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1683 - accuracy: 0.9750 - val_loss: 0.2326 - val_accuracy: 0.9512\n",
            "Epoch 1927/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0481 - val_accuracy: 1.0000\n",
            "Epoch 1928/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.2209 - accuracy: 0.9000 - val_loss: 0.0370 - val_accuracy: 1.0000\n",
            "Epoch 1929/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0526 - accuracy: 0.9500 - val_loss: 0.0331 - val_accuracy: 1.0000\n",
            "Epoch 1930/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0404 - accuracy: 0.9750 - val_loss: 0.0548 - val_accuracy: 1.0000\n",
            "Epoch 1931/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.0885 - accuracy: 0.9750 - val_loss: 0.3221 - val_accuracy: 0.8537\n",
            "Epoch 1932/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0356 - accuracy: 1.0000 - val_loss: 0.3419 - val_accuracy: 0.7805\n",
            "Epoch 1933/2000\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.0535 - accuracy: 0.9750 - val_loss: 0.5054 - val_accuracy: 0.7805\n",
            "Epoch 1934/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0333 - accuracy: 0.9750 - val_loss: 0.4355 - val_accuracy: 0.8537\n",
            "Epoch 1935/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.4030 - val_accuracy: 0.8780\n",
            "Epoch 1936/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0360 - accuracy: 1.0000 - val_loss: 0.2809 - val_accuracy: 0.9024\n",
            "Epoch 1937/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0376 - accuracy: 1.0000 - val_loss: 0.1806 - val_accuracy: 0.9512\n",
            "Epoch 1938/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0553 - accuracy: 1.0000 - val_loss: 0.1705 - val_accuracy: 0.9268\n",
            "Epoch 1939/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1172 - accuracy: 0.9250 - val_loss: 0.1957 - val_accuracy: 0.9268\n",
            "Epoch 1940/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1085 - accuracy: 0.9750 - val_loss: 0.1996 - val_accuracy: 0.9268\n",
            "Epoch 1941/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0689 - accuracy: 0.9750 - val_loss: 0.2186 - val_accuracy: 0.9268\n",
            "Epoch 1942/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.1779 - val_accuracy: 0.9268\n",
            "Epoch 1943/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.1480 - val_accuracy: 0.9512\n",
            "Epoch 1944/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.2211 - accuracy: 0.9750 - val_loss: 0.0645 - val_accuracy: 0.9756\n",
            "Epoch 1945/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.0815 - accuracy: 0.9750 - val_loss: 0.0507 - val_accuracy: 0.9756\n",
            "Epoch 1946/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0720 - accuracy: 0.9750 - val_loss: 0.0453 - val_accuracy: 0.9756\n",
            "Epoch 1947/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0389 - accuracy: 1.0000 - val_loss: 0.0196 - val_accuracy: 1.0000\n",
            "Epoch 1948/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 0.1274 - val_accuracy: 0.9512\n",
            "Epoch 1949/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.1246 - accuracy: 0.9500 - val_loss: 0.1923 - val_accuracy: 0.9268\n",
            "Epoch 1950/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1352 - accuracy: 0.9750 - val_loss: 0.5699 - val_accuracy: 0.7805\n",
            "Epoch 1951/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1079 - accuracy: 0.9750 - val_loss: 0.7073 - val_accuracy: 0.7561\n",
            "Epoch 1952/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1680 - accuracy: 0.9250 - val_loss: 0.4006 - val_accuracy: 0.8293\n",
            "Epoch 1953/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0741 - val_accuracy: 1.0000\n",
            "Epoch 1954/2000\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.0728 - accuracy: 0.9750 - val_loss: 0.1219 - val_accuracy: 0.9756\n",
            "Epoch 1955/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0536 - accuracy: 0.9750 - val_loss: 0.0793 - val_accuracy: 1.0000\n",
            "Epoch 1956/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0337 - accuracy: 1.0000 - val_loss: 0.0662 - val_accuracy: 0.9756\n",
            "Epoch 1957/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.1948 - accuracy: 0.9250 - val_loss: 0.0944 - val_accuracy: 0.9756\n",
            "Epoch 1958/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1834 - accuracy: 0.9750 - val_loss: 0.3083 - val_accuracy: 0.8537\n",
            "Epoch 1959/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.1300 - accuracy: 0.9000 - val_loss: 0.0732 - val_accuracy: 1.0000\n",
            "Epoch 1960/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.0520 - val_accuracy: 1.0000\n",
            "Epoch 1961/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0484 - val_accuracy: 1.0000\n",
            "Epoch 1962/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.0477 - val_accuracy: 0.9756\n",
            "Epoch 1963/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 0.0438 - val_accuracy: 0.9756\n",
            "Epoch 1964/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0918 - accuracy: 0.9750 - val_loss: 0.0414 - val_accuracy: 0.9756\n",
            "Epoch 1965/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0508 - accuracy: 1.0000 - val_loss: 0.0344 - val_accuracy: 1.0000\n",
            "Epoch 1966/2000\n",
            "5/5 [==============================] - 1s 237ms/step - loss: 0.0427 - accuracy: 1.0000 - val_loss: 0.0366 - val_accuracy: 1.0000\n",
            "Epoch 1967/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1088 - accuracy: 0.9500 - val_loss: 0.0588 - val_accuracy: 1.0000\n",
            "Epoch 1968/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1368 - accuracy: 0.9250 - val_loss: 0.0240 - val_accuracy: 1.0000\n",
            "Epoch 1969/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.0321 - val_accuracy: 1.0000\n",
            "Epoch 1970/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.2565 - val_accuracy: 0.9024\n",
            "Epoch 1971/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0420 - accuracy: 0.9750 - val_loss: 0.4555 - val_accuracy: 0.9024\n",
            "Epoch 1972/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0937 - accuracy: 0.9750 - val_loss: 0.1346 - val_accuracy: 0.9512\n",
            "Epoch 1973/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.1510 - val_accuracy: 0.9268\n",
            "Epoch 1974/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1992 - accuracy: 0.9500 - val_loss: 0.0759 - val_accuracy: 0.9756\n",
            "Epoch 1975/2000\n",
            "5/5 [==============================] - 1s 230ms/step - loss: 0.1880 - accuracy: 0.9250 - val_loss: 0.1116 - val_accuracy: 0.9268\n",
            "Epoch 1976/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 0.1006 - val_accuracy: 1.0000\n",
            "Epoch 1977/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.1062 - accuracy: 0.9500 - val_loss: 0.3258 - val_accuracy: 0.9268\n",
            "Epoch 1978/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 1.7398 - val_accuracy: 0.7317\n",
            "Epoch 1979/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 5.5168 - val_accuracy: 0.5366\n",
            "Epoch 1980/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 8.0517 - val_accuracy: 0.5122\n",
            "Epoch 1981/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 9.3476 - val_accuracy: 0.5122\n",
            "Epoch 1982/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0383 - accuracy: 0.9750 - val_loss: 7.1703 - val_accuracy: 0.4878\n",
            "Epoch 1983/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1144 - accuracy: 0.9500 - val_loss: 0.8514 - val_accuracy: 0.8049\n",
            "Epoch 1984/2000\n",
            "5/5 [==============================] - 1s 238ms/step - loss: 0.1400 - accuracy: 0.9500 - val_loss: 0.2307 - val_accuracy: 0.9268\n",
            "Epoch 1985/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.1314 - accuracy: 0.9750 - val_loss: 2.4254 - val_accuracy: 0.7317\n",
            "Epoch 1986/2000\n",
            "5/5 [==============================] - 1s 231ms/step - loss: 0.0624 - accuracy: 0.9750 - val_loss: 7.9805 - val_accuracy: 0.5610\n",
            "Epoch 1987/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0624 - accuracy: 1.0000 - val_loss: 2.5181 - val_accuracy: 0.7073\n",
            "Epoch 1988/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0715 - accuracy: 0.9750 - val_loss: 0.1511 - val_accuracy: 0.9512\n",
            "Epoch 1989/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.0708 - val_accuracy: 1.0000\n",
            "Epoch 1990/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1070 - accuracy: 0.9750 - val_loss: 0.0541 - val_accuracy: 0.9756\n",
            "Epoch 1991/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 0.0772 - val_accuracy: 0.9756\n",
            "Epoch 1992/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0719 - accuracy: 0.9500 - val_loss: 0.1634 - val_accuracy: 0.9512\n",
            "Epoch 1993/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0423 - accuracy: 1.0000 - val_loss: 0.1711 - val_accuracy: 0.9268\n",
            "Epoch 1994/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 0.1328 - val_accuracy: 0.9268\n",
            "Epoch 1995/2000\n",
            "5/5 [==============================] - 1s 232ms/step - loss: 0.0790 - accuracy: 0.9750 - val_loss: 0.0816 - val_accuracy: 0.9512\n",
            "Epoch 1996/2000\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 0.0344 - val_accuracy: 0.9756\n",
            "Epoch 1997/2000\n",
            "5/5 [==============================] - 1s 241ms/step - loss: 0.0332 - accuracy: 0.9750 - val_loss: 0.1198 - val_accuracy: 0.9512\n",
            "Epoch 1998/2000\n",
            "5/5 [==============================] - 1s 235ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.2135 - val_accuracy: 0.9512\n",
            "Epoch 1999/2000\n",
            "5/5 [==============================] - 1s 233ms/step - loss: 0.0497 - accuracy: 1.0000 - val_loss: 0.2173 - val_accuracy: 0.9268\n",
            "Epoch 2000/2000\n",
            "5/5 [==============================] - 1s 236ms/step - loss: 0.3718 - accuracy: 0.9500 - val_loss: 0.0418 - val_accuracy: 1.0000\n",
            "CPU times: user 9h 47min 10s, sys: 25min 19s, total: 10h 12min 30s\n",
            "Wall time: 39min 3s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tdm_wsdQcMV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "647708c4-3cf1-4dbf-e627-cea5b1593119"
      },
      "source": [
        "# evaluate model\n",
        "_ori, acc_ori = model.evaluate(testX, testY, verbose=0)\n",
        "print('acc is> %.3f' % (acc_ori * 100.0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "acc is> 100.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhoMnDK0T0au",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e6c34d45-88a7-4623-eb28-d95aef63fcab"
      },
      "source": [
        "ori_model = load_model(pathModelSave)\n",
        "_ori, acc_ori = ori_model.evaluate(testX, testY, verbose=0)\n",
        "print('acc is> %.3f' % (acc_ori * 100.0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "acc is> 100.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77mVn8g9emUd"
      },
      "source": [
        "model = load_model(pathModelSave)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-w-a1BsJ7ksM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "1a9858f4-d5e8-45f7-f38b-7ad93be9f2a7"
      },
      "source": [
        "# \n",
        "path_healthy = '/content/drive/My Drive/datasets/vigna_mungo_leaves/train/Mild/7.jpg'\n",
        "img_vis = cv2.imread(path_healthy)\n",
        "img_vis = cv2.resize(img_vis, dsize=(img_size, img_size))\n",
        "img_vis = cv2.cvtColor(img_vis, cv2.COLOR_BGR2RGB)\n",
        "# plt.imshow(cv2.cvtColor(img_vis, cv2.COLOR_BGR2RGB))\n",
        "plt.imshow(img_vis)\n",
        "print(img_vis.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(128, 128, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WftXe6oRegqJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        },
        "outputId": "374d3a6e-aaea-463d-8959-1974ab094ad9"
      },
      "source": [
        "# It is for intermediate conv2d layers visualization\n",
        "from keras.models import Model\n",
        "\n",
        "layer_outputs = [layer.output for layer in model.layers]\n",
        "# print(layer_outputs)\n",
        "activation_model = Model(inputs = model.input, outputs=layer_outputs)\n",
        "# print(activation_model)\n",
        "activations = activation_model.predict(img_vis.reshape(1,128,128,3))\n",
        "# print(activations[22].shape)\n",
        "\n",
        "# sys.exit()\n",
        "def display_activation(activations, col_size, row_size, act_index): \n",
        "    activation = activations[act_index]\n",
        "    activation_index = 0\n",
        "    fig, ax = plt.subplots(row_size, col_size, figsize=(row_size*4.5, col_size*2.5)) # sharex=True, sharey=True\n",
        "    for row in range(0,row_size):\n",
        "        for col in range(0,col_size):\n",
        "            ax[row][col].imshow(activation[0][:, :, activation_index], cmap='PuOr')\n",
        "            ax[row,col].axis('off')\n",
        "            activation_index += 1\n",
        "\n",
        "display_activation(activations, 5, 5, 17)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1620x900 with 25 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlhbcurdSFJT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "98589eec-1ee7-4e18-9d98-45e4d56c5c77"
      },
      "source": [
        "# confusion matrix drawing for multiclass classification \n",
        "# https://github.com/javaidnabi31/Multi-class-with-imbalanced-dataset-classification/blob/master/20-news-group-classification.ipynb\n",
        "\n",
        "def convert_string_label(intLabel):\n",
        "  Y = []\n",
        "  # print(intLabel)\n",
        "  length = len(intLabel)\n",
        "  for i in range(length):\n",
        "    if intLabel[i] == 0:\n",
        "      Y.append(\"Healthy\")\n",
        "    elif intLabel[i] == 1:\n",
        "      Y.append(\"Mild\")\n",
        "    elif intLabel[i] == 2:\n",
        "      Y.append(\"Severe\")\n",
        "  return Y\n",
        "  \n",
        "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "    \n",
        "    import itertools\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "\n",
        "\n",
        "model = load_model(pathModelSave)\n",
        "\n",
        "y_pred = model.predict(testX)\n",
        "y_pred = np.rint(y_pred.argmax(axis=1))\n",
        "y_pred = y_pred.tolist()\n",
        "\n",
        "testY_ = np.rint(testY_)\n",
        "testY_ = testY_.tolist()\n",
        "\n",
        "y_true = convert_string_label(testY_)\n",
        "y_predicted = convert_string_label(y_pred)\n",
        "\n",
        "cnf_matrix = confusion_matrix(y_true, y_predicted, labels=['Healthy', 'Mild', 'Severe'])\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix, classes=['Healthy', 'Mild', 'Severe'], title='Confusion matrix, without normalization')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUgAAAEYCAYAAAA+mm/EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQTrnXB6eIJ1zLg9PkM45l8f/B9LhSKyFUCxsAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFLAkzCnRgJy"
      },
      "source": [
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "\t\n",
        "  # plot loss\n",
        "  plt.subplot(211)\n",
        "  plt.title('Cross Entropy Loss')\n",
        "  plt.plot(history.history['loss'], color='blue', label='train')\n",
        "  plt.plot(history.history['val_loss'], color='orange', label='test')\n",
        "  plt.show()\n",
        "\n",
        "  # plot accuracy\n",
        "  plt.subplot(212)\n",
        "  plt.title('Classification Accuracy')\n",
        "  plt.plot(history.history['accuracy'], color='blue', label='train')\n",
        "  plt.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "  plt.show()\n",
        "  \n",
        "  # save plot to file\n",
        "  # filename = sys.argv[0].split('/')[-1]\n",
        "  # pyplot.savefig(filename + '_plot.png')\n",
        "  # pyplot.close()\n",
        "\n",
        "  plt.plot(history.history[\"accuracy\"])\n",
        "  plt.plot(history.history['val_accuracy'])\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title(\"model accuracy\")\n",
        "\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.legend([\"Training Accuracy\",\"Validation Accuracy\",\"Training loss\",\"Validation Loss\"])\n",
        "  plt.show()\n",
        "\n",
        "  # Plot training & validation accuracy values\n",
        "  plt.plot(history.history['accuracy'])\n",
        "  plt.plot(history.history['val_accuracy'])\n",
        "  plt.title('Model accuracy')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Training Accuracy', 'Validation Accuracy'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "  # Plot training & validation loss values\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('Model loss')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Training Loss', 'Validation Loss'], loc='upper left')\n",
        "  plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGWttQxWZ2Gu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b15f2a39-274a-4610-c664-66b6b388fe76"
      },
      "source": [
        "# learning curves\n",
        "summarize_diagnostics(history_ori)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAACSCAYAAABVCTF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO2dd5hVxfn4P+/u0kGqCgiCChpbbMSA\nqNHEiho1xt6IhWhM1Og3lp9GxRJbotFobJGIYkGJKBYUREG67NKRtvTOLgu7sP3und8fM2fvuWfP\nbbu37C7zeZ77nHPnzJnznvaed955Z0aUUlgsFoul6ZOVaQEsFovFkhysQrdYLJZmglXoFovF0kyw\nCt1isViaCVahWywWSzPBKnSLxWJpJliFbrFYLM0Eq9At9UZErhKRXBHZIyJbRGS8iJycQXnWiki5\nkcf5vRTnvpNF5KZUyxgPIjJURKZlWg5L0yMn0wJYmiYichdwH3AL8DVQBZwDXAjUUUYikqOUCqRB\ntAuUUt8ku9A0ym+x1BtroVsSRkQ6Ao8CtymlPlZKlSqlqpVSnyml/mLyPCIiY0RklIiUAENFpKeI\njBORIhHJF5GbXWWeaKz9EhHZJiLPmfTWpowdIrJLROaIyP71kHmoiEwTkb+LyE4RWSMi55ptTwCn\nAC+5rXoRUSJym4isBFaatJuN7EXmXHq6jqFE5HYRWS0ihSLyrIhkiUhLk/9oV979RKRMRPZN8DxO\nMteg2CxP8pzjahHZbc7vapPeT0SmmH0KRWR0otfP0kRQStmf/SX0Q1viASAnSp5HgGrgIrTh0Ab4\nHvg30Bo4FigAfmnyzwSuNevtgYFm/ffAZ0BbIBs4AdgnwjHXAmdE2DbUyHOzKedWYDMgZvtk4CbP\nPgqYCHQx8v8SKASOB1oB/wK+9+T/zuQ/EFjhlGnO+2lX3juAz6LIOs0nvQuwE7gWXbu+0vzvCrQD\nSoDDTN4ewJFm/X3gAXMfWgMnZ/oZsr/U/KyFbqkPXYFCFdsFMVMp9YlSKgh0AwYD9yqlKpRS84H/\nANeZvNVAPxHpppTao5Sa5UrvCvRTStUopfKUUiVRjvmJseSd382ubeuUUm8opWqAkWilF8vaf1Ip\nVaSUKgeuBkYopeYqpSqB+4FBItLXlf9pk3898E+00sUc70oREfP/WuCdGMf2ch6wUin1jlIqoJR6\nH1gGXGC2B4GjRKSNUmqLUmqJSa8G+gA9zbW3/vlmilXolvqwA+gmIrHaYDa41nsCRUqp3a60dcAB\nZv1G4FBgmXElnG/S30H76D8Qkc0i8oyItIhyzIuUUp1cvzdc27Y6K0qpMrPaPsFzWOcqYw/6WhwQ\nIf86sw9KqdlAGXCaiPwE6AeMi3FsL2HHdx3jAKVUKXA5uk1ji4h8YY4DcA8gwA8iskREbkjwuJYm\nglXolvowE6hEu1Oi4R7KczPQRUQ6uNIOBDYBKKVWKqWuBPYDngbGiEg7pX3zw5VSRwAnAecTsuqT\nSaRhR73n0Mf5IyLt0LWHTa48vV3rB5p9HEYC16Ct8zFKqYoEZQw7vusYzjX8Wil1JrrmsQx4w6Rv\nVUrdrJTqiXZh/VtE+iV4bEsTwCp0S8IopYqBh4CXReQiEWkrIi1E5FwReSbCPhuAGcCTpqHzp2ir\nfBSAiFwjIvsa98wus1tQRE4XkaNFJBvtI65GuxaSzTbg4Bh53gd+JyLHikgr4G/AbKXUWleev4hI\nZxHpjfaTuxsgRwEXo5X62zGOJeY61f6AL4FDRYeL5ojI5cARwOcisr+IXGg+MpXAHsx1EpFLRaSX\nKXcn+iOVimtoyTSZduLbX9P9oX3KuUAp2p3xBXCS2fYIMMqTvxfwOVAErAJucW0bBWxHK6IlaNcJ\naB/0cnOMbcCLRGiMRTeKlpsynN9Ys20onoZGtGLrZ9YHoRsxdwIvere79rnFyF5kzqWXp7zbgdVo\nV8w/gGzP/t8YOSXKdR1qyvL+coCTgTyg2CxPNvv0AKaY9F3oRt4jzLZn0Fb8HiP7sEw/O/aXmp/T\nwm+xWBqIiCigv1IqP0qeEcBmpdSD6ZPMsrdgOxZZLGnCRMP8Bjgus5JYmivWh26xpAEReQxYDDyr\nlFqTaXkszRPrcrFYLJZmgrXQLRaLpZlgFbrFYrE0EzLWKNqtWzfVt2/fTB3eYrFYmiR5eXmFSinf\nQd0yptD79u1Lbm5upg5vsVgsTRIR8Q7/UIt1uVgsFkszwSp0i8ViSRaBcti9KmOHtwrdYrFYksXU\n38Bn/SBD4eBWoVssFkuy2PKVXqrMjH1mFbrFYrEkHWuhWywWS/PAWugWi8XSXLAK3WKxWJoH1kK3\nWCyWZoJV6BaLxdJcsArdYrFYmgc2Dt1isViaC9ZCt1gsluZBY/Whi8hhIjLf9SsRkTs9eU4TkWJX\nnodSJ7LFYrE0cjKk0GMOn6uUWg4cCyAi2cAmYKxP1qlKqfOTK57FYrE0QRqrhe7hV8AqpVTE8Xgt\nFovF0jQU+hXA+xG2DRKRBSIyXkSObKBcFovF0nRp7FEuItIS+DXwkc/muUAfpdQxwL+ATyKUMUxE\nckUkt6CgoD7yWiwWSxOg8Vvo5wJzlVLbvBuUUiVKqT1m/UughYh088n3ulJqgFJqwL77+k6JZ7FY\nLE2fJuBDv5II7hYR6S4iYtZPNOXuaLh4FovF0gRprFEuACLSDjgT+L0r7RYApdSrwG+BW0UkAJQD\nVyiVISeSxWKxZJxGrNCVUqVAV0/aq671l4CXkiuaxWKxNFGagMvFYrFYLPFgFbrFYrE0Fxp52KLF\nYrFY4sRa6BaLxdJMsArdYrFYmgtWoVssFkvzwFroFovF0kywCj3NLHwYCmdnWgqLxdIssVEu6SNY\nA4sfhQkDMy2JxWJpjlgLPY0ESvQyq0Vm5bBYLM0Tq9DTSOEsvcxum1k5GgPLXoBSO1+JxZJcrEJP\nH5OH6KVkZ1aOVFFVDOtGx85XUQBz74Rvz0q9TBbL3oS10C1JY/aNMP0KKP4xvvxVdqRjiyWpWIWe\nCZrpCL9lm/Syqjh6PqeGEqxJrTwWy16HjXKxJAunsVdVx5dfBVIni8WyN2ItdEvScBR6MIZCdx46\nq9AtliTTiBW6iKwVkUUiMl9Ecn22i4i8KCL5IrJQRI5PvqiWuCheCtu+1euxFLrz0CnrcrFYkkpj\nnoLOcLpSqjDCtnOB/ub3c+AVs7Skm5X/Dq0Hq6LnVVahW/YCNo8HpeCAIek7ZhN3uVwIvK00s4BO\nItIjSWVbEqFVtwQym4abDD18FktamDwEppyX3mPunJve4xniVegKmCAieSIyzGf7AcAG1/+NJq3x\n0dznrg7r/RrjXK0it+xNpPPdn39f+o7lIl6FfrJS6ni0a+U2ETm1PgcTkWEikisiuQUFBfUpouE0\n+wZA1y2NpbCtQrfsTUw8OdMSpJy4FLpSapNZbgfGAid6smwCerv+9zJp3nJeV0oNUEoN2Hfffesn\ncUOJFZvd1BH3LY1lkTTz2orF4qZwRqYlSDkxFbqItBORDs46cBaw2JNtHHCdiXYZCBQrpbYkXdpk\nUOESqzm6X9zDGcQ6P2uhWyzNiniiXPYHxoqIk/89pdRXInILgFLqVeBLYAiQD5QBv0uNuEkgUB5a\nb47uF7eFHjN6xSp0iyWptOkB5Vugx7kZOXxMha6UWg0c45P+qmtdAbclV7QU4e492SwH50pAoVsL\n3WJJDdktM3LYva+nqLuzTYsOmZMjVYS5XGLUQJqjy6mxsHOh/WDGS01laPyhpo5zz4OZqf3v3Qq9\nQ//MyZEqslwKPeZDZRVOSiiYCeOPgaX/yLQkTYMffg+f9IKaGB3hmgIZ7qy39yr07LbhF33bFFj0\naGZkSioJuFw+/0lqRUkVOxfAe6LvWWOkdK1eZqhzSZNj23d6WbY+s3IkhcyOj7R3KfSivFCPsezW\n4Qpv0mmw6OH6l138IwTKGiReUtCN15rm2OgLobFqNn6SWTksySG7tV7GGqqiKeBY6LtXZuTwe5dC\nX/9RaD27VfLGAQ+UwhdHwszrklNeQ3D7xZu9D9e2ATQLHCMkFW6KdLcTOcfL0LSOe5dCd/uUs1r7\nP0Dl2xIv1+msVDC9fnIllTgVum0QtTQajBpKhUJf9nzyy4xKZo2ovUuhu10QXpeLw9juiZdbY2Lb\ns9vUT65k4lbi0V6QZm+9W5oMkkKFvuXr5JcZDee9ypAu2LsUejAOhV4fahV66+SU1xDCFHUQpl0G\nY3v55POce8GMJmS1S+wsliaEuZ+pmApR0vys1IYtxjlbWJLZuxR6PBZ6fXAac7ISGV4+VbhdLjW6\n3aDcJ8bXe+4TB0P+66kVzWLxI5UWeto//q4olwwYSFah+7FtSsiXvvXb2L5xp5zqEqjYbtJUZgYC\nC3O5eNwqwRqo3m22+Zz77hWpk8tiiUgKG0XTrdDD3r/0R5ntXQo9nkZR0CGME8yES9/+Kvawm045\npevg4/31+qzfwZhOGah6RfGhz7sbPtpHj2fjd+6ydz0OKWfdB5mWIPkEAzDpjOT2Aah97lLQrpMJ\nl4vTWzsDbpe96w12K7FYLpdEwo78emSuGWm2uWJrdy7UHWL2rI2/7ESJZqGvGmFkqoyg0M2DqBQs\nfwkqd6RGxgbjWHRNwOdfsjzTEiSX8i2wbRLMvCZ5ZabU5ZJuFacyGle/lyn0FPnQ440mWfWGXm4a\nl5zj+h/QteqSSynX+asI1UHzOOxaAHl/ghnXpkrIvQcbTRQHKVToybDQV78NRfPiy6uCkNVKr1sL\nPcWERbm0St4DtGd1lI1uKzINlmUkC10FQ0o8GIjucnGuU0U9YvLTSmO10F1KZG90YxXOhkWPxZ+/\n9rlrpD70WdfDV8fHzqcU2kK3Cj21lKzQro4NY0JpkpMchb5tMsy+IfL2MAstDf68SHHoqib0gKkY\nCt2J1mmuQwekE2kMkU8pIJpRMmEgLHoo/rJS6XJJpg+9JFbQgLkmWWboXGeo7h1z0uYe3DsUut+Y\nH5KdnAdo+/cxMvjdyFTe3KD/uvtcI1nozuMgZqLpRq/Qm0A8erMccz/ZNJEol88Pi77dMabcLpcN\nY+HrE2H1W8mTIwrxTEHXW0S+E5EfRWSJiNzhk+c0ESkWkfnml8DnOQ34dfhJlkKPVaV2W8zpaHGP\nNJZLmLUew0J3SGaVccPHyXuoa69jY3W5uLAKPTbpjENPZZtGbS9RR6FXhQbpKl6SuuO6iKc+GADu\nVkrNNXOL5onIRKXUj558U5VS5ydfxCRQX4WejGqSbxnp8qHX+K9HGifd+2Il8wWbeoleHjw0eWU2\nCZrARyfTpNPlooIpbNdwLHQnyqXadW7paRyPeWZKqS1KqblmfTewFDgg1YIlFceFEJZmFLoKwvox\ndbdDnDchltXt40NPqT8tUqNoAhZ6ratl7/DIpZRUvchbJ0FlUWrKTjvptNBTOPGE8167G0Vra2iN\n0IcuIn2B44DZPpsHicgCERkvIkcmQbYk4nMxHYW+5m2Ydqn/bnGFF8a4UconyiWVqEhhix6F7hsj\n63mx0t0po7Gz7AXYtTjBnVLwIpdvhW/PgJnXx84bKG/8ir+5uFwcYyq7rV7WlIeO31gsdAcRaQ/8\nD7hTKVXi2TwX6KOUOgb4F+A784CIDBORXBHJLSgoqK/M9SCKQi/fEnm3zV/ELrpe07xFeMlL18Gu\nBH1twWrtm659YMxSsiNb6MEAzPtL3bK8L1a8VVMVjO5vX/Xf+MqJmzR+aKp3w+av9byXc++Eb36R\nYAEpUOiBUr0smBo774RB8L+uyZchmR/7tEa5JKhYE1HETt42PfSyfEtqe8H6ENcbKyIt0Mr8XaXU\nx97tSqkSpdQes/4l0EJEuvnke10pNUApNWDfffdtoOi1hcKSp6L3vvRzcdT60KM8mPE8YCpGw6H7\n2M7DVZQLP9xaV65P+8KXR8U+ppuFf9XDDGz63BzPdD1u2Sm6hb51Qt2yvHHo8X7vZ98IH0SZ5Xyx\nKyY5qe6mNFRjZw2Fyefo2a4gcUsrFe612v4EcTRa71qQ7IMnkDXevKmMcvGQ6DESmezZeTba9tbL\n8k2Ear2NRKGLiABvAkuVUs9FyNPd5ENETjTlpqffeGUhLLg/huXkczEdhR7N0ojnhfG74d4hbEMH\n1Yt1H0D+q3owr4ZS7LRNK9exBX0LoljovtTTQo8VvdLxcH856o0z3Gq1noi5prLhRf74bEhpu9m5\nUC+rjNsiy9Mek/8fmH9/lIJToNCd+xfLmEgF9bFYY5EqCz33T+GzlCUiU23+RGQyZbfqqgMxyja5\n3qH0+NDjiXIZDFwLLBKR+Sbt/wEHAiilXgV+C9wqIgGgHLhCqTRF0jtjkZdvTmw/r0vCj3i+zn5K\n3/0QfHsWnO8NCHJkSEK1tfYyu0L5JKtuFE88o8DVjuXi7JekanWHQ4Ev9XqwOgnDDJtzzn9NLyUb\nfnJnA4pTMP8evX6V57F1roXj5vC+4D/crJfHPllXPqfsZOPIkJExtxM5nwxb6CteqpuWSoVeY9ql\nJBvaHKAt9A6HJF5OA4j5ZimlphHjzVZKvQT4XL3kU1kJu3ZB166QkwPUVOgNkeJ9N4/3n7WkVnlF\nm6YtQZfLYXfA8hfCPwQlS13HjLOBRqn6K3snLEuyoke5+OGNckk0vMtP7pIVsOmz2Mf2Y/IF0ONM\nOOz28HSvldxQxRZtf+c5qR12OIZC+PFZmH+vu/AGieZLJjt8JaQQ41To0Sz0nQtg46dwdJK6tiSq\nWBPJ77RLBaug7QFQup5G53JpbHzyCXTvDiucXriOsvYq9IKZ+iJOHqI7tXjJ8lqjPkTbVlMFCx8J\nd5s4PcQi7hevQq/PzXfKDgKOQm9gHHrCCt3nvL84HPasch07AeW7+XPIM/3YSjeEXCI57cPztfD8\nTxSnlufHnny9dJSod8AzL/PvISELvSgv8SiUeP267nalpI2TkgofunnO5v1f3U1fnwiLHk6e/Km0\n0Ne+o5eVhbpWWpRH6IPeCMMWGwMtjHFWXY1+YPKM9eZW6FsmwsSTYPm/IhcUj4W+cWzkbfmvw+Lh\nOuzRoXYMh0gvXLwKPZGHV4UvVVBbydGiXGJZeLV5E1XosdoT0NaLY+0mwhdHwlcD/MtsaG/MmjL/\n9Oo9ofVaJeo6tjv0M6If3+dF3jEnZAh8NQAmnR6vpKbIOBW6++MZTEI7AySoEOP1oZv3wnFrhRVh\nrnHSXBaJKvR61IZqyqH9Qfqa17rqrIXuS0ujM6uqCH+hWnQIrTsWYUkE3zXEp9CjkfenumlOj9RI\nD1+8IVT1Uei1vTsV+rZGcbkEA6GPT1hRnrIStdDjsRwXPqgn2XCsUqVg+7TYFlhgdyh/ZaFnWwSF\nHC/uWlbBzNC623L36z3rVkAL/xqhcI9CD1Zrq3PKr0P3Z9fCxOStj5JJmkJMgYUez3PmuDbLt8Ci\n4fVvm0ily8WhpjwUi+48W1ah+9NV8tj8Ug9K1i8If+HcjaIbHMs6yunVKvR6vBxrRvmn1/YQa6CF\nnogVUauEA3rc5uXPR2gU9Vjofa7wKcs1vC7Uw+USx7Vc9aZeLn9Rd5DZ9Bl8cwqs9sSqR3phg5VQ\n4ek7EMnCjpe177rKcilpt4Vb63Jx3Rv3cYtdbSVuvOfhGCHbp9Tf9x+3iybCuD4NIRU+9HjUkPNM\nzhwKix6BwlkJyOEWKYUuF+d96Xk+5LTT6840lFah+9MpMIsenbfy3r9y6/o+naq8E2Md7UV3FLrT\nqJoIMyNM/BDT5eIhKS4XQzCgx20GQMzDlWDXf2dO0fpGuSQi9+LhMOMqqNqp/2+fHF9ZgVLd+9Gb\nFg/FS/1DRd0uG/dwt8pPobvkcj87VTtCUQ5hmHtQvQcWPgQ754c2bYji0ovG1IvjzOhWqBGetUBp\nguGzjgERj7KO10KPw2VWa2xUhC/dVO+O/bFLpYXe5UTo+nPodQG03k+n7fjBKSix49aTJqfQN6rz\nAKhR2XUVeuWOcKvH7d/2kqhCj+cBTrRRNKkuF9dHJJaFHmn4XGdEuFS6XNyUbghds7INoXSlYNci\n/31qKuq+zJFcLu8JzPlD6P8XR+gwUi/uRla3cnH7xf1cLu7tVUW6w5gX57n5qIPuYDXdVTOacWXd\nYyZEjA9umA/d534Hq2FsL/ioIxTN9S9jzTvwv26h/ZWrkc+ZED0S8Vql3qglP7yTrvjVbj7pHbtX\nbCotdBWAVqY/ZRsz3NWOWYmX0wCanEKvqNZ+6jYtykOWWl8zv2HVjtAkzbFwXqLt38WX37khGz+N\nnKfWh+5RbM5L7fVbR3q4EmrRN2UHvQo9Rtii3wPm+KbrHbaYoEIPVoX22TEnlL52VPgMMflvhNZr\nKlydqQx+FrpzzVe+Ev5/h88wRO5r4T5nd0Oi+/qObld3+z6uzlPhhYf/LdtYN0s8Cs2PaB+Cpc/B\nl0eH/hd8r5WzmwmDoXqXXv/qBP9y5vxBG0pObXfbt3pZvlm/a1Hnx22gDz1sXKKAtsCdOVr9FHp1\ncexjJarQE+opGgjdE29fizSFmjZZhf7KDX+Apc/oxLbma1hZFKrCRyOnQ+jCe5VDJJwb8v1FkfM4\n1qbX6ncURk5bT3oDLPTq3TDnNleji0cpecMW3XIHA/rY+xwOh9wcSq9V6EmMcolG2XqoMgrFXdvy\nNhL+MCy0XlMBhTPDt/u51rxKPtqEvWG1F7dV69rHfW7O8dzbgwEIuKJiQjtGPq5DfS30aPvNuzv8\n/9RLYOZ14QqqaE54Hj9jpfaczHnkeaZDcIekeom34TJSPvfHTwVMXLfz3/PuuMtY8XLy3JmJ5A8G\nQorcO8JrmiaMbnIK/Yyz24X+OC4Vp3rz3VnQ6RjodHTdWGWHox+F85Yk/hIVTA8pHy/ZreGUj6G1\nGZ+mwjPwmGPJZbfx7NiARtFVI2Dlv0PKLUyZ+oQtuucHdSz0rBwdXuVQuUO/GPUdbdFrzawaEXsf\nd7RQsFofv851cuGnNAOlsOBB+NxlJQc8oZH1Ueg1HoXtpqYq5HKRbF079JMtHqUWzzR1lUWw+SvP\nfvV4fd3GhneegO8vClnAXiIptmjDLsTd6BvheXdb3MGAx8Xq7dHruj+5f4xSk06xy8W5l14L3bd9\nJfk0OYXeuWsLAsrzIDoNEKAHI8pqHcFaAnqeC+16x/cSufn2DFjyhP+2boOg98XQ2rh7Jp0Wvt1R\nJnWqYUHtTph8nic9jofIHaYJdV0uZEUux1Hokh36sGW31WnFPyY2OJfbPeQ93uwbY+/vZuIpMO7g\n6Aq9yqfRK1Cm703JspAS8daSoimeMIVu8q0ZBd/+KpResdVTXlkob5ueunZTHcFCj+VCi8dVMPk8\nmHxu+DHq06Dv7LNnrf/+XmPEIZLrwRtC6uazQ8L/F82Dte/VzRfpOXX3V1CBcHm9tUHv/Y1kfKXS\nhx50K3SPhe41MFJEk1PoAMHsfcIT9vd0zPBWJfu7GsYcq9MvDjsWkYbadW5i6wj+e+frXCeErVq7\nEzZ/Cd+e7cof4UWtqdRhUBNOghWeTlNhD3iWPr9IFtL6MaHB9x3L3bF+KgsSs9DdfuSG+gl3zIbS\ntdH9lrl/DP8vWeEul6pi2LO6buRGVAvd9ZJXFuoefjOvDbcIvWGVy18MKZHW3bUC8bXQg/FVtyvN\nWHYVET4MzqiJ7hFC2/WJXF6kj6LToBwpYCCSIRTp3s66HmYP8/9oue/BzoW6XWTG1XXzVXrG8ave\nrQfVcu/vtdC9Fq/3GkfqSJVMl0uwRg9NUJvX7XLxGG/xuIKTQJNU6C2Dodb1SYt/yZ33xRiK92cv\nu/6YU3ZixhPBHa8MoSqr8zWO5OYJVuqX3xni1sFt8buHs9022b+cb06FMZ20m8Ud/gZ1X7jsVv6h\nXaAbtrZ8pRW6cw79jJ+6uiT0MsTz0YvUcNgQnO72vttWh/9v2TncX75nFYw7BObcGkqrqfTIaV7S\niu06Embxo6FtlYUw967YMi56OFRmy476I+w7fr6KT6E7H9aP99W9Yr04ykzVQLsDQ+uRiGSJ1lTA\nosdgmRk4VbKgo+t4kRR31PHu34Cd8/y3OQ2x448JpS14IDyPU+tqf7Bezr4Rpl0W3oCtPAo9lgI3\n2/fsczarq3+jY8MhuY2iC+6D8cfCbtfwEJEsdL+aZQpokgrdzT++vJsXXhDkapf1e+wzEfOrWoXu\nM89oIux3WkjhOTcvUrTC9xfraIEt48PTvR8Ih6I8mHePVuyLhofSa2NafQhzuYjuuLL9+2hnoB++\nox6GwR/AT4wSqy4OhQHGc40WuHpIupVBQ0YZjBZu6iWnfbgyKVmml+6G0/It4Qpg/Yd66Xf9nVpQ\nPDgWeot9tELZ/GXdPOs/ik+huz9KZabxb8JgWPQoFMwIbfvhZj0RCsSoEUVQXJVFsOihkJundQ/o\n4aodRrpvsWpfebf7p3uNGIAlf9Mf0rXv62fcMU6cD5QzsXKly/3jdbl4r6l36GNzbx55/XwOGfo/\nlgedhvUkulyc++3UMIIRLPQeZ1sLPR6u+fc7jF8wpPb/7kB3AH5+8TmhTL3Co1KOOVa45RZCESn1\npceZoTKcmxepoXXnXFgdRwOhQ/6rsPRZPcbHokfi26fMFQEQb/tATlvIbgl9LtcTYoC20B1LKJ5y\n3Oe19B+hhrsUh2kVlJh43xadPBum181ctjHcx7pnFf6zLElifmnHKszpEFlpL3029ocVfKJyaqBw\nhq4JbP0mlO4eaC5sVM+V4bH7kSxRr6XorqXpHf33CwZgd5SIlsKZ2vLePi08PVpI5oyrYNYNrkMH\nQ8eCcPeP1+Xivd5TLvDIq7cX79Hv6F13G1UX7/0tmA7l20Jhr344Bp2jrMMsdFfttuOR+rjeDnEp\noGkq9MsruO6Vkbw346qw5P9O0nODLlzTj09yL6SooifTZTTr1oXyVFS35rXXaLCFXrGrkMKdHgs9\n3qiQXvH29DPEY+3ucHVqiTeu2W3Ftuiol9XFrhfHddxgoK4cZZvDX7J178HkcykvJzmTTkRh1XbT\n4NbK05Fk1Rt1M+9eEa4AljwJ72d7hrklupvKD6dBMFrNCaKP5ujgVeijXQaHY7F6cWKzP2gFnx8K\nX/7UtS2CZem1FAeNDM1SH/QNhfsAABJUSURBVG0/FYCCaf7bHJb8TQ/j4CarRXQ3h1tpqxoTZeV0\nIvJY6O5hmIvmwNRLI0ePmI9tVUC/ozVBY2xNHuKf38vEk2Fs99AIig47XSG1znmZj0R5WQ2rVpvj\ntHC18zmdjX4YFqpdpYimqdCzW/HkB9cxYUK4+HeNeo79bt1GRXUbLn7+E7reuImTT21J376hPMVl\nWnF1PfiwBonwzTc1VFZoBff4C4ewfTtMjWOKR4Bgr0sSO1jJclj4cPQ8robglaty+GS+z1gtXjmq\nyhg0yPzJbqWtiqpiNq13/LWubt4ftID3s8J7FK5737fctm1h1YrY46vM2Ggm5+5+Zsy8Xi5+fixX\nvzwqckO0m9354T7WSENC1FTA0r9Hn7bt5A/hp2ZKveUv6qV7zPvD7qi7j2nIVYffW3ebQ6DUM3aM\nS7GujTB2UNVO+PrnicU4V7uiPwZ/APufFm7cRPKV11TWb+yZ1W/BxiiTrbsVevlm+Ky/q1eoqydq\nTTls+F94uRvG6N6/eX+uW66pFXVtr90hShljq7qEJbGm7Y3mNx9/jK4NQegeLX9BF10V4NPPcqip\nQRt3R/4/PaaL0zawdhR8/5sYB28YTVOhAwccAGecARtcPcZrgjkUlOznm3/K0lMBKC7XCr1oT5fa\nbUfcE/kOj8m7pnZ94fpQz7s1q4O0aqGVxNZd3dl/fzj11Nhyf7/sFH59eY/YGd18cXh4w10Murbd\nyp3/fTJmvrKqtswyPZMLCiCY05FARQnzp2sroro6aCZHDnVSCSx7jZnTq7Su9xu/GujQpoRVy2KP\nDzJlrhPWlli8+6F3L2frrh68N+NqCnfE0Z9g/WiYfXPsfHEwciRwqImdL9+kl79wNYZ2PpYRFUEu\nes41TovxV+cu8ERnuVn4IIzpEnl7JNwfEzAfhigKyRXOV4VxV0VS6OvHhNYrC+rvB4429oy39rJn\nVejjWxlS6FWbZ+DLnlWw/J9107dPAeDEQ3TtqUVO6LxOPKFUt01FcoHEGhto51yCRYtDQ2WYcYhy\nsgIEgjlcZLy86qdPMOCZPXw3PXTfC9evY+LE6MU3hHgniT5HRJaLSL6I3OezvZWIjDbbZ4tI32QL\nGolevaC8HIpiNCL/7rX/ctrj31FZ7Ty8ISWydNMRtLq+gpcm3FZnv6LiUPjXkGdDjV4iinat9I0v\nKY/yonr4xWPf882Ck8LSRkz+Xdz7x0OX9jtZV9iHTUU9gdDHzEtQ6du/Zg3stx+sXr8Pu7Zu5bzj\n9HmWbpjD9BH/1CM4GnLWvk7veQcz8r+RrcKTD53GSRW/DEvrf9eKOvnyt/YDYOnC+CMASgIHsnLr\nobX/P/siup+/UvbTkTFexech2PaQqNsdpkzazfwfO7J5Z8/atD3tXfHqOR248UZhT0XdiKfHXzqa\nP7/zHLN7biJw9N/DN+5eGTlkMBHm3Rs95rlsU+3qf0Yahe72Kzv3+j2BaZeG0hf+NTRNX6pxGmxd\nneFaLotRQ43AQ2O0IeS8qwClI9rDokfYvegd3nsPts6bQOGGUEjyg/fHuA/TryDrq6PrJOdkBwjU\n5PD551ofVVZCXh787cnQM9qtww6eeqpepxIX8UwSnQ28DJwLHAFcKSJHeLLdCOxUSvUDngeeTrag\n0WjdGjp3hrFj9UxGSsFNN4XnWVNwMFOWnsa118J338Gdd8Kpj02hzx1rAagKtOLPo57n4zkX8+zn\n2vKcnX8iawp0T8rfv/kqm4p60enmnUxYdCZPfXYfbVrqF6G0MtR79aPZvwXgqpffpedtm5CrFVOX\nnRwmS2V1a466N9SAdd/opxi/4BySi3DQnWu4ZcQrnPN0qIfhqY9N4ZJ/jmHyj7/grKd0qOTBpkbY\nr/squpV/Upu3U8vNDG5X5/tNry6bGNo6cqPyl/ecR3sJVZ0e/+QB8rf1Z1NRT96dHmr3WLmtPwA5\nwV1s3aVdJ+VVkds27vvgSfr/Kdxf3SI7shtgyDNfkLu8X8TtDje98QZtL1vM4OExfMTApCW/4rjj\noFVOSAl26BS6Fnfcq/2lbovQobisA//86s8MPL0np14yqM72pLDy5VpLv6S8g/92w7/+o2uzC+e4\nOk0V5fHd2z6jQMZqJ0gmTvy5TwPmjtI4x2oybNqpe5G7FbrDHX/O4eXh0+m+9Gy6Te0Ja95h+pQ9\nrJju07Aegwlj12sLvUYr765doY2xBSct+VVY3u4V71JVmZrRF+Ox0E8E8pVSq5VSVcAHwIWePBcC\nI836GOBXIsmYATkxLroI+msdwWuvacUdDOov5Q7Tq/3tt+G00+D55+G9iafyh//TnTNEIFDTgq39\nP+ae95+lw40l/GncVJ757B6ezZvI4Rf8nmHDoLisE2c/NYFNRb14eaLusPTN4jMAuOEGuOzFD8m6\npob3Z1zFll09WbECXpj8OOsLe3PNv0MNLEs2HkXHm3ZxxD1LKCjZjyHPjOegO1cz5Bm/WObofDhL\nW1LnPfs594/+G6c9rgccq65pyWuTbqGiug2trq9g8PBpTF12Kh/PuYTTn5jM7PyBYeWMy7ugTtnR\n+HjOxTw0Zjj97lrJP8f7+I6B1kPL+etHjwPQ60+bGPraWwAUl+3D9OWD+XjOxfz1o8c47oF5XPrC\nh8wyMp337Ofc9lb4NLWf5l3I9pLwF/pBU7abRz/+K0Nf+y/jF5xL7uoBYduWbPTaIvDm5JuorG7N\njBUnUVzmX9t6bdIw5GrF+kL9vCzeeBQAP6z6GQBrtvcF4K1PjwVg7prj65Sxs7Rz7fqWXfG53dxu\nPofZ+Sdy3Ssj2bE73EWzYkv/sP83vfGf2vVON4e7S3aWdmL1lp6IwKgx4df09Jz4/Lwbi7Sy3LCj\nF/vfujVGbs2f33nON/3tqdeys7RTnfTSivDxj7oNCz9O0Z7ORKOsUu/vp9BHDLuR6Q+7jK2Z1zF4\nUwc+vP1y37IWrj+a9YW9fbedVd6HrCxF53Z13VJKZYWd97u3XcP0Vx6MKnd9ERUjgkJEfguco5S6\nyfy/Fvi5UuqPrjyLTZ6N5v8qk6fQU9YwYBjAgQceeMK6dalt8Y2XPXu0Qm9nDO2yMj0jUqe6zxcA\nGzfq38CBof3bmxp2SQls3Qo9e4bSampg4UIYNQoefBBOPx3+8hf9YenaFYqL4Ykn4Nhj4bjj4A9/\ngLPPqGLg4JYMPknxh0unsiS/Cw/f9AUtDr2G+ct70LtnJf8c/iM1LbtTGjyA/HwYPhx+8xtYv15/\nvMrLtTx9+kBuLnToAKNHw5lnwnnnwWWX6Ym2l5nQ7UceqmRQq7upDLTl7fmPsGLxLqgsoEPr3fzy\nlGKuvqKMSZOyqerwMyZ/uZFPpw9k3DjhnHN0e0a/fnDV6V9T+MMIVm07hMc/eZDyqra89RZ06QJ3\n3w3XXQdvvglr18K4cbBoEWzfDi+8AIMGwbKFRRzWYzmz8gcx/OFKLjrhU066dAjH9Z3HtOU6gqJ7\nd1i6FAIBuOsumDULpo+ZQLd9s5i17Bi+mNSNJ54I2RPdOhRw7yWv8+60y7nnL0HKc5/iT2//i67t\nd1BZ3SrsI3F83zyuHvwuu8o60aPLTt6YdC0dO9SwvOA4tmwNVZ17dNrMwH6zGJurld/P+83iqF6L\neXPyTRx2GCw3Q6Ls17mEEw6cxpUnvc9Nb/yHqkDImj//uM+494Kn2Vrcnd+e+D8mLDqTJRuP5Pnx\nf+bg/VYzZelptGpRwTf3n8H4BefSveNWsrKC/PEtbWV3aruT0bdfzvj55zIrfyD77lPAuLtDttaB\nt69jd3kHgiqLkvKOXD14FMMveZilmw/ngr9/huN2zM4KcNrhk1lTcBC9umzkqpPe44pBH5C35gSu\nf3UkW3b14OWht7Fs8094f+aVHHJwkJt+9gDDP36YotIuZEsNu8o68+BFj/HYpXoy55HfX8fIqddz\nfN+5DD31LT6fdz73j34KUFxz8ihuPv0Ntpfsx9cLz+aUoxZwx5uPsausM9ec/A7v3HodxWX70LFt\nCTe+/h96d93AI5cMp88da1lf2IdXb/g9U5efwrvTr+H0I77lw9svY8uuHhzdezEA05YP5pRHQ7Wt\nDh2ge7sVrPjHYWwr3o/9O2rf/K7SjnRqF+pz8MW8IZRXt+GYAxfQv3s+s/NPZNT0aziw63q6tC/i\n9rd1I3j+P/rRo7P/B+zZWR+Rt/23jB4dnp4lNVw28EPe/6Ouoa7s8hr9zxnmU0JsRCRPKTXAd1s6\nFbqbAQMGqNxcn/GjLRZLSlAqvsjaePOlqxx3eaDLdKutYBCyGzitrPsYjszR5HfLkm6iKfR4XC6b\nAHc9o5dJ880jIjlAR8AzQIPFYskk8SqfZCmpZCs7kVCZzrpI8pS5U67fejRZGhPxKPQ5QH8ROUhE\nWgJXAN7A0nGAM//Zb4FvVSzT32KxWCxJJWbfbqVUQET+CHwNZAMjlFJLRORRIFcpNQ54E3hHRPKB\nIrTSt1gsFksaielDT9mBRQqA+raKdgOiDMScMRqrXNB4ZbNyJYaVKzGao1x9lFK+Q8xmTKE3BBHJ\njdQokEkaq1zQeGWzciWGlSsx9ja5mmzXf4vFYrGEYxW6xWKxNBOaqkJ/PdMCRKCxygWNVzYrV2JY\nuRJjr5KrSfrQLRaLxVKXpmqhWywWi8VDk1PosYbyTfGxe4vIdyLyo4gsEZE7TPojIrJJROab3xDX\nPvcbWZeLyNmRS2+wbGtFZJE5fq5J6yIiE0VkpVl2NukiIi8auRaKSN2RpJIj02GuazJfREpE5M5M\nXC8RGSEi280wFU5awtdHRK43+VeKyPV+x0qCXM+KyDJz7LEi0smk9xWRctd1e9W1zwnm/ucb2RvU\njzGCXAnft2S/rxHkGu2Saa2IzDfp6bxekXRDep8xpVST+aE7Nq0CDgZaAguAI9J4/B7A8Wa9A7AC\nPaTwI8D/+eQ/wsjYCjjIyJ6dItnWAt08ac8A95n1+4CnzfoQYDx6dKaBwOw03butQJ9MXC/gVOB4\nYHF9rw/QBVhtlp3NeucUyHUWkGPWn3bJ1dedz1POD0ZWMbKfmwK5ErpvqXhf/eTybP8H8FAGrlck\n3ZDWZ6ypWejxDOWbMpRSW5RSc836bmApcECUXS4EPlBKVSql1gD56HNIF+5hjUcCF7nS31aaWUAn\nEUlwGqWE+RWwSikVrTNZyq6XUup7dC9m7/ESuT5nAxOVUkVKqZ3ARKBBA9n7yaWUmqBU7Szbs9Dj\nJ0XEyLaPUmqW0lrhbde5JE2uKES6b0l/X6PJZazsywD/uRFD+VJxvSLphrQ+Y01NoR8AuCadYyPR\nFWrKED0r03HAbJP0R1N1GuFUq0ivvAqYICJ5oocpBthfKeVMxbIVcMaJzcR1vILwFy3T1wsSvz6Z\nuG43oC05h4NEZJ6ITBERZ0bmA4ws6ZArkfuW7ut1CrBNKeWeVTvt18ujG9L6jDU1hd4oEJH2wP+A\nO5VSJcArwCHAscAWdLUv3ZyslDoePbPUbSISNu+csUQyEtIkelC3XwMfmaTGcL3CyOT1iYSIPAAE\ngHdN0hbgQKXUccBdwHsiEv/8hw2n0d03D1cSbjSk/Xr56IZa0vGMNTWFHs9QvilFRFqgb9i7SqmP\nAZRS25RSNUqpIPAGITdB2uRVSm0yy+3AWCPDNseVYpbOrLvpvo7nAnOVUtuMjBm/XoZEr0/a5BOR\nocD5wNVGEWBcGjvMeh7aP32okcHtlkmJXPW4b+m8XjnAb4DaqSXSfb38dANpfsaamkKPZyjflGF8\ndG8CS5VSz7nS3f7niwGnBX4ccIXoSbQPAvqjG2OSLVc7EengrKMb1RYTPqzx9cCnLrmuMy3tA4Fi\nV7UwFYRZTpm+Xi4SvT5fA2eJSGfjbjjLpCUVETkHuAf4tVKqzJW+r+g5fhGRg9HXZ7WRrUREBppn\n9DrXuSRTrkTvWzrf1zOAZcpMsmPkTdv1iqQbSPcz1pCW3Uz80K3DK9Bf2wfSfOyT0VWmhcB88xsC\nvAMsMunjgB6ufR4wsi6ngS3pUeQ6GB1BsABY4lwXoCswCVgJfAN0MemCnvh7lZF7QAqvWTv0ZCcd\nXWlpv17oD8oWoBrtl7yxPtcH7dPON7/fpUiufLQf1XnGXjV5LzH3dz4wF7jAVc4AtIJdBbyE6TSY\nZLkSvm/Jfl/95DLpbwG3ePKm83pF0g1pfcZsT1GLxWJpJjQ1l4vFYrFYImAVusVisTQTrEK3WCyW\nZoJV6BaLxdJMsArdYrFYmglWoVssFkszwSp0i8ViaSZYhW6xWCzNhP8P6gOK1orPAIQAAAAASUVO\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAACSCAYAAABLwAHLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEWCAYAAABsY4yMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nknRT9AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEWCAYAAABsY4yMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYVrPo/wVAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVBYGqy7Zvg_"
      },
      "source": [
        "# alien data preparation for prediction\n",
        "from tqdm import tqdm\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "def predict_imgs(path, type, modelPath): # 'type' is type of imgae like healthy, mild or severe\n",
        "  tic = time.clock()\n",
        "  model = load_model(modelPath)\n",
        "\n",
        "  T = []\n",
        "  names = []\n",
        "  filenames = [img for img in glob.glob(path + '*')]\n",
        "\n",
        "  count = 0\n",
        "  for i in tqdm(filenames):\n",
        "    split = i.split(os.sep)\n",
        "    count = count + 1\n",
        "    img = cv2.imread(i)\n",
        "    img = cv2.resize(img, dsize=(img_size, img_size))\n",
        "    img = img.astype('float32')\n",
        "    img = img / 255.0\n",
        "    T.append(img)\n",
        "    names.append(split[-1])\n",
        "\n",
        "  T = np.asarray(T)  \n",
        "  p = model.predict(T)\n",
        "  \n",
        "  toc = time.clock()\n",
        "  print(\"time to predict\" + str(np.asarray(filenames).shape) + \"images is:\", toc-tic)\n",
        "\n",
        "  probability = p\n",
        "  count = 0\n",
        "  healthy = 0\n",
        "  mild = 0\n",
        "  severe = 0\n",
        "\n",
        "  for i in names:\n",
        "    img = mpimg.imread(path+i)\n",
        "    # plt.imshow(img) # to avovid DATA Loading\n",
        "    if probability[count][0] > probability[count][1] and probability[count][0] > probability[count][2]:\n",
        "      healthy = healthy + 1\n",
        "      print(\"%.2f\" % (probability[count][0]*100) + \"% Healthy\")\n",
        "      # plt.title(\"%.2f\" % (probability[count][0]*100) + \"% Healthy\")\n",
        "    elif probability[count][1] > probability[count][0] and probability[count][1] > probability[count][2]:\n",
        "      mild = mild + 1\n",
        "      print(\"%.2f\" % (probability[count][1]*100) + \"% Mild\")\n",
        "      # plt.title(\"%.2f\" % (probability[count][1]*100) + \"% Mild\")\n",
        "    else:\n",
        "      severe = severe + 1\n",
        "      print(\"%.2f\" % (probability[count][2]*100) + \"% Severe\")\n",
        "      # plt.title(\"%.2f\" % (probability[count][2]*100) + \"% Severe\")\n",
        "    count = count + 1\n",
        "    # plt.show()\n",
        "\n",
        "  print(\"total \" + type + \" images:\", count)\n",
        "  print(\"Pridicted Healthy:\", healthy)\n",
        "  print(\"Pridicted Mild:\", mild)\n",
        "  print(\"Pridicted Severe:\", severe)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKwURArK1t40"
      },
      "source": [
        "# this is the new prediction function <optimized> to calcultae prediction time per image\n",
        "model = load_model(pathModelSave)\n",
        "\n",
        "def new_prediction_fun(path):\n",
        "  filenames = [img for img in glob.glob(path + '/*')]\n",
        "  count = 0\n",
        "  total_time = 0\n",
        "  h = 0\n",
        "  m = 0\n",
        "  s = 0 \n",
        "  for i in filenames:\n",
        "      count += 1\n",
        "      tic = time.clock()\n",
        "      img = cv2.imread(i)\n",
        "      img = cv2.resize(img, dsize=(img_size, img_size))\n",
        "      img = img.astype('float32')\n",
        "      img = img / 255.0\n",
        "      img = img[np.newaxis, :]\n",
        "      p = model.predict(img)[0]\n",
        "      max_val_index = p.argmax()\n",
        "      toc = time.clock()\n",
        "      time_t = toc-tic\n",
        "      if (max_val_index == 0):\n",
        "        # print(\"%.2f\" % (p[max_val_index]*100) + \"% Healthy and prediction time is: \", time_t, \" sec\")\n",
        "        h += 1\n",
        "      elif (max_val_index == 1):\n",
        "        # print(\"%.2f\" % (p[max_val_index]*100) + \"% mild and prediction time is: \", time_t, \" sec\")\n",
        "        m += 1\n",
        "      elif (max_val_index == 2):\n",
        "        # print(\"%.2f\" % (p[max_val_index]*100) + \"% severe and prediction time is: \", time_t, \" sec\")\n",
        "        s += 1\n",
        "      total_time += time_t\n",
        "  print(\"\\n\")    \n",
        "  print(\"Total prediction time for \"+str(count)+\" images is: \", total_time, \"sec\")\n",
        "  print(\"Average prediction time is:\", total_time/count, \"sec\")\n",
        "  print(\"Healthy predictions out of total \"+str(count)+\" \"+str(os.path.split(path)[1])+\" images are: \",h)\n",
        "  print(\"Mild predictions out of total \"+str(count)+\" \"+str(os.path.split(path)[1])+\" images are: \",m)\n",
        "  print(\"Severe predictions out of total \"+str(count)+\" \"+str(os.path.split(path)[1])+\" images are: \",s)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWCBrYDFOt0v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "e19856ef-79ae-4023-9e0e-ac780baba3bd"
      },
      "source": [
        "# new predction function on already resized 13 different images\n",
        "# new_prediction_fun('/content/drive/My Drive/datasets/alien_test_leaves_ori/already_resized/different_32x32')\n",
        "# new_prediction_fun('/content/drive/My Drive/datasets/alien_test_leaves_ori/already_resized/different_64x64')\n",
        "new_prediction_fun('/content/drive/My Drive/datasets/alien_test_leaves_ori/already_resized/different_128x128')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Total prediction time for 13 images is:  1.2613269999999979 sec\n",
            "Average prediction time is: 0.09702515384615368 sec\n",
            "Healthy predictions out of total 13 different_128x128 images are:  9\n",
            "Mild predictions out of total 13 different_128x128 images are:  4\n",
            "Severe predictions out of total 13 different_128x128 images are:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8995Pfq17o0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "b20f6f5c-3c26-4673-fbd8-5d5791400b68"
      },
      "source": [
        "new_prediction_fun('/content/drive/My Drive/datasets/alien_test_leaves_ori/healthy')\n",
        "new_prediction_fun('/content/drive/My Drive/datasets/alien_test_leaves_ori/mild')\n",
        "new_prediction_fun('/content/drive/My Drive/datasets/alien_test_leaves_ori/severe')\n",
        "new_prediction_fun('/content/drive/My Drive/datasets/alien_test_leaves_ori/different')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Total prediction time for 96 images is:  32.122791 sec\n",
            "Average prediction time is: 0.33461240625 sec\n",
            "Healthy predictions out of total 96 healthy images are:  86\n",
            "Mild predictions out of total 96 healthy images are:  9\n",
            "Severe predictions out of total 96 healthy images are:  1\n",
            "\n",
            "\n",
            "Total prediction time for 229 images is:  74.70858899999995 sec\n",
            "Average prediction time is: 0.3262383799126635 sec\n",
            "Healthy predictions out of total 229 mild images are:  0\n",
            "Mild predictions out of total 229 mild images are:  224\n",
            "Severe predictions out of total 229 mild images are:  5\n",
            "\n",
            "\n",
            "Total prediction time for 108 images is:  35.27363400000003 sec\n",
            "Average prediction time is: 0.3266077222222225 sec\n",
            "Healthy predictions out of total 108 severe images are:  0\n",
            "Mild predictions out of total 108 severe images are:  13\n",
            "Severe predictions out of total 108 severe images are:  95\n",
            "\n",
            "\n",
            "Total prediction time for 13 images is:  1.1084089999999946 sec\n",
            "Average prediction time is: 0.08526223076923035 sec\n",
            "Healthy predictions out of total 13 different images are:  9\n",
            "Mild predictions out of total 13 different images are:  4\n",
            "Severe predictions out of total 13 different images are:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIEGkuECzu5q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "60600826-97c1-4279-f844-706ee67e411e"
      },
      "source": [
        "# single image testing for time to pridict\n",
        "\n",
        "\n",
        "predict_imgs('/content/drive/My Drive/datasets/alien_test_leaves_ori/single_img_test_for_time_to_predict/healthy/', 'single_image', pathModelSave)\n",
        "print(\"*********************\")\n",
        "predict_imgs('/content/drive/My Drive/datasets/alien_test_leaves_ori/single_img_test_for_time_to_predict/mild/', 'single_image', pathModelSave)\n",
        "print(\"*********************\")\n",
        "predict_imgs('/content/drive/My Drive/datasets/alien_test_leaves_ori/single_img_test_for_time_to_predict/severe/', 'single_image', pathModelSave)\n",
        "print(\"*********************\")\n",
        "predict_imgs('/content/drive/My Drive/datasets/alien_test_leaves_ori/single_img_test_for_time_to_predict/diff/', 'single_image', pathModelSave)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.57it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "time to predict(1,)images is: 3.3308600000000013\n",
            "65.45% Healthy\n",
            "total single_image images: 1\n",
            "Pridicted Healthy: 1\n",
            "Pridicted Mild: 0\n",
            "Pridicted Severe: 0\n",
            "*********************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.94it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "time to predict(1,)images is: 3.6672480000000007\n",
            "98.04% Mild\n",
            "total single_image images: 1\n",
            "Pridicted Healthy: 0\n",
            "Pridicted Mild: 1\n",
            "Pridicted Severe: 0\n",
            "*********************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.55it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "time to predict(1,)images is: 3.2954360000000236\n",
            "98.72% Severe\n",
            "total single_image images: 1\n",
            "Pridicted Healthy: 0\n",
            "Pridicted Mild: 0\n",
            "Pridicted Severe: 1\n",
            "*********************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 25.45it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "time to predict(1,)images is: 3.163517000000013\n",
            "100.00% Healthy\n",
            "total single_image images: 1\n",
            "Pridicted Healthy: 1\n",
            "Pridicted Mild: 0\n",
            "Pridicted Severe: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2ZF-ESZcikm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e4696a99-b2e9-4dc9-946a-0361f2545769"
      },
      "source": [
        "predict_imgs('/content/drive/My Drive/datasets/alien_test_leaves_ori/healthy/', 'healthy', pathModelSave)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 96/96 [01:15<00:00,  1.28it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "time to predict(96,)images is: 12.929141000000001\n",
            "65.45% Healthy\n",
            "58.33% Healthy\n",
            "82.65% Healthy\n",
            "62.63% Healthy\n",
            "94.14% Healthy\n",
            "76.94% Healthy\n",
            "90.31% Healthy\n",
            "77.54% Healthy\n",
            "92.48% Healthy\n",
            "87.67% Healthy\n",
            "94.33% Healthy\n",
            "60.86% Healthy\n",
            "60.17% Healthy\n",
            "57.75% Mild\n",
            "47.85% Healthy\n",
            "50.07% Healthy\n",
            "59.96% Mild\n",
            "56.71% Healthy\n",
            "84.81% Healthy\n",
            "59.62% Healthy\n",
            "80.13% Mild\n",
            "50.91% Healthy\n",
            "47.16% Healthy\n",
            "68.62% Healthy\n",
            "90.07% Healthy\n",
            "83.66% Healthy\n",
            "79.48% Healthy\n",
            "86.61% Healthy\n",
            "61.59% Healthy\n",
            "69.07% Healthy\n",
            "81.09% Healthy\n",
            "89.68% Healthy\n",
            "87.97% Healthy\n",
            "73.03% Healthy\n",
            "86.77% Healthy\n",
            "61.37% Healthy\n",
            "78.46% Healthy\n",
            "62.21% Healthy\n",
            "70.47% Healthy\n",
            "54.21% Healthy\n",
            "96.66% Healthy\n",
            "84.54% Healthy\n",
            "96.82% Healthy\n",
            "85.13% Healthy\n",
            "72.37% Healthy\n",
            "50.97% Healthy\n",
            "83.44% Healthy\n",
            "52.69% Mild\n",
            "74.11% Healthy\n",
            "48.74% Healthy\n",
            "97.18% Healthy\n",
            "89.39% Healthy\n",
            "93.76% Healthy\n",
            "78.27% Healthy\n",
            "97.67% Healthy\n",
            "94.17% Healthy\n",
            "76.73% Healthy\n",
            "43.50% Healthy\n",
            "49.49% Healthy\n",
            "60.45% Healthy\n",
            "92.78% Healthy\n",
            "86.22% Healthy\n",
            "90.79% Healthy\n",
            "81.62% Healthy\n",
            "95.83% Healthy\n",
            "81.47% Healthy\n",
            "91.08% Healthy\n",
            "68.96% Healthy\n",
            "72.67% Healthy\n",
            "73.99% Healthy\n",
            "90.95% Healthy\n",
            "74.15% Healthy\n",
            "65.81% Mild\n",
            "52.73% Healthy\n",
            "77.53% Healthy\n",
            "39.17% Healthy\n",
            "96.83% Healthy\n",
            "81.27% Healthy\n",
            "37.27% Mild\n",
            "66.92% Healthy\n",
            "88.95% Healthy\n",
            "68.47% Healthy\n",
            "69.16% Healthy\n",
            "69.61% Healthy\n",
            "97.03% Healthy\n",
            "77.48% Healthy\n",
            "68.40% Mild\n",
            "59.30% Healthy\n",
            "39.19% Mild\n",
            "43.60% Mild\n",
            "69.00% Healthy\n",
            "36.61% Severe\n",
            "79.57% Healthy\n",
            "85.54% Healthy\n",
            "55.63% Healthy\n",
            "79.80% Healthy\n",
            "total healthy images: 96\n",
            "Pridicted Healthy: 86\n",
            "Pridicted Mild: 9\n",
            "Pridicted Severe: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqyciR6okDRg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "70b34bf2-0e0c-4293-9103-5d69126ac561"
      },
      "source": [
        "predict_imgs('/content/drive/My Drive/datasets/alien_test_leaves_ori/mild/', 'mild', pathModelSave)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 229/229 [03:03<00:00,  1.25it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "time to predict(229,)images is: 22.098448999999988\n",
            "98.04% Mild\n",
            "97.69% Mild\n",
            "98.18% Mild\n",
            "96.40% Mild\n",
            "99.09% Mild\n",
            "96.77% Mild\n",
            "98.69% Mild\n",
            "94.91% Mild\n",
            "99.57% Mild\n",
            "99.29% Mild\n",
            "98.33% Mild\n",
            "99.56% Mild\n",
            "99.86% Mild\n",
            "99.26% Mild\n",
            "98.58% Mild\n",
            "95.84% Mild\n",
            "98.59% Mild\n",
            "95.88% Mild\n",
            "98.74% Mild\n",
            "98.12% Mild\n",
            "99.63% Mild\n",
            "97.92% Mild\n",
            "97.96% Mild\n",
            "98.20% Mild\n",
            "98.52% Mild\n",
            "100.00% Mild\n",
            "97.89% Mild\n",
            "98.04% Mild\n",
            "97.83% Mild\n",
            "98.09% Mild\n",
            "97.88% Mild\n",
            "95.24% Mild\n",
            "75.06% Mild\n",
            "84.14% Mild\n",
            "52.91% Mild\n",
            "73.34% Mild\n",
            "53.55% Mild\n",
            "85.31% Mild\n",
            "97.63% Mild\n",
            "99.17% Mild\n",
            "99.78% Mild\n",
            "97.88% Mild\n",
            "98.02% Mild\n",
            "95.02% Mild\n",
            "94.60% Mild\n",
            "94.02% Mild\n",
            "98.27% Mild\n",
            "93.04% Mild\n",
            "97.75% Mild\n",
            "95.92% Mild\n",
            "99.00% Mild\n",
            "98.65% Mild\n",
            "93.86% Mild\n",
            "98.18% Mild\n",
            "99.69% Mild\n",
            "99.65% Mild\n",
            "91.39% Mild\n",
            "94.21% Mild\n",
            "94.03% Mild\n",
            "94.62% Mild\n",
            "98.69% Mild\n",
            "99.14% Mild\n",
            "98.15% Mild\n",
            "93.47% Mild\n",
            "90.75% Mild\n",
            "91.30% Mild\n",
            "99.53% Mild\n",
            "86.67% Mild\n",
            "99.17% Mild\n",
            "98.53% Mild\n",
            "99.98% Mild\n",
            "97.10% Mild\n",
            "99.22% Mild\n",
            "98.26% Mild\n",
            "99.48% Mild\n",
            "97.60% Mild\n",
            "99.98% Mild\n",
            "96.74% Mild\n",
            "99.99% Mild\n",
            "95.29% Mild\n",
            "99.86% Mild\n",
            "97.14% Mild\n",
            "98.23% Mild\n",
            "96.39% Mild\n",
            "79.77% Mild\n",
            "87.98% Mild\n",
            "99.95% Mild\n",
            "99.77% Mild\n",
            "98.44% Mild\n",
            "70.82% Severe\n",
            "65.73% Mild\n",
            "93.87% Mild\n",
            "99.88% Mild\n",
            "99.71% Mild\n",
            "99.54% Mild\n",
            "77.27% Mild\n",
            "98.64% Mild\n",
            "77.56% Mild\n",
            "100.00% Mild\n",
            "95.06% Mild\n",
            "73.47% Mild\n",
            "99.12% Mild\n",
            "69.63% Severe\n",
            "99.19% Mild\n",
            "98.52% Mild\n",
            "99.13% Mild\n",
            "97.75% Mild\n",
            "98.35% Mild\n",
            "96.25% Mild\n",
            "53.30% Mild\n",
            "50.99% Mild\n",
            "99.98% Mild\n",
            "82.84% Mild\n",
            "61.02% Severe\n",
            "95.55% Mild\n",
            "95.72% Mild\n",
            "96.62% Mild\n",
            "93.31% Mild\n",
            "100.00% Mild\n",
            "100.00% Mild\n",
            "99.98% Mild\n",
            "78.38% Mild\n",
            "99.14% Mild\n",
            "97.74% Mild\n",
            "99.66% Mild\n",
            "98.21% Mild\n",
            "98.13% Mild\n",
            "97.74% Mild\n",
            "100.00% Mild\n",
            "94.71% Mild\n",
            "99.20% Mild\n",
            "100.00% Mild\n",
            "98.02% Mild\n",
            "98.56% Mild\n",
            "96.50% Mild\n",
            "98.36% Mild\n",
            "99.86% Mild\n",
            "99.84% Mild\n",
            "97.87% Mild\n",
            "100.00% Mild\n",
            "98.94% Mild\n",
            "100.00% Mild\n",
            "100.00% Mild\n",
            "96.18% Mild\n",
            "98.54% Mild\n",
            "99.35% Mild\n",
            "99.91% Mild\n",
            "99.89% Mild\n",
            "96.79% Mild\n",
            "100.00% Mild\n",
            "89.92% Mild\n",
            "99.12% Mild\n",
            "96.82% Mild\n",
            "99.95% Mild\n",
            "86.29% Mild\n",
            "99.98% Mild\n",
            "96.18% Mild\n",
            "99.52% Mild\n",
            "99.71% Mild\n",
            "99.99% Mild\n",
            "99.99% Mild\n",
            "99.68% Mild\n",
            "97.12% Mild\n",
            "100.00% Mild\n",
            "77.29% Mild\n",
            "99.94% Mild\n",
            "64.64% Mild\n",
            "99.38% Mild\n",
            "59.48% Mild\n",
            "99.84% Mild\n",
            "99.82% Mild\n",
            "96.72% Mild\n",
            "97.44% Mild\n",
            "92.99% Mild\n",
            "98.94% Mild\n",
            "95.11% Mild\n",
            "100.00% Mild\n",
            "94.45% Mild\n",
            "99.83% Mild\n",
            "96.65% Mild\n",
            "95.35% Mild\n",
            "98.28% Mild\n",
            "98.44% Mild\n",
            "99.97% Mild\n",
            "99.39% Mild\n",
            "99.99% Mild\n",
            "75.84% Mild\n",
            "100.00% Mild\n",
            "76.41% Mild\n",
            "96.93% Mild\n",
            "67.34% Mild\n",
            "96.55% Mild\n",
            "86.02% Mild\n",
            "99.99% Mild\n",
            "87.76% Mild\n",
            "100.00% Mild\n",
            "99.48% Mild\n",
            "99.92% Mild\n",
            "99.93% Mild\n",
            "99.00% Mild\n",
            "94.57% Mild\n",
            "99.68% Mild\n",
            "97.50% Mild\n",
            "99.13% Mild\n",
            "91.18% Mild\n",
            "98.68% Mild\n",
            "90.86% Mild\n",
            "97.82% Mild\n",
            "80.32% Mild\n",
            "99.97% Mild\n",
            "89.74% Mild\n",
            "99.21% Mild\n",
            "71.40% Mild\n",
            "99.96% Mild\n",
            "87.41% Mild\n",
            "99.99% Mild\n",
            "100.00% Mild\n",
            "100.00% Mild\n",
            "100.00% Mild\n",
            "100.00% Mild\n",
            "97.48% Mild\n",
            "87.62% Mild\n",
            "99.96% Mild\n",
            "59.25% Severe\n",
            "84.70% Mild\n",
            "100.00% Mild\n",
            "98.31% Mild\n",
            "74.76% Severe\n",
            "80.54% Mild\n",
            "total mild images: 229\n",
            "Pridicted Healthy: 0\n",
            "Pridicted Mild: 224\n",
            "Pridicted Severe: 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88EeTgvckLzk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9f794f2a-d3fe-4820-fff8-85f6aa06b96e"
      },
      "source": [
        "predict_imgs('/content/drive/My Drive/datasets/alien_test_leaves_ori/severe/', 'severe', pathModelSave)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 108/108 [01:13<00:00,  1.48it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "time to predict(108,)images is: 9.885964000000001\n",
            "98.72% Severe\n",
            "94.09% Severe\n",
            "99.26% Severe\n",
            "98.55% Severe\n",
            "99.66% Severe\n",
            "96.58% Severe\n",
            "52.96% Mild\n",
            "66.67% Severe\n",
            "94.79% Severe\n",
            "87.47% Severe\n",
            "96.17% Severe\n",
            "98.84% Severe\n",
            "93.72% Severe\n",
            "96.35% Severe\n",
            "90.18% Severe\n",
            "98.78% Severe\n",
            "98.16% Severe\n",
            "99.60% Severe\n",
            "98.72% Severe\n",
            "98.66% Severe\n",
            "96.65% Severe\n",
            "90.82% Severe\n",
            "98.24% Severe\n",
            "94.19% Severe\n",
            "52.74% Mild\n",
            "52.89% Mild\n",
            "60.22% Mild\n",
            "90.58% Mild\n",
            "75.93% Severe\n",
            "61.91% Severe\n",
            "93.07% Severe\n",
            "71.53% Severe\n",
            "90.58% Severe\n",
            "59.75% Severe\n",
            "74.72% Severe\n",
            "52.94% Severe\n",
            "76.50% Severe\n",
            "72.09% Mild\n",
            "99.71% Severe\n",
            "99.06% Severe\n",
            "81.59% Severe\n",
            "62.29% Severe\n",
            "95.13% Severe\n",
            "92.94% Severe\n",
            "81.98% Severe\n",
            "99.19% Severe\n",
            "72.31% Severe\n",
            "57.90% Mild\n",
            "90.37% Severe\n",
            "86.12% Severe\n",
            "76.66% Severe\n",
            "93.32% Severe\n",
            "98.81% Severe\n",
            "96.11% Severe\n",
            "99.42% Severe\n",
            "97.48% Severe\n",
            "99.41% Severe\n",
            "96.85% Severe\n",
            "99.13% Severe\n",
            "96.85% Severe\n",
            "99.37% Severe\n",
            "97.92% Severe\n",
            "98.99% Severe\n",
            "97.72% Severe\n",
            "95.24% Severe\n",
            "99.97% Severe\n",
            "96.63% Severe\n",
            "92.03% Severe\n",
            "98.77% Severe\n",
            "92.81% Severe\n",
            "99.84% Severe\n",
            "99.15% Severe\n",
            "72.16% Severe\n",
            "53.74% Mild\n",
            "74.73% Severe\n",
            "61.57% Mild\n",
            "82.16% Severe\n",
            "75.16% Severe\n",
            "93.34% Severe\n",
            "83.44% Severe\n",
            "78.45% Severe\n",
            "78.69% Severe\n",
            "58.14% Mild\n",
            "99.81% Severe\n",
            "67.26% Severe\n",
            "84.42% Severe\n",
            "57.83% Severe\n",
            "97.77% Severe\n",
            "84.40% Severe\n",
            "89.02% Severe\n",
            "97.12% Severe\n",
            "93.53% Severe\n",
            "94.84% Severe\n",
            "91.62% Severe\n",
            "69.80% Severe\n",
            "98.75% Mild\n",
            "96.81% Severe\n",
            "89.55% Severe\n",
            "71.83% Severe\n",
            "58.30% Severe\n",
            "93.81% Mild\n",
            "96.10% Mild\n",
            "99.06% Severe\n",
            "96.48% Severe\n",
            "99.46% Severe\n",
            "98.55% Severe\n",
            "99.76% Severe\n",
            "99.47% Severe\n",
            "total severe images: 108\n",
            "Pridicted Healthy: 0\n",
            "Pridicted Mild: 13\n",
            "Pridicted Severe: 95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LMIFUw3dMZ3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "1197227f-10de-457b-e15f-7337d66c2438"
      },
      "source": [
        "%%time\n",
        "predict_imgs('/content/drive/My Drive/datasets/alien_test_leaves_ori/different/', 'different', pathModelSave)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 13/13 [00:03<00:00,  3.57it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "time to predict(13,)images is: 2.1547379999999947\n",
            "99.97% Mild\n",
            "99.28% Mild\n",
            "99.50% Mild\n",
            "100.00% Healthy\n",
            "99.84% Mild\n",
            "100.00% Healthy\n",
            "99.97% Healthy\n",
            "100.00% Healthy\n",
            "100.00% Healthy\n",
            "100.00% Healthy\n",
            "99.59% Healthy\n",
            "100.00% Healthy\n",
            "100.00% Healthy\n",
            "total different images: 13\n",
            "Pridicted Healthy: 9\n",
            "Pridicted Mild: 4\n",
            "Pridicted Severe: 0\n",
            "CPU times: user 4.37 s, sys: 673 ms, total: 5.04 s\n",
            "Wall time: 7.18 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqFS552PvCyj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "86b1bb0a-8028-41e7-a0a6-77f35f3b7678"
      },
      "source": [
        "print(type(history_ori))\n",
        "...\n",
        "# list all data in history\n",
        "print(history_ori.history.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'keras.callbacks.History'>\n",
            "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hn7EJTZnw2Mf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "48935698-b0b5-4de3-b017-48fd93cea1e2"
      },
      "source": [
        "print(history_ori.history['loss'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.6147231479606978, 1.638691039574219, 1.1768211504308188, 1.222878444485548, 0.6862581706628567, 0.7577413974738703, 0.8293126210933779, 0.6553598206217696, 0.9123166770469852, 1.2399330139160156, 1.1069551502786033, 0.9066931736178514, 0.8899625278100735, 0.8668171196449094, 0.8336983308559511, 0.80722436090795, 0.8750437701620707, 1.02267611899027, 1.0757231188983452, 1.0458749038417166, 1.0272093865929581, 1.5775422061361917, 1.8811370919390422, 1.8215750601233505, 1.7706577952315168, 1.705599877892471, 1.670259045391548, 1.837127173819193, 2.297400497808689, 2.2415619129087867, 1.5030158903540634, 1.566637306678586, 1.5825008531896079, 1.256303252243414, 1.166381010195104, 0.9020444590870927, 1.0108669909035288, 1.1365164431130015, 1.0660212912210605, 0.9423243534274217, 0.8777701505800573, 1.0720796933988246, 0.9314502041514326, 0.8425584188321742, 0.7651184535608059, 0.5809717381872782, 0.6715523324361662, 0.8672836640986, 0.9982242177172405, 0.8429510011905577, 1.3315966885264328, 1.2720696519060832, 1.3697489936177323, 1.32198820463041, 1.2933392873624476, 1.3636266894456817, 1.3714894317999118, 1.6157696770458687, 1.3723895026416313, 1.5239403538587617, 1.8735678254104242, 1.3387877475924608, 0.8233503742915828, 0.5976552701577907, 0.6526198067316195, 0.9549437383326088, 1.0641399592888066, 1.0371817030557773, 0.6782682232740449, 0.9206902980804443, 1.4019411831367306, 1.4730355565140887, 1.4202162579792301, 1.0570874853831966, 1.163092909789667, 1.6791668170835914, 1.9998826747987328, 1.354267748390756, 1.068869643095063, 1.0282553870503495, 1.3176769512455637, 1.8111375017863949, 1.2839039767660745, 1.1893310430573254, 1.338253486447218, 1.8646018098040325, 3.024034988589403, 2.6767064187584855, 0.8537880095039926, 0.512214744963297, 0.3589280000547083, 0.36594766669157075, 0.6234625025493342, 2.961462579122404, 1.8654798182045542, 2.788183398363067, 2.982215834826958, 2.936971931241271, 3.6252709249170816, 4.117927853654071, 2.268579017825243, 1.2454931445238067, 1.586156618304369, 2.4811036354157983, 3.3460020088567966, 4.06538453916224, 4.7192737300221514, 4.85805976681593, 5.561247569758717, 5.843154953747261, 4.878602679182843, 4.3984460132878, 4.5933287085556405, 5.918806006268757, 6.168267505924876, 5.007365412828399, 3.6084102537573837, 1.810180861775468, 1.066950798034668, 0.5298954640946737, 0.5180126528550939, 0.2585684580773842, 0.593741783281652, 1.2898330979230928, 0.375321552520845, 0.5343995624926032, 0.5823706714436412, 0.4769162637431447, 0.9740861421678124, 0.7423789152284948, 1.2638567482552878, 2.1669559478759766, 2.577180885687107, 1.925078380398634, 1.0862486595060767, 0.8171749696498964, 1.452536908591666, 0.558621248094047, 1.0412915189091752, 0.4342996645264509, 0.3922799018824973, 1.7055118839915206, 3.259402461168243, 4.190225042947909, 0.8825021255307082, 0.9930596119020043, 1.6392710848552425, 2.7116225172833697, 3.851300216302639, 1.3490864125693716, 0.28283215732109257, 0.3140887392730248, 0.3909109598252831, 0.24861331393079059, 0.22378217301717618, 0.4020323840583243, 0.30127397179603577, 0.6012084702166115, 0.3689586076794601, 0.9422986609179799, 3.467874840992253, 0.35928686308424646, 0.2515025462546363, 0.2922350664327784, 0.903361868567583, 2.5454691212351728, 0.9709179634001197, 0.18843118919105065, 0.239338928606452, 0.8370674979395982, 1.7779275702267159, 1.795293217752038, 1.6135224612747752, 1.1732792549017, 0.6848692421506091, 0.4816112136695443, 0.5037264729418406, 0.5127246263550549, 0.6129176849272193, 2.164268633214439, 3.397934681031762, 3.4784785712637554, 2.2199008464813232, 0.2906067447691429, 0.16688129162733875, 0.47945292673369005, 0.5412281400910238, 0.26159289107862405, 0.32477660013771636, 1.0890423321142428, 0.9659578160541814, 0.5508282497161772, 0.3556911656405868, 0.7550762004968596, 0.8380756498110004, 0.6715288810977121, 0.6086570782609647, 0.6220178695895323, 0.8004196471557384, 0.6637906105053134, 0.5215318537339931, 0.6815978404952259, 0.6740427656871516, 0.5354653480576306, 1.119613172077551, 0.30515006820603113, 0.4219745335214567, 0.46728434202420277, 1.3191102428358934, 0.6829015869056669, 0.5846681738862904, 0.22410205658525229, 0.5475130316506072, 1.0838875634277738, 0.8402823376946333, 1.6247708128719796, 1.0772683533226572, 1.404308952936312, 1.3022950800453745, 1.2403666624208776, 1.009174932793873, 1.7374739908590549, 1.2580912781924736, 1.2871094273357857, 1.901095622923316, 1.3757785587775997, 1.0239590173814355, 0.1259122957907072, 0.12776123255309535, 0.180044472853585, 0.12552236194336197, 0.2285534397857945, 0.5145909437319127, 0.5344863243219329, 1.506391827653094, 2.4758850190697648, 2.981567080427961, 3.049052366396276, 3.021433388314596, 2.074371651905339, 1.6208767556562655, 1.2363146870601467, 1.4328015904601028, 2.8262793378132147, 3.7236959178273272, 4.049081197599086, 2.5592449699960103, 2.765390000692228, 2.6312373556741853, 2.367529020076845, 2.7745132329987316, 2.740007470293743, 2.202966794735048, 2.5734706506496523, 3.4493157223957343, 2.184683555509986, 1.2800288491132783, 1.026560341439596, 0.9417616768581111, 0.2563596280609689, 0.2212321756453049, 0.19872005111197147, 0.34829824713126917, 1.0402766567904775, 0.3950083873620847, 0.3790925597976439, 0.31630316167138517, 0.2543232049338701, 0.5002756189645791, 0.7749941465331287, 0.49848781271678644, 0.35068533642262945, 0.5686825706318969, 0.2720872207385738, 3.4192973811451983, 3.438446521759033, 0.8849123251147386, 0.5893506887482434, 0.5754898350413252, 0.5560941521714373, 2.1316945727278545, 1.5696217025198587, 0.6761126823541594, 0.3107206850517087, 0.4800194082554521, 0.35780777200693037, 0.49923703038110967, 0.4281747809997419, 0.6403710978423677, 0.7245296966738817, 0.3122496401391378, 0.5324004859459109, 0.6705149324928842, 0.32209339229072015, 0.13489733840815904, 0.13857953600222017, 0.20844769823115047, 0.35057046555164384, 0.3094790358914108, 0.15043210272291085, 0.14173110492709207, 0.3826927306448541, 0.7928183253218488, 0.3892568422526848, 0.4276682974361792, 0.4708556205761142, 0.49317294577272924, 0.4472623242110741, 0.4726821344073226, 3.318293801168116, 1.4297714000794945, 1.0902997008184108, 1.2752155239989118, 1.136523054867256, 0.9376230298019037, 0.8444916184355573, 0.8437300397128593, 0.6556513280403323, 0.8291577973016878, 0.8067448938765177, 2.1170445884146343, 2.3121174835577243, 0.39737639703401706, 0.3512595352239725, 0.2991669879453938, 0.3489252401561272, 0.7412323784537431, 0.8152993146966143, 0.25886403769254684, 0.20586565527610662, 0.30391672653395957, 0.33556905979426893, 0.19152256986126304, 0.18876852395535423, 0.17277096081297935, 0.22066556762267903, 0.5814081561274644, 0.9523693352210812, 0.9620667521546526, 0.7547476785938915, 1.0351022714521827, 0.7066925357027751, 0.4255444305699046, 0.37237825085658854, 0.40041697911191276, 0.35723516585805065, 0.6785446530798587, 0.8992928113879227, 0.9323543694506331, 0.9196546452074517, 0.6034052012170233, 0.8169503766225605, 0.20436774312359532, 0.30204660086551816, 0.4589405267885545, 0.3718233209375928, 0.26930429023213504, 0.17758343452814876, 0.5097282025508765, 2.3738982619308846, 2.259312117972025, 0.8643801677517775, 0.8926540035300139, 0.5293907216045914, 0.2439423176210101, 0.2046307425309972, 0.13794731903003482, 0.11045717720578356, 0.11026421461890383, 0.3963073492050171, 0.5478158411456318, 0.18608560703876542, 0.28007045097467376, 0.7282363670628246, 0.32873984916907983, 0.11077543120922112, 0.09653860266979147, 0.12243245405758299, 0.42942054387999745, 0.380612676463476, 0.33432007126691865, 0.13022938443393242, 0.16862879107456383, 0.24975136831039335, 0.19654171609478752, 0.10034654467798225, 0.7256648787638036, 0.2855457343706271, 0.3702697441345308, 0.31739803530820987, 0.29788648609707996, 0.16674731744498741, 0.2109087594762081, 0.3111578840308073, 0.16790214680680415, 0.07828608219988825, 0.0728030705585985, 0.11565070298909233, 0.15396496875597754, 0.15750787868278054, 0.4207982566298508, 0.31187237799167633, 0.20157977457090123, 0.10686027862858481, 0.08863421179149754, 0.11094194350241707, 0.0646924386936717, 0.11406398946192206, 0.07810375766783226, 0.11185962739173413, 0.15031925624054743, 0.10353019506466098, 0.8695070474613004, 0.22998081056810007, 0.0842412682477294, 0.09594013029709458, 0.12262397211771912, 0.11452530110936339, 0.40214520547448135, 0.4096415155544514, 0.1821634407813956, 0.10298818323715794, 0.10602799478759307, 0.9398433292034741, 0.37245528672526523, 0.5495996129948918, 0.09495475322644158, 0.2475689264417558, 0.32952260005390044, 0.26577950040128356, 0.17909615793515268, 0.09468677083439217, 0.11246530359565485, 0.2463428596625241, 1.2160718848065633, 1.0800948942579873, 0.07232904206484375, 0.07746061180695528, 0.15994809318061282, 0.29613752426897605, 0.19966630501354612, 0.1144573868922435, 0.17607161788860473, 0.15992156425263823, 0.5860613933423671, 1.6864276804575107, 2.309293037507592, 2.383146716327202, 1.1445388081597119, 0.352270731838738, 0.21368884722270617, 0.14323336485682464, 0.11997853060502832, 0.346005041788264, 0.430741270413486, 0.14969897247487451, 0.13583973050117493, 0.15788039733178733, 0.26083058082475896, 0.2893557692082917, 0.2651381147798242, 0.6570103966244837, 0.23729366945420824, 0.9498567479412731, 1.620485683766807, 0.7979893182835928, 0.42577306889906164, 0.3482314519947622, 0.29324990910727805, 0.133506185988464, 0.4306051351993186, 0.830897186405775, 3.0756535166647376, 5.293587428767506, 5.138603629135504, 3.7718188820815666, 3.272294852791763, 2.5603663543375528, 4.261054120412687, 5.749494668914051, 5.240356933779832, 4.168483478267018, 1.7297844236216895, 1.029800805467658, 0.513169464223632, 0.6966080706930016, 0.7543228687661723, 0.4105978841643508, 0.3444699996673479, 0.4284569106587186, 0.4110450460234793, 0.42447015534086924, 0.3691843526392448, 0.25288629559118575, 0.41675985930487514, 0.3642066908523259, 1.555952153554777, 3.723137041417564, 3.337262996813146, 1.7290394189881115, 0.6722188516996983, 0.42815398751962475, 0.5771875871890565, 0.6701935117314683, 0.6604032390296641, 0.5883258619550161, 0.3424581815758379, 0.23046145654104583, 0.8997117388062179, 1.2381414188350346, 1.0740154000806974, 0.40304653237789595, 0.16904347150575189, 0.301252571956777, 0.2652416318405147, 1.7197034175801602, 2.5132085041323524, 3.059792326717925, 3.4401189641254954, 2.2005194861722863, 0.9234252719655094, 0.5389681118781815, 0.29691823554600066, 0.6970468038783931, 0.7418985950147233, 0.8179559479013268, 0.8918782237735463, 0.6197785351470839, 0.25142949155145666, 0.32078308993723337, 0.3832423490722005, 0.40575558335730444, 0.5969815957800076, 0.4034872034013771, 0.22579349038651123, 0.4222287432540481, 0.8006112024914928, 2.154160540278365, 2.455479334040386, 1.759796174561105, 3.5245827232919087, 4.214604668500947, 2.9531933737964167, 1.509357442034454, 1.6672314268241568, 1.3695281647690913, 4.122886587933796, 5.860730962055485, 5.116073596768263, 3.6606762554587386, 1.72916348096801, 0.8876483774766689, 0.8544868594262658, 0.9660694915346983, 0.9477639667144636, 2.962205898470995, 2.87661232599398, 1.730353262366318, 2.666455767867042, 3.6557629530022786, 1.6313336269884575, 1.5292678764317094, 1.4888386084221121, 1.1838751137710926, 1.0999239649987076, 1.0688642402656559, 0.7695882592759118, 0.45140265964153337, 0.27416089576918906, 0.12964599587522993, 0.1676222283802018, 0.1261438274949153, 0.04914376278203435, 0.039690929851154, 0.037583928214522395, 0.043335974761625616, 0.05788203406079513, 0.054224419396188925, 0.06203440025948533, 0.05489781793070639, 0.10900106290128173, 0.27931960596044253, 0.10564996349829726, 0.5385170389966267, 0.9407276845559841, 2.653467678442234, 3.282311044088224, 2.770406723022461, 0.2507204095401415, 0.20733114068464534, 0.10009621149610455, 0.1120152960463268, 0.09675853533624876, 0.1889257836666685, 0.08922174310016377, 0.08802692414397692, 0.10083335936183065, 0.09837369988786011, 0.10625865681823797, 0.12071800990052885, 0.13620381556996486, 0.07625949145976181, 0.08854185969273491, 0.1108229340213101, 0.2584986543146575, 0.31757250019326444, 0.10552880329238933, 0.07775546014081777, 0.130324445167988, 0.1371493156652943, 0.09652383805241255, 0.07298141319827153, 0.18817574476323476, 0.46478060396706183, 0.23454123258408976, 0.10740418634490996, 0.2598339463697701, 0.36346379185958605, 0.4532035924387789, 0.3853150929275349, 0.10193683398197541, 0.04527443789354548, 0.07177574252823322, 0.08626317905216682, 0.09474806002591078, 0.10587766159484845, 0.12020633395806682, 0.21164794727342157, 0.2678714147357202, 0.2218870594841996, 0.12813757854604685, 0.10566115110158557, 0.10952649644871311, 0.08577017150833499, 0.10099464336554974, 0.0950173439639734, 0.07822272414625508, 0.07850704639979707, 0.09067217291832515, 0.1309402899294183, 0.15513276686982774, 0.1490495589152887, 0.14256144332040738, 0.172237576076352, 0.19390795897783303, 0.21620201042330847, 0.20674499147003744, 0.35951773655350977, 0.20495262258209107, 0.30993151753323106, 0.31047211219443055, 0.541669768531148, 0.13951807615642503, 0.38448199297574054, 0.21930724566393509, 0.7122741949449225, 0.7148481520210824, 0.7701911641875419, 0.5587427825099085, 1.139640369429821, 0.8278190449970525, 2.013537848868021, 2.3467311161320383, 1.368315469927904, 0.3034141517085273, 0.14092714267941872, 0.18765864176562103, 0.23956500135771022, 0.3371024177489212, 0.37113172844018244, 0.20306608551068278, 0.12440297272192632, 0.5377400727806295, 0.6237097829580307, 0.13410311700526353, 0.2544000240457358, 0.34248871681076, 0.3039270671447966, 0.09221831072553448, 0.06528361260084571, 0.06829929582365765, 0.09224234880856806, 0.11639313833935686, 0.07264604756932297, 0.10731689886349004, 0.13446849888962945, 0.06263215266304409, 0.06597037437065255, 0.054786467754350206, 0.0435116756451884, 0.04971226192329351, 0.0830479990797424, 0.21269085352371514, 0.25924707613260733, 0.24224979066142313, 0.19065158914706512, 0.13073740623005461, 0.22580357219614997, 0.5312527710253873, 1.1114563771137378, 0.8047619431120593, 0.7628094065116673, 0.6008474978095875, 0.4429311984241372, 0.27415966178949286, 0.19819129815484146, 0.33279610243512364, 1.8968117091713883, 1.995055384752227, 1.6663882674240484, 0.4220494730483241, 0.3393732025713955, 0.3711918095700307, 0.9462920718130435, 0.419786141890033, 2.432164436433373, 2.2974975399854705, 2.2841828160169646, 2.1072877558266243, 2.394847439556587, 2.8006461073712603, 2.627275653001739, 1.5641915274829399, 1.01756207099775, 0.6836405905281625, 0.2077372244164552, 0.36219685624222975, 0.6222184735251641, 0.8321845236414669, 0.6437141178289383, 0.6797603570299632, 0.9241885699433978, 0.8651454181455802, 0.9625638498947388, 1.2909407441209002, 1.7568077924774914, 1.012312789515751, 0.12714196935511854, 0.19638735992356954, 0.2107742412708609, 0.1360431318568838, 0.11241748419067846, 0.8994802696681468, 1.4814709832028645, 1.5953174640492696, 1.4149238452678774, 0.9105940591998216, 1.2426734435849074, 0.9480065661596089, 0.6487346485189003, 1.1989950668521043, 0.8936759438820001, 0.6875809521482485, 0.5523148870816817, 0.46264261014549424, 0.3789361998961107, 0.16993758737820516, 0.1495396454888356, 0.11977522947481481, 0.47389349124431446, 0.8571097004772504, 0.6010850776986378, 1.6671018774916486, 1.6753391579883854, 1.4925072076844006, 1.4097215140738137, 1.3883175064877766, 1.255984794802782, 1.0247742795362704, 0.8352560855266524, 0.6853925401299465, 0.46236560675429134, 0.2721366743761592, 0.20597376385930835, 0.15553891286821808, 0.47904313809987975, 0.5146292842152279, 0.43508010783528045, 0.38512381548970576, 1.0537663551229166, 0.9959408684474665, 0.9518888378288688, 0.7813606784713069, 0.790293146413183, 0.7383370680461933, 0.5671347214772207, 0.2395240120567018, 0.06700955863428734, 0.16715353763684992, 0.5341059416930032, 0.256120533625618, 0.16641390518989504, 0.1529504153423193, 0.42063015657363506, 0.9738338480635387, 1.3721014086793109, 1.1849143025351734, 0.9178228230647197, 0.31995839585845426, 0.19579603240779805, 0.5920839994285461, 0.5426291232338039, 0.510039420434978, 1.2272144381592913, 2.027395492646752, 1.9027785673374082, 0.3187352019680164, 0.08261147417446099, 0.07134665123175649, 0.06349384831264615, 0.09671687368848701, 0.9286969064212427, 1.318076607657642, 0.8196221761087455, 0.6165566776833702, 0.6211525408619243, 0.5363562269840481, 0.5265206253246927, 0.16556393117757467, 0.12542944141981624, 0.0874669832026972, 0.0719912212949655, 0.3509540837002555, 0.9467111454322571, 1.7539264399830887, 1.8693693905341915, 1.8800169025979392, 1.5396691938725913, 0.8749468652985808, 0.5343882790312353, 0.26176035222483846, 0.4759822465002355, 0.609507789914837, 0.5825465049640071, 0.5259705554671222, 0.5899486689169596, 0.9169965291895518, 0.8562070480207118, 0.5225306269826322, 0.4709142481840057, 0.7649945638812624, 0.7551395251052226, 0.8707437676990905, 1.2743917103947662, 0.8226995786152235, 1.3590240245912133, 1.7241732932825249, 1.7907212027714816, 4.221714008145288, 2.0450152565793336, 2.0535231218105436, 1.0776981188032217, 0.8240987774955035, 0.5486009686235154, 0.7501693283414991, 1.6226582692218405, 2.0375292406576437, 1.6330170747710437, 1.688384893463879, 1.8786535039657681, 2.131865428385847, 2.192553746082434, 1.769944705069065, 1.132845063213963, 0.910216636908533, 0.6072121394484761, 0.33893434314938153, 0.12466484712031826, 0.2689778543220799, 0.7571368130286762, 0.2431333821422879, 0.11554498805965456, 0.38643206927141677, 0.5279140385188573, 0.5102957545257696, 0.30480257439909086, 0.1082784693420674, 0.051996244623651586, 1.1459519587426656, 1.0957693036092588, 0.825529409618334, 0.3759322591677341, 0.13706864464452004, 0.1307787915292709, 0.08574711224000345, 0.1722546139931737, 0.10670812664240502, 0.2017070164045369, 0.09480224972299411, 0.34749006788996023, 0.578971316177558, 0.5446414468384407, 0.4813155144376385, 0.5252813097407542, 0.7060830196956309, 0.87598053020675, 0.488805260120255, 0.2718138760544939, 0.23199794764443096, 0.15316591025670853, 0.21715027314224622, 0.23810586792121574, 0.4006707345457782, 0.5949933357297573, 0.3885665900448746, 0.310630230040704, 0.2850919419717861, 0.8215094118765215, 1.2071101520119645, 1.4490094039498307, 1.1564649328952883, 1.0054129129502831, 0.8336636238708729, 0.6143090337935109, 0.5806274808554274, 0.5325490267487334, 0.2029676040486864, 0.10739838680615876, 0.10620372177942133, 0.09516671626465167, 0.09369844207313002, 0.09584482406016166, 0.08966533831752292, 0.24329776127493327, 0.3211934444574049, 0.295793284812556, 0.12957429663929804, 0.06974084857809919, 0.04630643086651306, 0.2851964024618011, 0.2963205220551505, 0.11580211597511818, 0.15521652781313694, 0.29100501836879494, 1.0697234723626114, 1.476685657733824, 0.4172428854763871, 0.45817094446137185, 0.5472381612195111, 0.800485964437163, 0.7689061331138208, 0.6665620144187592, 0.16582802915022846, 0.14282147163488312, 0.07635912446982353, 0.04093185876227813, 0.03580293649021059, 0.32851277800736856, 0.5046805915275089, 0.2190740838683801, 0.23466711091772063, 0.13405287402068697, 0.5035861167650693, 0.5602344174112659, 0.5474418059289392, 0.497380187333231, 0.11252724899620772, 0.12113795738749593, 0.09650101793416004, 0.09960996898504473, 0.42184898039199764, 0.4934277708938647, 0.14712954022085864, 0.0792334252506496, 0.4065955116558343, 0.7994749692734331, 0.8060971592757397, 0.7724519073679226, 0.7933921889719985, 0.8176585225979003, 0.7886287957804686, 0.8228749313914194, 0.8206660122690131, 0.25347132198285405, 0.4191775718510787, 0.5654825654857587, 0.3470849275429983, 0.3574891157970741, 1.6542420241890885, 1.6333468963460225, 1.793553732517289, 2.2045822594223954, 1.6684902862804691, 1.5772885578434641, 1.3395384491943731, 1.789770731111852, 1.0539253557600625, 0.8965838548341175, 0.3769307104847962, 0.3207726466764764, 0.4092140364369786, 0.22486959686275662, 0.3268955419430645, 0.46190307426788824, 0.09819473356232843, 0.0886055311658732, 0.05811681708274125, 0.04566156325887366, 0.05866909916470077, 0.10059359408034829, 0.11668852151360182, 0.0840822799307317, 0.3840331088683409, 0.5658138344510141, 0.9243178967068472, 0.8832424747411207, 0.4837983660428308, 0.30115409954110295, 0.03163940495834118, 0.2128049094737834, 1.0345997910658409, 0.7181689826024146, 0.07580838570791501, 0.1017395759898624, 0.8672800077488874, 0.6037895161794816, 0.14080827974532617, 0.07200010383513006, 0.9306697096766495, 1.3344473493535345, 1.8845553078302524, 0.24526237024727424, 1.3028926573148603, 2.1174395985719636, 2.377607139145456, 2.0656029378495577, 0.07310822407151402, 0.19362254587581335, 0.28497065245968906, 0.369012424580344, 0.9694559893956999, 0.28443312136362403, 0.6357423590450753, 0.8646801942732276, 0.3300750357348751, 0.27782214124627214, 0.37972516409584983, 0.4571186362306723, 0.2094670519596193, 2.328709629250736, 2.4979283082775954, 1.5362424836834756, 0.7681155892872683, 1.0407755585705363, 0.9214647223309773, 0.6425409840374459, 0.5836024982173268, 0.9797185203117296, 1.1284326400335243, 1.349355287128696, 1.1468303794745447, 0.6773359725229079, 0.8952647876562323, 0.8675406972605099, 0.8516020755079098, 0.9149861570175101, 0.7027069259571229, 0.46013127597866627, 0.4825278712868145, 0.4848644424956746, 0.3181287593622806, 0.2679165899554813, 0.07036806650249651, 0.08227617163409866, 0.0717998008057759, 0.1367445511249371, 0.2672074906646541, 0.22366491481470138, 0.1995210234677737, 0.12294219648422923, 0.5411367838131832, 1.350970263785978, 1.6627123248649807, 2.0173555041050037, 2.0130683628660515, 2.2181419628422434, 1.8157866219194925, 1.4044562636352167, 1.7913512268739684, 1.6071230329178479, 1.4399542566541463, 1.2113414989937332, 0.9899674674173783, 0.4459202404292982, 0.5609519587426515, 0.3309906164167176, 0.3286293204987376, 0.5549665710934233, 0.05290627575165517, 0.05210076204470746, 0.141078309479692, 0.20127396511833934, 0.4613408071390728, 0.7937168500989729, 0.7352445169231587, 0.7575040903248896, 0.8824651843496235, 1.147619252778141, 1.5141766051656749, 1.4389286928067344, 1.5048405106474714, 2.028140924325805, 1.9758694456328025, 0.5280279027604747, 0.7372582221237614, 0.8523106778540276, 0.9242485238284599, 0.7746969403290167, 0.5114307112810088, 0.4889595246896511, 2.287118356402327, 4.344764758900898, 1.9855787259776418, 0.6306370373209885, 1.5195078079293414, 2.8166491898094734, 3.3823762899491845, 0.18394094507728856, 0.1014812747243701, 0.3682834962155761, 0.46236156390571015, 0.5955901327670734, 0.5420113553338479, 0.6974232642025482, 0.17753527935299024, 0.18660047278376068, 0.4530741110378053, 0.37690301933767706, 0.07896364119280805, 0.09512123417841682, 0.17031372356707214, 0.21509947574899033, 0.27836365426078485, 0.1770993924693335, 0.1048058761601768, 0.058128280129295024, 0.031526002955726606, 0.23354911842722142, 0.8096299759089584, 1.4606955160455006, 0.9095364387442426, 1.0795752144441373, 0.611800383089292, 1.0841900775345361, 1.4976408597899646, 1.507818911133743, 1.360076962447748, 1.2346302474417337, 1.292311610245123, 1.170950463995701, 0.8043906870411663, 0.34336055887919564, 0.9371612660768556, 0.9629843860137753, 0.4258001563025684, 1.0262211782903212, 1.412712210925614, 1.101979695013497, 1.7778189043760126, 1.4502014281160216, 1.2770733688238378, 1.174751681814264, 1.0292696438548041, 0.3998495163415522, 0.3732759251554565, 0.49072969741210704, 0.7694350926250946, 1.4994024474446366, 0.7505500475137258, 0.4933452753395569, 0.09408677278952382, 0.07953663661067743, 0.2199321396470379, 0.1930430529687328, 0.07379511180886589, 0.038523442369584764, 0.6769441867746958, 1.403879438958517, 1.8775488850552813, 0.05970062115570394, 0.6659782888742573, 1.0042077896750259, 0.9355413314500233, 0.484278047426104, 0.22881481960052397, 0.04995730758514028, 0.03955734521250412, 0.10888339088637067, 0.09245604295184177, 0.018770350061325786, 0.034043228271468426, 0.13456005198673754, 0.22806343325646594, 0.2921404017180973, 0.3554644154852523, 0.2403787431390899, 0.07537777630080576, 0.04171649972207577, 0.059351532256675076, 0.05888631984360073, 0.04183424481087103, 0.045135738859066694, 0.048142618816289146, 0.08542809177689799, 0.4763080145073728, 0.8730732420826381, 0.7835048146535417, 0.4956263093325372, 0.2652999138027975, 0.21414677693290995, 0.1582520466290589, 0.11746393452844264, 0.08993863141896748, 0.07519934060252215, 0.06898104158927908, 0.0845991309244887, 0.2936557896382732, 0.4759051980217919, 0.556765760408669, 0.27748816405854576, 0.13287700506897104, 0.19167800938330623, 0.12489092355917264, 0.5607003408609095, 0.7409706062767882, 0.747677698992647, 0.4173890704788813, 0.46278630960278394, 0.5358908714317694, 0.2897447827385693, 0.14216591817958255, 0.13639318070760587, 0.13078837359228979, 0.1863790169419833, 0.4318755161446284, 0.21870570113597063, 0.02871195004613915, 0.03858411312134327, 0.06844024983055112, 0.056103369508935255, 0.5569910357717607, 0.6022271903504323, 0.764011930827642, 0.4984936417966354, 0.24032947060186416, 0.6765927670966471, 0.6936532171761117, 1.092768273202748, 0.1862801010379704, 0.19372540607156868, 0.4790363195068317, 0.030585399170110866, 0.014981473080408206, 0.15003327916308148, 0.4862746988854757, 0.38070903415614227, 0.725038398874969, 0.6348384056345378, 0.5076706900563739, 0.24201844754719698, 0.38032609690264685, 0.5114036289700956, 0.35358397196534674, 0.11864683805359208, 1.234415747045737, 1.565897448799394, 1.3545741777506475, 1.026904919837806, 1.559222037835819, 2.5702848653025105, 2.565331137761837, 2.133687583411612, 1.1646159233116522, 0.19527935313143222, 0.14760532648510777, 0.20102200857178193, 0.2658538069681083, 0.4028394413535574, 0.3283176306754396, 0.20834429269917765, 0.06685231102803699, 0.055501209670626675, 0.07567883747567354, 0.07662144105806208, 0.040046039784168146, 0.04395400205195495, 0.17840639814143863, 0.4968521642617927, 0.1906574775270334, 0.534398041120556, 0.5156519383919281, 0.27383022446471794, 0.11446683217932664, 0.07043507286444521, 0.3847727710190822, 0.25226881046144006, 0.2508491789922118, 0.40653243633668595, 0.594612340397406, 0.4602148715149691, 0.3157329844579203, 0.18381928116619614, 0.17936677322421285, 0.25219744858782733, 0.15611926487202632, 0.040325600573318875, 0.018326906083884972, 0.014329364072315312, 0.015106682737695803, 0.056815781345127415, 0.020425225314128756, 0.02106563491383895, 0.1423032959786871, 0.16635082307748816, 0.03971236685246612, 0.012921101141115486, 0.009664172306784388, 0.013897361734119087, 0.05861847230060049, 0.018756869955834147, 0.008698845612099564, 0.040852278442953985, 0.24978217860561705, 0.8416671708407926, 1.3217656332999468, 1.2508090710630868, 1.1568399754909389, 1.3116469175168668, 1.0719098535979665, 0.30179731841994134, 0.22111927397640013, 0.4527521704028292, 0.4201432985151414, 0.4035597858480575, 1.4965672522230307, 1.9998932263041773, 0.6064197901840799, 0.08279009999298467, 2.4553851470714663, 1.8370857384146713, 0.24736754823669155, 0.21400608046252917, 0.6168535463284792, 0.7682381228021369, 0.5977797003735493, 0.24952425326152547, 0.19088423033401075, 0.2560495343513605, 0.6721950729445714, 1.0721769005787858, 1.2549870795436862, 1.3056436725166305, 1.262485868620499, 0.7303305091599014, 0.3003929554109984, 0.11606775041919475, 0.07159760798946614, 0.10772596938015962, 0.04871468646622195, 0.050420688642699996, 0.06140372368490051, 0.04335794724998201, 0.018928125608576145, 0.01629168642138233, 0.02009375145120785, 0.025584654871902496, 0.19991401714704385, 0.30538060248079824, 0.7812207073154973, 0.8226774055965063, 0.7759113355380732, 0.11073866651660376, 0.10752354555113082, 0.28209231833915976, 0.6094094680071377, 0.7685069726075886, 0.7324440109844479, 0.6422439670011333, 0.8078237395143, 0.9655033505135556, 1.0400198607821949, 0.6157919126555675, 1.1870112741762124, 1.3578457695759603, 1.322825793890998, 1.2408071873108317, 1.2146114847148455, 1.2814336472783463, 1.3082337067432335, 1.45502619045545, 1.4635073339067353, 1.3132297469348997, 1.1940026283269263, 0.9615820115727174, 1.2410157268076125, 1.407203849689345, 1.1927069376466843, 1.017096736956829, 0.341283151124782, 0.06782653940930819, 0.19045294150206113, 0.268983936691678, 0.43184289848210117, 0.17205872550243284, 0.22541795571039364, 1.1930806431465033, 0.942502675305416, 0.1758021585311082, 0.24600092998919468, 0.07234790703204254, 0.11408375421686887, 0.13023447241091451, 0.15476488540404784, 0.17367717405895525, 0.127734356174276, 0.09071167846945527, 0.0751601005905652, 0.065327512486608, 0.0564636822632454, 0.046000406067089834, 0.04359928752881654, 0.040457147397807224, 0.03462060322848762, 0.029820937331817, 0.038368087333255085, 0.0400997598338929, 0.02601309218765137, 0.02586198362143655, 0.2574295671452646, 0.11973072605444653, 0.04546968193750306, 0.14892422566215208, 0.25678264242121324, 0.16351535789868737, 0.12774792333699977, 0.06974723095978644, 0.10072639597531567, 0.1955543690302165, 0.20918083842559831, 0.3877264972429768, 0.15024521242345898, 0.11219961150966744, 1.2244760873841076, 0.4324229490920538, 1.4375652540020827, 0.47802066385019115, 0.22441579587757587, 0.14775443460974025, 0.15075671428916748, 0.2212644610511389, 0.2153014623213605, 0.17712494961224587, 0.08259971802429546, 0.03893543737507482, 0.036489161004017036, 0.03792797810420896, 0.04430319028200224, 0.05605431778089618, 0.06884904258514303, 0.1531951234200522, 0.21822937614653223, 0.25346368987454587, 0.25899443467163263, 0.1962204986229179, 0.5165276303108307, 0.635771760234869, 0.650379141023533, 0.5105032369690712, 0.07867076804168613, 1.3099510815095639, 0.522387985051354, 0.600903863189903, 0.7785448669115218, 3.4070904671964124, 0.8079996450645167, 0.162185890690946, 0.09797704839942659, 0.19572831651695619, 0.13554654107429087, 0.03254547150714732, 0.24511444875856908, 0.38921483253943734, 0.1954788896340377, 0.16294048727516983, 1.3644024249983997, 0.9983574138605036, 0.30111734696171283, 0.23666144367740433, 0.8829177850667492, 0.966357801099792, 0.6743017972970703, 0.3470739022624216, 0.19595793648282203, 0.12883473962272812, 0.11475039161060278, 0.08452358051408043, 0.36601001337715766, 0.924768328666687, 0.5282206041056935, 0.4965277383240258, 0.24367040931815054, 0.742004466749211, 0.6797592977342968, 0.3518500472262797, 0.19216345750340602, 0.44411806765625755, 0.3261506099526475, 0.4292156020367146, 0.3931377421124081, 0.2844693338521188, 0.18469705188527302, 0.14208819446858664, 0.21629821456877923, 0.6273721059920584, 0.024387144484291374, 0.13132073725687432, 0.497697288670191, 0.4781262801006073, 0.35698712426351475, 0.0967463206772418, 0.03388061584542179, 0.01403857130143168, 0.03788622502229262, 0.05333693316450125, 0.06334702114074345, 0.03360961081919568, 0.04527021129708773, 0.16959778314871318, 2.5727240196088466, 3.098760189079657, 0.04786431398836767, 0.3556606368298029, 0.5356639514197368, 0.7964036610096294, 1.0601195500618452, 0.2637791560301571, 0.17567812651129605, 0.6330045161200205, 0.8640708750381458, 0.224587999125971, 0.07394464339573993, 0.05013843166919442, 0.06589810547426701, 0.0651239225921816, 0.06402520905692477, 0.1873841113421538, 0.4237396557980058, 0.2039232106833923, 0.13274696541995537, 0.16325132462384873, 0.07604662960671349, 0.190500176136372, 0.2504525199470752, 0.01804225741967102, 0.029389958437649313, 0.04945588803647985, 0.07111914865061231, 0.3040005912175175, 0.45168751441889715, 0.5611583852186436, 0.7086829830120068, 0.9009821342844544, 0.8502789065185026, 0.10806600940104988, 0.17868395496034503, 0.23680951973704106, 0.2712139276545491, 0.582822619721566, 1.0089072250738376, 0.7322700024474549, 0.28661847187375805, 0.5013168351756687, 0.6771750734196536, 0.8413634328856726, 0.794756592911454, 0.7602345255370715, 0.4720314740566986, 0.06902267057278262, 0.43254565250514665, 0.749715637233926, 0.5340975610221305, 0.41542238851483176, 0.18561952090367856, 0.0428963369099287, 0.021921355300015065, 0.5437044748445947, 0.7304778576991539, 0.5447205567844077, 0.4660757984921674, 0.33219350274388176, 0.05740846440241468, 0.25736215751527286, 0.33651652275698213, 0.12664242212592466, 0.06590791580426257, 0.05737137917724506, 0.12834048467381606, 0.178658639418001, 0.1848900683696961, 0.22786858424057377, 0.30402709684654483, 0.47547125955386993, 0.7374907381321597, 0.03838150347771106, 0.07634906382612293, 0.1533184194165032, 0.8898685276508331, 1.0601446072502834, 4.338844116141156, 4.240896879172906, 2.7744407799185775, 1.6060778018904895, 0.9988233061825357, 1.9245937423008244, 0.3715311714061877, 0.18087899695696136, 0.23650637215071932, 0.24376472507648897, 0.21027767389058705, 0.12143575061089927, 0.4571693830373811, 0.4397660944519987, 0.12000343821424261, 0.07711073488462716, 0.08732061960387089, 0.06954887009962432, 0.06576935245911733, 0.053451252064938094, 0.05767662841426721, 0.1460021419860124, 0.08938551503354397, 0.026803562019001508, 0.027117273839837985, 0.37116290750152364, 0.7036692383812695, 0.8975522227417125, 0.369535241548608, 0.056106893988482356, 0.044066765264710185, 0.03849395976555193, 0.03542700254662877, 0.06829025927081381, 0.04225427648865351, 0.05299650912354814, 0.03383393502771491, 0.022986655441544403, 0.1181232706874697, 0.46838177340961873, 0.8708040481699466, 1.0833100342177027, 1.290572191157042, 1.3294846284680293, 1.3325254539164102, 1.3558225253733194, 2.008137543026994, 1.0792511294527751, 0.10820445813602134, 0.07106132441957726, 0.038530025722050776, 0.025072271140615845, 0.04894950749683342, 0.08248130921288621, 0.058518732059361, 0.040347464201065636, 0.13766314498178783, 0.14621236366139517, 0.23296642867042952, 0.13973458041499082, 0.32395330254590454, 0.19392071270526573, 0.44036464502171774, 0.19909963541005443, 0.47720896692097575, 0.5219466858057652, 0.42522062776928266, 0.9115613170660941, 1.3154351169423757, 1.369065374108287, 1.138820280460428, 0.8729364784914828, 0.9460202426486897, 1.7058854510148815, 1.3177609618125599, 0.5412164221551193, 0.02265427380033787, 0.11515370929191704, 0.17195501943113015, 0.1526978893619499, 0.11376894494857724, 0.1250445214669448, 0.14543384119419564, 0.15890730581419873, 0.1071737601546707, 0.3370544462317101, 0.534577988946339, 0.3859568620675595, 0.2699501449496227, 0.23696631547531757, 0.1389538089676906, 0.171399832458996, 0.38148684289151, 0.24654338147398425, 0.2851074033351213, 0.42342417262454723, 0.34979931921704366, 0.2942180865028182, 0.044044864571333164, 0.022600870539152797, 0.013697083592776878, 0.013410544409430812, 0.016187087376992412, 0.01186529927686135, 0.4369210848969332, 0.406107784036954, 0.36803558112602863, 0.3514493977637335, 0.32115827206214864, 0.24581454874537373, 0.6957280268938697, 0.49447697641549315, 0.011831634836997226, 0.14087183241982493, 0.8977941652623619, 1.2526026208226273, 1.1858412143660768, 1.4666191862850877, 1.0799041448570768, 0.3121893573098177, 0.031357448502652326, 0.0067362637435469256, 0.06134118176111392, 0.028989426747457622, 0.03724293425103696, 0.9191334520713476, 1.2009652917359945, 0.4394552823501815, 0.12678992369147613, 0.13674834850560108, 0.14801985801644083, 0.1364599364822469, 0.12427818959773371, 0.11375892039805188, 0.12942047985043467, 0.2721873604431294, 0.27912763930380163, 0.24115709124541934, 0.11134535633737402, 0.4482271486183269, 0.3395631704938751, 1.1560392350685333, 1.6014611575661637, 2.1470456297804676, 2.2382025195331274, 1.6851818299876913, 1.2683144095475787, 0.9580506987726616, 1.0046147384388704, 1.2115626858697996, 1.331701888403963, 2.9114960722811194, 3.939300385088711, 3.151294695168009, 1.982121944427493, 0.9131480978756417, 5.16884603151461, 4.345281284029891, 3.1732950094269543, 1.9527041359645565, 1.9689417961167126, 1.4221250693790797, 4.874146426596293, 4.914054358877787, 2.9989740938056832, 0.17160026079674448, 0.009024392836846988, 0.4225741101477624, 0.5705931584297792, 0.2977014074681281, 0.4066077658861592, 0.25465722022174925, 0.17887593794465628, 0.05058971638000668, 0.038776872355913664, 0.030998087703911863, 0.03148351028198288, 0.2621134743094472, 0.1392284405486995, 0.0129614326120734, 0.023919175948388483, 0.03174192367603654, 0.03495361381314202, 0.16064960512484527, 0.2825186751146159, 0.26467535552524724, 0.30229557708130084, 0.011205250853757806, 0.021483039075175795, 0.014945761769479027, 0.015240842778372852, 0.019888909812635108, 0.022633980069591282, 0.024952221018416244, 0.025587428013351177, 0.02643823854101001, 0.020536223857606076, 0.014952971013527288, 0.039974126739652116, 0.046896438958666714, 0.024968018026878026, 0.09635177952370169, 0.01327049538570175, 0.020289829636145975, 0.01775408348440556, 0.01845006395759389, 0.10979065216123694, 0.20282069103019992, 0.021554846195014275, 0.050491129871594105, 0.12395763308538846, 0.13638354546093046, 0.04596785043945491, 0.15432077573566902, 0.06544623069646882, 0.03300991089923716, 0.03823619727114508, 0.04083881361311353, 0.049474955004215435, 0.04894323463224459, 0.04830876092721776, 0.04874848086990646, 0.050056199349477894, 0.06518780304155904, 0.05343860288494176, 0.04989272927732821, 0.04776453244169427, 0.05153334640121235, 0.07333923745353808, 0.07412089125824511, 0.0715032528813736, 0.06424284793058355, 0.043711216283998336, 0.026477823433685068, 0.07311246263306224, 0.08616867130792631, 0.06462038649130879, 0.05452693540255274, 0.06816341060908687, 0.25954601572962793, 0.595117837554071, 0.0589196971906814, 0.01769245863422883, 0.019190777513408537, 0.026451006304567704, 0.03903109957352127, 0.0773472246183346, 0.14215388660088094, 0.1247286245387641, 0.16363439090028117, 0.2768376897850142, 0.2479653757139359, 0.6015484755597582, 0.5982164306986406, 0.33829514889572604, 0.033887843869196355, 0.38219298942656277, 0.24940445076696582, 0.7708842449071931, 2.2178812986466943, 3.1880397825706295, 2.559594087484406, 0.9497571238657323, 0.0538010450943228, 0.03578596709338876, 0.33543329213450596, 0.6112917196459886, 2.975866355547091, 1.7238837241048026, 0.13109374131500973, 0.27031670837868105, 0.1908500561514091, 0.32251801723387186, 0.3622315616869345, 0.3053625724171913, 0.3244358929920808, 0.48544991089080136, 0.47451098953806425, 0.3522696487787626, 0.20979355802626565, 0.16269926027198714, 0.12777011709829644, 0.08920782543672674, 0.13744003659769255, 0.06078886865956209, 0.03892100490516097, 0.01646051385809764, 0.10017633238216726, 0.2117079269799713, 0.27596741957766024, 0.13852770399286626, 0.006883882096345343, 0.009949600800343721, 0.016476882397333477, 0.029540453730122665, 0.0337147980810586, 0.2793846602853369, 0.32815221606239636, 0.05605002556770093, 0.03255298603702302, 0.08741727654155622, 0.5179791712188512, 0.8113302603010086, 0.88007210231441, 0.6743727151940897, 0.08734611412749074, 0.01580152325672449, 0.43292043115272416, 0.12991378301234274, 0.20231109909333853, 0.06726197290108979, 0.01406758237082125, 0.016845258518115747, 0.01898150090781245, 0.06887860852897042, 0.04847120301210231, 0.05228803220748754, 0.05365920503177998, 0.034489301579192326, 0.03204672879300921, 0.021198236450489762, 0.010322842378117479, 0.010201912476410011, 0.012341981736404349, 0.03660576966835723, 0.016234978311286993, 0.9288899967583214, 1.992316168257231, 2.0532050162136573, 2.0276528353115726, 1.6743825217708945, 1.729180643471276, 3.390697761279781, 5.845112594162545, 8.626413673889346, 8.896777644390014, 6.890925433577561, 4.704911781520378, 4.804032793722865, 5.0650280772185905, 3.9936536027163996, 4.046747117507748, 3.2430881901485162, 2.558558485993339, 2.4081168981587013, 2.206399157098154, 2.0665944592697865, 1.9908021652117007, 1.9701511367428592, 1.5965893604769938, 1.5298984952089263, 0.6620467902593102, 0.5711860852685143, 0.5479180101623259, 0.7271444575077423, 0.5183107936641247, 1.2982679401955954, 0.8609682986649071, 1.4654391160825404, 0.8716410444140797, 1.005098713130304, 1.2206263920155966, 2.334719541596203, 2.9611495413431306, 2.16538029182248, 1.2188448411662405, 1.1168085485696793, 0.8763455051656176, 0.7205742926779771, 0.41510826567324194, 0.24989225807324303, 0.3703588480129838, 0.3497076594248051, 0.32073117897096204, 0.3011229181968857, 0.08521404889662092, 0.1356821434072605, 0.5212420333267712, 0.38445771939941775, 0.1633813133159448, 0.11190694150026524, 0.02808003474265428, 0.05417522737861429, 0.08890923406473054, 0.025803863452892983, 0.08840423851684247, 0.02614524201830713, 0.03885193572595443, 0.08026867331482651, 0.09503003483263367, 0.03522002042793646, 0.029614618020032804]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oKRTS_9yG0n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "05fcc111-a3e9-48c9-e464-8a4a4c93faf9"
      },
      "source": [
        "print(history_ori.history['val_loss'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.6147231479606978, 1.638691039574219, 1.1768211504308188, 1.222878444485548, 0.6862581706628567, 0.7577413974738703, 0.8293126210933779, 0.6553598206217696, 0.9123166770469852, 1.2399330139160156, 1.1069551502786033, 0.9066931736178514, 0.8899625278100735, 0.8668171196449094, 0.8336983308559511, 0.80722436090795, 0.8750437701620707, 1.02267611899027, 1.0757231188983452, 1.0458749038417166, 1.0272093865929581, 1.5775422061361917, 1.8811370919390422, 1.8215750601233505, 1.7706577952315168, 1.705599877892471, 1.670259045391548, 1.837127173819193, 2.297400497808689, 2.2415619129087867, 1.5030158903540634, 1.566637306678586, 1.5825008531896079, 1.256303252243414, 1.166381010195104, 0.9020444590870927, 1.0108669909035288, 1.1365164431130015, 1.0660212912210605, 0.9423243534274217, 0.8777701505800573, 1.0720796933988246, 0.9314502041514326, 0.8425584188321742, 0.7651184535608059, 0.5809717381872782, 0.6715523324361662, 0.8672836640986, 0.9982242177172405, 0.8429510011905577, 1.3315966885264328, 1.2720696519060832, 1.3697489936177323, 1.32198820463041, 1.2933392873624476, 1.3636266894456817, 1.3714894317999118, 1.6157696770458687, 1.3723895026416313, 1.5239403538587617, 1.8735678254104242, 1.3387877475924608, 0.8233503742915828, 0.5976552701577907, 0.6526198067316195, 0.9549437383326088, 1.0641399592888066, 1.0371817030557773, 0.6782682232740449, 0.9206902980804443, 1.4019411831367306, 1.4730355565140887, 1.4202162579792301, 1.0570874853831966, 1.163092909789667, 1.6791668170835914, 1.9998826747987328, 1.354267748390756, 1.068869643095063, 1.0282553870503495, 1.3176769512455637, 1.8111375017863949, 1.2839039767660745, 1.1893310430573254, 1.338253486447218, 1.8646018098040325, 3.024034988589403, 2.6767064187584855, 0.8537880095039926, 0.512214744963297, 0.3589280000547083, 0.36594766669157075, 0.6234625025493342, 2.961462579122404, 1.8654798182045542, 2.788183398363067, 2.982215834826958, 2.936971931241271, 3.6252709249170816, 4.117927853654071, 2.268579017825243, 1.2454931445238067, 1.586156618304369, 2.4811036354157983, 3.3460020088567966, 4.06538453916224, 4.7192737300221514, 4.85805976681593, 5.561247569758717, 5.843154953747261, 4.878602679182843, 4.3984460132878, 4.5933287085556405, 5.918806006268757, 6.168267505924876, 5.007365412828399, 3.6084102537573837, 1.810180861775468, 1.066950798034668, 0.5298954640946737, 0.5180126528550939, 0.2585684580773842, 0.593741783281652, 1.2898330979230928, 0.375321552520845, 0.5343995624926032, 0.5823706714436412, 0.4769162637431447, 0.9740861421678124, 0.7423789152284948, 1.2638567482552878, 2.1669559478759766, 2.577180885687107, 1.925078380398634, 1.0862486595060767, 0.8171749696498964, 1.452536908591666, 0.558621248094047, 1.0412915189091752, 0.4342996645264509, 0.3922799018824973, 1.7055118839915206, 3.259402461168243, 4.190225042947909, 0.8825021255307082, 0.9930596119020043, 1.6392710848552425, 2.7116225172833697, 3.851300216302639, 1.3490864125693716, 0.28283215732109257, 0.3140887392730248, 0.3909109598252831, 0.24861331393079059, 0.22378217301717618, 0.4020323840583243, 0.30127397179603577, 0.6012084702166115, 0.3689586076794601, 0.9422986609179799, 3.467874840992253, 0.35928686308424646, 0.2515025462546363, 0.2922350664327784, 0.903361868567583, 2.5454691212351728, 0.9709179634001197, 0.18843118919105065, 0.239338928606452, 0.8370674979395982, 1.7779275702267159, 1.795293217752038, 1.6135224612747752, 1.1732792549017, 0.6848692421506091, 0.4816112136695443, 0.5037264729418406, 0.5127246263550549, 0.6129176849272193, 2.164268633214439, 3.397934681031762, 3.4784785712637554, 2.2199008464813232, 0.2906067447691429, 0.16688129162733875, 0.47945292673369005, 0.5412281400910238, 0.26159289107862405, 0.32477660013771636, 1.0890423321142428, 0.9659578160541814, 0.5508282497161772, 0.3556911656405868, 0.7550762004968596, 0.8380756498110004, 0.6715288810977121, 0.6086570782609647, 0.6220178695895323, 0.8004196471557384, 0.6637906105053134, 0.5215318537339931, 0.6815978404952259, 0.6740427656871516, 0.5354653480576306, 1.119613172077551, 0.30515006820603113, 0.4219745335214567, 0.46728434202420277, 1.3191102428358934, 0.6829015869056669, 0.5846681738862904, 0.22410205658525229, 0.5475130316506072, 1.0838875634277738, 0.8402823376946333, 1.6247708128719796, 1.0772683533226572, 1.404308952936312, 1.3022950800453745, 1.2403666624208776, 1.009174932793873, 1.7374739908590549, 1.2580912781924736, 1.2871094273357857, 1.901095622923316, 1.3757785587775997, 1.0239590173814355, 0.1259122957907072, 0.12776123255309535, 0.180044472853585, 0.12552236194336197, 0.2285534397857945, 0.5145909437319127, 0.5344863243219329, 1.506391827653094, 2.4758850190697648, 2.981567080427961, 3.049052366396276, 3.021433388314596, 2.074371651905339, 1.6208767556562655, 1.2363146870601467, 1.4328015904601028, 2.8262793378132147, 3.7236959178273272, 4.049081197599086, 2.5592449699960103, 2.765390000692228, 2.6312373556741853, 2.367529020076845, 2.7745132329987316, 2.740007470293743, 2.202966794735048, 2.5734706506496523, 3.4493157223957343, 2.184683555509986, 1.2800288491132783, 1.026560341439596, 0.9417616768581111, 0.2563596280609689, 0.2212321756453049, 0.19872005111197147, 0.34829824713126917, 1.0402766567904775, 0.3950083873620847, 0.3790925597976439, 0.31630316167138517, 0.2543232049338701, 0.5002756189645791, 0.7749941465331287, 0.49848781271678644, 0.35068533642262945, 0.5686825706318969, 0.2720872207385738, 3.4192973811451983, 3.438446521759033, 0.8849123251147386, 0.5893506887482434, 0.5754898350413252, 0.5560941521714373, 2.1316945727278545, 1.5696217025198587, 0.6761126823541594, 0.3107206850517087, 0.4800194082554521, 0.35780777200693037, 0.49923703038110967, 0.4281747809997419, 0.6403710978423677, 0.7245296966738817, 0.3122496401391378, 0.5324004859459109, 0.6705149324928842, 0.32209339229072015, 0.13489733840815904, 0.13857953600222017, 0.20844769823115047, 0.35057046555164384, 0.3094790358914108, 0.15043210272291085, 0.14173110492709207, 0.3826927306448541, 0.7928183253218488, 0.3892568422526848, 0.4276682974361792, 0.4708556205761142, 0.49317294577272924, 0.4472623242110741, 0.4726821344073226, 3.318293801168116, 1.4297714000794945, 1.0902997008184108, 1.2752155239989118, 1.136523054867256, 0.9376230298019037, 0.8444916184355573, 0.8437300397128593, 0.6556513280403323, 0.8291577973016878, 0.8067448938765177, 2.1170445884146343, 2.3121174835577243, 0.39737639703401706, 0.3512595352239725, 0.2991669879453938, 0.3489252401561272, 0.7412323784537431, 0.8152993146966143, 0.25886403769254684, 0.20586565527610662, 0.30391672653395957, 0.33556905979426893, 0.19152256986126304, 0.18876852395535423, 0.17277096081297935, 0.22066556762267903, 0.5814081561274644, 0.9523693352210812, 0.9620667521546526, 0.7547476785938915, 1.0351022714521827, 0.7066925357027751, 0.4255444305699046, 0.37237825085658854, 0.40041697911191276, 0.35723516585805065, 0.6785446530798587, 0.8992928113879227, 0.9323543694506331, 0.9196546452074517, 0.6034052012170233, 0.8169503766225605, 0.20436774312359532, 0.30204660086551816, 0.4589405267885545, 0.3718233209375928, 0.26930429023213504, 0.17758343452814876, 0.5097282025508765, 2.3738982619308846, 2.259312117972025, 0.8643801677517775, 0.8926540035300139, 0.5293907216045914, 0.2439423176210101, 0.2046307425309972, 0.13794731903003482, 0.11045717720578356, 0.11026421461890383, 0.3963073492050171, 0.5478158411456318, 0.18608560703876542, 0.28007045097467376, 0.7282363670628246, 0.32873984916907983, 0.11077543120922112, 0.09653860266979147, 0.12243245405758299, 0.42942054387999745, 0.380612676463476, 0.33432007126691865, 0.13022938443393242, 0.16862879107456383, 0.24975136831039335, 0.19654171609478752, 0.10034654467798225, 0.7256648787638036, 0.2855457343706271, 0.3702697441345308, 0.31739803530820987, 0.29788648609707996, 0.16674731744498741, 0.2109087594762081, 0.3111578840308073, 0.16790214680680415, 0.07828608219988825, 0.0728030705585985, 0.11565070298909233, 0.15396496875597754, 0.15750787868278054, 0.4207982566298508, 0.31187237799167633, 0.20157977457090123, 0.10686027862858481, 0.08863421179149754, 0.11094194350241707, 0.0646924386936717, 0.11406398946192206, 0.07810375766783226, 0.11185962739173413, 0.15031925624054743, 0.10353019506466098, 0.8695070474613004, 0.22998081056810007, 0.0842412682477294, 0.09594013029709458, 0.12262397211771912, 0.11452530110936339, 0.40214520547448135, 0.4096415155544514, 0.1821634407813956, 0.10298818323715794, 0.10602799478759307, 0.9398433292034741, 0.37245528672526523, 0.5495996129948918, 0.09495475322644158, 0.2475689264417558, 0.32952260005390044, 0.26577950040128356, 0.17909615793515268, 0.09468677083439217, 0.11246530359565485, 0.2463428596625241, 1.2160718848065633, 1.0800948942579873, 0.07232904206484375, 0.07746061180695528, 0.15994809318061282, 0.29613752426897605, 0.19966630501354612, 0.1144573868922435, 0.17607161788860473, 0.15992156425263823, 0.5860613933423671, 1.6864276804575107, 2.309293037507592, 2.383146716327202, 1.1445388081597119, 0.352270731838738, 0.21368884722270617, 0.14323336485682464, 0.11997853060502832, 0.346005041788264, 0.430741270413486, 0.14969897247487451, 0.13583973050117493, 0.15788039733178733, 0.26083058082475896, 0.2893557692082917, 0.2651381147798242, 0.6570103966244837, 0.23729366945420824, 0.9498567479412731, 1.620485683766807, 0.7979893182835928, 0.42577306889906164, 0.3482314519947622, 0.29324990910727805, 0.133506185988464, 0.4306051351993186, 0.830897186405775, 3.0756535166647376, 5.293587428767506, 5.138603629135504, 3.7718188820815666, 3.272294852791763, 2.5603663543375528, 4.261054120412687, 5.749494668914051, 5.240356933779832, 4.168483478267018, 1.7297844236216895, 1.029800805467658, 0.513169464223632, 0.6966080706930016, 0.7543228687661723, 0.4105978841643508, 0.3444699996673479, 0.4284569106587186, 0.4110450460234793, 0.42447015534086924, 0.3691843526392448, 0.25288629559118575, 0.41675985930487514, 0.3642066908523259, 1.555952153554777, 3.723137041417564, 3.337262996813146, 1.7290394189881115, 0.6722188516996983, 0.42815398751962475, 0.5771875871890565, 0.6701935117314683, 0.6604032390296641, 0.5883258619550161, 0.3424581815758379, 0.23046145654104583, 0.8997117388062179, 1.2381414188350346, 1.0740154000806974, 0.40304653237789595, 0.16904347150575189, 0.301252571956777, 0.2652416318405147, 1.7197034175801602, 2.5132085041323524, 3.059792326717925, 3.4401189641254954, 2.2005194861722863, 0.9234252719655094, 0.5389681118781815, 0.29691823554600066, 0.6970468038783931, 0.7418985950147233, 0.8179559479013268, 0.8918782237735463, 0.6197785351470839, 0.25142949155145666, 0.32078308993723337, 0.3832423490722005, 0.40575558335730444, 0.5969815957800076, 0.4034872034013771, 0.22579349038651123, 0.4222287432540481, 0.8006112024914928, 2.154160540278365, 2.455479334040386, 1.759796174561105, 3.5245827232919087, 4.214604668500947, 2.9531933737964167, 1.509357442034454, 1.6672314268241568, 1.3695281647690913, 4.122886587933796, 5.860730962055485, 5.116073596768263, 3.6606762554587386, 1.72916348096801, 0.8876483774766689, 0.8544868594262658, 0.9660694915346983, 0.9477639667144636, 2.962205898470995, 2.87661232599398, 1.730353262366318, 2.666455767867042, 3.6557629530022786, 1.6313336269884575, 1.5292678764317094, 1.4888386084221121, 1.1838751137710926, 1.0999239649987076, 1.0688642402656559, 0.7695882592759118, 0.45140265964153337, 0.27416089576918906, 0.12964599587522993, 0.1676222283802018, 0.1261438274949153, 0.04914376278203435, 0.039690929851154, 0.037583928214522395, 0.043335974761625616, 0.05788203406079513, 0.054224419396188925, 0.06203440025948533, 0.05489781793070639, 0.10900106290128173, 0.27931960596044253, 0.10564996349829726, 0.5385170389966267, 0.9407276845559841, 2.653467678442234, 3.282311044088224, 2.770406723022461, 0.2507204095401415, 0.20733114068464534, 0.10009621149610455, 0.1120152960463268, 0.09675853533624876, 0.1889257836666685, 0.08922174310016377, 0.08802692414397692, 0.10083335936183065, 0.09837369988786011, 0.10625865681823797, 0.12071800990052885, 0.13620381556996486, 0.07625949145976181, 0.08854185969273491, 0.1108229340213101, 0.2584986543146575, 0.31757250019326444, 0.10552880329238933, 0.07775546014081777, 0.130324445167988, 0.1371493156652943, 0.09652383805241255, 0.07298141319827153, 0.18817574476323476, 0.46478060396706183, 0.23454123258408976, 0.10740418634490996, 0.2598339463697701, 0.36346379185958605, 0.4532035924387789, 0.3853150929275349, 0.10193683398197541, 0.04527443789354548, 0.07177574252823322, 0.08626317905216682, 0.09474806002591078, 0.10587766159484845, 0.12020633395806682, 0.21164794727342157, 0.2678714147357202, 0.2218870594841996, 0.12813757854604685, 0.10566115110158557, 0.10952649644871311, 0.08577017150833499, 0.10099464336554974, 0.0950173439639734, 0.07822272414625508, 0.07850704639979707, 0.09067217291832515, 0.1309402899294183, 0.15513276686982774, 0.1490495589152887, 0.14256144332040738, 0.172237576076352, 0.19390795897783303, 0.21620201042330847, 0.20674499147003744, 0.35951773655350977, 0.20495262258209107, 0.30993151753323106, 0.31047211219443055, 0.541669768531148, 0.13951807615642503, 0.38448199297574054, 0.21930724566393509, 0.7122741949449225, 0.7148481520210824, 0.7701911641875419, 0.5587427825099085, 1.139640369429821, 0.8278190449970525, 2.013537848868021, 2.3467311161320383, 1.368315469927904, 0.3034141517085273, 0.14092714267941872, 0.18765864176562103, 0.23956500135771022, 0.3371024177489212, 0.37113172844018244, 0.20306608551068278, 0.12440297272192632, 0.5377400727806295, 0.6237097829580307, 0.13410311700526353, 0.2544000240457358, 0.34248871681076, 0.3039270671447966, 0.09221831072553448, 0.06528361260084571, 0.06829929582365765, 0.09224234880856806, 0.11639313833935686, 0.07264604756932297, 0.10731689886349004, 0.13446849888962945, 0.06263215266304409, 0.06597037437065255, 0.054786467754350206, 0.0435116756451884, 0.04971226192329351, 0.0830479990797424, 0.21269085352371514, 0.25924707613260733, 0.24224979066142313, 0.19065158914706512, 0.13073740623005461, 0.22580357219614997, 0.5312527710253873, 1.1114563771137378, 0.8047619431120593, 0.7628094065116673, 0.6008474978095875, 0.4429311984241372, 0.27415966178949286, 0.19819129815484146, 0.33279610243512364, 1.8968117091713883, 1.995055384752227, 1.6663882674240484, 0.4220494730483241, 0.3393732025713955, 0.3711918095700307, 0.9462920718130435, 0.419786141890033, 2.432164436433373, 2.2974975399854705, 2.2841828160169646, 2.1072877558266243, 2.394847439556587, 2.8006461073712603, 2.627275653001739, 1.5641915274829399, 1.01756207099775, 0.6836405905281625, 0.2077372244164552, 0.36219685624222975, 0.6222184735251641, 0.8321845236414669, 0.6437141178289383, 0.6797603570299632, 0.9241885699433978, 0.8651454181455802, 0.9625638498947388, 1.2909407441209002, 1.7568077924774914, 1.012312789515751, 0.12714196935511854, 0.19638735992356954, 0.2107742412708609, 0.1360431318568838, 0.11241748419067846, 0.8994802696681468, 1.4814709832028645, 1.5953174640492696, 1.4149238452678774, 0.9105940591998216, 1.2426734435849074, 0.9480065661596089, 0.6487346485189003, 1.1989950668521043, 0.8936759438820001, 0.6875809521482485, 0.5523148870816817, 0.46264261014549424, 0.3789361998961107, 0.16993758737820516, 0.1495396454888356, 0.11977522947481481, 0.47389349124431446, 0.8571097004772504, 0.6010850776986378, 1.6671018774916486, 1.6753391579883854, 1.4925072076844006, 1.4097215140738137, 1.3883175064877766, 1.255984794802782, 1.0247742795362704, 0.8352560855266524, 0.6853925401299465, 0.46236560675429134, 0.2721366743761592, 0.20597376385930835, 0.15553891286821808, 0.47904313809987975, 0.5146292842152279, 0.43508010783528045, 0.38512381548970576, 1.0537663551229166, 0.9959408684474665, 0.9518888378288688, 0.7813606784713069, 0.790293146413183, 0.7383370680461933, 0.5671347214772207, 0.2395240120567018, 0.06700955863428734, 0.16715353763684992, 0.5341059416930032, 0.256120533625618, 0.16641390518989504, 0.1529504153423193, 0.42063015657363506, 0.9738338480635387, 1.3721014086793109, 1.1849143025351734, 0.9178228230647197, 0.31995839585845426, 0.19579603240779805, 0.5920839994285461, 0.5426291232338039, 0.510039420434978, 1.2272144381592913, 2.027395492646752, 1.9027785673374082, 0.3187352019680164, 0.08261147417446099, 0.07134665123175649, 0.06349384831264615, 0.09671687368848701, 0.9286969064212427, 1.318076607657642, 0.8196221761087455, 0.6165566776833702, 0.6211525408619243, 0.5363562269840481, 0.5265206253246927, 0.16556393117757467, 0.12542944141981624, 0.0874669832026972, 0.0719912212949655, 0.3509540837002555, 0.9467111454322571, 1.7539264399830887, 1.8693693905341915, 1.8800169025979392, 1.5396691938725913, 0.8749468652985808, 0.5343882790312353, 0.26176035222483846, 0.4759822465002355, 0.609507789914837, 0.5825465049640071, 0.5259705554671222, 0.5899486689169596, 0.9169965291895518, 0.8562070480207118, 0.5225306269826322, 0.4709142481840057, 0.7649945638812624, 0.7551395251052226, 0.8707437676990905, 1.2743917103947662, 0.8226995786152235, 1.3590240245912133, 1.7241732932825249, 1.7907212027714816, 4.221714008145288, 2.0450152565793336, 2.0535231218105436, 1.0776981188032217, 0.8240987774955035, 0.5486009686235154, 0.7501693283414991, 1.6226582692218405, 2.0375292406576437, 1.6330170747710437, 1.688384893463879, 1.8786535039657681, 2.131865428385847, 2.192553746082434, 1.769944705069065, 1.132845063213963, 0.910216636908533, 0.6072121394484761, 0.33893434314938153, 0.12466484712031826, 0.2689778543220799, 0.7571368130286762, 0.2431333821422879, 0.11554498805965456, 0.38643206927141677, 0.5279140385188573, 0.5102957545257696, 0.30480257439909086, 0.1082784693420674, 0.051996244623651586, 1.1459519587426656, 1.0957693036092588, 0.825529409618334, 0.3759322591677341, 0.13706864464452004, 0.1307787915292709, 0.08574711224000345, 0.1722546139931737, 0.10670812664240502, 0.2017070164045369, 0.09480224972299411, 0.34749006788996023, 0.578971316177558, 0.5446414468384407, 0.4813155144376385, 0.5252813097407542, 0.7060830196956309, 0.87598053020675, 0.488805260120255, 0.2718138760544939, 0.23199794764443096, 0.15316591025670853, 0.21715027314224622, 0.23810586792121574, 0.4006707345457782, 0.5949933357297573, 0.3885665900448746, 0.310630230040704, 0.2850919419717861, 0.8215094118765215, 1.2071101520119645, 1.4490094039498307, 1.1564649328952883, 1.0054129129502831, 0.8336636238708729, 0.6143090337935109, 0.5806274808554274, 0.5325490267487334, 0.2029676040486864, 0.10739838680615876, 0.10620372177942133, 0.09516671626465167, 0.09369844207313002, 0.09584482406016166, 0.08966533831752292, 0.24329776127493327, 0.3211934444574049, 0.295793284812556, 0.12957429663929804, 0.06974084857809919, 0.04630643086651306, 0.2851964024618011, 0.2963205220551505, 0.11580211597511818, 0.15521652781313694, 0.29100501836879494, 1.0697234723626114, 1.476685657733824, 0.4172428854763871, 0.45817094446137185, 0.5472381612195111, 0.800485964437163, 0.7689061331138208, 0.6665620144187592, 0.16582802915022846, 0.14282147163488312, 0.07635912446982353, 0.04093185876227813, 0.03580293649021059, 0.32851277800736856, 0.5046805915275089, 0.2190740838683801, 0.23466711091772063, 0.13405287402068697, 0.5035861167650693, 0.5602344174112659, 0.5474418059289392, 0.497380187333231, 0.11252724899620772, 0.12113795738749593, 0.09650101793416004, 0.09960996898504473, 0.42184898039199764, 0.4934277708938647, 0.14712954022085864, 0.0792334252506496, 0.4065955116558343, 0.7994749692734331, 0.8060971592757397, 0.7724519073679226, 0.7933921889719985, 0.8176585225979003, 0.7886287957804686, 0.8228749313914194, 0.8206660122690131, 0.25347132198285405, 0.4191775718510787, 0.5654825654857587, 0.3470849275429983, 0.3574891157970741, 1.6542420241890885, 1.6333468963460225, 1.793553732517289, 2.2045822594223954, 1.6684902862804691, 1.5772885578434641, 1.3395384491943731, 1.789770731111852, 1.0539253557600625, 0.8965838548341175, 0.3769307104847962, 0.3207726466764764, 0.4092140364369786, 0.22486959686275662, 0.3268955419430645, 0.46190307426788824, 0.09819473356232843, 0.0886055311658732, 0.05811681708274125, 0.04566156325887366, 0.05866909916470077, 0.10059359408034829, 0.11668852151360182, 0.0840822799307317, 0.3840331088683409, 0.5658138344510141, 0.9243178967068472, 0.8832424747411207, 0.4837983660428308, 0.30115409954110295, 0.03163940495834118, 0.2128049094737834, 1.0345997910658409, 0.7181689826024146, 0.07580838570791501, 0.1017395759898624, 0.8672800077488874, 0.6037895161794816, 0.14080827974532617, 0.07200010383513006, 0.9306697096766495, 1.3344473493535345, 1.8845553078302524, 0.24526237024727424, 1.3028926573148603, 2.1174395985719636, 2.377607139145456, 2.0656029378495577, 0.07310822407151402, 0.19362254587581335, 0.28497065245968906, 0.369012424580344, 0.9694559893956999, 0.28443312136362403, 0.6357423590450753, 0.8646801942732276, 0.3300750357348751, 0.27782214124627214, 0.37972516409584983, 0.4571186362306723, 0.2094670519596193, 2.328709629250736, 2.4979283082775954, 1.5362424836834756, 0.7681155892872683, 1.0407755585705363, 0.9214647223309773, 0.6425409840374459, 0.5836024982173268, 0.9797185203117296, 1.1284326400335243, 1.349355287128696, 1.1468303794745447, 0.6773359725229079, 0.8952647876562323, 0.8675406972605099, 0.8516020755079098, 0.9149861570175101, 0.7027069259571229, 0.46013127597866627, 0.4825278712868145, 0.4848644424956746, 0.3181287593622806, 0.2679165899554813, 0.07036806650249651, 0.08227617163409866, 0.0717998008057759, 0.1367445511249371, 0.2672074906646541, 0.22366491481470138, 0.1995210234677737, 0.12294219648422923, 0.5411367838131832, 1.350970263785978, 1.6627123248649807, 2.0173555041050037, 2.0130683628660515, 2.2181419628422434, 1.8157866219194925, 1.4044562636352167, 1.7913512268739684, 1.6071230329178479, 1.4399542566541463, 1.2113414989937332, 0.9899674674173783, 0.4459202404292982, 0.5609519587426515, 0.3309906164167176, 0.3286293204987376, 0.5549665710934233, 0.05290627575165517, 0.05210076204470746, 0.141078309479692, 0.20127396511833934, 0.4613408071390728, 0.7937168500989729, 0.7352445169231587, 0.7575040903248896, 0.8824651843496235, 1.147619252778141, 1.5141766051656749, 1.4389286928067344, 1.5048405106474714, 2.028140924325805, 1.9758694456328025, 0.5280279027604747, 0.7372582221237614, 0.8523106778540276, 0.9242485238284599, 0.7746969403290167, 0.5114307112810088, 0.4889595246896511, 2.287118356402327, 4.344764758900898, 1.9855787259776418, 0.6306370373209885, 1.5195078079293414, 2.8166491898094734, 3.3823762899491845, 0.18394094507728856, 0.1014812747243701, 0.3682834962155761, 0.46236156390571015, 0.5955901327670734, 0.5420113553338479, 0.6974232642025482, 0.17753527935299024, 0.18660047278376068, 0.4530741110378053, 0.37690301933767706, 0.07896364119280805, 0.09512123417841682, 0.17031372356707214, 0.21509947574899033, 0.27836365426078485, 0.1770993924693335, 0.1048058761601768, 0.058128280129295024, 0.031526002955726606, 0.23354911842722142, 0.8096299759089584, 1.4606955160455006, 0.9095364387442426, 1.0795752144441373, 0.611800383089292, 1.0841900775345361, 1.4976408597899646, 1.507818911133743, 1.360076962447748, 1.2346302474417337, 1.292311610245123, 1.170950463995701, 0.8043906870411663, 0.34336055887919564, 0.9371612660768556, 0.9629843860137753, 0.4258001563025684, 1.0262211782903212, 1.412712210925614, 1.101979695013497, 1.7778189043760126, 1.4502014281160216, 1.2770733688238378, 1.174751681814264, 1.0292696438548041, 0.3998495163415522, 0.3732759251554565, 0.49072969741210704, 0.7694350926250946, 1.4994024474446366, 0.7505500475137258, 0.4933452753395569, 0.09408677278952382, 0.07953663661067743, 0.2199321396470379, 0.1930430529687328, 0.07379511180886589, 0.038523442369584764, 0.6769441867746958, 1.403879438958517, 1.8775488850552813, 0.05970062115570394, 0.6659782888742573, 1.0042077896750259, 0.9355413314500233, 0.484278047426104, 0.22881481960052397, 0.04995730758514028, 0.03955734521250412, 0.10888339088637067, 0.09245604295184177, 0.018770350061325786, 0.034043228271468426, 0.13456005198673754, 0.22806343325646594, 0.2921404017180973, 0.3554644154852523, 0.2403787431390899, 0.07537777630080576, 0.04171649972207577, 0.059351532256675076, 0.05888631984360073, 0.04183424481087103, 0.045135738859066694, 0.048142618816289146, 0.08542809177689799, 0.4763080145073728, 0.8730732420826381, 0.7835048146535417, 0.4956263093325372, 0.2652999138027975, 0.21414677693290995, 0.1582520466290589, 0.11746393452844264, 0.08993863141896748, 0.07519934060252215, 0.06898104158927908, 0.0845991309244887, 0.2936557896382732, 0.4759051980217919, 0.556765760408669, 0.27748816405854576, 0.13287700506897104, 0.19167800938330623, 0.12489092355917264, 0.5607003408609095, 0.7409706062767882, 0.747677698992647, 0.4173890704788813, 0.46278630960278394, 0.5358908714317694, 0.2897447827385693, 0.14216591817958255, 0.13639318070760587, 0.13078837359228979, 0.1863790169419833, 0.4318755161446284, 0.21870570113597063, 0.02871195004613915, 0.03858411312134327, 0.06844024983055112, 0.056103369508935255, 0.5569910357717607, 0.6022271903504323, 0.764011930827642, 0.4984936417966354, 0.24032947060186416, 0.6765927670966471, 0.6936532171761117, 1.092768273202748, 0.1862801010379704, 0.19372540607156868, 0.4790363195068317, 0.030585399170110866, 0.014981473080408206, 0.15003327916308148, 0.4862746988854757, 0.38070903415614227, 0.725038398874969, 0.6348384056345378, 0.5076706900563739, 0.24201844754719698, 0.38032609690264685, 0.5114036289700956, 0.35358397196534674, 0.11864683805359208, 1.234415747045737, 1.565897448799394, 1.3545741777506475, 1.026904919837806, 1.559222037835819, 2.5702848653025105, 2.565331137761837, 2.133687583411612, 1.1646159233116522, 0.19527935313143222, 0.14760532648510777, 0.20102200857178193, 0.2658538069681083, 0.4028394413535574, 0.3283176306754396, 0.20834429269917765, 0.06685231102803699, 0.055501209670626675, 0.07567883747567354, 0.07662144105806208, 0.040046039784168146, 0.04395400205195495, 0.17840639814143863, 0.4968521642617927, 0.1906574775270334, 0.534398041120556, 0.5156519383919281, 0.27383022446471794, 0.11446683217932664, 0.07043507286444521, 0.3847727710190822, 0.25226881046144006, 0.2508491789922118, 0.40653243633668595, 0.594612340397406, 0.4602148715149691, 0.3157329844579203, 0.18381928116619614, 0.17936677322421285, 0.25219744858782733, 0.15611926487202632, 0.040325600573318875, 0.018326906083884972, 0.014329364072315312, 0.015106682737695803, 0.056815781345127415, 0.020425225314128756, 0.02106563491383895, 0.1423032959786871, 0.16635082307748816, 0.03971236685246612, 0.012921101141115486, 0.009664172306784388, 0.013897361734119087, 0.05861847230060049, 0.018756869955834147, 0.008698845612099564, 0.040852278442953985, 0.24978217860561705, 0.8416671708407926, 1.3217656332999468, 1.2508090710630868, 1.1568399754909389, 1.3116469175168668, 1.0719098535979665, 0.30179731841994134, 0.22111927397640013, 0.4527521704028292, 0.4201432985151414, 0.4035597858480575, 1.4965672522230307, 1.9998932263041773, 0.6064197901840799, 0.08279009999298467, 2.4553851470714663, 1.8370857384146713, 0.24736754823669155, 0.21400608046252917, 0.6168535463284792, 0.7682381228021369, 0.5977797003735493, 0.24952425326152547, 0.19088423033401075, 0.2560495343513605, 0.6721950729445714, 1.0721769005787858, 1.2549870795436862, 1.3056436725166305, 1.262485868620499, 0.7303305091599014, 0.3003929554109984, 0.11606775041919475, 0.07159760798946614, 0.10772596938015962, 0.04871468646622195, 0.050420688642699996, 0.06140372368490051, 0.04335794724998201, 0.018928125608576145, 0.01629168642138233, 0.02009375145120785, 0.025584654871902496, 0.19991401714704385, 0.30538060248079824, 0.7812207073154973, 0.8226774055965063, 0.7759113355380732, 0.11073866651660376, 0.10752354555113082, 0.28209231833915976, 0.6094094680071377, 0.7685069726075886, 0.7324440109844479, 0.6422439670011333, 0.8078237395143, 0.9655033505135556, 1.0400198607821949, 0.6157919126555675, 1.1870112741762124, 1.3578457695759603, 1.322825793890998, 1.2408071873108317, 1.2146114847148455, 1.2814336472783463, 1.3082337067432335, 1.45502619045545, 1.4635073339067353, 1.3132297469348997, 1.1940026283269263, 0.9615820115727174, 1.2410157268076125, 1.407203849689345, 1.1927069376466843, 1.017096736956829, 0.341283151124782, 0.06782653940930819, 0.19045294150206113, 0.268983936691678, 0.43184289848210117, 0.17205872550243284, 0.22541795571039364, 1.1930806431465033, 0.942502675305416, 0.1758021585311082, 0.24600092998919468, 0.07234790703204254, 0.11408375421686887, 0.13023447241091451, 0.15476488540404784, 0.17367717405895525, 0.127734356174276, 0.09071167846945527, 0.0751601005905652, 0.065327512486608, 0.0564636822632454, 0.046000406067089834, 0.04359928752881654, 0.040457147397807224, 0.03462060322848762, 0.029820937331817, 0.038368087333255085, 0.0400997598338929, 0.02601309218765137, 0.02586198362143655, 0.2574295671452646, 0.11973072605444653, 0.04546968193750306, 0.14892422566215208, 0.25678264242121324, 0.16351535789868737, 0.12774792333699977, 0.06974723095978644, 0.10072639597531567, 0.1955543690302165, 0.20918083842559831, 0.3877264972429768, 0.15024521242345898, 0.11219961150966744, 1.2244760873841076, 0.4324229490920538, 1.4375652540020827, 0.47802066385019115, 0.22441579587757587, 0.14775443460974025, 0.15075671428916748, 0.2212644610511389, 0.2153014623213605, 0.17712494961224587, 0.08259971802429546, 0.03893543737507482, 0.036489161004017036, 0.03792797810420896, 0.04430319028200224, 0.05605431778089618, 0.06884904258514303, 0.1531951234200522, 0.21822937614653223, 0.25346368987454587, 0.25899443467163263, 0.1962204986229179, 0.5165276303108307, 0.635771760234869, 0.650379141023533, 0.5105032369690712, 0.07867076804168613, 1.3099510815095639, 0.522387985051354, 0.600903863189903, 0.7785448669115218, 3.4070904671964124, 0.8079996450645167, 0.162185890690946, 0.09797704839942659, 0.19572831651695619, 0.13554654107429087, 0.03254547150714732, 0.24511444875856908, 0.38921483253943734, 0.1954788896340377, 0.16294048727516983, 1.3644024249983997, 0.9983574138605036, 0.30111734696171283, 0.23666144367740433, 0.8829177850667492, 0.966357801099792, 0.6743017972970703, 0.3470739022624216, 0.19595793648282203, 0.12883473962272812, 0.11475039161060278, 0.08452358051408043, 0.36601001337715766, 0.924768328666687, 0.5282206041056935, 0.4965277383240258, 0.24367040931815054, 0.742004466749211, 0.6797592977342968, 0.3518500472262797, 0.19216345750340602, 0.44411806765625755, 0.3261506099526475, 0.4292156020367146, 0.3931377421124081, 0.2844693338521188, 0.18469705188527302, 0.14208819446858664, 0.21629821456877923, 0.6273721059920584, 0.024387144484291374, 0.13132073725687432, 0.497697288670191, 0.4781262801006073, 0.35698712426351475, 0.0967463206772418, 0.03388061584542179, 0.01403857130143168, 0.03788622502229262, 0.05333693316450125, 0.06334702114074345, 0.03360961081919568, 0.04527021129708773, 0.16959778314871318, 2.5727240196088466, 3.098760189079657, 0.04786431398836767, 0.3556606368298029, 0.5356639514197368, 0.7964036610096294, 1.0601195500618452, 0.2637791560301571, 0.17567812651129605, 0.6330045161200205, 0.8640708750381458, 0.224587999125971, 0.07394464339573993, 0.05013843166919442, 0.06589810547426701, 0.0651239225921816, 0.06402520905692477, 0.1873841113421538, 0.4237396557980058, 0.2039232106833923, 0.13274696541995537, 0.16325132462384873, 0.07604662960671349, 0.190500176136372, 0.2504525199470752, 0.01804225741967102, 0.029389958437649313, 0.04945588803647985, 0.07111914865061231, 0.3040005912175175, 0.45168751441889715, 0.5611583852186436, 0.7086829830120068, 0.9009821342844544, 0.8502789065185026, 0.10806600940104988, 0.17868395496034503, 0.23680951973704106, 0.2712139276545491, 0.582822619721566, 1.0089072250738376, 0.7322700024474549, 0.28661847187375805, 0.5013168351756687, 0.6771750734196536, 0.8413634328856726, 0.794756592911454, 0.7602345255370715, 0.4720314740566986, 0.06902267057278262, 0.43254565250514665, 0.749715637233926, 0.5340975610221305, 0.41542238851483176, 0.18561952090367856, 0.0428963369099287, 0.021921355300015065, 0.5437044748445947, 0.7304778576991539, 0.5447205567844077, 0.4660757984921674, 0.33219350274388176, 0.05740846440241468, 0.25736215751527286, 0.33651652275698213, 0.12664242212592466, 0.06590791580426257, 0.05737137917724506, 0.12834048467381606, 0.178658639418001, 0.1848900683696961, 0.22786858424057377, 0.30402709684654483, 0.47547125955386993, 0.7374907381321597, 0.03838150347771106, 0.07634906382612293, 0.1533184194165032, 0.8898685276508331, 1.0601446072502834, 4.338844116141156, 4.240896879172906, 2.7744407799185775, 1.6060778018904895, 0.9988233061825357, 1.9245937423008244, 0.3715311714061877, 0.18087899695696136, 0.23650637215071932, 0.24376472507648897, 0.21027767389058705, 0.12143575061089927, 0.4571693830373811, 0.4397660944519987, 0.12000343821424261, 0.07711073488462716, 0.08732061960387089, 0.06954887009962432, 0.06576935245911733, 0.053451252064938094, 0.05767662841426721, 0.1460021419860124, 0.08938551503354397, 0.026803562019001508, 0.027117273839837985, 0.37116290750152364, 0.7036692383812695, 0.8975522227417125, 0.369535241548608, 0.056106893988482356, 0.044066765264710185, 0.03849395976555193, 0.03542700254662877, 0.06829025927081381, 0.04225427648865351, 0.05299650912354814, 0.03383393502771491, 0.022986655441544403, 0.1181232706874697, 0.46838177340961873, 0.8708040481699466, 1.0833100342177027, 1.290572191157042, 1.3294846284680293, 1.3325254539164102, 1.3558225253733194, 2.008137543026994, 1.0792511294527751, 0.10820445813602134, 0.07106132441957726, 0.038530025722050776, 0.025072271140615845, 0.04894950749683342, 0.08248130921288621, 0.058518732059361, 0.040347464201065636, 0.13766314498178783, 0.14621236366139517, 0.23296642867042952, 0.13973458041499082, 0.32395330254590454, 0.19392071270526573, 0.44036464502171774, 0.19909963541005443, 0.47720896692097575, 0.5219466858057652, 0.42522062776928266, 0.9115613170660941, 1.3154351169423757, 1.369065374108287, 1.138820280460428, 0.8729364784914828, 0.9460202426486897, 1.7058854510148815, 1.3177609618125599, 0.5412164221551193, 0.02265427380033787, 0.11515370929191704, 0.17195501943113015, 0.1526978893619499, 0.11376894494857724, 0.1250445214669448, 0.14543384119419564, 0.15890730581419873, 0.1071737601546707, 0.3370544462317101, 0.534577988946339, 0.3859568620675595, 0.2699501449496227, 0.23696631547531757, 0.1389538089676906, 0.171399832458996, 0.38148684289151, 0.24654338147398425, 0.2851074033351213, 0.42342417262454723, 0.34979931921704366, 0.2942180865028182, 0.044044864571333164, 0.022600870539152797, 0.013697083592776878, 0.013410544409430812, 0.016187087376992412, 0.01186529927686135, 0.4369210848969332, 0.406107784036954, 0.36803558112602863, 0.3514493977637335, 0.32115827206214864, 0.24581454874537373, 0.6957280268938697, 0.49447697641549315, 0.011831634836997226, 0.14087183241982493, 0.8977941652623619, 1.2526026208226273, 1.1858412143660768, 1.4666191862850877, 1.0799041448570768, 0.3121893573098177, 0.031357448502652326, 0.0067362637435469256, 0.06134118176111392, 0.028989426747457622, 0.03724293425103696, 0.9191334520713476, 1.2009652917359945, 0.4394552823501815, 0.12678992369147613, 0.13674834850560108, 0.14801985801644083, 0.1364599364822469, 0.12427818959773371, 0.11375892039805188, 0.12942047985043467, 0.2721873604431294, 0.27912763930380163, 0.24115709124541934, 0.11134535633737402, 0.4482271486183269, 0.3395631704938751, 1.1560392350685333, 1.6014611575661637, 2.1470456297804676, 2.2382025195331274, 1.6851818299876913, 1.2683144095475787, 0.9580506987726616, 1.0046147384388704, 1.2115626858697996, 1.331701888403963, 2.9114960722811194, 3.939300385088711, 3.151294695168009, 1.982121944427493, 0.9131480978756417, 5.16884603151461, 4.345281284029891, 3.1732950094269543, 1.9527041359645565, 1.9689417961167126, 1.4221250693790797, 4.874146426596293, 4.914054358877787, 2.9989740938056832, 0.17160026079674448, 0.009024392836846988, 0.4225741101477624, 0.5705931584297792, 0.2977014074681281, 0.4066077658861592, 0.25465722022174925, 0.17887593794465628, 0.05058971638000668, 0.038776872355913664, 0.030998087703911863, 0.03148351028198288, 0.2621134743094472, 0.1392284405486995, 0.0129614326120734, 0.023919175948388483, 0.03174192367603654, 0.03495361381314202, 0.16064960512484527, 0.2825186751146159, 0.26467535552524724, 0.30229557708130084, 0.011205250853757806, 0.021483039075175795, 0.014945761769479027, 0.015240842778372852, 0.019888909812635108, 0.022633980069591282, 0.024952221018416244, 0.025587428013351177, 0.02643823854101001, 0.020536223857606076, 0.014952971013527288, 0.039974126739652116, 0.046896438958666714, 0.024968018026878026, 0.09635177952370169, 0.01327049538570175, 0.020289829636145975, 0.01775408348440556, 0.01845006395759389, 0.10979065216123694, 0.20282069103019992, 0.021554846195014275, 0.050491129871594105, 0.12395763308538846, 0.13638354546093046, 0.04596785043945491, 0.15432077573566902, 0.06544623069646882, 0.03300991089923716, 0.03823619727114508, 0.04083881361311353, 0.049474955004215435, 0.04894323463224459, 0.04830876092721776, 0.04874848086990646, 0.050056199349477894, 0.06518780304155904, 0.05343860288494176, 0.04989272927732821, 0.04776453244169427, 0.05153334640121235, 0.07333923745353808, 0.07412089125824511, 0.0715032528813736, 0.06424284793058355, 0.043711216283998336, 0.026477823433685068, 0.07311246263306224, 0.08616867130792631, 0.06462038649130879, 0.05452693540255274, 0.06816341060908687, 0.25954601572962793, 0.595117837554071, 0.0589196971906814, 0.01769245863422883, 0.019190777513408537, 0.026451006304567704, 0.03903109957352127, 0.0773472246183346, 0.14215388660088094, 0.1247286245387641, 0.16363439090028117, 0.2768376897850142, 0.2479653757139359, 0.6015484755597582, 0.5982164306986406, 0.33829514889572604, 0.033887843869196355, 0.38219298942656277, 0.24940445076696582, 0.7708842449071931, 2.2178812986466943, 3.1880397825706295, 2.559594087484406, 0.9497571238657323, 0.0538010450943228, 0.03578596709338876, 0.33543329213450596, 0.6112917196459886, 2.975866355547091, 1.7238837241048026, 0.13109374131500973, 0.27031670837868105, 0.1908500561514091, 0.32251801723387186, 0.3622315616869345, 0.3053625724171913, 0.3244358929920808, 0.48544991089080136, 0.47451098953806425, 0.3522696487787626, 0.20979355802626565, 0.16269926027198714, 0.12777011709829644, 0.08920782543672674, 0.13744003659769255, 0.06078886865956209, 0.03892100490516097, 0.01646051385809764, 0.10017633238216726, 0.2117079269799713, 0.27596741957766024, 0.13852770399286626, 0.006883882096345343, 0.009949600800343721, 0.016476882397333477, 0.029540453730122665, 0.0337147980810586, 0.2793846602853369, 0.32815221606239636, 0.05605002556770093, 0.03255298603702302, 0.08741727654155622, 0.5179791712188512, 0.8113302603010086, 0.88007210231441, 0.6743727151940897, 0.08734611412749074, 0.01580152325672449, 0.43292043115272416, 0.12991378301234274, 0.20231109909333853, 0.06726197290108979, 0.01406758237082125, 0.016845258518115747, 0.01898150090781245, 0.06887860852897042, 0.04847120301210231, 0.05228803220748754, 0.05365920503177998, 0.034489301579192326, 0.03204672879300921, 0.021198236450489762, 0.010322842378117479, 0.010201912476410011, 0.012341981736404349, 0.03660576966835723, 0.016234978311286993, 0.9288899967583214, 1.992316168257231, 2.0532050162136573, 2.0276528353115726, 1.6743825217708945, 1.729180643471276, 3.390697761279781, 5.845112594162545, 8.626413673889346, 8.896777644390014, 6.890925433577561, 4.704911781520378, 4.804032793722865, 5.0650280772185905, 3.9936536027163996, 4.046747117507748, 3.2430881901485162, 2.558558485993339, 2.4081168981587013, 2.206399157098154, 2.0665944592697865, 1.9908021652117007, 1.9701511367428592, 1.5965893604769938, 1.5298984952089263, 0.6620467902593102, 0.5711860852685143, 0.5479180101623259, 0.7271444575077423, 0.5183107936641247, 1.2982679401955954, 0.8609682986649071, 1.4654391160825404, 0.8716410444140797, 1.005098713130304, 1.2206263920155966, 2.334719541596203, 2.9611495413431306, 2.16538029182248, 1.2188448411662405, 1.1168085485696793, 0.8763455051656176, 0.7205742926779771, 0.41510826567324194, 0.24989225807324303, 0.3703588480129838, 0.3497076594248051, 0.32073117897096204, 0.3011229181968857, 0.08521404889662092, 0.1356821434072605, 0.5212420333267712, 0.38445771939941775, 0.1633813133159448, 0.11190694150026524, 0.02808003474265428, 0.05417522737861429, 0.08890923406473054, 0.025803863452892983, 0.08840423851684247, 0.02614524201830713, 0.03885193572595443, 0.08026867331482651, 0.09503003483263367, 0.03522002042793646, 0.029614618020032804]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tqyw1_KiyHuM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b0b4e892-44f2-474b-c45e-66d6c384a622"
      },
      "source": [
        "print(history_ori.history['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.946699595451355, 1.2099444627761842, 1.5479833126068114, 1.4524463057518004, 1.5711600065231324, 1.1737653374671937, 1.19598987698555, 0.9857332468032837, 1.0154624938964845, 0.8693858504295349, 0.9027871727943421, 0.5639498233795166, 0.7342651784420013, 0.6883358538150788, 0.8946852028369904, 0.7550951600074768, 0.8813461244106293, 1.0280081629753113, 0.5583542943000793, 0.8001842617988586, 0.7221287369728089, 0.6247177362442017, 0.6913618385791779, 0.6470989406108856, 0.4815889477729797, 0.8266039490699768, 0.4851489007472992, 0.5452690482139587, 0.3905809998512268, 0.658229586482048, 0.5177216589450836, 0.7678817749023438, 0.5784137129783631, 0.6956564903259277, 0.6553878903388977, 0.5838504791259765, 0.3958095759153366, 0.45830739140510557, 0.5090103089809418, 0.5797443747520447, 0.3284350037574768, 0.4602947771549225, 0.25136353075504303, 0.5348820418119431, 0.3065753012895584, 0.41552906334400175, 0.5294168174266816, 0.31463918536901475, 0.3621480420231819, 0.635984480381012, 0.46765053272247314, 0.42186282873153685, 0.3494979843497276, 0.5769266247749328, 0.43311522006988523, 0.4728669494390488, 0.6200619757175445, 0.30963314473629, 0.4788943827152252, 0.49684945344924925, 0.6380031526088714, 0.5133257180452346, 0.2667942032217979, 0.28261901438236237, 0.4653774589300156, 0.40436544790863993, 0.16888704523444176, 0.300993786752224, 0.4618034243583679, 0.23715534806251526, 0.4029479265213013, 0.24122051298618316, 0.27638733983039854, 0.21908116936683655, 0.240763883292675, 0.49749302864074707, 0.4060033708810806, 0.34062780141830445, 0.26266264691948893, 0.4254420459270477, 0.3882887065410614, 0.2402885563671589, 0.309877809882164, 0.3777199238538742, 0.18549915552139282, 0.43145430386066436, 0.22833015620708466, 0.5282209247350693, 0.27616044208407403, 0.32565348893404006, 0.2328379511833191, 0.20153121054172515, 0.6966126024723053, 0.23184841126203537, 0.4519523188471794, 0.3990479752421379, 0.2314506098628044, 0.3097794383764267, 0.281915557384491, 0.3447320759296417, 0.4223884046077728, 0.6561859726905823, 0.42124178260564804, 0.5719085812568665, 0.3513582915067673, 0.41568779945373535, 0.4707245588302612, 0.3181543037295341, 0.3488445967435837, 0.4504838943481445, 0.23323037922382356, 0.2447833925485611, 0.2514956720173359, 0.4618420869112015, 0.3139334723353386, 0.3200626090168953, 0.309008177369833, 0.33987520486116407, 0.28172130286693575, 0.3141783207654953, 0.3011510979384184, 0.23429251089692116, 0.23421216011047363, 0.41081990003585817, 0.148381008207798, 0.26144381463527677, 0.3640561893582344, 0.3794970721006393, 0.24783728420734405, 0.3103625446557999, 0.37488842010498047, 0.1564893141388893, 0.18729933649301528, 0.31294824182987213, 0.25596818029880525, 0.087041737139225, 0.24794151037931442, 0.22657972127199172, 0.20324018597602844, 0.278086069971323, 0.2540921844542027, 0.2603291615843773, 0.31358875185251234, 0.5813272058963775, 0.2308906987309456, 0.3513923943042755, 0.10625723600387574, 0.3024528153240681, 0.2519145945087075, 0.5660017907619477, 0.2614784941077232, 0.3070939712226391, 0.3913486585021019, 0.20671919882297515, 0.20867356583476065, 0.2550662890076637, 0.17229129374027252, 0.16256940215826035, 0.35982052981853485, 0.28869996070861814, 0.32962877824902537, 0.1981693297624588, 0.08596536070108414, 0.15844416096806527, 0.28075774312019347, 0.2249590590596199, 0.2595131918787956, 0.18582829385995864, 0.6933060824871063, 0.19061400592327118, 0.17936524748802185, 0.1837667554616928, 0.16229948103427888, 0.1439733162522316, 0.321238149702549, 0.18992089182138444, 0.13298484236001967, 0.19570886343717575, 0.3220803178846836, 0.28199484273791314, 0.15347529649734498, 0.2647469609975815, 0.17563252300024032, 0.21895260214805604, 0.24385983496904373, 0.3401351422071457, 0.183259516954422, 0.20179892405867578, 0.15014488995075226, 0.4988557696342468, 0.3863502457737923, 0.2545494884252548, 0.28710304796695707, 0.18506475239992143, 0.3852804347872734, 0.28671618849039077, 0.16008155792951584, 0.28271897211670877, 0.27890848368406296, 0.16513498052954673, 0.25925350189208984, 0.26572268903255464, 0.36126644089818, 0.3431130155920982, 0.13928870521485806, 0.2832551971077919, 0.11377795115113258, 0.13692230433225633, 0.19114799946546554, 0.29039516001939775, 0.1476630762219429, 0.09452784471213818, 0.09283718056976795, 0.4180764824151993, 0.30435790717601774, 0.2073998674750328, 0.06989727690815925, 0.31058536767959594, 0.10669968593865634, 0.135009104013443, 0.21418602019548416, 0.17982549518346785, 0.3220093011856079, 0.20895114094018935, 0.5333101689815521, 0.18872757628560066, 0.16848532855510712, 0.12266158759593963, 0.3221162974834442, 0.1389341399073601, 0.13316864222288133, 0.34212754257023337, 0.3842784151434898, 0.12042246833443641, 0.46019080877304075, 0.323517382144928, 0.22328531444072724, 0.09351348131895065, 0.11762228161096573, 0.3951918721199036, 0.1347916081547737, 0.19164194613695146, 0.2912029415369034, 0.26094549894332886, 0.1953544110059738, 0.214706689119339, 0.23578486144542693, 0.12582495510578157, 0.14931505359709263, 0.29941901601850984, 0.2190712571144104, 0.26074463278055193, 0.32446460947394373, 0.21964942663908005, 0.16749251037836074, 0.2919912688434124, 0.4473289430141449, 0.17931415066123008, 0.20593974068760873, 0.2811253756284714, 0.09194059260189533, 0.07902519330382347, 0.11583635061979294, 0.22893628776073455, 0.15410248637199403, 0.16376703679561616, 0.18651183769106866, 0.08827349320054054, 0.26508343070745466, 0.17685583159327506, 0.3376630410552025, 0.2591722458600998, 0.2944761473685503, 0.2702034428715706, 0.105105821788311, 0.3112904168665409, 0.4611350893974304, 0.16662878915667534, 0.35724816620349886, 0.28082342855632303, 0.17820005118846893, 0.3130658969283104, 0.39466998279094695, 0.427501405775547, 0.22738509252667427, 0.4414909303188324, 0.24123453646898269, 0.19108565337955952, 0.28685915991663935, 0.1736660346388817, 0.16689955890178682, 0.16257308796048164, 0.162227363884449, 0.18388785570859909, 0.09310024827718735, 0.09947694763541222, 0.1972195751965046, 0.1642659731209278, 0.4622044414281845, 0.29364439398050307, 0.3226195439696312, 0.04478200674057007, 0.30931027233600616, 0.20321615636348725, 0.08027957826852798, 0.14668547362089157, 0.1437975734472275, 0.25714669078588487, 0.32283991426229475, 0.19223845154047012, 0.30683421343564987, 0.16713987588882445, 0.3351212114095688, 0.19064278304576873, 0.18192562982439994, 0.11307032033801079, 0.039327452331781386, 0.2051322154700756, 0.28576949536800383, 0.051722452789545056, 0.17390353940427303, 0.3148490250110626, 0.22621219456195832, 0.4118304654955864, 0.22067099213600158, 0.3895604357123375, 0.08177899569272995, 0.2120509773492813, 0.23746772482991219, 0.16962449252605438, 0.1799610361456871, 0.3851428396999836, 0.091072416305542, 0.13521261066198348, 0.17650634050369263, 0.1642529010772705, 0.2510681986808777, 0.20289263054728507, 0.14094935804605485, 0.11647123470902443, 0.1583050951361656, 0.10137035399675369, 0.12063264548778534, 0.33727458864450455, 0.1519918940961361, 0.13706381022930145, 0.14443395361304284, 0.06009182631969452, 0.07251173481345177, 0.37898017168045045, 0.06463459543883801, 0.4024289771914482, 0.09481990933418274, 0.14849343784153463, 0.16071902140974997, 0.27361877262592316, 0.06397183202207088, 0.33028287068009377, 0.16597187295556068, 0.26371960192918775, 0.08850867524743081, 0.13204366154968739, 0.12227517813444137, 0.12049171105027198, 0.1246462568640709, 0.2691973127424717, 0.0831670181825757, 0.058331231400370595, 0.10871683582663536, 0.13779653757810592, 0.05930438712239265, 0.12991248890757562, 0.4213923096656799, 0.05503611210733652, 0.14599257633090018, 0.12971555218100547, 0.11691079884767533, 0.24301344119012355, 0.07677442505955696, 0.10427056942135096, 0.27428408712148666, 0.16253698617219925, 0.11837693452835082, 0.07491107359528541, 0.10779544934630395, 0.12102054320275783, 0.24733402095735074, 0.13555706590414046, 0.12039564549922943, 0.12065531611442566, 0.12331066466867924, 0.232779061794281, 0.20266057439148427, 0.23681211546063424, 0.11151314526796341, 0.05714951679110527, 0.08359044622629881, 0.04772636480629444, 0.12082708496600389, 0.1703361988067627, 0.1804216407239437, 0.032300671003758906, 0.18973370641469955, 0.13896280955523252, 0.1769689816981554, 0.16433472707867622, 0.1664315715432167, 0.04878247529268265, 0.13672553673386573, 0.1754047866910696, 0.08599293306469917, 0.34026477113366127, 0.20467036217451096, 0.174153583496809, 0.13733896166086196, 0.08749351166188717, 0.17269541285932064, 0.11143514961004257, 0.08317577727138996, 0.04520274810492993, 0.10402766168117523, 0.09061122611165047, 0.17009196281433106, 0.11268269903957844, 0.22576043307781218, 0.1529753588140011, 0.11059385538101196, 0.09590904293581844, 0.22068106904625892, 0.06527096033096313, 0.0947760596871376, 0.20493384227156639, 0.19391845278441905, 0.1798286915756762, 0.027025231346488, 0.14282532185316085, 0.0756041668355465, 0.18975260034203528, 0.07315208725631236, 0.1126333698630333, 0.04793401770293713, 0.09781629741191863, 0.3336401402950287, 0.07802466601133347, 0.07323552444577217, 0.09315668027848005, 0.2399520069360733, 0.09607951939105988, 0.14740238524973392, 0.05217048153281212, 0.030490241199731826, 0.10835346821695566, 0.04356318823993206, 0.18257797248661517, 0.08139533288776875, 0.13635114766657352, 0.14571800827980042, 0.24805620312690735, 0.033802452869713305, 0.0855401186272502, 0.12276001125574112, 0.168113674223423, 0.28607716895639895, 0.2005112048238516, 0.24554741382598877, 0.19285401850938796, 0.22770490907132626, 0.12933218330144883, 0.41477044522762296, 0.10280722007155418, 0.11460902541875839, 0.054765678197145465, 0.21801688000559807, 0.11280882135033607, 0.2131023198366165, 0.16976970266550778, 0.14722365625202655, 0.46071638241410257, 0.2568149551749229, 0.21271064337342976, 0.07499677240848542, 0.09589077830314637, 0.1065510280430317, 0.17639120221138, 0.07742379549890757, 0.14350465983152388, 0.1686477355659008, 0.2761345760896802, 0.07288780193775893, 0.21387194581329821, 0.2638117104768753, 0.10828813463449478, 0.07726726830005645, 0.18965381123125552, 0.09286954514682293, 0.12280604131519794, 0.1872337728738785, 0.06715823300182819, 0.1344449955970049, 0.12404912263154984, 0.24966700747609138, 0.16143477726727723, 0.08338710069656372, 0.19031544886529445, 0.1105924965813756, 0.20387333855032921, 0.15524967946112156, 0.07194924429059028, 0.19992875354364514, 0.06637036353349686, 0.10072441324591637, 0.12473795562982559, 0.07301080413162708, 0.14482476226985455, 0.20770646184682845, 0.2872372852638364, 0.14745223112404346, 0.30290877555962653, 0.12333885617554188, 0.06607902683317661, 0.03598575294017792, 0.2527623727917671, 0.25840577147901056, 0.2711040288209915, 0.04784061908721924, 0.1263754814863205, 0.10567596852779389, 0.15406304821372033, 0.28663480281829834, 0.15626271665096284, 0.16009170953184365, 0.23307981230318547, 0.1584810957312584, 0.18406892120838164, 0.1291270662099123, 0.14385776594281197, 0.1813531219959259, 0.04644207367673516, 0.26619585454463957, 0.16019498985260724, 0.0448319599032402, 0.3454704746603966, 0.4623024374246597, 0.1797520624473691, 0.09566601365804672, 0.22872231528162956, 0.1353760715574026, 0.042546753538772464, 0.08615209870040416, 0.17080258056521416, 0.05296718552708626, 0.12855439782142639, 0.036629038862884045, 0.12089264318346978, 0.06221994366496801, 0.1142839513719082, 0.17050319984555246, 0.024598435126245023, 0.12671251818537713, 0.06919021178036928, 0.2716512835584581, 0.1849218264222145, 0.08604231476783752, 0.27409576922655104, 0.06402937229722738, 0.1980851911008358, 0.08624658938497305, 0.14520093202590942, 0.19072183072566987, 0.1374217568896711, 0.09111641384661198, 0.05053559094667435, 0.05417599081993103, 0.1009244816377759, 0.0836723130196333, 0.09839446414262057, 0.1797062885016203, 0.05999392755329609, 0.07004864607006311, 0.1474060755223036, 0.3948760058730841, 0.36149444468319414, 0.2254107730463147, 0.029802243039011956, 0.3542156137526035, 0.09413441941142082, 0.1386038798838854, 0.12657254207879304, 0.07915207035839558, 0.10704535208642482, 0.18740722127258777, 0.20297950878739357, 0.04262954033911228, 0.05591229386627674, 0.036794681660830976, 0.07357168737798929, 0.08018576297909022, 0.1279385205358267, 0.21006477745249869, 0.012833700864575803, 0.07642735131084918, 0.13288415372371673, 0.05545408241450787, 0.03945531286299229, 0.0174590808339417, 0.027159309852868317, 0.1761733029037714, 0.11181968096643687, 0.017702823597937824, 0.14634979190304875, 0.08621225077658892, 0.10286435196176172, 0.10147314295172691, 0.1299125974997878, 0.17459187973290682, 0.29724442046135663, 0.29832029454410075, 0.07432441432029009, 0.1216760165989399, 0.2500049385242164, 0.20508151762187482, 0.14314369671046734, 0.19845080375671387, 0.21572371423244477, 0.05804158318787813, 0.172452044300735, 0.06523891128599643, 0.26607727333903314, 0.21369220688939095, 0.13393729142844676, 0.2874492611736059, 0.28192206770181655, 0.07798926793038845, 0.048508547246456146, 0.1391067411750555, 0.15331154111772777, 0.0818790152668953, 0.17679670508950948, 0.175213423371315, 0.07725428715348244, 0.16062570754438638, 0.025886735692620278, 0.018321980163455008, 0.03351525031030178, 0.07473124694079161, 0.10404354371130467, 0.046583665907382964, 0.1396535774692893, 0.0763043750077486, 0.23650750070810317, 0.14836314991116523, 0.17900306694209575, 0.10749938022345304, 0.1246244627982378, 0.22861988916993142, 0.1076678424840793, 0.10767163895070553, 0.19418792985379696, 0.1774748794734478, 0.23259619027376174, 0.25000144094228743, 0.17248657681047916, 0.26335323601961136, 0.09064582958817483, 0.27844140976667403, 0.024610468558967112, 0.05384066291153431, 0.2259817011654377, 0.1643213864415884, 0.11670175772160292, 0.07887890702113509, 0.06521352529525756, 0.05566281978972256, 0.10675457920879125, 0.17839204967021943, 0.12353217303752899, 0.10506120771169662, 0.14324432257562875, 0.13488813675940037, 0.1954811186529696, 0.08091748356819153, 0.14757164642214776, 0.045159030519425866, 0.467078273370862, 0.0404967037960887, 0.0547569552436471, 0.18710252130404115, 0.06895583011209964, 0.04490824518725276, 0.045302400924265386, 0.10235921200364828, 0.09900074396282435, 0.0341020043939352, 0.14000062495470048, 0.01860887873917818, 0.034594429098069666, 0.050962708331644534, 0.08182652536779642, 0.030072130262851715, 0.137503020465374, 0.24804368540644645, 0.01900474838912487, 0.060238076746463774, 0.03813680876046419, 0.1237692566588521, 0.049520792067050935, 0.13577668219804764, 0.06494901720434428, 0.2740295916795731, 0.11392496768385171, 0.4515670627355576, 0.11901569552719593, 0.2513545650988817, 0.09792771246284246, 0.3207243822515011, 0.13590830080211164, 0.11502796746790409, 0.24731303229928017, 0.22320338785648347, 0.06947358716279269, 0.11124140173196792, 0.05727564916014671, 0.14701472464948892, 0.13725298903882505, 0.22893630098551512, 0.04494300596415997, 0.04020305313169956, 0.0970188269391656, 0.33304528295993807, 0.21314116567373276, 0.14944512620568276, 0.0804194189608097, 0.13140937071293593, 0.11447964012622833, 0.09066516906023026, 0.1565251864492893, 0.05789212062954903, 0.15834978315979242, 0.15594108626246453, 0.077999035269022, 0.026063614524900913, 0.23179264292120932, 0.06476060263812541, 0.09887555576860904, 0.07137375250458718, 0.19361486481502652, 0.1238207470625639, 0.1678586397320032, 0.14847897794097661, 0.07178950179368257, 0.39263966754078866, 0.11341623365879058, 0.4291131585836411, 0.13180507123470306, 0.11051668450236321, 0.2019184447824955, 0.05342268571257591, 0.0743438746780157, 0.11364254709333181, 0.18923668041825295, 0.08359088152647018, 0.11232005506753921, 0.16347647532820703, 0.21893369480967523, 0.23387939371168615, 0.12081548599526286, 0.0325857462361455, 0.08266585897654295, 0.20209997110068798, 0.03720614928752184, 0.03247733216267079, 0.02534252032637596, 0.13730723578482867, 0.05833641439676285, 0.09734437353909016, 0.07883823961019516, 0.10887195132672786, 0.12425029911100864, 0.16371474992483853, 0.09857441429048777, 0.15622121877968312, 0.12994160475209354, 0.0378283366560936, 0.1518265360966325, 0.08065483830869198, 0.03497534673660994, 0.33972016125917437, 0.0986110339872539, 0.2357829911634326, 0.053210953064262864, 0.12359030619263649, 0.02340469490736723, 0.04894346361979842, 0.08907658960670232, 0.18364517167210578, 0.021465339325368406, 0.10875645168125629, 0.03822935614734888, 0.14719172716140747, 0.15385501850396394, 0.23921485356986522, 0.16732945293188095, 0.1702155541628599, 0.07409436292946339, 0.0772111363708973, 0.10460433382540942, 0.18236355148255826, 0.19709305167198182, 0.11436644652858377, 0.07821988053619862, 0.08315425012260676, 0.10016125328838825, 0.11059243083000184, 0.1809759933501482, 0.13665251433849335, 0.04814570564776659, 0.08584792502224445, 0.022383869159966707, 0.044343312829732896, 0.09459785744547844, 0.028408798016607763, 0.04193771220743656, 0.04216262996196747, 0.42573179565370084, 0.01630508555099368, 0.08517116280272603, 0.023681922629475594, 0.1948007933795452, 0.0750599130988121, 0.09104363806545734, 0.03782828357070685, 0.03389688655734062, 0.07673757597804069, 0.02760892603546381, 0.05692942254245281, 0.07024740427732468, 0.2179544077254832, 0.11945005748420953, 0.05744925243780017, 0.04746023025363684, 0.03928266428411007, 0.13463864978402854, 0.05749105676077306, 0.19768856838345528, 0.5826882295310497, 0.26627553422003986, 0.21115940809249878, 0.3220996199175715, 0.2502322981134057, 0.8651818804442882, 0.09553172215819358, 0.3357560321688652, 0.398212605714798, 0.20208343341946602, 0.30632632300257684, 0.3304481148719788, 0.19615352675318717, 0.28758423328399657, 0.08240711586549879, 0.07458261586725712, 0.11898668706417084, 0.16962379217147827, 0.07079829126596451, 0.1902204565703869, 0.12002412080764771, 0.07191366888582706, 0.024600723199546336, 0.21595191434025765, 0.130486848205328, 0.07741451766341925, 0.09689180999994278, 0.3164738953113556, 0.13885532915592194, 0.13222376443445683, 0.0900641594082117, 0.20991350039839746, 0.14088599048554898, 0.1955441102385521, 0.10053244354203343, 0.1987967848777771, 0.15612221732735634, 0.28440436720848083, 0.1616291247308254, 0.13823443856090306, 0.19155418463051319, 0.2073616348206997, 0.29046818148344755, 0.07551939152181149, 0.17241906486451625, 0.1300632819533348, 0.122936437651515, 0.17751598171889782, 0.07633075378835201, 0.2835448358207941, 0.14961757101118564, 0.1181472510099411, 0.056750960648059845, 0.129532390832901, 0.14159362465143205, 0.07936808485537768, 0.03840615041553974, 0.118905711453408, 0.042287231981754304, 0.06201944034546614, 0.05868707541376352, 0.0889455497264862, 0.08128485204651952, 0.1905605047941208, 0.03969181701540947, 0.10284216208383441, 0.1067281872034073, 0.10383742824196815, 0.027983513846993446, 0.1952826865017414, 0.07517240988090634, 0.13589614098891617, 0.06537380199879408, 0.11196012366563082, 0.031219223421066998, 0.057592746987938884, 0.040571969794109465, 0.06046837270259857, 0.1231879860162735, 0.09459734763950109, 0.09319369606673718, 0.15246342020109296, 0.1529322400689125, 0.09916973561048507, 0.03896372485905886, 0.10470605096779764, 0.1325021654367447, 0.05645302245393395, 0.05365637103095651, 0.021768993232399225, 0.10312928520143032, 0.17380207404494286, 0.2207569632679224, 0.4213218852877617, 0.22593727931380272, 0.19268047735095023, 0.15015912875533105, 0.0843786921352148, 0.2625079698860645, 0.08833681792020798, 0.18256822749972343, 0.037337227165699004, 0.16800689846277236, 0.05367152327671647, 0.03280384559184313, 0.09587583281099796, 0.16798622692003845, 0.05038051549345255, 0.09347620522603392, 0.051970145851373675, 0.13723965790122747, 0.11503141075372696, 0.09702378045767546, 0.016801829636096954, 0.10417981296777726, 0.11808490254916251, 0.33890870921313765, 0.05250614993274212, 0.09211300536990166, 0.06597484741359949, 0.1006871341727674, 0.01482702437788248, 0.09757670275866985, 0.02921012993901968, 0.07067644372582435, 0.13884729705750942, 0.05448028715327382, 0.08142582811415196, 0.02843439457938075, 0.17120333388447762, 0.054158322792500255, 0.06386166345328093, 0.06483903601765632, 0.1183461726643145, 0.13044160306453706, 0.10306527633219957, 0.0172438639216125, 0.17329518366605043, 0.09346834309399128, 0.040389907034114006, 0.07806996572762728, 0.04562719538807869, 0.03824327643960714, 0.042650312557816504, 0.05833872146904469, 0.23744003800675273, 0.0818297790363431, 0.06366518307477236, 0.07331654792651535, 0.024200573517009615, 0.07533936025574803, 0.0655756339430809, 0.03810992192011327, 0.027658886928111314, 0.05331833832897246, 0.04009062480181456, 0.041291166096925735, 0.08410687036812306, 0.02900280700996518, 0.04452890972606838, 0.010909447818994522, 0.0408481108956039, 0.13407300817780196, 0.03785665929317474, 0.12827951684594155, 0.06787235615774989, 0.15523949936032294, 0.14217921234667302, 0.08664736049249769, 0.07664199955761433, 0.10624143118038773, 0.06848545707762241, 0.0637535322457552, 0.2954073417931795, 0.017561207385733725, 0.04417903609573841, 0.13339726137928665, 0.3249969337135553, 0.13909475514665245, 0.04128582729026675, 0.029384048096835612, 0.03667490286752582, 0.12987721851095557, 0.11680374294519424, 0.12082999814301729, 0.06548126563429832, 0.059718548273667696, 0.246985864918679, 0.11151500986889004, 0.05961230453103781, 0.09632029607892037, 0.12148503586649895, 0.2673566348850727, 0.024122319649904966, 0.32663603127002716, 0.04569462984800339, 0.06471749320626259, 0.033587807416915895, 0.2010502178221941, 0.32861963799223304, 0.026072951126843692, 0.13684535175561904, 0.12377981916069984, 0.0632221207022667, 0.1641448199748993, 0.07826556265354156, 0.04329531313851476, 0.08227967992424964, 0.04928238093852997, 0.02691703997552395, 0.03641897290945053, 0.20215134881436825, 0.06799629032611847, 0.06655315421521664, 0.09698665104806423, 0.2352069579064846, 0.0334077138453722, 0.04177626818418503, 0.04574227072298527, 0.21275305151939392, 0.09744060151278973, 0.030463989358395338, 0.01382691040635109, 0.08712481604889036, 0.11987484097480774, 0.04942633435130119, 0.04761474821716547, 0.22446741424500943, 0.09365965011529624, 0.028254703897982836, 0.04552985690534115, 0.14696779996156692, 0.10853844285011291, 0.11406809911131859, 0.021296915761195124, 0.028077916521579028, 0.04854511450976133, 0.04970392677932978, 0.09725630432367324, 0.024804297275841235, 0.06372856860980392, 0.0376258946955204, 0.1528017282485962, 0.026225405698642134, 0.1914058937691152, 0.03311576033011079, 0.06567318700253963, 0.07660384587943554, 0.08126583490520715, 0.05856428290717304, 0.02917627841234207, 0.060969695914536715, 0.05713994242250919, 0.019848915562033654, 0.07603680938482285, 0.14225586894899606, 0.02129406351596117, 0.03484066817909479, 0.07163790613412857, 0.09316374193876982, 0.10681852241978049, 0.14597133807837964, 0.07008096873760224, 0.29058344308286904, 0.31675220690667627, 0.05863358429633081, 0.33743381006643175, 0.06836038865149022, 0.23712398931384088, 0.19091334319673478, 0.01885236264206469, 0.03477065972983837, 0.0630663501098752, 0.1447680950164795, 0.3271790508180857, 0.09142383802682161, 0.03136227000504732, 0.037575472798198464, 0.025105752982199192, 0.02179834507405758, 0.03051731325685978, 0.054975580889731646, 0.05253717787563801, 0.05610891506075859, 0.032104407995939256, 0.11700682900846004, 0.058650615811347964, 0.01757793501019478, 0.014219095837324858, 0.0159817055799067, 0.20419019320979714, 0.04631605502218008, 0.055595694575458765, 0.14863503631204367, 0.04703662535175681, 0.03135561761446297, 0.042798770032823084, 0.0530738296918571, 0.07426651180721819, 0.04411863889545202, 0.05446437015198171, 0.1955971833318472, 0.030997826415114105, 0.008992196572944523, 0.012255552038550378, 0.36381164453923703, 0.08633037521503865, 0.07803106969222426, 0.03164634648710489, 0.06564527302980423, 0.11175975557416677, 0.15911818221211432, 0.041726503521203995, 0.0556941150687635, 0.07675050161778926, 0.06206324435770512, 0.0921383781824261, 0.0157824695808813, 0.04465936820488423, 0.03543101027607918, 0.14935868382453918, 0.01728385016322136, 0.12515989188104867, 0.1406410526484251, 0.1837575390934944, 0.015803075209259988, 0.09823112562298775, 0.04063563011586666, 0.14043914009816943, 0.030462594330310823, 0.21538714747875928, 0.0821254350244999, 0.2252803299576044, 0.09134452249854803, 0.005956747569143772, 0.179673741851002, 0.023309755139052868, 0.06519342251121998, 0.24513693228363992, 0.07995371036231518, 0.04724130127578974, 0.15998925045132636, 0.03528398950584233, 0.09610430030152202, 0.08006196964997798, 0.0499698250554502, 0.16834957534447312, 0.041378504037857054, 0.0592399513348937, 0.03529793936759233, 0.08363186214119196, 0.025656794477254153, 0.12133052125573159, 0.04036405235528946, 0.05630239779129624, 0.021960683306679128, 0.020738696586340664, 0.04109534096205607, 0.04328658692538738, 0.08382785022258758, 0.14517902433872223, 0.040431578457355496, 0.03445366807281971, 0.043688408378511664, 0.016497429995797574, 0.03612129483371973, 0.006906164903193712, 0.04096894001122564, 0.021113885939121245, 0.025881461054086684, 0.0234748771879822, 0.18279642410343513, 0.26173783699050546, 0.02724243151023984, 0.14197865445166827, 0.08170478628017008, 0.06062559182755649, 0.10728634130209684, 0.027657944709062576, 0.026691802451387046, 0.014286094531416892, 0.03426659069955349, 0.04489008048549294, 0.04640223209280521, 0.04149951310828328, 0.044991265749558806, 0.03421680685132742, 0.0162186972098425, 0.038304700911976394, 0.05957574334461242, 0.020890654111281038, 0.041703459620475766, 0.1334925766568631, 0.03097382336854935, 0.10153578752651811, 0.08975397124886512, 0.0990219666622579, 0.01494432743638754, 0.06127645671367645, 0.05178791186772287, 0.10498194266110658, 0.17758834552951158, 0.01524910661391914, 0.14778792122378945, 0.04541850406676531, 0.03290959652513266, 0.14252779353410006, 0.13643333027139307, 0.012711355136707425, 0.08621212774887681, 0.046926208026707175, 0.112590217217803, 0.03664823193103075, 0.09697741419076919, 0.1339200807735324, 0.05138637414202094, 0.03136952230706811, 0.053658737475052475, 0.011255761503707617, 0.2686112027615309, 0.08663703501224518, 0.13705466352403164, 0.05265920013189316, 0.08613117425702513, 0.01478115355130285, 0.06156848445534706, 0.06303805140778422, 0.09605764565058053, 0.06398530234582722, 0.06152554987929761, 0.05795537662925199, 0.04422773895785213, 0.03957958049140871, 0.2972899508662522, 0.1040382681414485, 0.01536975228227675, 0.11414095386862755, 0.02313284119591117, 0.05568297412246466, 0.07174199372529984, 0.017195407627150418, 0.031583941727876666, 0.15072015803307295, 0.006408036057837308, 0.23418846391141415, 0.1075437793508172, 0.15409822082147, 0.016256896872073413, 0.017562856897711754, 0.015793300420045852, 0.17789132986217737, 0.09824457177892328, 0.050518601294606925, 0.016618357505649328, 0.06558989910408855, 0.0691735785221681, 0.011792265437543392, 0.04248404880054295, 0.138187400624156, 0.021829063538461924, 0.04375092461705208, 0.02712048524990678, 0.0314581542275846, 0.0201102863997221, 0.019913961179554462, 0.023184171225875617, 0.0533587544457987, 0.030271738255396485, 0.018882962060160935, 0.08601916681509465, 0.016914468491449952, 0.06587997516617179, 0.019849308673292397, 0.012264527648221701, 0.02662043459713459, 0.07632842129096389, 0.08626177161931992, 0.13366278843022883, 0.07657158696092665, 0.02003093119710684, 0.04055467396974564, 0.03062256667762995, 0.4520705960690975, 0.11878646099939942, 0.27274451213888823, 0.06517382042948157, 0.05754494750872254, 0.17301029786467553, 0.03893235921859741, 0.1877910051494837, 0.020290052075870334, 0.1085093505680561, 0.16312168398872018, 0.015172834554687143, 0.07648507058620453, 0.1778198616579175, 0.04070953615009785, 0.006485902052372694, 0.041577487345784904, 0.07806072058156133, 0.0694351198617369, 0.12237291052006186, 0.011428095283918083, 0.0154043719638139, 0.0839963142760098, 0.024022227339446544, 0.0087838564068079, 0.019496870110742748, 0.0228100482840091, 0.00664047310128808, 0.03237333707511425, 0.009843348525464535, 0.02754033440724015, 0.11206298382021487, 0.015272653836291283, 0.005610746366437524, 0.029005090380087493, 0.0699471365660429, 0.0278570044785738, 0.04539899143856019, 0.012733517913147807, 0.05318798169028014, 0.11576914023607969, 0.05054160170257092, 0.02502308040857315, 0.046066755155334246, 0.015017263730987907, 0.13584976997226478, 0.10087534841150045, 0.17380355279892684, 0.29419609014876186, 0.024425308778882028, 0.025457606837153434, 0.04492693264037371, 0.10845959344878793, 0.033066484774462876, 0.04889817982912063, 0.05854695700109005, 0.012055040418636054, 0.01578591000288725, 0.017780542746186255, 0.03923364963848144, 0.015072712022811175, 0.03205860171001405, 0.03340946985408664, 0.024093130137771368, 0.008757144352421165, 0.02386552150128409, 0.029939402360469103, 0.014397424319759012, 0.018014527205377818, 0.09819326102733612, 0.07234324496239423, 0.044826787896454334, 0.12230353020131587, 0.06753596835769712, 0.019919673819094895, 0.013136808527633548, 0.12663183361291885, 0.29746273197233675, 0.11875048144720494, 0.013145526446169242, 0.05298813590779901, 0.062158457655459645, 0.017143047228455544, 0.09535283930599689, 0.11257375287823379, 0.06241198668722063, 0.006464660633355379, 0.014762813551351428, 0.11519297817721963, 0.06968367276713253, 0.011160728603135795, 0.01705367094837129, 0.003831322770565748, 0.05040273647755385, 0.026595584861934186, 0.012868773099035025, 0.03672891348833218, 0.02980831270106137, 0.1358307171612978, 0.009067932656034828, 0.06924521373584866, 0.0815058016218245, 0.03790602311491966, 0.12571453475393354, 0.012639488431159408, 0.049931113980710505, 0.033624134585261346, 0.021370330010540783, 0.170612065307796, 0.027955262688919902, 0.0700551698449999, 0.0580683532403782, 0.028387778205797076, 0.018813680065795778, 0.01757559021934867, 0.06553951161913574, 0.11236033019085881, 0.018899159133434297, 0.09551522340625525, 0.10295918332412839, 0.021323803742416204, 0.04586867466568947, 0.04944474333897233, 0.04542277143336833, 0.0444825385697186, 0.03802534388378263, 0.14631672725081443, 0.009101116191595792, 0.012667335593141616, 0.026579253608360887, 0.012056552153080703, 0.050861681636888534, 0.02310558003373444, 0.024442296056076885, 0.10922075156122446, 0.010036392346955835, 0.01124827042222023, 0.04180711908265948, 0.12595047625945882, 0.0053642521263100205, 0.045331821171566845, 0.034615230094641444, 0.09987769888248295, 0.132630087248981, 0.1497725650668144, 0.08266273587942123, 0.2470665452769026, 0.11573189981281758, 0.1276170047931373, 0.0453395158983767, 0.08677156423218549, 0.06849307261873036, 0.18017013370990753, 0.11422869637608528, 0.02166164250811562, 0.011975889513269066, 0.049495077691972256, 0.02224318655207753, 0.04597705553751439, 0.16730458699166775, 0.05159825272858143, 0.05608578026294708, 0.45092865647748115, 0.13925152495503426, 0.049258397938683626, 0.03333404706791043, 0.02528872834518552, 0.08645857684314251, 0.078227333817631, 0.0994573175907135, 0.03292082203552127, 0.07703220420517028, 0.055468115396797656, 0.034321592282503845, 0.13884225077927112, 0.043707031710073355, 0.14244080632925032, 0.02185362484306097, 0.15458885729312896, 0.021548085287213324, 0.07350558564066886, 0.13464370244182647, 0.06604800131171942, 0.06414339765906334, 0.050471619609743355, 0.03242959741037339, 0.0863439730834216, 0.0905340219847858, 0.23376608779653907, 0.03302056393586099, 0.18779991948977112, 0.25836223349906506, 0.07071082056500018, 0.07709866939112545, 0.031537215877324346, 0.08660754007287323, 0.07629864439368247, 0.039363763947039845, 0.015366200474090874, 0.015157011291012167, 0.018512654351070523, 0.11007076296955347, 0.026092487992718814, 0.062213387340307236, 0.1318373574875295, 0.04684105236083269, 0.012026975583285093, 0.011953014973551035, 0.23978085212875158, 0.04052461703540757, 0.05634021898731589, 0.015846234944183378, 0.04583163904026151, 0.0024332584580406547, 0.141412323853001, 0.051234689191915095, 0.07487093433737754, 0.15380590837448835, 0.010494690202176572, 0.03420324502512813, 0.04284926345571875, 0.02289691623300314, 0.08364339228719472, 0.025549592403694987, 0.009255865355953574, 0.08711343365721405, 0.02433739332482219, 0.06520491195842623, 0.022874059295281766, 0.17789057241752743, 0.06182636496378109, 0.02078960407525301, 0.10907104071229697, 0.010275930794887245, 0.026836758595891297, 0.019826944451779127, 0.05105855696601793, 0.08815631377510727, 0.0347993936855346, 0.018788109393790366, 0.026073392690159382, 0.16784001300111412, 0.036051280051469806, 0.019001109135570005, 0.044984936469700185, 0.14853148569818586, 0.03431470729410648, 0.044675100268796085, 0.03695689591113478, 0.01016077509848401, 0.0519767728052102, 0.1994527201168239, 0.09673636124643963, 0.010414224630221725, 0.2866538578644395, 0.052073943242430684, 0.15909936311654746, 0.07346683950163424, 0.015369196189567447, 0.036236167512834074, 0.06478971717879176, 0.00646997350268066, 0.017123699467629195, 0.047372070513665675, 0.022114785853773355, 0.007784970407374203, 0.06804504506289959, 0.036282028257846835, 0.06690074885264038, 0.05582142334897071, 0.01773617616854608, 0.007522223563864827, 0.014376507140696049, 0.019450151454657318, 0.020602438133209944, 0.0405639061704278, 0.02714543789625168, 0.08907699427800253, 0.10283892523730173, 0.11189233476761729, 0.2638798272004351, 0.07967523788101971, 0.05353259239345789, 0.17486875653266906, 0.0622813496273011, 0.10429180087521672, 0.008737955754622818, 0.11772903762757778, 0.027187330205924808, 0.05544964913278818, 0.013297141063958406, 0.09979919400066137, 0.05132507196394727, 0.09114889306947589, 0.13588595343753695, 0.02263640055898577, 0.019718050956726074, 0.03273367364890874, 0.04477629805915058, 0.04703649170696735, 0.026350945979356766, 0.14708159370347856, 0.05094113340601325, 0.017284589586779475, 0.05683950670063496, 0.1091028128284961, 0.014366779755800963, 0.09087486173957586, 0.09382690805941821, 0.040139210782945155, 0.028177762962877752, 0.11142355352640151, 0.02990960902534425, 0.0059883938636630775, 0.019884478487074374, 0.1334355439990759, 0.05217528583016247, 0.10924599934369325, 0.05675514061003924, 0.004757974809035659, 0.06603893684223294, 0.042308548977598545, 0.033127964846789835, 0.008598795905709267, 0.02768714663106948, 0.015410894330125302, 0.03160234956303611, 0.023605432535987347, 0.14300306104123592, 0.025713796063791962, 0.07781777675263583, 0.034046700468752536, 0.2783589409664273, 0.0700710485689342, 0.17572464710101485, 0.014820723328739405, 0.20420051841065287, 0.00832499477546662, 0.039539562165737153, 0.08412839770317078, 0.052476605772972106, 0.009647819236852229, 0.14537743669934572, 0.13139706440269946, 0.029288441594690084, 0.005449309409596026, 0.008764569403138012, 0.12365390956401826, 0.021489474875852465, 0.0944941932335496, 0.040315986564382914, 0.04830023106187582, 0.04891901649534702, 0.017620080942288043, 0.0438717155251652, 0.012329273228533565, 0.05646520433947444, 0.025315028335899114, 0.10068715857341885, 0.01014703162945807, 0.013950602989643813, 0.04881789265200496, 0.0022633276879787446, 0.012497359549161046, 0.02382984720170498, 0.07026437055319548, 0.06712025813758374, 0.0290959931910038, 0.009785511158406734, 0.06166771532734856, 0.0036481674760580063, 0.015860631177201868, 0.004747703205794096, 0.06627475935965776, 0.022629765467718242, 0.004666065098717809, 0.018736959854140877, 0.016429599304683507, 0.007636576145887375, 0.014060901384800673, 0.029334181640297174, 0.008568609645590187, 0.16827540670055896, 0.0035597597365267576, 0.004603273095563054, 0.04813752565532923, 0.022043557616416364, 0.025052411016076803, 0.025457067089155315, 0.016571941878646614, 0.12838571360334755, 0.02315738657489419, 0.1617353132198332, 0.05601042092312127, 0.046462364960461855, 0.12013173720333725, 0.03551250677555799, 0.04044232417363673, 0.15124211354414002, 0.006869148043915629, 0.06549794561578892, 0.03369742664508522, 0.02273975368589163, 0.2202020032564178, 0.029336631717160343, 0.012805574422236532, 0.05588136790320277, 0.09450558315729722, 0.029370678355917335, 0.05497674392536282, 0.07317968688439577, 0.09438204993493855, 0.015780333429574966, 0.043349840212613344, 0.010415239608846605, 0.06650019926019013, 0.017518506024498493, 0.003038059431128204, 0.033543937187641856, 0.01346750371158123, 0.08111761980690062, 0.017772835679352283, 0.3214233395992778, 0.06183352288790047, 0.010675779543817043, 0.037365078227594495, 0.00870716932695359, 0.0856087360996753, 0.01014953963458538, 0.005880291480571032, 0.04965800989884883, 0.03887781854718923, 0.018750867049675435, 0.8129157685674727, 0.30497280331328513, 0.6306307226419449, 0.3631035305559635, 0.1237363401800394, 0.3108715670183301, 0.060891523212194446, 0.3713558432646096, 0.6848249346017837, 0.037522518634796144, 0.08472091183066369, 0.2909760992974043, 0.0482268039137125, 0.09442457407712937, 0.1958054170012474, 0.03921754267066717, 0.017476941272616387, 0.01231471453793347, 0.1036665417253971, 0.050141914002597335, 0.12843776745721697, 0.10495374500751495, 0.009618922974914313, 0.03330789098981768, 0.04940251128282398, 0.01975169775541872, 0.389277845621109, 0.014837420545518398, 0.05358300870284438, 0.03850369337014854, 0.0057246545795351265, 0.058909070864319804, 0.01052083745598793, 0.17540435264818371, 0.012304379884153605, 0.011447184532880784, 0.18928808723576368, 0.03896146900951862, 0.04234501784667373, 0.03395720664411783, 0.09527736527379602, 0.02992383548989892, 0.030117946217069404, 0.008219045464647934, 0.045033952221274376, 0.04647606313228607, 0.021321791876107454, 0.2039287774823606, 0.1551496965577826, 0.033285241154953835, 0.008611769927665592, 0.032909716782160106, 0.008369164355099202, 0.031077246740460397, 0.04936264813877642, 0.039252229314297435, 0.0419823071686551, 0.18863003458827735, 0.027826717030256985, 0.03101873891428113, 0.022153260372579097, 0.022315814346075057, 0.012396010104566813, 0.05029606129974127, 0.041250515831052326, 0.02879266843665391, 0.019469283730722965, 0.014094393188133835, 0.021308990591205657, 0.024734020745381714, 0.036931383237242696, 0.05275583784095943, 0.024731715000234543, 0.004378141544293612, 0.017533572064712642, 0.007772219181060791, 0.017092338763177395, 0.08732017958536745, 0.014412043523043394, 0.018283732794225217, 0.13416818203404546, 0.03996863359352574, 0.16041246093809605, 0.116003795072902, 0.01274654632434249, 0.260744552873075, 0.02124101989902556, 0.016592614771798252, 0.08469896093010902, 0.040746422670781615, 0.19864776097238063, 0.11397395953536034, 0.012999661359935999, 0.03559479722753167, 0.0041711193975061175, 0.08163158874958754, 0.036776487296447155, 0.01036389225628227, 0.0492396303685382, 0.012405412318184973, 0.03710489915683866, 0.024735440220683812, 0.02104044482111931, 0.047702954383566976, 0.10361948513891547, 0.04078981673810631, 0.05191666618920863, 0.05237634517252445, 0.028194280131720005, 0.08988407840952277, 0.03816478280350566, 0.019286538031883536, 0.025828471104614437, 0.2939359400421381, 0.2941275527700782, 0.1584792800247669, 0.058517464250326154, 0.24221613090485333, 0.1154681345447898, 0.2464706612750888, 0.03487177826464176, 0.030626566824503244, 0.18009656984359027, 0.06168033890426159, 0.006826378544792533, 0.05453374236822128, 0.025738499686121942, 0.009347738139331341, 0.10811317525804043, 0.01832346136216074, 0.10886123031377792, 0.09400356998667121, 0.027181183733046056, 0.025094179809093474, 0.03142349403351545, 0.10592969488352537, 0.007251163315959275, 0.02731357696466148, 0.11115828752517701, 0.021583453845232727, 0.029809535574167968, 0.013081920892000198, 0.005843053641729057, 0.032969841710291804, 0.16589679794851692, 0.02625485030002892, 0.2922500340268016, 0.12774047795683147, 0.26946059465408323, 0.026379138289485127, 0.06231775125488639, 0.016234910720959304, 0.08305079489946365, 0.023623443394899368, 0.14586858190596103, 0.14845533352345228, 0.03709012037143111, 0.0037098619737662374, 0.006943090748973191, 0.014741859026253223, 0.03637493741698563, 0.006452821521088481, 0.011147203389555216, 0.10987439081072807, 0.0482993514277041, 0.007427691295742988, 0.022209995938465, 0.02784476145170629, 0.020224885456264018, 0.0616742211394012, 0.06217022491618991, 0.09080560551956296, 0.03287778148660436, 0.05243027750402689, 0.02521197278983891, 0.5301614718744532, 0.21961557045578955, 0.2608337176963687, 0.42156770909205077, 0.3217015414498746, 0.13277714997529982, 0.3548687845468521, 0.03296006675809622, 0.11608455120585859, 0.14079628586769105, 0.2422301832586527, 0.17464634627103806, 0.14015504568815232, 0.13884590566158295, 0.05228704959154129, 0.04353675674647093, 0.026271448843181132, 0.1610340766608715, 0.14439342077821493, 0.01872778940014541, 0.07903673388063907, 0.1483150881715119, 0.03865670785307884, 0.043433179054409264, 0.06969936084933578, 0.04651475939899683, 0.07484754379838705, 0.1545965664088726, 0.038740418199449775, 0.1243996050208807, 0.05041979905217886, 0.055193214863538745, 0.345043317694217, 0.11437441918533295, 0.06889043273404241, 0.10542667675763369, 0.03403207799419761, 0.052827677316963674, 0.1129047829657793, 0.0727716013789177, 0.14252181753981857, 0.022120202612131833, 0.06986334803514183, 0.024217249313369393, 0.03979808986186981, 0.08663624376058579, 0.03793470216915011, 0.025197884533554316, 0.05178937190212309, 0.07032119408249855, 0.040132499672472476, 0.01602296018972993, 0.021044005826115608, 0.015322237182408572, 0.28223056280985476, 0.21124249547719956, 0.06697251964360476, 0.3570773422718048, 0.2881733927875757, 0.19183645509183406, 0.06874578408896923, 0.05681545212864876, 0.035068096593022346, 0.08427450908347964, 0.0903397205285728, 0.058665571734309196]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7p46PMHyIZ6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9d7ec340-3420-406e-d2c9-8a54bd713af4"
      },
      "source": [
        "print(history_ori.history['val_accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.3, 0.525, 0.5, 0.55, 0.375, 0.425, 0.625, 0.55, 0.425, 0.45, 0.6, 0.75, 0.65, 0.625, 0.625, 0.675, 0.675, 0.525, 0.725, 0.6, 0.7, 0.8, 0.775, 0.725, 0.75, 0.675, 0.725, 0.625, 0.875, 0.75, 0.7, 0.725, 0.75, 0.8, 0.75, 0.75, 0.85, 0.825, 0.775, 0.8, 0.875, 0.825, 0.9, 0.775, 0.875, 0.875, 0.8, 0.9, 0.825, 0.775, 0.85, 0.85, 0.9, 0.825, 0.825, 0.775, 0.75, 0.875, 0.8, 0.85, 0.725, 0.775, 0.875, 0.9, 0.85, 0.825, 0.95, 0.875, 0.8, 0.875, 0.9, 0.925, 0.925, 0.925, 0.95, 0.775, 0.9, 0.85, 0.925, 0.825, 0.875, 0.85, 0.9, 0.9, 0.925, 0.8, 0.9, 0.9, 0.825, 0.95, 0.925, 0.9, 0.775, 0.875, 0.825, 0.85, 0.95, 0.925, 0.875, 0.875, 0.775, 0.75, 0.825, 0.8, 0.925, 0.9, 0.825, 0.9, 0.9, 0.85, 0.925, 0.925, 0.925, 0.85, 0.875, 0.85, 0.875, 0.925, 0.875, 0.825, 0.875, 0.925, 0.975, 0.875, 0.975, 0.875, 0.825, 0.85, 0.9, 0.875, 0.85, 0.975, 0.95, 0.825, 0.925, 0.95, 0.925, 0.95, 0.925, 0.9, 0.875, 0.9, 0.9, 0.875, 0.9, 0.9, 1.0, 0.85, 0.85, 0.775, 0.9, 0.9, 0.85, 0.9, 0.975, 0.875, 0.95, 0.9, 0.825, 0.925, 0.925, 0.925, 1.0, 0.9, 0.85, 0.9, 0.925, 0.95, 0.775, 0.95, 0.95, 0.95, 0.975, 0.95, 0.9, 0.975, 0.95, 0.975, 0.9, 0.925, 0.9, 0.9, 0.975, 0.925, 0.925, 0.875, 0.95, 0.925, 0.975, 0.8, 0.875, 0.9, 0.825, 0.925, 0.85, 0.9, 0.975, 0.875, 0.9, 0.975, 0.85, 0.875, 0.875, 0.825, 0.975, 0.925, 0.95, 0.95, 0.925, 0.875, 0.925, 0.95, 0.925, 0.875, 0.875, 0.875, 0.975, 0.875, 0.95, 0.95, 0.95, 0.925, 0.85, 0.925, 0.875, 0.975, 0.925, 0.95, 0.85, 0.925, 0.925, 0.825, 0.9, 0.95, 0.8, 0.85, 0.95, 0.975, 0.975, 0.85, 0.925, 0.925, 0.9, 0.95, 0.9, 0.875, 0.9, 0.95, 0.95, 0.9, 0.95, 0.85, 0.875, 0.925, 0.925, 0.95, 0.825, 0.925, 0.925, 0.875, 0.975, 0.975, 0.95, 0.925, 0.95, 0.925, 0.95, 0.975, 0.925, 0.925, 0.875, 0.925, 0.875, 0.85, 0.975, 0.875, 0.875, 0.95, 0.875, 0.9, 0.925, 0.875, 0.875, 0.8, 0.925, 0.825, 0.925, 0.95, 0.875, 0.975, 0.9, 0.925, 0.95, 0.975, 0.975, 0.975, 0.95, 0.925, 0.825, 0.925, 0.875, 1.0, 0.875, 0.9, 1.0, 0.9, 0.925, 0.825, 0.875, 0.9, 0.925, 0.95, 0.875, 0.95, 0.9, 0.95, 1.0, 0.925, 0.9, 1.0, 0.9, 0.9, 0.925, 0.85, 0.95, 0.875, 0.975, 0.9, 0.925, 0.925, 0.95, 0.85, 1.0, 0.975, 0.9, 0.95, 0.875, 0.925, 0.925, 0.975, 0.95, 0.95, 0.95, 0.9, 0.925, 0.95, 0.95, 0.975, 0.975, 0.85, 0.975, 0.85, 0.975, 0.925, 0.95, 0.9, 0.975, 0.925, 0.95, 0.875, 0.95, 0.975, 0.95, 0.95, 0.95, 0.925, 1.0, 1.0, 0.95, 0.9, 0.975, 0.95, 0.875, 1.0, 0.95, 0.975, 0.95, 0.9, 1.0, 0.975, 0.9, 0.925, 0.95, 0.975, 0.975, 0.95, 0.9, 0.95, 0.95, 0.95, 0.95, 0.875, 0.925, 0.9, 1.0, 1.0, 0.975, 1.0, 0.975, 0.95, 0.975, 1.0, 0.925, 0.925, 0.925, 0.925, 0.925, 1.0, 0.95, 0.925, 0.975, 0.85, 0.925, 0.925, 0.95, 0.975, 0.925, 0.975, 0.975, 1.0, 0.95, 0.975, 0.925, 0.95, 0.9, 0.925, 0.975, 0.975, 0.9, 0.975, 0.975, 0.95, 0.875, 0.925, 1.0, 0.95, 0.975, 0.975, 0.95, 0.925, 1.0, 0.95, 0.875, 0.975, 0.975, 0.975, 0.825, 0.975, 0.95, 1.0, 1.0, 0.95, 1.0, 0.925, 0.975, 0.95, 0.975, 0.95, 1.0, 0.95, 0.925, 0.95, 0.9, 0.9, 0.95, 0.925, 0.875, 0.95, 0.85, 0.95, 0.95, 1.0, 0.925, 0.975, 0.925, 0.925, 0.95, 0.825, 0.975, 0.9, 1.0, 0.975, 0.975, 0.95, 0.975, 0.95, 0.975, 0.875, 0.975, 0.95, 0.95, 0.975, 1.0, 0.925, 0.975, 0.95, 0.925, 0.975, 0.925, 0.975, 0.875, 0.925, 0.925, 0.925, 0.925, 0.95, 0.95, 1.0, 0.9, 1.0, 0.95, 0.925, 0.975, 0.95, 0.925, 0.825, 0.95, 0.9, 0.925, 0.95, 1.0, 0.9, 0.9, 0.875, 0.975, 0.925, 0.975, 0.95, 0.925, 0.9, 0.95, 0.875, 0.95, 0.925, 0.925, 0.95, 0.925, 1.0, 0.925, 0.975, 1.0, 0.85, 0.85, 0.95, 0.95, 0.95, 0.95, 0.975, 0.95, 0.95, 1.0, 0.975, 0.975, 0.95, 1.0, 0.95, 0.925, 1.0, 0.925, 1.0, 0.925, 0.925, 0.95, 0.875, 1.0, 0.95, 0.975, 0.95, 0.925, 0.925, 0.95, 0.975, 1.0, 0.975, 1.0, 0.975, 0.95, 0.975, 0.975, 0.975, 0.875, 0.9, 0.925, 1.0, 0.85, 0.95, 0.95, 0.95, 0.975, 0.925, 0.95, 0.925, 1.0, 1.0, 1.0, 0.975, 0.975, 0.95, 0.9, 1.0, 0.95, 0.975, 0.975, 1.0, 1.0, 1.0, 0.9, 0.95, 1.0, 0.95, 0.975, 0.975, 0.975, 0.95, 0.95, 0.875, 0.925, 0.975, 0.95, 0.925, 0.925, 0.95, 0.925, 0.925, 1.0, 0.9, 0.975, 0.925, 0.95, 0.95, 0.925, 0.9, 0.975, 1.0, 0.95, 0.9, 0.975, 0.975, 0.925, 0.95, 0.95, 1.0, 1.0, 1.0, 0.975, 0.95, 1.0, 0.925, 1.0, 0.975, 0.95, 0.95, 0.975, 0.975, 0.925, 0.925, 0.925, 0.95, 0.95, 0.95, 0.875, 0.975, 0.925, 0.975, 0.9, 1.0, 1.0, 0.925, 0.95, 0.95, 0.975, 0.975, 0.975, 0.95, 0.925, 0.95, 0.95, 0.95, 0.95, 0.925, 0.975, 0.925, 1.0, 0.9, 1.0, 0.975, 0.9, 1.0, 1.0, 1.0, 0.975, 0.95, 1.0, 0.975, 1.0, 1.0, 0.975, 0.975, 1.0, 0.925, 0.925, 1.0, 0.975, 1.0, 0.95, 1.0, 0.95, 0.975, 0.9, 0.95, 0.875, 0.95, 0.925, 0.95, 0.85, 0.975, 0.95, 0.9, 0.9, 0.975, 0.95, 1.0, 0.95, 0.95, 0.925, 0.975, 1.0, 0.975, 0.9, 0.925, 0.975, 0.95, 0.95, 0.925, 0.975, 0.925, 0.975, 0.95, 0.925, 0.975, 1.0, 0.9, 0.975, 0.975, 0.95, 0.925, 0.925, 0.975, 0.975, 0.95, 0.875, 0.95, 0.9, 0.975, 0.975, 0.925, 0.975, 0.975, 0.95, 0.975, 0.975, 0.975, 0.95, 0.9, 0.9, 0.925, 1.0, 0.975, 0.925, 1.0, 1.0, 1.0, 0.95, 1.0, 0.95, 0.975, 0.925, 0.925, 0.95, 0.95, 0.95, 0.95, 1.0, 0.95, 0.95, 1.0, 0.875, 0.95, 0.925, 1.0, 0.95, 1.0, 1.0, 0.975, 0.95, 1.0, 0.95, 1.0, 0.975, 0.975, 0.95, 0.95, 0.975, 0.975, 0.975, 0.975, 0.95, 0.9, 0.95, 0.975, 0.975, 0.975, 0.925, 0.95, 0.925, 1.0, 0.975, 1.0, 1.0, 0.975, 1.0, 1.0, 1.0, 0.875, 1.0, 0.95, 1.0, 0.95, 0.975, 0.975, 1.0, 1.0, 0.95, 0.975, 1.0, 0.975, 0.925, 0.925, 1.0, 0.975, 1.0, 0.95, 0.975, 0.925, 0.9, 0.875, 0.925, 0.9, 0.9, 0.75, 0.95, 0.9, 0.9, 0.925, 0.875, 0.875, 0.95, 0.95, 0.95, 0.975, 0.925, 0.925, 1.0, 0.9, 0.925, 0.975, 1.0, 0.925, 0.975, 0.975, 0.95, 0.875, 0.95, 0.925, 0.95, 0.9, 0.95, 0.925, 0.975, 0.9, 0.925, 0.9, 0.925, 0.95, 0.95, 0.925, 0.975, 0.975, 0.925, 0.925, 0.95, 0.925, 0.95, 0.9, 0.95, 0.925, 0.975, 0.95, 0.925, 0.975, 1.0, 0.95, 1.0, 0.975, 0.975, 0.975, 0.975, 0.9, 1.0, 0.975, 0.975, 0.95, 1.0, 0.925, 0.975, 0.95, 0.975, 0.95, 1.0, 0.95, 1.0, 1.0, 0.95, 0.975, 0.95, 0.925, 0.975, 0.975, 1.0, 0.95, 0.925, 0.975, 1.0, 1.0, 0.95, 0.95, 0.95, 0.875, 0.925, 0.9, 0.925, 0.95, 0.9, 0.975, 0.95, 1.0, 0.925, 0.975, 1.0, 0.975, 0.95, 1.0, 0.95, 1.0, 0.925, 0.975, 0.975, 1.0, 0.95, 0.925, 0.9, 0.975, 0.975, 0.975, 0.975, 1.0, 0.95, 1.0, 0.975, 0.925, 0.975, 1.0, 1.0, 0.925, 0.975, 0.975, 0.975, 0.975, 0.95, 0.95, 1.0, 0.95, 0.95, 0.975, 0.975, 1.0, 1.0, 0.975, 0.975, 0.925, 0.975, 0.975, 0.975, 1.0, 0.95, 0.975, 1.0, 1.0, 0.975, 1.0, 1.0, 0.95, 1.0, 0.975, 1.0, 0.975, 0.975, 1.0, 0.95, 0.975, 0.925, 0.95, 0.95, 0.95, 0.95, 0.975, 1.0, 0.9, 1.0, 1.0, 0.95, 0.9, 0.95, 1.0, 1.0, 1.0, 0.95, 0.975, 0.975, 0.975, 0.975, 0.9, 1.0, 0.975, 0.975, 0.975, 0.9, 1.0, 0.825, 0.975, 0.975, 1.0, 0.875, 0.8, 1.0, 0.95, 0.925, 0.975, 0.925, 0.975, 1.0, 0.975, 0.975, 1.0, 1.0, 0.95, 0.975, 0.975, 0.975, 0.875, 1.0, 1.0, 1.0, 0.9, 0.95, 1.0, 1.0, 0.975, 0.925, 1.0, 0.975, 0.925, 0.95, 1.0, 1.0, 0.95, 0.95, 0.925, 1.0, 1.0, 0.975, 0.975, 0.975, 1.0, 0.975, 1.0, 0.95, 1.0, 0.95, 1.0, 0.975, 0.975, 0.95, 0.975, 1.0, 0.975, 0.95, 1.0, 0.95, 0.95, 1.0, 0.975, 0.95, 0.975, 0.975, 0.95, 1.0, 0.875, 0.875, 0.975, 0.925, 0.975, 0.95, 0.95, 1.0, 1.0, 0.975, 0.925, 0.9, 0.95, 1.0, 1.0, 1.0, 1.0, 1.0, 0.975, 0.975, 0.975, 1.0, 0.925, 0.975, 1.0, 1.0, 1.0, 0.925, 1.0, 0.975, 0.975, 0.975, 1.0, 0.975, 0.975, 0.975, 1.0, 0.975, 0.925, 0.975, 1.0, 1.0, 0.875, 0.975, 0.975, 1.0, 0.975, 0.975, 0.9, 0.975, 0.975, 0.95, 0.975, 0.95, 1.0, 1.0, 1.0, 0.95, 1.0, 0.975, 0.95, 0.925, 1.0, 0.95, 1.0, 0.95, 0.975, 0.9, 0.95, 0.95, 0.975, 1.0, 0.95, 1.0, 0.975, 0.925, 0.975, 0.975, 0.925, 0.975, 0.95, 0.95, 0.975, 0.95, 0.975, 0.975, 1.0, 0.975, 0.975, 0.975, 0.975, 0.975, 1.0, 1.0, 1.0, 0.975, 0.95, 0.95, 0.975, 1.0, 0.975, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.975, 0.9, 1.0, 0.95, 0.975, 0.975, 0.95, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.975, 1.0, 1.0, 1.0, 0.975, 0.975, 1.0, 1.0, 0.975, 1.0, 0.975, 0.95, 0.975, 1.0, 0.975, 0.975, 0.975, 0.95, 1.0, 0.925, 1.0, 1.0, 0.925, 0.975, 1.0, 0.975, 0.975, 0.95, 0.975, 0.95, 0.975, 1.0, 1.0, 0.975, 1.0, 0.925, 1.0, 0.975, 0.975, 0.95, 1.0, 0.95, 0.975, 0.975, 0.95, 0.975, 0.975, 0.975, 0.975, 0.975, 0.975, 1.0, 0.95, 0.975, 1.0, 0.975, 1.0, 1.0, 0.925, 1.0, 0.925, 0.95, 0.95, 1.0, 1.0, 1.0, 0.925, 0.95, 0.975, 1.0, 1.0, 1.0, 1.0, 1.0, 0.975, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.975, 1.0, 1.0, 0.95, 1.0, 0.975, 1.0, 1.0, 1.0, 0.975, 0.95, 0.975, 0.975, 1.0, 0.975, 1.0, 0.9, 0.975, 0.9, 0.975, 0.975, 0.925, 1.0, 0.9, 1.0, 0.925, 0.9, 1.0, 0.975, 0.95, 0.975, 1.0, 1.0, 0.975, 1.0, 0.975, 1.0, 1.0, 0.95, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.975, 1.0, 1.0, 1.0, 0.975, 1.0, 0.975, 1.0, 0.975, 0.95, 1.0, 1.0, 1.0, 1.0, 0.95, 0.95, 0.95, 0.975, 1.0, 1.0, 0.975, 0.95, 0.975, 1.0, 0.975, 1.0, 1.0, 1.0, 1.0, 1.0, 0.975, 0.975, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.95, 0.975, 1.0, 0.95, 0.975, 1.0, 1.0, 0.95, 0.925, 0.95, 1.0, 0.975, 0.975, 1.0, 0.975, 0.95, 0.975, 1.0, 1.0, 0.975, 0.95, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.925, 1.0, 0.95, 0.95, 1.0, 0.95, 1.0, 0.975, 1.0, 1.0, 0.95, 1.0, 0.95, 0.975, 1.0, 1.0, 1.0, 0.975, 0.925, 1.0, 0.975, 0.975, 1.0, 0.975, 0.975, 0.975, 0.975, 1.0, 0.975, 1.0, 1.0, 1.0, 1.0, 0.975, 1.0, 1.0, 0.975, 1.0, 1.0, 1.0, 0.95, 1.0, 0.975, 1.0, 0.975, 0.975, 0.925, 0.95, 0.925, 0.925, 0.95, 1.0, 0.95, 0.95, 0.95, 0.95, 1.0, 1.0, 1.0, 1.0, 0.975, 0.95, 0.975, 0.975, 0.9, 0.9, 0.95, 1.0, 1.0, 0.975, 0.975, 0.975, 1.0, 0.975, 1.0, 1.0, 0.9, 1.0, 0.975, 1.0, 0.95, 1.0, 0.975, 0.95, 0.975, 0.975, 0.975, 1.0, 0.95, 0.975, 0.9, 1.0, 0.925, 0.925, 0.975, 0.975, 1.0, 0.975, 0.975, 0.975, 1.0, 1.0, 1.0, 0.95, 1.0, 1.0, 0.95, 0.975, 1.0, 1.0, 0.925, 1.0, 0.975, 1.0, 1.0, 1.0, 0.975, 0.975, 0.975, 0.95, 1.0, 1.0, 1.0, 1.0, 0.975, 1.0, 1.0, 0.95, 1.0, 0.975, 1.0, 0.95, 0.975, 1.0, 0.975, 1.0, 1.0, 1.0, 0.975, 0.925, 0.975, 1.0, 0.975, 0.95, 1.0, 1.0, 0.975, 0.95, 1.0, 0.975, 0.975, 1.0, 0.975, 0.95, 0.95, 1.0, 0.925, 0.975, 0.95, 0.95, 1.0, 0.975, 1.0, 1.0, 1.0, 0.975, 1.0, 1.0, 0.975, 0.975, 0.975, 0.975, 1.0, 1.0, 1.0, 1.0, 1.0, 0.975, 1.0, 0.975, 0.95, 0.95, 0.925, 0.975, 0.975, 0.95, 0.975, 0.975, 1.0, 0.925, 1.0, 1.0, 1.0, 0.975, 0.975, 0.975, 0.95, 1.0, 1.0, 0.975, 0.975, 0.975, 1.0, 0.975, 1.0, 1.0, 0.975, 0.925, 1.0, 0.95, 0.95, 0.975, 1.0, 0.95, 0.975, 1.0, 1.0, 0.925, 0.975, 0.95, 0.975, 1.0, 0.975, 1.0, 1.0, 1.0, 0.975, 1.0, 1.0, 1.0, 0.95, 1.0, 0.95, 0.975, 0.925, 0.95, 0.95, 1.0, 0.975, 1.0, 0.975, 1.0, 1.0, 1.0, 0.95, 0.95, 0.975, 1.0, 1.0, 0.95, 1.0, 0.975, 0.975, 0.975, 0.975, 1.0, 0.975, 1.0, 0.975, 1.0, 0.95, 1.0, 1.0, 0.95, 1.0, 1.0, 1.0, 0.975, 0.975, 1.0, 1.0, 0.975, 1.0, 1.0, 1.0, 0.95, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.975, 1.0, 1.0, 0.975, 1.0, 1.0, 1.0, 1.0, 0.95, 1.0, 0.95, 0.975, 0.975, 0.95, 0.975, 0.975, 0.975, 1.0, 0.975, 0.975, 1.0, 0.9, 0.975, 1.0, 0.975, 0.925, 0.975, 0.975, 0.975, 0.95, 1.0, 0.975, 1.0, 0.95, 1.0, 1.0, 1.0, 1.0, 0.95, 1.0, 0.9, 0.975, 1.0, 0.975, 1.0, 0.975, 1.0, 1.0, 0.975, 0.975, 1.0, 0.85, 0.9, 0.775, 0.95, 0.925, 0.9, 0.975, 0.9, 0.8, 1.0, 0.975, 0.875, 1.0, 0.975, 0.9, 0.975, 1.0, 1.0, 0.95, 1.0, 0.95, 0.95, 1.0, 1.0, 0.975, 1.0, 0.9, 1.0, 0.975, 0.975, 1.0, 0.975, 1.0, 0.95, 1.0, 1.0, 0.95, 1.0, 1.0, 1.0, 0.95, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.95, 0.925, 1.0, 1.0, 1.0, 1.0, 1.0, 0.95, 0.975, 0.975, 0.95, 1.0, 1.0, 1.0, 1.0, 1.0, 0.975, 0.975, 1.0, 1.0, 1.0, 1.0, 1.0, 0.975, 0.975, 1.0, 1.0, 1.0, 1.0, 1.0, 0.975, 1.0, 1.0, 0.95, 0.975, 0.925, 0.95, 1.0, 0.925, 1.0, 1.0, 0.975, 0.975, 0.925, 0.975, 1.0, 1.0, 1.0, 0.95, 0.975, 1.0, 0.975, 1.0, 1.0, 1.0, 1.0, 0.975, 0.975, 1.0, 0.975, 0.975, 1.0, 0.975, 0.975, 1.0, 1.0, 0.9, 0.925, 0.95, 0.975, 0.925, 0.95, 0.95, 1.0, 0.975, 0.975, 0.975, 1.0, 0.975, 1.0, 1.0, 0.95, 1.0, 0.95, 0.975, 0.975, 1.0, 1.0, 0.95, 1.0, 1.0, 0.975, 1.0, 1.0, 1.0, 1.0, 1.0, 0.925, 1.0, 0.95, 0.95, 0.95, 0.975, 0.95, 1.0, 0.975, 1.0, 0.95, 0.95, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.925, 0.975, 1.0, 1.0, 1.0, 1.0, 0.975, 0.975, 0.975, 0.975, 1.0, 1.0, 0.875, 0.925, 0.95, 0.8, 0.875, 0.95, 0.9, 1.0, 0.975, 0.95, 0.875, 0.95, 0.95, 0.925, 1.0, 0.975, 1.0, 0.9, 0.95, 1.0, 0.95, 0.95, 1.0, 1.0, 0.95, 0.975, 0.975, 0.925, 1.0, 0.925, 0.975, 0.975, 0.95, 0.95, 0.95, 0.95, 1.0, 0.975, 0.975, 0.975, 0.975, 1.0, 1.0, 1.0, 0.975, 0.975, 0.975, 1.0, 0.975, 0.95, 1.0, 1.0, 1.0, 1.0, 0.925, 0.875, 0.975, 0.925, 0.875, 0.925, 0.95, 0.975, 1.0, 0.95, 0.95, 1.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "widr5nt2lTni"
      },
      "source": [
        "**Predictions: When train and validate on total 24 images**<br> \n",
        "total Severe images: 96<br>\n",
        "Pridicted Healthy: 95<br>\n",
        "Pridicted Mild: 1<br>\n",
        "Pridicted Severe: 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teUeI-9fguXH"
      },
      "source": [
        "**Predictions: When train and validate on total 24 images**<br> \n",
        "total Severe images: 108<br>\n",
        "Pridicted Healthy: 0<br>\n",
        "Pridicted Mild: 16<br>\n",
        "Pridicted Severe: 92"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv0PRqIYhG7b"
      },
      "source": [
        "**Predictions: When train and validate on total 24 images**<br> \n",
        "total Mild images: 229<br>\n",
        "Pridicted Healthy: 26<br>\n",
        "Pridicted Mild: 181<br>\n",
        "Pridicted Severe: 22"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3r8r6e4C3-_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eq36QXxcn8Sb"
      },
      "source": [
        "**CNN_2:** implementation on segmented leaf images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBN_-7YjH5s6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "d9fe7188-523f-47fe-8cf4-a8ef10150e21"
      },
      "source": [
        "X_seg, Y_seg = prepare_data('/content/drive/My Drive/datasets/seg_leaves/*/*/*', img_size)\n",
        "\n",
        "# load dataset\n",
        "trainX_seg, testX_seg_, trainY_seg, testY_seg_ = train_test_split(X_seg, Y_seg, test_size=0.2, random_state = 0)\n",
        "trainX_seg, testX_seg = prep_pixels(trainX_seg, testX_seg_)\n",
        "\n",
        "# hot encoding\n",
        "trainY_seg = to_categorical(trainY_seg)\n",
        "testY_seg  = to_categorical(testY_seg_)\n",
        "\n",
        "datagen_seg = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
        "it_train_seg = datagen_seg.flow(trainX_seg, trainY_seg, batch_size=8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 201/201 [00:53<00:00,  3.79it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " total images are: 201\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCiM7LG0op13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "30f67b90-98f2-474e-b7d5-479aa9eb5d12"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "checkpoint_seg = ModelCheckpoint(pathModelSave_seg, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "# early = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')\n",
        "csv_logger_seg = CSVLogger(pathToSaveCSV_seg, append=False, separator=',')\n",
        "\n",
        "# define model\n",
        "model = define_model()\n",
        "\n",
        "# fit model\n",
        "steps = int(trainX_seg.shape[0] / 32)\n",
        "history_seg = model.fit_generator(\n",
        "    it_train_seg,\n",
        "    steps_per_epoch = steps,\n",
        "    epochs= EPOCSH,\n",
        "    callbacks = [checkpoint_seg, csv_logger_seg],\n",
        "    validation_data = (testX_seg, testY_seg),\n",
        "    verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "5/5 [==============================] - 1s 256ms/step - loss: 0.0723 - acc: 0.9750 - val_loss: 0.3410 - val_acc: 0.8537\n",
            "\n",
            "Epoch 00751: val_acc did not improve from 0.97561\n",
            "Epoch 752/2000\n",
            "5/5 [==============================] - 1s 258ms/step - loss: 0.1266 - acc: 0.9250 - val_loss: 0.2201 - val_acc: 0.9024\n",
            "\n",
            "Epoch 00752: val_acc did not improve from 0.97561\n",
            "Epoch 753/2000\n",
            "5/5 [==============================] - 1s 251ms/step - loss: 0.0832 - acc: 0.9750 - val_loss: 0.2458 - val_acc: 0.9024\n",
            "\n",
            "Epoch 00753: val_acc did not improve from 0.97561\n",
            "Epoch 754/2000\n",
            "5/5 [==============================] - 1s 251ms/step - loss: 0.1639 - acc: 0.9500 - val_loss: 0.4003 - val_acc: 0.8537\n",
            "\n",
            "Epoch 00754: val_acc did not improve from 0.97561\n",
            "Epoch 755/2000\n",
            "5/5 [==============================] - 1s 248ms/step - loss: 0.1322 - acc: 0.9250 - val_loss: 0.7617 - val_acc: 0.7317\n",
            "\n",
            "Epoch 00755: val_acc did not improve from 0.97561\n",
            "Epoch 756/2000\n",
            "5/5 [==============================] - 1s 250ms/step - loss: 0.1572 - acc: 0.9250 - val_loss: 1.2144 - val_acc: 0.6098\n",
            "\n",
            "Epoch 00756: val_acc did not improve from 0.97561\n",
            "Epoch 757/2000\n",
            "5/5 [==============================] - 1s 250ms/step - loss: 0.1805 - acc: 0.9250 - val_loss: 1.2947 - val_acc: 0.5854\n",
            "\n",
            "Epoch 00757: val_acc did not improve from 0.97561\n",
            "Epoch 758/2000\n",
            "5/5 [==============================] - 1s 255ms/step - loss: 0.2044 - acc: 0.9250 - val_loss: 1.3349 - val_acc: 0.6585\n",
            "\n",
            "Epoch 00758: val_acc did not improve from 0.97561\n",
            "Epoch 759/2000\n",
            "5/5 [==============================] - 1s 255ms/step - loss: 0.0510 - acc: 1.0000 - val_loss: 1.2731 - val_acc: 0.6829\n",
            "\n",
            "Epoch 00759: val_acc did not improve from 0.97561\n",
            "Epoch 760/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.0423 - acc: 1.0000 - val_loss: 0.8972 - val_acc: 0.7561\n",
            "\n",
            "Epoch 00760: val_acc did not improve from 0.97561\n",
            "Epoch 761/2000\n",
            "5/5 [==============================] - 1s 256ms/step - loss: 0.1150 - acc: 0.9500 - val_loss: 0.6787 - val_acc: 0.8049\n",
            "\n",
            "Epoch 00761: val_acc did not improve from 0.97561\n",
            "Epoch 762/2000\n",
            "5/5 [==============================] - 1s 253ms/step - loss: 0.0321 - acc: 1.0000 - val_loss: 0.6346 - val_acc: 0.8537\n",
            "\n",
            "Epoch 00762: val_acc did not improve from 0.97561\n",
            "Epoch 763/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.0998 - acc: 0.9250 - val_loss: 0.6493 - val_acc: 0.8049\n",
            "\n",
            "Epoch 00763: val_acc did not improve from 0.97561\n",
            "Epoch 764/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.1022 - acc: 0.9500 - val_loss: 0.7281 - val_acc: 0.7561\n",
            "\n",
            "Epoch 00764: val_acc did not improve from 0.97561\n",
            "Epoch 765/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.1245 - acc: 0.9250 - val_loss: 0.6622 - val_acc: 0.8049\n",
            "\n",
            "Epoch 00765: val_acc did not improve from 0.97561\n",
            "Epoch 766/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.2049 - acc: 0.9000 - val_loss: 0.2349 - val_acc: 0.9268\n",
            "\n",
            "Epoch 00766: val_acc did not improve from 0.97561\n",
            "Epoch 767/2000\n",
            "5/5 [==============================] - 1s 270ms/step - loss: 0.3587 - acc: 0.8750 - val_loss: 1.4432 - val_acc: 0.6585\n",
            "\n",
            "Epoch 00767: val_acc did not improve from 0.97561\n",
            "Epoch 768/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.1027 - acc: 0.9750 - val_loss: 1.1135 - val_acc: 0.6829\n",
            "\n",
            "Epoch 00768: val_acc did not improve from 0.97561\n",
            "Epoch 769/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.1485 - acc: 0.9500 - val_loss: 0.4444 - val_acc: 0.8780\n",
            "\n",
            "Epoch 00769: val_acc did not improve from 0.97561\n",
            "Epoch 770/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.2513 - acc: 0.8750 - val_loss: 0.4601 - val_acc: 0.8537\n",
            "\n",
            "Epoch 00770: val_acc did not improve from 0.97561\n",
            "Epoch 771/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.1966 - acc: 0.9500 - val_loss: 0.7695 - val_acc: 0.7317\n",
            "\n",
            "Epoch 00771: val_acc did not improve from 0.97561\n",
            "Epoch 772/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.0989 - acc: 0.9750 - val_loss: 0.8754 - val_acc: 0.7317\n",
            "\n",
            "Epoch 00772: val_acc did not improve from 0.97561\n",
            "Epoch 773/2000\n",
            "5/5 [==============================] - 1s 252ms/step - loss: 0.5744 - acc: 0.8000 - val_loss: 0.2446 - val_acc: 0.9024\n",
            "\n",
            "Epoch 00773: val_acc did not improve from 0.97561\n",
            "Epoch 774/2000\n",
            "5/5 [==============================] - 1s 247ms/step - loss: 0.1046 - acc: 0.9750 - val_loss: 0.6898 - val_acc: 0.7073\n",
            "\n",
            "Epoch 00774: val_acc did not improve from 0.97561\n",
            "Epoch 775/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.2244 - acc: 0.9750 - val_loss: 0.3196 - val_acc: 0.8537\n",
            "\n",
            "Epoch 00775: val_acc did not improve from 0.97561\n",
            "Epoch 776/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.1009 - acc: 0.9500 - val_loss: 0.1792 - val_acc: 0.9268\n",
            "\n",
            "Epoch 00776: val_acc did not improve from 0.97561\n",
            "Epoch 777/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.0809 - acc: 1.0000 - val_loss: 0.1961 - val_acc: 0.9512\n",
            "\n",
            "Epoch 00777: val_acc did not improve from 0.97561\n",
            "Epoch 778/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.1598 - acc: 0.9250 - val_loss: 0.3073 - val_acc: 0.8537\n",
            "\n",
            "Epoch 00778: val_acc did not improve from 0.97561\n",
            "Epoch 779/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.0477 - acc: 1.0000 - val_loss: 0.1800 - val_acc: 0.9512\n",
            "\n",
            "Epoch 00779: val_acc did not improve from 0.97561\n",
            "Epoch 780/2000\n",
            "5/5 [==============================] - 1s 273ms/step - loss: 0.2928 - acc: 0.9000 - val_loss: 0.2792 - val_acc: 0.8780\n",
            "\n",
            "Epoch 00780: val_acc did not improve from 0.97561\n",
            "Epoch 781/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.1594 - acc: 0.9250 - val_loss: 0.7488 - val_acc: 0.7073\n",
            "\n",
            "Epoch 00781: val_acc did not improve from 0.97561\n",
            "Epoch 782/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.1693 - acc: 0.9750 - val_loss: 1.5383 - val_acc: 0.6585\n",
            "\n",
            "Epoch 00782: val_acc did not improve from 0.97561\n",
            "Epoch 783/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.1266 - acc: 0.9500 - val_loss: 1.9245 - val_acc: 0.6098\n",
            "\n",
            "Epoch 00783: val_acc did not improve from 0.97561\n",
            "Epoch 784/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.1668 - acc: 0.9500 - val_loss: 1.5960 - val_acc: 0.6585\n",
            "\n",
            "Epoch 00784: val_acc did not improve from 0.97561\n",
            "Epoch 785/2000\n",
            "5/5 [==============================] - 1s 251ms/step - loss: 0.0988 - acc: 0.9500 - val_loss: 0.8763 - val_acc: 0.7317\n",
            "\n",
            "Epoch 00785: val_acc did not improve from 0.97561\n",
            "Epoch 786/2000\n",
            "5/5 [==============================] - 1s 249ms/step - loss: 0.3303 - acc: 0.8500 - val_loss: 1.0545 - val_acc: 0.6341\n",
            "\n",
            "Epoch 00786: val_acc did not improve from 0.97561\n",
            "Epoch 787/2000\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 0.1129 - acc: 0.9750 - val_loss: 2.0781 - val_acc: 0.5122\n",
            "\n",
            "Epoch 00787: val_acc did not improve from 0.97561\n",
            "Epoch 788/2000\n",
            "5/5 [==============================] - 1s 276ms/step - loss: 0.3542 - acc: 0.9000 - val_loss: 1.8034 - val_acc: 0.5854\n",
            "\n",
            "Epoch 00788: val_acc did not improve from 0.97561\n",
            "Epoch 789/2000\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 0.2190 - acc: 0.9000 - val_loss: 0.2540 - val_acc: 0.9268\n",
            "\n",
            "Epoch 00789: val_acc did not improve from 0.97561\n",
            "Epoch 790/2000\n",
            "5/5 [==============================] - 1s 272ms/step - loss: 0.0849 - acc: 0.9500 - val_loss: 0.3339 - val_acc: 0.8537\n",
            "\n",
            "Epoch 00790: val_acc did not improve from 0.97561\n",
            "Epoch 791/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.0441 - acc: 1.0000 - val_loss: 0.4860 - val_acc: 0.8049\n",
            "\n",
            "Epoch 00791: val_acc did not improve from 0.97561\n",
            "Epoch 792/2000\n",
            "5/5 [==============================] - 1s 272ms/step - loss: 0.0683 - acc: 1.0000 - val_loss: 0.6704 - val_acc: 0.7805\n",
            "\n",
            "Epoch 00792: val_acc did not improve from 0.97561\n",
            "Epoch 793/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.1823 - acc: 0.9000 - val_loss: 0.8334 - val_acc: 0.7073\n",
            "\n",
            "Epoch 00793: val_acc did not improve from 0.97561\n",
            "Epoch 794/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.4189 - acc: 0.8000 - val_loss: 0.4760 - val_acc: 0.8049\n",
            "\n",
            "Epoch 00794: val_acc did not improve from 0.97561\n",
            "Epoch 795/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.0698 - acc: 1.0000 - val_loss: 0.6382 - val_acc: 0.7317\n",
            "\n",
            "Epoch 00795: val_acc did not improve from 0.97561\n",
            "Epoch 796/2000\n",
            "5/5 [==============================] - 1s 271ms/step - loss: 0.2514 - acc: 0.9000 - val_loss: 2.2241 - val_acc: 0.5366\n",
            "\n",
            "Epoch 00796: val_acc did not improve from 0.97561\n",
            "Epoch 797/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.0707 - acc: 0.9750 - val_loss: 2.2910 - val_acc: 0.4878\n",
            "\n",
            "Epoch 00797: val_acc did not improve from 0.97561\n",
            "Epoch 798/2000\n",
            "5/5 [==============================] - 1s 258ms/step - loss: 0.1724 - acc: 0.9500 - val_loss: 1.9409 - val_acc: 0.5122\n",
            "\n",
            "Epoch 00798: val_acc did not improve from 0.97561\n",
            "Epoch 799/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.0864 - acc: 1.0000 - val_loss: 2.2091 - val_acc: 0.4146\n",
            "\n",
            "Epoch 00799: val_acc did not improve from 0.97561\n",
            "Epoch 800/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.0617 - acc: 0.9750 - val_loss: 1.2392 - val_acc: 0.6098\n",
            "\n",
            "Epoch 00800: val_acc did not improve from 0.97561\n",
            "Epoch 801/2000\n",
            "5/5 [==============================] - 1s 273ms/step - loss: 0.0907 - acc: 0.9750 - val_loss: 0.2575 - val_acc: 0.9024\n",
            "\n",
            "Epoch 00801: val_acc did not improve from 0.97561\n",
            "Epoch 802/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.1029 - acc: 0.9500 - val_loss: 0.7112 - val_acc: 0.8049\n",
            "\n",
            "Epoch 00802: val_acc did not improve from 0.97561\n",
            "Epoch 803/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.0942 - acc: 0.9500 - val_loss: 1.3152 - val_acc: 0.6585\n",
            "\n",
            "Epoch 00803: val_acc did not improve from 0.97561\n",
            "Epoch 804/2000\n",
            "5/5 [==============================] - 1s 270ms/step - loss: 0.0665 - acc: 0.9750 - val_loss: 3.0681 - val_acc: 0.5610\n",
            "\n",
            "Epoch 00804: val_acc did not improve from 0.97561\n",
            "Epoch 805/2000\n",
            "5/5 [==============================] - 1s 281ms/step - loss: 0.1647 - acc: 0.9250 - val_loss: 0.9859 - val_acc: 0.7073\n",
            "\n",
            "Epoch 00805: val_acc did not improve from 0.97561\n",
            "Epoch 806/2000\n",
            "5/5 [==============================] - 1s 296ms/step - loss: 0.3664 - acc: 0.8750 - val_loss: 1.5564 - val_acc: 0.6098\n",
            "\n",
            "Epoch 00806: val_acc did not improve from 0.97561\n",
            "Epoch 807/2000\n",
            "5/5 [==============================] - 1s 284ms/step - loss: 0.1545 - acc: 0.9250 - val_loss: 3.2817 - val_acc: 0.5122\n",
            "\n",
            "Epoch 00807: val_acc did not improve from 0.97561\n",
            "Epoch 808/2000\n",
            "5/5 [==============================] - 1s 283ms/step - loss: 0.0784 - acc: 0.9750 - val_loss: 2.9973 - val_acc: 0.5122\n",
            "\n",
            "Epoch 00808: val_acc did not improve from 0.97561\n",
            "Epoch 809/2000\n",
            "5/5 [==============================] - 1s 279ms/step - loss: 0.1183 - acc: 0.9500 - val_loss: 2.0183 - val_acc: 0.5610\n",
            "\n",
            "Epoch 00809: val_acc did not improve from 0.97561\n",
            "Epoch 810/2000\n",
            "5/5 [==============================] - 1s 274ms/step - loss: 0.0800 - acc: 1.0000 - val_loss: 1.5956 - val_acc: 0.6098\n",
            "\n",
            "Epoch 00810: val_acc did not improve from 0.97561\n",
            "Epoch 811/2000\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 0.1501 - acc: 0.9250 - val_loss: 1.8045 - val_acc: 0.5854\n",
            "\n",
            "Epoch 00811: val_acc did not improve from 0.97561\n",
            "Epoch 812/2000\n",
            "5/5 [==============================] - 1s 273ms/step - loss: 0.0440 - acc: 1.0000 - val_loss: 1.1073 - val_acc: 0.6829\n",
            "\n",
            "Epoch 00812: val_acc did not improve from 0.97561\n",
            "Epoch 813/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.1008 - acc: 0.9500 - val_loss: 0.1769 - val_acc: 0.9512\n",
            "\n",
            "Epoch 00813: val_acc did not improve from 0.97561\n",
            "Epoch 814/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.0421 - acc: 1.0000 - val_loss: 0.2528 - val_acc: 0.8780\n",
            "\n",
            "Epoch 00814: val_acc did not improve from 0.97561\n",
            "Epoch 815/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.1046 - acc: 0.9750 - val_loss: 0.6142 - val_acc: 0.8049\n",
            "\n",
            "Epoch 00815: val_acc did not improve from 0.97561\n",
            "Epoch 816/2000\n",
            "5/5 [==============================] - 1s 273ms/step - loss: 0.2931 - acc: 0.8750 - val_loss: 1.0797 - val_acc: 0.7805\n",
            "\n",
            "Epoch 00816: val_acc did not improve from 0.97561\n",
            "Epoch 817/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.1322 - acc: 0.9250 - val_loss: 0.5843 - val_acc: 0.7317\n",
            "\n",
            "Epoch 00817: val_acc did not improve from 0.97561\n",
            "Epoch 818/2000\n",
            "5/5 [==============================] - 1s 272ms/step - loss: 0.1060 - acc: 0.9500 - val_loss: 0.7326 - val_acc: 0.7073\n",
            "\n",
            "Epoch 00818: val_acc did not improve from 0.97561\n",
            "Epoch 819/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.1480 - acc: 0.9500 - val_loss: 1.8947 - val_acc: 0.5366\n",
            "\n",
            "Epoch 00819: val_acc did not improve from 0.97561\n",
            "Epoch 820/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.1773 - acc: 0.9250 - val_loss: 2.8170 - val_acc: 0.4878\n",
            "\n",
            "Epoch 00820: val_acc did not improve from 0.97561\n",
            "Epoch 821/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.0820 - acc: 0.9750 - val_loss: 3.2460 - val_acc: 0.4634\n",
            "\n",
            "Epoch 00821: val_acc did not improve from 0.97561\n",
            "Epoch 822/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.0660 - acc: 0.9750 - val_loss: 3.6157 - val_acc: 0.4390\n",
            "\n",
            "Epoch 00822: val_acc did not improve from 0.97561\n",
            "Epoch 823/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.1238 - acc: 0.9500 - val_loss: 2.9463 - val_acc: 0.5366\n",
            "\n",
            "Epoch 00823: val_acc did not improve from 0.97561\n",
            "Epoch 824/2000\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 0.4958 - acc: 0.8000 - val_loss: 1.2804 - val_acc: 0.6829\n",
            "\n",
            "Epoch 00824: val_acc did not improve from 0.97561\n",
            "Epoch 825/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.2302 - acc: 0.9250 - val_loss: 1.1992 - val_acc: 0.7073\n",
            "\n",
            "Epoch 00825: val_acc did not improve from 0.97561\n",
            "Epoch 826/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.1862 - acc: 0.9000 - val_loss: 0.6925 - val_acc: 0.7561\n",
            "\n",
            "Epoch 00826: val_acc did not improve from 0.97561\n",
            "Epoch 827/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.0938 - acc: 0.9500 - val_loss: 0.3988 - val_acc: 0.8537\n",
            "\n",
            "Epoch 00827: val_acc did not improve from 0.97561\n",
            "Epoch 828/2000\n",
            "5/5 [==============================] - 1s 256ms/step - loss: 0.0907 - acc: 0.9750 - val_loss: 0.4203 - val_acc: 0.8293\n",
            "\n",
            "Epoch 00828: val_acc did not improve from 0.97561\n",
            "Epoch 829/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.1188 - acc: 0.9750 - val_loss: 1.7266 - val_acc: 0.6341\n",
            "\n",
            "Epoch 00829: val_acc did not improve from 0.97561\n",
            "Epoch 830/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.0760 - acc: 1.0000 - val_loss: 3.0571 - val_acc: 0.4878\n",
            "\n",
            "Epoch 00830: val_acc did not improve from 0.97561\n",
            "Epoch 831/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.1659 - acc: 0.9500 - val_loss: 3.2349 - val_acc: 0.4878\n",
            "\n",
            "Epoch 00831: val_acc did not improve from 0.97561\n",
            "Epoch 832/2000\n",
            "5/5 [==============================] - 1s 271ms/step - loss: 0.1407 - acc: 0.9500 - val_loss: 2.0490 - val_acc: 0.5366\n",
            "\n",
            "Epoch 00832: val_acc did not improve from 0.97561\n",
            "Epoch 833/2000\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 0.1100 - acc: 0.9500 - val_loss: 0.6635 - val_acc: 0.7073\n",
            "\n",
            "Epoch 00833: val_acc did not improve from 0.97561\n",
            "Epoch 834/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.0767 - acc: 0.9750 - val_loss: 0.4166 - val_acc: 0.8780\n",
            "\n",
            "Epoch 00834: val_acc did not improve from 0.97561\n",
            "Epoch 835/2000\n",
            "5/5 [==============================] - 1s 270ms/step - loss: 0.1009 - acc: 0.9750 - val_loss: 0.5281 - val_acc: 0.7805\n",
            "\n",
            "Epoch 00835: val_acc did not improve from 0.97561\n",
            "Epoch 836/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.1264 - acc: 0.9750 - val_loss: 0.9593 - val_acc: 0.8049\n",
            "\n",
            "Epoch 00836: val_acc did not improve from 0.97561\n",
            "Epoch 837/2000\n",
            "5/5 [==============================] - 1s 258ms/step - loss: 0.0399 - acc: 1.0000 - val_loss: 1.4505 - val_acc: 0.7317\n",
            "\n",
            "Epoch 00837: val_acc did not improve from 0.97561\n",
            "Epoch 838/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.2726 - acc: 0.9500 - val_loss: 0.9424 - val_acc: 0.7317\n",
            "\n",
            "Epoch 00838: val_acc did not improve from 0.97561\n",
            "Epoch 839/2000\n",
            "5/5 [==============================] - 1s 273ms/step - loss: 0.0920 - acc: 0.9750 - val_loss: 0.6151 - val_acc: 0.8049\n",
            "\n",
            "Epoch 00839: val_acc did not improve from 0.97561\n",
            "Epoch 840/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.0596 - acc: 1.0000 - val_loss: 0.5440 - val_acc: 0.8293\n",
            "\n",
            "Epoch 00840: val_acc did not improve from 0.97561\n",
            "Epoch 841/2000\n",
            "5/5 [==============================] - 1s 270ms/step - loss: 0.0202 - acc: 1.0000 - val_loss: 0.5136 - val_acc: 0.8293\n",
            "\n",
            "Epoch 00841: val_acc did not improve from 0.97561\n",
            "Epoch 842/2000\n",
            "5/5 [==============================] - 1s 274ms/step - loss: 0.2686 - acc: 0.9000 - val_loss: 1.0907 - val_acc: 0.7561\n",
            "\n",
            "Epoch 00842: val_acc did not improve from 0.97561\n",
            "Epoch 843/2000\n",
            "5/5 [==============================] - 1s 271ms/step - loss: 0.1073 - acc: 0.9500 - val_loss: 1.8269 - val_acc: 0.5610\n",
            "\n",
            "Epoch 00843: val_acc did not improve from 0.97561\n",
            "Epoch 844/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.0768 - acc: 1.0000 - val_loss: 1.1794 - val_acc: 0.7073\n",
            "\n",
            "Epoch 00844: val_acc did not improve from 0.97561\n",
            "Epoch 845/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.2582 - acc: 0.9500 - val_loss: 0.8518 - val_acc: 0.8049\n",
            "\n",
            "Epoch 00845: val_acc did not improve from 0.97561\n",
            "Epoch 846/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.0384 - acc: 1.0000 - val_loss: 1.2036 - val_acc: 0.7561\n",
            "\n",
            "Epoch 00846: val_acc did not improve from 0.97561\n",
            "Epoch 847/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.0917 - acc: 0.9500 - val_loss: 1.8137 - val_acc: 0.6585\n",
            "\n",
            "Epoch 00847: val_acc did not improve from 0.97561\n",
            "Epoch 848/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.1183 - acc: 0.9750 - val_loss: 0.7186 - val_acc: 0.8293\n",
            "\n",
            "Epoch 00848: val_acc did not improve from 0.97561\n",
            "Epoch 849/2000\n",
            "5/5 [==============================] - 1s 246ms/step - loss: 0.0880 - acc: 0.9750 - val_loss: 0.5280 - val_acc: 0.8537\n",
            "\n",
            "Epoch 00849: val_acc did not improve from 0.97561\n",
            "Epoch 850/2000\n",
            "5/5 [==============================] - 1s 246ms/step - loss: 0.0827 - acc: 0.9750 - val_loss: 0.4524 - val_acc: 0.8049\n",
            "\n",
            "Epoch 00850: val_acc did not improve from 0.97561\n",
            "Epoch 851/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.4125 - acc: 0.8750 - val_loss: 0.7888 - val_acc: 0.7805\n",
            "\n",
            "Epoch 00851: val_acc did not improve from 0.97561\n",
            "Epoch 852/2000\n",
            "5/5 [==============================] - 1s 278ms/step - loss: 0.0728 - acc: 0.9750 - val_loss: 1.3937 - val_acc: 0.5854\n",
            "\n",
            "Epoch 00852: val_acc did not improve from 0.97561\n",
            "Epoch 853/2000\n",
            "5/5 [==============================] - 1s 276ms/step - loss: 0.2148 - acc: 0.8750 - val_loss: 1.7420 - val_acc: 0.6098\n",
            "\n",
            "Epoch 00853: val_acc did not improve from 0.97561\n",
            "Epoch 854/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.0837 - acc: 0.9750 - val_loss: 2.0481 - val_acc: 0.6341\n",
            "\n",
            "Epoch 00854: val_acc did not improve from 0.97561\n",
            "Epoch 855/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.1262 - acc: 0.9750 - val_loss: 2.2977 - val_acc: 0.5610\n",
            "\n",
            "Epoch 00855: val_acc did not improve from 0.97561\n",
            "Epoch 856/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.1065 - acc: 0.9750 - val_loss: 1.0588 - val_acc: 0.7073\n",
            "\n",
            "Epoch 00856: val_acc did not improve from 0.97561\n",
            "Epoch 857/2000\n",
            "5/5 [==============================] - 1s 258ms/step - loss: 0.2330 - acc: 0.9000 - val_loss: 1.1150 - val_acc: 0.7805\n",
            "\n",
            "Epoch 00857: val_acc did not improve from 0.97561\n",
            "Epoch 858/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.1486 - acc: 0.9500 - val_loss: 0.8981 - val_acc: 0.7805\n",
            "\n",
            "Epoch 00858: val_acc did not improve from 0.97561\n",
            "Epoch 859/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.1398 - acc: 0.9500 - val_loss: 0.9555 - val_acc: 0.7805\n",
            "\n",
            "Epoch 00859: val_acc did not improve from 0.97561\n",
            "Epoch 860/2000\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 0.0469 - acc: 1.0000 - val_loss: 1.5377 - val_acc: 0.7805\n",
            "\n",
            "Epoch 00860: val_acc did not improve from 0.97561\n",
            "Epoch 861/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.2865 - acc: 0.9000 - val_loss: 2.6245 - val_acc: 0.6341\n",
            "\n",
            "Epoch 00861: val_acc did not improve from 0.97561\n",
            "Epoch 862/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.1531 - acc: 0.9250 - val_loss: 7.8389 - val_acc: 0.2439\n",
            "\n",
            "Epoch 00862: val_acc did not improve from 0.97561\n",
            "Epoch 863/2000\n",
            "5/5 [==============================] - 1s 273ms/step - loss: 0.4614 - acc: 0.8250 - val_loss: 9.7307 - val_acc: 0.2195\n",
            "\n",
            "Epoch 00863: val_acc did not improve from 0.97561\n",
            "Epoch 864/2000\n",
            "5/5 [==============================] - 1s 292ms/step - loss: 0.1575 - acc: 0.9500 - val_loss: 10.0357 - val_acc: 0.2195\n",
            "\n",
            "Epoch 00864: val_acc did not improve from 0.97561\n",
            "Epoch 865/2000\n",
            "5/5 [==============================] - 1s 289ms/step - loss: 0.0391 - acc: 1.0000 - val_loss: 9.2783 - val_acc: 0.2195\n",
            "\n",
            "Epoch 00865: val_acc did not improve from 0.97561\n",
            "Epoch 866/2000\n",
            "5/5 [==============================] - 1s 288ms/step - loss: 0.1481 - acc: 0.9500 - val_loss: 8.9358 - val_acc: 0.2195\n",
            "\n",
            "Epoch 00866: val_acc did not improve from 0.97561\n",
            "Epoch 867/2000\n",
            "5/5 [==============================] - 1s 288ms/step - loss: 0.1721 - acc: 0.9000 - val_loss: 8.0253 - val_acc: 0.2195\n",
            "\n",
            "Epoch 00867: val_acc did not improve from 0.97561\n",
            "Epoch 868/2000\n",
            "5/5 [==============================] - 1s 291ms/step - loss: 0.4336 - acc: 0.8500 - val_loss: 8.3164 - val_acc: 0.2195\n",
            "\n",
            "Epoch 00868: val_acc did not improve from 0.97561\n",
            "Epoch 869/2000\n",
            "5/5 [==============================] - 1s 295ms/step - loss: 0.3345 - acc: 0.8750 - val_loss: 8.7660 - val_acc: 0.2195\n",
            "\n",
            "Epoch 00869: val_acc did not improve from 0.97561\n",
            "Epoch 870/2000\n",
            "5/5 [==============================] - 1s 271ms/step - loss: 0.5555 - acc: 0.8250 - val_loss: 7.5920 - val_acc: 0.2439\n",
            "\n",
            "Epoch 00870: val_acc did not improve from 0.97561\n",
            "Epoch 871/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.1577 - acc: 0.9750 - val_loss: 7.4008 - val_acc: 0.2439\n",
            "\n",
            "Epoch 00871: val_acc did not improve from 0.97561\n",
            "Epoch 872/2000\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 0.4141 - acc: 0.8250 - val_loss: 7.5575 - val_acc: 0.2439\n",
            "\n",
            "Epoch 00872: val_acc did not improve from 0.97561\n",
            "Epoch 873/2000\n",
            "5/5 [==============================] - 1s 275ms/step - loss: 0.0695 - acc: 0.9750 - val_loss: 7.8701 - val_acc: 0.2195\n",
            "\n",
            "Epoch 00873: val_acc did not improve from 0.97561\n",
            "Epoch 874/2000\n",
            "5/5 [==============================] - 1s 276ms/step - loss: 0.2529 - acc: 0.9000 - val_loss: 7.5130 - val_acc: 0.2439\n",
            "\n",
            "Epoch 00874: val_acc did not improve from 0.97561\n",
            "Epoch 875/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.1638 - acc: 0.9500 - val_loss: 7.5903 - val_acc: 0.2439\n",
            "\n",
            "Epoch 00875: val_acc did not improve from 0.97561\n",
            "Epoch 876/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.1440 - acc: 0.9750 - val_loss: 7.4292 - val_acc: 0.2439\n",
            "\n",
            "Epoch 00876: val_acc did not improve from 0.97561\n",
            "Epoch 877/2000\n",
            "5/5 [==============================] - 1s 271ms/step - loss: 0.0420 - acc: 1.0000 - val_loss: 7.1127 - val_acc: 0.2439\n",
            "\n",
            "Epoch 00877: val_acc did not improve from 0.97561\n",
            "Epoch 878/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.0636 - acc: 0.9750 - val_loss: 6.8317 - val_acc: 0.2439\n",
            "\n",
            "Epoch 00878: val_acc did not improve from 0.97561\n",
            "Epoch 879/2000\n",
            "5/5 [==============================] - 1s 270ms/step - loss: 0.0823 - acc: 0.9750 - val_loss: 6.3161 - val_acc: 0.2439\n",
            "\n",
            "Epoch 00879: val_acc did not improve from 0.97561\n",
            "Epoch 880/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.1814 - acc: 0.9750 - val_loss: 5.6638 - val_acc: 0.2439\n",
            "\n",
            "Epoch 00880: val_acc did not improve from 0.97561\n",
            "Epoch 881/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.1345 - acc: 0.9000 - val_loss: 5.1959 - val_acc: 0.2439\n",
            "\n",
            "Epoch 00881: val_acc did not improve from 0.97561\n",
            "Epoch 882/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.2216 - acc: 0.9000 - val_loss: 5.3382 - val_acc: 0.2439\n",
            "\n",
            "Epoch 00882: val_acc did not improve from 0.97561\n",
            "Epoch 883/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.1846 - acc: 0.9250 - val_loss: 5.0073 - val_acc: 0.2439\n",
            "\n",
            "Epoch 00883: val_acc did not improve from 0.97561\n",
            "Epoch 884/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.0823 - acc: 0.9750 - val_loss: 4.3447 - val_acc: 0.2927\n",
            "\n",
            "Epoch 00884: val_acc did not improve from 0.97561\n",
            "Epoch 885/2000\n",
            "5/5 [==============================] - 1s 256ms/step - loss: 0.2120 - acc: 0.9250 - val_loss: 3.7742 - val_acc: 0.3171\n",
            "\n",
            "Epoch 00885: val_acc did not improve from 0.97561\n",
            "Epoch 886/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.0624 - acc: 1.0000 - val_loss: 3.1510 - val_acc: 0.4390\n",
            "\n",
            "Epoch 00886: val_acc did not improve from 0.97561\n",
            "Epoch 887/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.1486 - acc: 0.9500 - val_loss: 2.6948 - val_acc: 0.5854\n",
            "\n",
            "Epoch 00887: val_acc did not improve from 0.97561\n",
            "Epoch 888/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.0953 - acc: 0.9500 - val_loss: 2.5635 - val_acc: 0.6098\n",
            "\n",
            "Epoch 00888: val_acc did not improve from 0.97561\n",
            "Epoch 889/2000\n",
            "5/5 [==============================] - 1s 258ms/step - loss: 0.3462 - acc: 0.8750 - val_loss: 2.5261 - val_acc: 0.4878\n",
            "\n",
            "Epoch 00889: val_acc did not improve from 0.97561\n",
            "Epoch 890/2000\n",
            "5/5 [==============================] - 1s 256ms/step - loss: 0.1719 - acc: 0.9750 - val_loss: 2.6215 - val_acc: 0.5366\n",
            "\n",
            "Epoch 00890: val_acc did not improve from 0.97561\n",
            "Epoch 891/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.0532 - acc: 1.0000 - val_loss: 2.4007 - val_acc: 0.5854\n",
            "\n",
            "Epoch 00891: val_acc did not improve from 0.97561\n",
            "Epoch 892/2000\n",
            "5/5 [==============================] - 1s 272ms/step - loss: 0.0953 - acc: 0.9500 - val_loss: 2.4164 - val_acc: 0.5854\n",
            "\n",
            "Epoch 00892: val_acc did not improve from 0.97561\n",
            "Epoch 893/2000\n",
            "5/5 [==============================] - 1s 252ms/step - loss: 0.1288 - acc: 0.9250 - val_loss: 2.2295 - val_acc: 0.5610\n",
            "\n",
            "Epoch 00893: val_acc did not improve from 0.97561\n",
            "Epoch 894/2000\n",
            "5/5 [==============================] - 1s 246ms/step - loss: 0.0949 - acc: 0.9750 - val_loss: 2.1122 - val_acc: 0.5122\n",
            "\n",
            "Epoch 00894: val_acc did not improve from 0.97561\n",
            "Epoch 895/2000\n",
            "5/5 [==============================] - 1s 253ms/step - loss: 0.0712 - acc: 0.9750 - val_loss: 2.0583 - val_acc: 0.5122\n",
            "\n",
            "Epoch 00895: val_acc did not improve from 0.97561\n",
            "Epoch 896/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.1362 - acc: 0.9500 - val_loss: 2.1574 - val_acc: 0.5366\n",
            "\n",
            "Epoch 00896: val_acc did not improve from 0.97561\n",
            "Epoch 897/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.4706 - acc: 0.8000 - val_loss: 2.4344 - val_acc: 0.5122\n",
            "\n",
            "Epoch 00897: val_acc did not improve from 0.97561\n",
            "Epoch 898/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.1607 - acc: 0.9500 - val_loss: 2.6030 - val_acc: 0.5122\n",
            "\n",
            "Epoch 00898: val_acc did not improve from 0.97561\n",
            "Epoch 899/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.0612 - acc: 0.9750 - val_loss: 1.3676 - val_acc: 0.6829\n",
            "\n",
            "Epoch 00899: val_acc did not improve from 0.97561\n",
            "Epoch 900/2000\n",
            "5/5 [==============================] - 1s 251ms/step - loss: 0.0840 - acc: 0.9750 - val_loss: 0.2501 - val_acc: 0.8780\n",
            "\n",
            "Epoch 00900: val_acc did not improve from 0.97561\n",
            "Epoch 901/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.1149 - acc: 0.9750 - val_loss: 0.3425 - val_acc: 0.9024\n",
            "\n",
            "Epoch 00901: val_acc did not improve from 0.97561\n",
            "Epoch 902/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.1655 - acc: 0.9250 - val_loss: 0.3106 - val_acc: 0.8537\n",
            "\n",
            "Epoch 00902: val_acc did not improve from 0.97561\n",
            "Epoch 903/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.5402 - acc: 0.8500 - val_loss: 0.1922 - val_acc: 0.9512\n",
            "\n",
            "Epoch 00903: val_acc did not improve from 0.97561\n",
            "Epoch 904/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.0847 - acc: 0.9750 - val_loss: 0.8520 - val_acc: 0.7317\n",
            "\n",
            "Epoch 00904: val_acc did not improve from 0.97561\n",
            "Epoch 905/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.1278 - acc: 0.9250 - val_loss: 1.6266 - val_acc: 0.5610\n",
            "\n",
            "Epoch 00905: val_acc did not improve from 0.97561\n",
            "Epoch 906/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.2456 - acc: 0.8750 - val_loss: 1.3967 - val_acc: 0.5610\n",
            "\n",
            "Epoch 00906: val_acc did not improve from 0.97561\n",
            "Epoch 907/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.2261 - acc: 0.9500 - val_loss: 0.5047 - val_acc: 0.8537\n",
            "\n",
            "Epoch 00907: val_acc did not improve from 0.97561\n",
            "Epoch 908/2000\n",
            "5/5 [==============================] - 1s 258ms/step - loss: 0.1495 - acc: 0.9500 - val_loss: 0.5503 - val_acc: 0.8293\n",
            "\n",
            "Epoch 00908: val_acc did not improve from 0.97561\n",
            "Epoch 909/2000\n",
            "5/5 [==============================] - 1s 255ms/step - loss: 0.2856 - acc: 0.8750 - val_loss: 0.5937 - val_acc: 0.7561\n",
            "\n",
            "Epoch 00909: val_acc did not improve from 0.97561\n",
            "Epoch 910/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.1061 - acc: 0.9750 - val_loss: 0.5303 - val_acc: 0.7317\n",
            "\n",
            "Epoch 00910: val_acc did not improve from 0.97561\n",
            "Epoch 911/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.1128 - acc: 0.9750 - val_loss: 0.3247 - val_acc: 0.8780\n",
            "\n",
            "Epoch 00911: val_acc did not improve from 0.97561\n",
            "Epoch 912/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.0689 - acc: 1.0000 - val_loss: 0.3028 - val_acc: 0.8780\n",
            "\n",
            "Epoch 00912: val_acc did not improve from 0.97561\n",
            "Epoch 913/2000\n",
            "5/5 [==============================] - 1s 279ms/step - loss: 0.0917 - acc: 0.9750 - val_loss: 0.2751 - val_acc: 0.9268\n",
            "\n",
            "Epoch 00913: val_acc did not improve from 0.97561\n",
            "Epoch 914/2000\n",
            "5/5 [==============================] - 1s 276ms/step - loss: 0.0692 - acc: 0.9750 - val_loss: 0.3178 - val_acc: 0.8780\n",
            "\n",
            "Epoch 00914: val_acc did not improve from 0.97561\n",
            "Epoch 915/2000\n",
            "5/5 [==============================] - 1s 270ms/step - loss: 0.0971 - acc: 0.9750 - val_loss: 0.3577 - val_acc: 0.8780\n",
            "\n",
            "Epoch 00915: val_acc did not improve from 0.97561\n",
            "Epoch 916/2000\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 0.0438 - acc: 1.0000 - val_loss: 0.3690 - val_acc: 0.8780\n",
            "\n",
            "Epoch 00916: val_acc did not improve from 0.97561\n",
            "Epoch 917/2000\n",
            "5/5 [==============================] - 1s 272ms/step - loss: 0.1494 - acc: 0.9000 - val_loss: 0.5581 - val_acc: 0.8537\n",
            "\n",
            "Epoch 00917: val_acc did not improve from 0.97561\n",
            "Epoch 918/2000\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 0.2201 - acc: 0.9500 - val_loss: 0.5887 - val_acc: 0.8537\n",
            "\n",
            "Epoch 00918: val_acc did not improve from 0.97561\n",
            "Epoch 919/2000\n",
            "5/5 [==============================] - 1s 271ms/step - loss: 0.0278 - acc: 1.0000 - val_loss: 0.3693 - val_acc: 0.8780\n",
            "\n",
            "Epoch 00919: val_acc did not improve from 0.97561\n",
            "Epoch 920/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.2279 - acc: 0.9250 - val_loss: 0.8598 - val_acc: 0.6585\n",
            "\n",
            "Epoch 00920: val_acc did not improve from 0.97561\n",
            "Epoch 921/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.2984 - acc: 0.8750 - val_loss: 0.2319 - val_acc: 0.9756\n",
            "\n",
            "Epoch 00921: val_acc did not improve from 0.97561\n",
            "Epoch 922/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.1586 - acc: 0.9500 - val_loss: 0.3709 - val_acc: 0.8780\n",
            "\n",
            "Epoch 00922: val_acc did not improve from 0.97561\n",
            "Epoch 923/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.0470 - acc: 1.0000 - val_loss: 0.4974 - val_acc: 0.8537\n",
            "\n",
            "Epoch 00923: val_acc did not improve from 0.97561\n",
            "Epoch 924/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.1740 - acc: 0.9500 - val_loss: 0.4537 - val_acc: 0.8780\n",
            "\n",
            "Epoch 00924: val_acc did not improve from 0.97561\n",
            "Epoch 925/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.2079 - acc: 0.9250 - val_loss: 0.4071 - val_acc: 0.8049\n",
            "\n",
            "Epoch 00925: val_acc did not improve from 0.97561\n",
            "Epoch 926/2000\n",
            "5/5 [==============================] - 1s 271ms/step - loss: 0.1807 - acc: 0.8750 - val_loss: 0.7427 - val_acc: 0.7073\n",
            "\n",
            "Epoch 00926: val_acc did not improve from 0.97561\n",
            "Epoch 927/2000\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 0.1231 - acc: 0.9500 - val_loss: 0.8325 - val_acc: 0.6341\n",
            "\n",
            "Epoch 00927: val_acc did not improve from 0.97561\n",
            "Epoch 928/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.3552 - acc: 0.9000 - val_loss: 0.4241 - val_acc: 0.8780\n",
            "\n",
            "Epoch 00928: val_acc did not improve from 0.97561\n",
            "Epoch 929/2000\n",
            "5/5 [==============================] - 1s 271ms/step - loss: 0.0633 - acc: 1.0000 - val_loss: 0.6036 - val_acc: 0.8293\n",
            "\n",
            "Epoch 00929: val_acc did not improve from 0.97561\n",
            "Epoch 930/2000\n",
            "5/5 [==============================] - 1s 271ms/step - loss: 0.2104 - acc: 0.9500 - val_loss: 0.9475 - val_acc: 0.6829\n",
            "\n",
            "Epoch 00930: val_acc did not improve from 0.97561\n",
            "Epoch 931/2000\n",
            "5/5 [==============================] - 1s 272ms/step - loss: 0.2542 - acc: 0.8750 - val_loss: 1.4598 - val_acc: 0.6098\n",
            "\n",
            "Epoch 00931: val_acc did not improve from 0.97561\n",
            "Epoch 932/2000\n",
            "5/5 [==============================] - 1s 272ms/step - loss: 0.2134 - acc: 0.9000 - val_loss: 1.1359 - val_acc: 0.7561\n",
            "\n",
            "Epoch 00932: val_acc did not improve from 0.97561\n",
            "Epoch 933/2000\n",
            "5/5 [==============================] - 1s 276ms/step - loss: 0.0731 - acc: 0.9750 - val_loss: 0.4460 - val_acc: 0.8293\n",
            "\n",
            "Epoch 00933: val_acc did not improve from 0.97561\n",
            "Epoch 934/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.0284 - acc: 1.0000 - val_loss: 0.3347 - val_acc: 0.9024\n",
            "\n",
            "Epoch 00934: val_acc did not improve from 0.97561\n",
            "Epoch 935/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.0437 - acc: 1.0000 - val_loss: 0.1988 - val_acc: 0.9024\n",
            "\n",
            "Epoch 00935: val_acc did not improve from 0.97561\n",
            "Epoch 936/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.0748 - acc: 0.9750 - val_loss: 0.1929 - val_acc: 0.9512\n",
            "\n",
            "Epoch 00936: val_acc did not improve from 0.97561\n",
            "Epoch 937/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.0392 - acc: 1.0000 - val_loss: 0.3204 - val_acc: 0.9024\n",
            "\n",
            "Epoch 00937: val_acc did not improve from 0.97561\n",
            "Epoch 938/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.0685 - acc: 0.9750 - val_loss: 1.0059 - val_acc: 0.8049\n",
            "\n",
            "Epoch 00938: val_acc did not improve from 0.97561\n",
            "Epoch 939/2000\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 0.0598 - acc: 0.9750 - val_loss: 1.2218 - val_acc: 0.7805\n",
            "\n",
            "Epoch 00939: val_acc did not improve from 0.97561\n",
            "Epoch 940/2000\n",
            "5/5 [==============================] - 1s 274ms/step - loss: 0.1489 - acc: 0.9750 - val_loss: 0.6703 - val_acc: 0.8293\n",
            "\n",
            "Epoch 00940: val_acc did not improve from 0.97561\n",
            "Epoch 941/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.0760 - acc: 0.9750 - val_loss: 0.4777 - val_acc: 0.8537\n",
            "\n",
            "Epoch 00941: val_acc did not improve from 0.97561\n",
            "Epoch 942/2000\n",
            "5/5 [==============================] - 1s 249ms/step - loss: 0.2790 - acc: 0.9000 - val_loss: 0.6641 - val_acc: 0.7805\n",
            "\n",
            "Epoch 00942: val_acc did not improve from 0.97561\n",
            "Epoch 943/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.1581 - acc: 0.9500 - val_loss: 0.3763 - val_acc: 0.8537\n",
            "\n",
            "Epoch 00943: val_acc did not improve from 0.97561\n",
            "Epoch 944/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.2538 - acc: 0.8750 - val_loss: 1.7935 - val_acc: 0.7805\n",
            "\n",
            "Epoch 00944: val_acc did not improve from 0.97561\n",
            "Epoch 945/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.2737 - acc: 0.8750 - val_loss: 1.8757 - val_acc: 0.7317\n",
            "\n",
            "Epoch 00945: val_acc did not improve from 0.97561\n",
            "Epoch 946/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.1055 - acc: 0.9750 - val_loss: 2.0003 - val_acc: 0.6585\n",
            "\n",
            "Epoch 00946: val_acc did not improve from 0.97561\n",
            "Epoch 947/2000\n",
            "5/5 [==============================] - 1s 258ms/step - loss: 0.1935 - acc: 0.9500 - val_loss: 1.7973 - val_acc: 0.6585\n",
            "\n",
            "Epoch 00947: val_acc did not improve from 0.97561\n",
            "Epoch 948/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.1844 - acc: 0.9250 - val_loss: 1.2451 - val_acc: 0.7561\n",
            "\n",
            "Epoch 00948: val_acc did not improve from 0.97561\n",
            "Epoch 949/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.0899 - acc: 0.9750 - val_loss: 1.1662 - val_acc: 0.7805\n",
            "\n",
            "Epoch 00949: val_acc did not improve from 0.97561\n",
            "Epoch 950/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.0990 - acc: 0.9500 - val_loss: 1.1967 - val_acc: 0.7561\n",
            "\n",
            "Epoch 00950: val_acc did not improve from 0.97561\n",
            "Epoch 951/2000\n",
            "5/5 [==============================] - 1s 255ms/step - loss: 0.1884 - acc: 0.9750 - val_loss: 1.0061 - val_acc: 0.7561\n",
            "\n",
            "Epoch 00951: val_acc did not improve from 0.97561\n",
            "Epoch 952/2000\n",
            "5/5 [==============================] - 1s 253ms/step - loss: 0.0716 - acc: 1.0000 - val_loss: 0.9441 - val_acc: 0.7317\n",
            "\n",
            "Epoch 00952: val_acc did not improve from 0.97561\n",
            "Epoch 953/2000\n",
            "5/5 [==============================] - 1s 258ms/step - loss: 0.0711 - acc: 0.9750 - val_loss: 1.0427 - val_acc: 0.7073\n",
            "\n",
            "Epoch 00953: val_acc did not improve from 0.97561\n",
            "Epoch 954/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.2600 - acc: 0.8250 - val_loss: 0.9921 - val_acc: 0.7073\n",
            "\n",
            "Epoch 00954: val_acc did not improve from 0.97561\n",
            "Epoch 955/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.1335 - acc: 0.9250 - val_loss: 1.1863 - val_acc: 0.7073\n",
            "\n",
            "Epoch 00955: val_acc did not improve from 0.97561\n",
            "Epoch 956/2000\n",
            "5/5 [==============================] - 1s 272ms/step - loss: 0.1419 - acc: 0.9250 - val_loss: 3.3687 - val_acc: 0.5122\n",
            "\n",
            "Epoch 00956: val_acc did not improve from 0.97561\n",
            "Epoch 957/2000\n",
            "5/5 [==============================] - 1s 273ms/step - loss: 0.2312 - acc: 0.8750 - val_loss: 3.5989 - val_acc: 0.4634\n",
            "\n",
            "Epoch 00957: val_acc did not improve from 0.97561\n",
            "Epoch 958/2000\n",
            "5/5 [==============================] - 1s 277ms/step - loss: 0.1085 - acc: 0.9500 - val_loss: 2.6557 - val_acc: 0.6585\n",
            "\n",
            "Epoch 00958: val_acc did not improve from 0.97561\n",
            "Epoch 959/2000\n",
            "5/5 [==============================] - 1s 271ms/step - loss: 0.3783 - acc: 0.9000 - val_loss: 0.3174 - val_acc: 0.8780\n",
            "\n",
            "Epoch 00959: val_acc did not improve from 0.97561\n",
            "Epoch 960/2000\n",
            "5/5 [==============================] - 1s 283ms/step - loss: 0.1133 - acc: 0.9500 - val_loss: 1.2276 - val_acc: 0.7805\n",
            "\n",
            "Epoch 00960: val_acc did not improve from 0.97561\n",
            "Epoch 961/2000\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 0.0130 - acc: 1.0000 - val_loss: 1.7042 - val_acc: 0.7561\n",
            "\n",
            "Epoch 00961: val_acc did not improve from 0.97561\n",
            "Epoch 962/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.0747 - acc: 0.9750 - val_loss: 2.2478 - val_acc: 0.6585\n",
            "\n",
            "Epoch 00962: val_acc did not improve from 0.97561\n",
            "Epoch 963/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.0235 - acc: 1.0000 - val_loss: 2.6585 - val_acc: 0.6585\n",
            "\n",
            "Epoch 00963: val_acc did not improve from 0.97561\n",
            "Epoch 964/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.3434 - acc: 0.9000 - val_loss: 1.9891 - val_acc: 0.7805\n",
            "\n",
            "Epoch 00964: val_acc did not improve from 0.97561\n",
            "Epoch 965/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.0338 - acc: 1.0000 - val_loss: 1.6132 - val_acc: 0.7561\n",
            "\n",
            "Epoch 00965: val_acc did not improve from 0.97561\n",
            "Epoch 966/2000\n",
            "5/5 [==============================] - 1s 271ms/step - loss: 0.0912 - acc: 0.9750 - val_loss: 1.6058 - val_acc: 0.7561\n",
            "\n",
            "Epoch 00966: val_acc did not improve from 0.97561\n",
            "Epoch 967/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.1591 - acc: 0.9250 - val_loss: 1.4854 - val_acc: 0.7805\n",
            "\n",
            "Epoch 00967: val_acc did not improve from 0.97561\n",
            "Epoch 968/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.0657 - acc: 0.9750 - val_loss: 1.5231 - val_acc: 0.7805\n",
            "\n",
            "Epoch 00968: val_acc did not improve from 0.97561\n",
            "Epoch 969/2000\n",
            "5/5 [==============================] - 1s 277ms/step - loss: 0.2032 - acc: 0.9500 - val_loss: 1.3790 - val_acc: 0.7805\n",
            "\n",
            "Epoch 00969: val_acc did not improve from 0.97561\n",
            "Epoch 970/2000\n",
            "5/5 [==============================] - 1s 276ms/step - loss: 0.0283 - acc: 1.0000 - val_loss: 1.4415 - val_acc: 0.7805\n",
            "\n",
            "Epoch 00970: val_acc did not improve from 0.97561\n",
            "Epoch 971/2000\n",
            "5/5 [==============================] - 1s 270ms/step - loss: 0.0656 - acc: 0.9500 - val_loss: 1.4908 - val_acc: 0.7317\n",
            "\n",
            "Epoch 00971: val_acc did not improve from 0.97561\n",
            "Epoch 972/2000\n",
            "5/5 [==============================] - 1s 272ms/step - loss: 0.3254 - acc: 0.9250 - val_loss: 1.7751 - val_acc: 0.6829\n",
            "\n",
            "Epoch 00972: val_acc did not improve from 0.97561\n",
            "Epoch 973/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.1628 - acc: 0.9500 - val_loss: 2.1481 - val_acc: 0.6098\n",
            "\n",
            "Epoch 00973: val_acc did not improve from 0.97561\n",
            "Epoch 974/2000\n",
            "5/5 [==============================] - 1s 258ms/step - loss: 0.1559 - acc: 0.9500 - val_loss: 2.1400 - val_acc: 0.6341\n",
            "\n",
            "Epoch 00974: val_acc did not improve from 0.97561\n",
            "Epoch 975/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.3291 - acc: 0.9000 - val_loss: 1.8172 - val_acc: 0.6341\n",
            "\n",
            "Epoch 00975: val_acc did not improve from 0.97561\n",
            "Epoch 976/2000\n",
            "5/5 [==============================] - 1s 276ms/step - loss: 0.2210 - acc: 0.9000 - val_loss: 1.4926 - val_acc: 0.5122\n",
            "\n",
            "Epoch 00976: val_acc did not improve from 0.97561\n",
            "Epoch 977/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.2176 - acc: 0.9000 - val_loss: 0.7784 - val_acc: 0.6829\n",
            "\n",
            "Epoch 00977: val_acc did not improve from 0.97561\n",
            "Epoch 978/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.0886 - acc: 1.0000 - val_loss: 0.3294 - val_acc: 0.8780\n",
            "\n",
            "Epoch 00978: val_acc did not improve from 0.97561\n",
            "Epoch 979/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.1675 - acc: 0.9500 - val_loss: 0.4957 - val_acc: 0.8293\n",
            "\n",
            "Epoch 00979: val_acc did not improve from 0.97561\n",
            "Epoch 980/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.1333 - acc: 0.9500 - val_loss: 0.6552 - val_acc: 0.8049\n",
            "\n",
            "Epoch 00980: val_acc did not improve from 0.97561\n",
            "Epoch 981/2000\n",
            "5/5 [==============================] - 1s 272ms/step - loss: 0.1031 - acc: 0.9750 - val_loss: 0.7528 - val_acc: 0.7561\n",
            "\n",
            "Epoch 00981: val_acc did not improve from 0.97561\n",
            "Epoch 982/2000\n",
            "5/5 [==============================] - 1s 270ms/step - loss: 0.1020 - acc: 0.9750 - val_loss: 0.8698 - val_acc: 0.7317\n",
            "\n",
            "Epoch 00982: val_acc did not improve from 0.97561\n",
            "Epoch 983/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.2123 - acc: 0.8750 - val_loss: 1.1903 - val_acc: 0.7805\n",
            "\n",
            "Epoch 00983: val_acc did not improve from 0.97561\n",
            "Epoch 984/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.0967 - acc: 0.9500 - val_loss: 1.9558 - val_acc: 0.7561\n",
            "\n",
            "Epoch 00984: val_acc did not improve from 0.97561\n",
            "Epoch 985/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.1972 - acc: 0.9750 - val_loss: 1.9677 - val_acc: 0.7073\n",
            "\n",
            "Epoch 00985: val_acc did not improve from 0.97561\n",
            "Epoch 986/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.0682 - acc: 0.9750 - val_loss: 1.9476 - val_acc: 0.7317\n",
            "\n",
            "Epoch 00986: val_acc did not improve from 0.97561\n",
            "Epoch 987/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.5841 - acc: 0.9000 - val_loss: 2.3834 - val_acc: 0.6341\n",
            "\n",
            "Epoch 00987: val_acc did not improve from 0.97561\n",
            "Epoch 988/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.1397 - acc: 0.9250 - val_loss: 2.7345 - val_acc: 0.5854\n",
            "\n",
            "Epoch 00988: val_acc did not improve from 0.97561\n",
            "Epoch 989/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.1961 - acc: 0.8750 - val_loss: 1.7438 - val_acc: 0.7073\n",
            "\n",
            "Epoch 00989: val_acc did not improve from 0.97561\n",
            "Epoch 990/2000\n",
            "5/5 [==============================] - 1s 253ms/step - loss: 0.2572 - acc: 0.9250 - val_loss: 1.6549 - val_acc: 0.7073\n",
            "\n",
            "Epoch 00990: val_acc did not improve from 0.97561\n",
            "Epoch 991/2000\n",
            "5/5 [==============================] - 1s 255ms/step - loss: 0.1082 - acc: 0.9750 - val_loss: 1.9250 - val_acc: 0.5854\n",
            "\n",
            "Epoch 00991: val_acc did not improve from 0.97561\n",
            "Epoch 992/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.1884 - acc: 0.8750 - val_loss: 1.5126 - val_acc: 0.7561\n",
            "\n",
            "Epoch 00992: val_acc did not improve from 0.97561\n",
            "Epoch 993/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.0631 - acc: 1.0000 - val_loss: 1.3836 - val_acc: 0.7805\n",
            "\n",
            "Epoch 00993: val_acc did not improve from 0.97561\n",
            "Epoch 994/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.1626 - acc: 0.9500 - val_loss: 1.5306 - val_acc: 0.7805\n",
            "\n",
            "Epoch 00994: val_acc did not improve from 0.97561\n",
            "Epoch 995/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.0482 - acc: 1.0000 - val_loss: 1.6855 - val_acc: 0.7805\n",
            "\n",
            "Epoch 00995: val_acc did not improve from 0.97561\n",
            "Epoch 996/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.0852 - acc: 0.9750 - val_loss: 1.6491 - val_acc: 0.7805\n",
            "\n",
            "Epoch 00996: val_acc did not improve from 0.97561\n",
            "Epoch 997/2000\n",
            "5/5 [==============================] - 1s 249ms/step - loss: 0.0694 - acc: 1.0000 - val_loss: 1.6533 - val_acc: 0.7805\n",
            "\n",
            "Epoch 00997: val_acc did not improve from 0.97561\n",
            "Epoch 998/2000\n",
            "5/5 [==============================] - 1s 245ms/step - loss: 0.1136 - acc: 0.9500 - val_loss: 1.6963 - val_acc: 0.7805\n",
            "\n",
            "Epoch 00998: val_acc did not improve from 0.97561\n",
            "Epoch 999/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.1309 - acc: 0.9500 - val_loss: 1.5653 - val_acc: 0.7561\n",
            "\n",
            "Epoch 00999: val_acc did not improve from 0.97561\n",
            "Epoch 1000/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.2661 - acc: 0.8500 - val_loss: 1.5604 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01000: val_acc did not improve from 0.97561\n",
            "Epoch 1001/2000\n",
            "5/5 [==============================] - 1s 256ms/step - loss: 0.0920 - acc: 0.9750 - val_loss: 1.6258 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01001: val_acc did not improve from 0.97561\n",
            "Epoch 1002/2000\n",
            "5/5 [==============================] - 1s 252ms/step - loss: 0.4051 - acc: 0.8500 - val_loss: 2.0324 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01002: val_acc did not improve from 0.97561\n",
            "Epoch 1003/2000\n",
            "5/5 [==============================] - 1s 254ms/step - loss: 0.0932 - acc: 0.9500 - val_loss: 2.0429 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01003: val_acc did not improve from 0.97561\n",
            "Epoch 1004/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.0540 - acc: 1.0000 - val_loss: 2.1669 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01004: val_acc did not improve from 0.97561\n",
            "Epoch 1005/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.2327 - acc: 0.9250 - val_loss: 2.5493 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01005: val_acc did not improve from 0.97561\n",
            "Epoch 1006/2000\n",
            "5/5 [==============================] - 1s 255ms/step - loss: 0.2392 - acc: 0.9250 - val_loss: 2.6179 - val_acc: 0.7317\n",
            "\n",
            "Epoch 01006: val_acc did not improve from 0.97561\n",
            "Epoch 1007/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.1636 - acc: 0.9250 - val_loss: 2.0041 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01007: val_acc did not improve from 0.97561\n",
            "Epoch 1008/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.2095 - acc: 0.9250 - val_loss: 0.9999 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01008: val_acc did not improve from 0.97561\n",
            "Epoch 1009/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.1619 - acc: 0.9500 - val_loss: 0.4348 - val_acc: 0.8780\n",
            "\n",
            "Epoch 01009: val_acc did not improve from 0.97561\n",
            "Epoch 1010/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.1219 - acc: 0.9500 - val_loss: 0.2448 - val_acc: 0.9268\n",
            "\n",
            "Epoch 01010: val_acc did not improve from 0.97561\n",
            "Epoch 1011/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.3693 - acc: 0.8750 - val_loss: 1.4574 - val_acc: 0.7073\n",
            "\n",
            "Epoch 01011: val_acc did not improve from 0.97561\n",
            "Epoch 1012/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.1964 - acc: 0.9500 - val_loss: 1.2318 - val_acc: 0.7073\n",
            "\n",
            "Epoch 01012: val_acc did not improve from 0.97561\n",
            "Epoch 1013/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.3997 - acc: 0.8750 - val_loss: 0.7944 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01013: val_acc did not improve from 0.97561\n",
            "Epoch 1014/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.1995 - acc: 0.9250 - val_loss: 0.7899 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01014: val_acc did not improve from 0.97561\n",
            "Epoch 1015/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.0470 - acc: 1.0000 - val_loss: 1.3858 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01015: val_acc did not improve from 0.97561\n",
            "Epoch 1016/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.1340 - acc: 0.9750 - val_loss: 1.7496 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01016: val_acc did not improve from 0.97561\n",
            "Epoch 1017/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.0748 - acc: 0.9500 - val_loss: 1.7012 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01017: val_acc did not improve from 0.97561\n",
            "Epoch 1018/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.1880 - acc: 0.9250 - val_loss: 1.7424 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01018: val_acc did not improve from 0.97561\n",
            "Epoch 1019/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.1491 - acc: 0.9500 - val_loss: 1.8328 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01019: val_acc did not improve from 0.97561\n",
            "Epoch 1020/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.2956 - acc: 0.9250 - val_loss: 1.8486 - val_acc: 0.7317\n",
            "\n",
            "Epoch 01020: val_acc did not improve from 0.97561\n",
            "Epoch 1021/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.1410 - acc: 0.9500 - val_loss: 1.6966 - val_acc: 0.6585\n",
            "\n",
            "Epoch 01021: val_acc did not improve from 0.97561\n",
            "Epoch 1022/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.2201 - acc: 0.9250 - val_loss: 2.3181 - val_acc: 0.5366\n",
            "\n",
            "Epoch 01022: val_acc did not improve from 0.97561\n",
            "Epoch 1023/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.1762 - acc: 0.9000 - val_loss: 2.9018 - val_acc: 0.5366\n",
            "\n",
            "Epoch 01023: val_acc did not improve from 0.97561\n",
            "Epoch 1024/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.1778 - acc: 0.9000 - val_loss: 2.6160 - val_acc: 0.5610\n",
            "\n",
            "Epoch 01024: val_acc did not improve from 0.97561\n",
            "Epoch 1025/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.1163 - acc: 0.9500 - val_loss: 2.1736 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01025: val_acc did not improve from 0.97561\n",
            "Epoch 1026/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.2254 - acc: 0.9000 - val_loss: 1.6534 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01026: val_acc did not improve from 0.97561\n",
            "Epoch 1027/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.0773 - acc: 1.0000 - val_loss: 1.4406 - val_acc: 0.6829\n",
            "\n",
            "Epoch 01027: val_acc did not improve from 0.97561\n",
            "Epoch 1028/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.0855 - acc: 0.9750 - val_loss: 1.2265 - val_acc: 0.6829\n",
            "\n",
            "Epoch 01028: val_acc did not improve from 0.97561\n",
            "Epoch 1029/2000\n",
            "5/5 [==============================] - 1s 253ms/step - loss: 0.1717 - acc: 0.9250 - val_loss: 0.7383 - val_acc: 0.7073\n",
            "\n",
            "Epoch 01029: val_acc did not improve from 0.97561\n",
            "Epoch 1030/2000\n",
            "5/5 [==============================] - 1s 256ms/step - loss: 0.0974 - acc: 0.9500 - val_loss: 0.5260 - val_acc: 0.8780\n",
            "\n",
            "Epoch 01030: val_acc did not improve from 0.97561\n",
            "Epoch 1031/2000\n",
            "5/5 [==============================] - 1s 258ms/step - loss: 0.0371 - acc: 1.0000 - val_loss: 0.4101 - val_acc: 0.9024\n",
            "\n",
            "Epoch 01031: val_acc did not improve from 0.97561\n",
            "Epoch 1032/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.1111 - acc: 0.9500 - val_loss: 0.3599 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01032: val_acc did not improve from 0.97561\n",
            "Epoch 1033/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.1140 - acc: 0.9750 - val_loss: 0.4923 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01033: val_acc did not improve from 0.97561\n",
            "Epoch 1034/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.0260 - acc: 1.0000 - val_loss: 0.8569 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01034: val_acc did not improve from 0.97561\n",
            "Epoch 1035/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.3336 - acc: 0.9000 - val_loss: 0.8381 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01035: val_acc did not improve from 0.97561\n",
            "Epoch 1036/2000\n",
            "5/5 [==============================] - 1s 281ms/step - loss: 0.0482 - acc: 1.0000 - val_loss: 0.2893 - val_acc: 0.8780\n",
            "\n",
            "Epoch 01036: val_acc did not improve from 0.97561\n",
            "Epoch 1037/2000\n",
            "5/5 [==============================] - 1s 285ms/step - loss: 0.2823 - acc: 0.9000 - val_loss: 1.3075 - val_acc: 0.6829\n",
            "\n",
            "Epoch 01037: val_acc did not improve from 0.97561\n",
            "Epoch 1038/2000\n",
            "5/5 [==============================] - 1s 290ms/step - loss: 0.1111 - acc: 0.9500 - val_loss: 3.4255 - val_acc: 0.4146\n",
            "\n",
            "Epoch 01038: val_acc did not improve from 0.97561\n",
            "Epoch 1039/2000\n",
            "5/5 [==============================] - 1s 288ms/step - loss: 0.1472 - acc: 0.9500 - val_loss: 3.9501 - val_acc: 0.3902\n",
            "\n",
            "Epoch 01039: val_acc did not improve from 0.97561\n",
            "Epoch 1040/2000\n",
            "5/5 [==============================] - 1s 277ms/step - loss: 0.0586 - acc: 0.9750 - val_loss: 3.9632 - val_acc: 0.3659\n",
            "\n",
            "Epoch 01040: val_acc did not improve from 0.97561\n",
            "Epoch 1041/2000\n",
            "5/5 [==============================] - 1s 270ms/step - loss: 0.1335 - acc: 0.9500 - val_loss: 3.9836 - val_acc: 0.3659\n",
            "\n",
            "Epoch 01041: val_acc did not improve from 0.97561\n",
            "Epoch 1042/2000\n",
            "5/5 [==============================] - 1s 273ms/step - loss: 0.1941 - acc: 0.9250 - val_loss: 4.5666 - val_acc: 0.3171\n",
            "\n",
            "Epoch 01042: val_acc did not improve from 0.97561\n",
            "Epoch 1043/2000\n",
            "5/5 [==============================] - 1s 274ms/step - loss: 0.0951 - acc: 0.9750 - val_loss: 4.4835 - val_acc: 0.3415\n",
            "\n",
            "Epoch 01043: val_acc did not improve from 0.97561\n",
            "Epoch 1044/2000\n",
            "5/5 [==============================] - 1s 271ms/step - loss: 0.0467 - acc: 1.0000 - val_loss: 2.3062 - val_acc: 0.5366\n",
            "\n",
            "Epoch 01044: val_acc did not improve from 0.97561\n",
            "Epoch 1045/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.3510 - acc: 0.8500 - val_loss: 0.4588 - val_acc: 0.9024\n",
            "\n",
            "Epoch 01045: val_acc did not improve from 0.97561\n",
            "Epoch 1046/2000\n",
            "5/5 [==============================] - 1s 255ms/step - loss: 0.0687 - acc: 0.9750 - val_loss: 0.8952 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01046: val_acc did not improve from 0.97561\n",
            "Epoch 1047/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.0900 - acc: 0.9750 - val_loss: 0.8262 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01047: val_acc did not improve from 0.97561\n",
            "Epoch 1048/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.1250 - acc: 0.9750 - val_loss: 1.2417 - val_acc: 0.5854\n",
            "\n",
            "Epoch 01048: val_acc did not improve from 0.97561\n",
            "Epoch 1049/2000\n",
            "5/5 [==============================] - 1s 250ms/step - loss: 0.0638 - acc: 0.9750 - val_loss: 1.5904 - val_acc: 0.5122\n",
            "\n",
            "Epoch 01049: val_acc did not improve from 0.97561\n",
            "Epoch 1050/2000\n",
            "5/5 [==============================] - 1s 255ms/step - loss: 0.0969 - acc: 0.9750 - val_loss: 1.3589 - val_acc: 0.6341\n",
            "\n",
            "Epoch 01050: val_acc did not improve from 0.97561\n",
            "Epoch 1051/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.0481 - acc: 1.0000 - val_loss: 0.9981 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01051: val_acc did not improve from 0.97561\n",
            "Epoch 1052/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.1145 - acc: 0.9500 - val_loss: 0.9138 - val_acc: 0.8049\n",
            "\n",
            "Epoch 01052: val_acc did not improve from 0.97561\n",
            "Epoch 1053/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.0374 - acc: 1.0000 - val_loss: 1.0004 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01053: val_acc did not improve from 0.97561\n",
            "Epoch 1054/2000\n",
            "5/5 [==============================] - 1s 275ms/step - loss: 0.0513 - acc: 1.0000 - val_loss: 0.9836 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01054: val_acc did not improve from 0.97561\n",
            "Epoch 1055/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.0362 - acc: 1.0000 - val_loss: 0.9939 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01055: val_acc did not improve from 0.97561\n",
            "Epoch 1056/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.1932 - acc: 0.9000 - val_loss: 0.6970 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01056: val_acc did not improve from 0.97561\n",
            "Epoch 1057/2000\n",
            "5/5 [==============================] - 1s 277ms/step - loss: 0.1649 - acc: 0.9500 - val_loss: 0.2904 - val_acc: 0.9024\n",
            "\n",
            "Epoch 01057: val_acc did not improve from 0.97561\n",
            "Epoch 1058/2000\n",
            "5/5 [==============================] - 1s 275ms/step - loss: 0.1636 - acc: 0.9500 - val_loss: 0.9250 - val_acc: 0.6585\n",
            "\n",
            "Epoch 01058: val_acc did not improve from 0.97561\n",
            "Epoch 1059/2000\n",
            "5/5 [==============================] - 1s 277ms/step - loss: 0.1627 - acc: 0.9250 - val_loss: 2.1556 - val_acc: 0.5122\n",
            "\n",
            "Epoch 01059: val_acc did not improve from 0.97561\n",
            "Epoch 1060/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.2801 - acc: 0.8750 - val_loss: 0.3375 - val_acc: 0.8780\n",
            "\n",
            "Epoch 01060: val_acc did not improve from 0.97561\n",
            "Epoch 1061/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.2477 - acc: 0.9500 - val_loss: 0.2814 - val_acc: 0.9024\n",
            "\n",
            "Epoch 01061: val_acc did not improve from 0.97561\n",
            "Epoch 1062/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.0907 - acc: 0.9500 - val_loss: 0.5784 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01062: val_acc did not improve from 0.97561\n",
            "Epoch 1063/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.2101 - acc: 0.9500 - val_loss: 0.8647 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01063: val_acc did not improve from 0.97561\n",
            "Epoch 1064/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.2243 - acc: 0.9500 - val_loss: 0.9165 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01064: val_acc did not improve from 0.97561\n",
            "Epoch 1065/2000\n",
            "5/5 [==============================] - 1s 249ms/step - loss: 0.0862 - acc: 0.9750 - val_loss: 0.8406 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01065: val_acc did not improve from 0.97561\n",
            "Epoch 1066/2000\n",
            "5/5 [==============================] - 1s 248ms/step - loss: 0.0923 - acc: 0.9750 - val_loss: 0.9857 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01066: val_acc did not improve from 0.97561\n",
            "Epoch 1067/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.2545 - acc: 0.9000 - val_loss: 0.9917 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01067: val_acc did not improve from 0.97561\n",
            "Epoch 1068/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.1014 - acc: 0.9750 - val_loss: 1.1448 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01068: val_acc did not improve from 0.97561\n",
            "Epoch 1069/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.1267 - acc: 0.9500 - val_loss: 1.3888 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01069: val_acc did not improve from 0.97561\n",
            "Epoch 1070/2000\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 0.1655 - acc: 0.9500 - val_loss: 1.8370 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01070: val_acc did not improve from 0.97561\n",
            "Epoch 1071/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.0683 - acc: 0.9750 - val_loss: 1.9827 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01071: val_acc did not improve from 0.97561\n",
            "Epoch 1072/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.0647 - acc: 0.9750 - val_loss: 2.0838 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01072: val_acc did not improve from 0.97561\n",
            "Epoch 1073/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.2495 - acc: 0.8750 - val_loss: 1.9057 - val_acc: 0.7317\n",
            "\n",
            "Epoch 01073: val_acc did not improve from 0.97561\n",
            "Epoch 1074/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.0520 - acc: 0.9750 - val_loss: 1.2531 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01074: val_acc did not improve from 0.97561\n",
            "Epoch 1075/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.0796 - acc: 0.9500 - val_loss: 1.0331 - val_acc: 0.7317\n",
            "\n",
            "Epoch 01075: val_acc did not improve from 0.97561\n",
            "Epoch 1076/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.0315 - acc: 1.0000 - val_loss: 1.0751 - val_acc: 0.6585\n",
            "\n",
            "Epoch 01076: val_acc did not improve from 0.97561\n",
            "Epoch 1077/2000\n",
            "5/5 [==============================] - 1s 256ms/step - loss: 0.0502 - acc: 0.9750 - val_loss: 1.2087 - val_acc: 0.6585\n",
            "\n",
            "Epoch 01077: val_acc did not improve from 0.97561\n",
            "Epoch 1078/2000\n",
            "5/5 [==============================] - 1s 256ms/step - loss: 0.1922 - acc: 0.9500 - val_loss: 0.6395 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01078: val_acc did not improve from 0.97561\n",
            "Epoch 1079/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.1802 - acc: 0.9000 - val_loss: 0.4208 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01079: val_acc did not improve from 0.97561\n",
            "Epoch 1080/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.2257 - acc: 0.9250 - val_loss: 1.7102 - val_acc: 0.6585\n",
            "\n",
            "Epoch 01080: val_acc did not improve from 0.97561\n",
            "Epoch 1081/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.0886 - acc: 0.9750 - val_loss: 2.4877 - val_acc: 0.5610\n",
            "\n",
            "Epoch 01081: val_acc did not improve from 0.97561\n",
            "Epoch 1082/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.0937 - acc: 0.9500 - val_loss: 2.7285 - val_acc: 0.5366\n",
            "\n",
            "Epoch 01082: val_acc did not improve from 0.97561\n",
            "Epoch 1083/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.3662 - acc: 0.8750 - val_loss: 3.2830 - val_acc: 0.3659\n",
            "\n",
            "Epoch 01083: val_acc did not improve from 0.97561\n",
            "Epoch 1084/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.1286 - acc: 0.9500 - val_loss: 2.8331 - val_acc: 0.4146\n",
            "\n",
            "Epoch 01084: val_acc did not improve from 0.97561\n",
            "Epoch 1085/2000\n",
            "5/5 [==============================] - 1s 253ms/step - loss: 0.0729 - acc: 0.9750 - val_loss: 0.4796 - val_acc: 0.8049\n",
            "\n",
            "Epoch 01085: val_acc did not improve from 0.97561\n",
            "Epoch 1086/2000\n",
            "5/5 [==============================] - 1s 253ms/step - loss: 0.0355 - acc: 1.0000 - val_loss: 0.2259 - val_acc: 0.9268\n",
            "\n",
            "Epoch 01086: val_acc did not improve from 0.97561\n",
            "Epoch 1087/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.1058 - acc: 0.9750 - val_loss: 0.2238 - val_acc: 0.9512\n",
            "\n",
            "Epoch 01087: val_acc did not improve from 0.97561\n",
            "Epoch 1088/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.0865 - acc: 0.9750 - val_loss: 0.1357 - val_acc: 0.9756\n",
            "\n",
            "Epoch 01088: val_acc did not improve from 0.97561\n",
            "Epoch 1089/2000\n",
            "5/5 [==============================] - 1s 274ms/step - loss: 0.0158 - acc: 1.0000 - val_loss: 0.1329 - val_acc: 0.9756\n",
            "\n",
            "Epoch 01089: val_acc did not improve from 0.97561\n",
            "Epoch 1090/2000\n",
            "5/5 [==============================] - 1s 270ms/step - loss: 0.2440 - acc: 0.9250 - val_loss: 1.3640 - val_acc: 0.6829\n",
            "\n",
            "Epoch 01090: val_acc did not improve from 0.97561\n",
            "Epoch 1091/2000\n",
            "5/5 [==============================] - 1s 274ms/step - loss: 0.0735 - acc: 0.9500 - val_loss: 3.2346 - val_acc: 0.5122\n",
            "\n",
            "Epoch 01091: val_acc did not improve from 0.97561\n",
            "Epoch 1092/2000\n",
            "5/5 [==============================] - 1s 271ms/step - loss: 0.0507 - acc: 1.0000 - val_loss: 3.9800 - val_acc: 0.3659\n",
            "\n",
            "Epoch 01092: val_acc did not improve from 0.97561\n",
            "Epoch 1093/2000\n",
            "5/5 [==============================] - 1s 272ms/step - loss: 0.1717 - acc: 0.9500 - val_loss: 5.5458 - val_acc: 0.2439\n",
            "\n",
            "Epoch 01093: val_acc did not improve from 0.97561\n",
            "Epoch 1094/2000\n",
            "5/5 [==============================] - 1s 272ms/step - loss: 0.1349 - acc: 0.9500 - val_loss: 5.6422 - val_acc: 0.2927\n",
            "\n",
            "Epoch 01094: val_acc did not improve from 0.97561\n",
            "Epoch 1095/2000\n",
            "5/5 [==============================] - 1s 277ms/step - loss: 0.1792 - acc: 0.9750 - val_loss: 4.8410 - val_acc: 0.4634\n",
            "\n",
            "Epoch 01095: val_acc did not improve from 0.97561\n",
            "Epoch 1096/2000\n",
            "5/5 [==============================] - 1s 277ms/step - loss: 0.2195 - acc: 0.9500 - val_loss: 2.3043 - val_acc: 0.5854\n",
            "\n",
            "Epoch 01096: val_acc did not improve from 0.97561\n",
            "Epoch 1097/2000\n",
            "5/5 [==============================] - 1s 275ms/step - loss: 0.2031 - acc: 0.9000 - val_loss: 0.3462 - val_acc: 0.8780\n",
            "\n",
            "Epoch 01097: val_acc did not improve from 0.97561\n",
            "Epoch 1098/2000\n",
            "5/5 [==============================] - 1s 291ms/step - loss: 0.3257 - acc: 0.9250 - val_loss: 0.4775 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01098: val_acc did not improve from 0.97561\n",
            "Epoch 1099/2000\n",
            "5/5 [==============================] - 1s 283ms/step - loss: 0.0821 - acc: 0.9750 - val_loss: 0.3339 - val_acc: 0.8780\n",
            "\n",
            "Epoch 01099: val_acc did not improve from 0.97561\n",
            "Epoch 1100/2000\n",
            "5/5 [==============================] - 1s 285ms/step - loss: 0.0594 - acc: 0.9750 - val_loss: 0.3089 - val_acc: 0.9024\n",
            "\n",
            "Epoch 01100: val_acc did not improve from 0.97561\n",
            "Epoch 1101/2000\n",
            "5/5 [==============================] - 1s 287ms/step - loss: 0.0895 - acc: 0.9750 - val_loss: 0.5515 - val_acc: 0.8049\n",
            "\n",
            "Epoch 01101: val_acc did not improve from 0.97561\n",
            "Epoch 1102/2000\n",
            "5/5 [==============================] - 1s 290ms/step - loss: 0.0634 - acc: 0.9500 - val_loss: 0.9420 - val_acc: 0.6829\n",
            "\n",
            "Epoch 01102: val_acc did not improve from 0.97561\n",
            "Epoch 1103/2000\n",
            "5/5 [==============================] - 1s 292ms/step - loss: 0.0471 - acc: 0.9750 - val_loss: 0.9080 - val_acc: 0.6829\n",
            "\n",
            "Epoch 01103: val_acc did not improve from 0.97561\n",
            "Epoch 1104/2000\n",
            "5/5 [==============================] - 1s 289ms/step - loss: 0.1062 - acc: 0.9750 - val_loss: 1.2268 - val_acc: 0.6829\n",
            "\n",
            "Epoch 01104: val_acc did not improve from 0.97561\n",
            "Epoch 1105/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.5991 - acc: 0.8250 - val_loss: 2.1935 - val_acc: 0.5854\n",
            "\n",
            "Epoch 01105: val_acc did not improve from 0.97561\n",
            "Epoch 1106/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.0370 - acc: 1.0000 - val_loss: 2.2122 - val_acc: 0.5854\n",
            "\n",
            "Epoch 01106: val_acc did not improve from 0.97561\n",
            "Epoch 1107/2000\n",
            "5/5 [==============================] - 1s 258ms/step - loss: 0.0413 - acc: 1.0000 - val_loss: 0.7250 - val_acc: 0.7317\n",
            "\n",
            "Epoch 01107: val_acc did not improve from 0.97561\n",
            "Epoch 1108/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.0413 - acc: 1.0000 - val_loss: 0.2879 - val_acc: 0.9024\n",
            "\n",
            "Epoch 01108: val_acc did not improve from 0.97561\n",
            "Epoch 1109/2000\n",
            "5/5 [==============================] - 1s 247ms/step - loss: 0.2691 - acc: 0.9250 - val_loss: 0.4751 - val_acc: 0.8780\n",
            "\n",
            "Epoch 01109: val_acc did not improve from 0.97561\n",
            "Epoch 1110/2000\n",
            "5/5 [==============================] - 1s 248ms/step - loss: 0.1755 - acc: 0.9000 - val_loss: 1.0348 - val_acc: 0.7317\n",
            "\n",
            "Epoch 01110: val_acc did not improve from 0.97561\n",
            "Epoch 1111/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.1425 - acc: 0.9750 - val_loss: 0.8530 - val_acc: 0.8049\n",
            "\n",
            "Epoch 01111: val_acc did not improve from 0.97561\n",
            "Epoch 1112/2000\n",
            "5/5 [==============================] - 1s 276ms/step - loss: 0.0672 - acc: 0.9750 - val_loss: 0.2099 - val_acc: 0.9268\n",
            "\n",
            "Epoch 01112: val_acc did not improve from 0.97561\n",
            "Epoch 1113/2000\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 0.0768 - acc: 0.9750 - val_loss: 0.6393 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01113: val_acc did not improve from 0.97561\n",
            "Epoch 1114/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.2050 - acc: 0.9250 - val_loss: 0.6376 - val_acc: 0.7317\n",
            "\n",
            "Epoch 01114: val_acc did not improve from 0.97561\n",
            "Epoch 1115/2000\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 0.0263 - acc: 1.0000 - val_loss: 0.2221 - val_acc: 0.9268\n",
            "\n",
            "Epoch 01115: val_acc did not improve from 0.97561\n",
            "Epoch 1116/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.0673 - acc: 0.9750 - val_loss: 0.1662 - val_acc: 0.9512\n",
            "\n",
            "Epoch 01116: val_acc did not improve from 0.97561\n",
            "Epoch 1117/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.0558 - acc: 0.9750 - val_loss: 0.2244 - val_acc: 0.9024\n",
            "\n",
            "Epoch 01117: val_acc did not improve from 0.97561\n",
            "Epoch 1118/2000\n",
            "5/5 [==============================] - 1s 272ms/step - loss: 0.0756 - acc: 0.9750 - val_loss: 0.1565 - val_acc: 0.9268\n",
            "\n",
            "Epoch 01118: val_acc did not improve from 0.97561\n",
            "Epoch 1119/2000\n",
            "5/5 [==============================] - 1s 272ms/step - loss: 0.1874 - acc: 0.9250 - val_loss: 0.7933 - val_acc: 0.6829\n",
            "\n",
            "Epoch 01119: val_acc did not improve from 0.97561\n",
            "Epoch 1120/2000\n",
            "5/5 [==============================] - 1s 275ms/step - loss: 0.0233 - acc: 1.0000 - val_loss: 1.4168 - val_acc: 0.6585\n",
            "\n",
            "Epoch 01120: val_acc did not improve from 0.97561\n",
            "Epoch 1121/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.1347 - acc: 0.9500 - val_loss: 1.8491 - val_acc: 0.5854\n",
            "\n",
            "Epoch 01121: val_acc did not improve from 0.97561\n",
            "Epoch 1122/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.2135 - acc: 0.9500 - val_loss: 0.9731 - val_acc: 0.6585\n",
            "\n",
            "Epoch 01122: val_acc did not improve from 0.97561\n",
            "Epoch 1123/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.1882 - acc: 0.9250 - val_loss: 1.0381 - val_acc: 0.6585\n",
            "\n",
            "Epoch 01123: val_acc did not improve from 0.97561\n",
            "Epoch 1124/2000\n",
            "5/5 [==============================] - 1s 272ms/step - loss: 0.3138 - acc: 0.9250 - val_loss: 1.0652 - val_acc: 0.6829\n",
            "\n",
            "Epoch 01124: val_acc did not improve from 0.97561\n",
            "Epoch 1125/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.0926 - acc: 0.9750 - val_loss: 0.8109 - val_acc: 0.7073\n",
            "\n",
            "Epoch 01125: val_acc did not improve from 0.97561\n",
            "Epoch 1126/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.0857 - acc: 0.9500 - val_loss: 0.3096 - val_acc: 0.8780\n",
            "\n",
            "Epoch 01126: val_acc did not improve from 0.97561\n",
            "Epoch 1127/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.2854 - acc: 0.9000 - val_loss: 0.9313 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01127: val_acc did not improve from 0.97561\n",
            "Epoch 1128/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.1345 - acc: 0.9000 - val_loss: 1.7238 - val_acc: 0.5610\n",
            "\n",
            "Epoch 01128: val_acc did not improve from 0.97561\n",
            "Epoch 1129/2000\n",
            "5/5 [==============================] - 1s 254ms/step - loss: 0.1114 - acc: 0.9750 - val_loss: 1.9696 - val_acc: 0.5366\n",
            "\n",
            "Epoch 01129: val_acc did not improve from 0.97561\n",
            "Epoch 1130/2000\n",
            "5/5 [==============================] - 1s 250ms/step - loss: 0.0833 - acc: 0.9750 - val_loss: 1.8772 - val_acc: 0.5366\n",
            "\n",
            "Epoch 01130: val_acc did not improve from 0.97561\n",
            "Epoch 1131/2000\n",
            "5/5 [==============================] - 1s 273ms/step - loss: 0.1440 - acc: 0.9250 - val_loss: 1.2216 - val_acc: 0.7317\n",
            "\n",
            "Epoch 01131: val_acc did not improve from 0.97561\n",
            "Epoch 1132/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.0701 - acc: 0.9750 - val_loss: 1.1695 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01132: val_acc did not improve from 0.97561\n",
            "Epoch 1133/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.1327 - acc: 0.9500 - val_loss: 1.5016 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01133: val_acc did not improve from 0.97561\n",
            "Epoch 1134/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.1235 - acc: 0.9250 - val_loss: 1.5513 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01134: val_acc did not improve from 0.97561\n",
            "Epoch 1135/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.1024 - acc: 0.9750 - val_loss: 1.5565 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01135: val_acc did not improve from 0.97561\n",
            "Epoch 1136/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.4017 - acc: 0.8750 - val_loss: 1.3580 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01136: val_acc did not improve from 0.97561\n",
            "Epoch 1137/2000\n",
            "5/5 [==============================] - 1s 247ms/step - loss: 0.0597 - acc: 0.9750 - val_loss: 1.1497 - val_acc: 0.6829\n",
            "\n",
            "Epoch 01137: val_acc did not improve from 0.97561\n",
            "Epoch 1138/2000\n",
            "5/5 [==============================] - 1s 246ms/step - loss: 0.0799 - acc: 0.9750 - val_loss: 1.1429 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01138: val_acc did not improve from 0.97561\n",
            "Epoch 1139/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.3096 - acc: 0.9000 - val_loss: 0.8046 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01139: val_acc did not improve from 0.97561\n",
            "Epoch 1140/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.2536 - acc: 0.9000 - val_loss: 0.2800 - val_acc: 0.9024\n",
            "\n",
            "Epoch 01140: val_acc did not improve from 0.97561\n",
            "Epoch 1141/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.1029 - acc: 0.9750 - val_loss: 0.1997 - val_acc: 0.9512\n",
            "\n",
            "Epoch 01141: val_acc did not improve from 0.97561\n",
            "Epoch 1142/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.2299 - acc: 0.9500 - val_loss: 0.2033 - val_acc: 0.9268\n",
            "\n",
            "Epoch 01142: val_acc did not improve from 0.97561\n",
            "Epoch 1143/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.1238 - acc: 0.9500 - val_loss: 3.9027 - val_acc: 0.3902\n",
            "\n",
            "Epoch 01143: val_acc did not improve from 0.97561\n",
            "Epoch 1144/2000\n",
            "5/5 [==============================] - 1s 272ms/step - loss: 0.2419 - acc: 0.9250 - val_loss: 5.1412 - val_acc: 0.2927\n",
            "\n",
            "Epoch 01144: val_acc did not improve from 0.97561\n",
            "Epoch 1145/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.0690 - acc: 0.9750 - val_loss: 5.1952 - val_acc: 0.2927\n",
            "\n",
            "Epoch 01145: val_acc did not improve from 0.97561\n",
            "Epoch 1146/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.0467 - acc: 1.0000 - val_loss: 4.4204 - val_acc: 0.3659\n",
            "\n",
            "Epoch 01146: val_acc did not improve from 0.97561\n",
            "Epoch 1147/2000\n",
            "5/5 [==============================] - 1s 270ms/step - loss: 0.0638 - acc: 0.9750 - val_loss: 3.0677 - val_acc: 0.5122\n",
            "\n",
            "Epoch 01147: val_acc did not improve from 0.97561\n",
            "Epoch 1148/2000\n",
            "5/5 [==============================] - 1s 279ms/step - loss: 0.0469 - acc: 1.0000 - val_loss: 1.1603 - val_acc: 0.7317\n",
            "\n",
            "Epoch 01148: val_acc did not improve from 0.97561\n",
            "Epoch 1149/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.0216 - acc: 1.0000 - val_loss: 0.2379 - val_acc: 0.9268\n",
            "\n",
            "Epoch 01149: val_acc did not improve from 0.97561\n",
            "Epoch 1150/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.5529 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01150: val_acc did not improve from 0.97561\n",
            "Epoch 1151/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.0731 - acc: 0.9750 - val_loss: 0.7734 - val_acc: 0.8049\n",
            "\n",
            "Epoch 01151: val_acc did not improve from 0.97561\n",
            "Epoch 1152/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.2478 - acc: 0.9250 - val_loss: 0.8088 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01152: val_acc did not improve from 0.97561\n",
            "Epoch 1153/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.0501 - acc: 1.0000 - val_loss: 0.4126 - val_acc: 0.8780\n",
            "\n",
            "Epoch 01153: val_acc did not improve from 0.97561\n",
            "Epoch 1154/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.1661 - acc: 0.9500 - val_loss: 0.4115 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01154: val_acc did not improve from 0.97561\n",
            "Epoch 1155/2000\n",
            "5/5 [==============================] - 1s 270ms/step - loss: 0.0276 - acc: 1.0000 - val_loss: 0.5120 - val_acc: 0.8049\n",
            "\n",
            "Epoch 01155: val_acc did not improve from 0.97561\n",
            "Epoch 1156/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.1146 - acc: 0.9500 - val_loss: 0.5236 - val_acc: 0.8049\n",
            "\n",
            "Epoch 01156: val_acc did not improve from 0.97561\n",
            "Epoch 1157/2000\n",
            "5/5 [==============================] - 1s 286ms/step - loss: 0.1829 - acc: 0.9000 - val_loss: 0.7303 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01157: val_acc did not improve from 0.97561\n",
            "Epoch 1158/2000\n",
            "5/5 [==============================] - 1s 280ms/step - loss: 0.0900 - acc: 0.9500 - val_loss: 0.5464 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01158: val_acc did not improve from 0.97561\n",
            "Epoch 1159/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.1634 - acc: 0.9250 - val_loss: 0.7256 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01159: val_acc did not improve from 0.97561\n",
            "Epoch 1160/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.1305 - acc: 0.9250 - val_loss: 0.9604 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01160: val_acc did not improve from 0.97561\n",
            "Epoch 1161/2000\n",
            "5/5 [==============================] - 1s 271ms/step - loss: 0.1963 - acc: 0.9500 - val_loss: 0.8073 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01161: val_acc did not improve from 0.97561\n",
            "Epoch 1162/2000\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 0.0490 - acc: 1.0000 - val_loss: 0.4586 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01162: val_acc did not improve from 0.97561\n",
            "Epoch 1163/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.1074 - acc: 0.9750 - val_loss: 0.6008 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01163: val_acc did not improve from 0.97561\n",
            "Epoch 1164/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.1509 - acc: 0.9250 - val_loss: 1.1222 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01164: val_acc did not improve from 0.97561\n",
            "Epoch 1165/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.0891 - acc: 0.9250 - val_loss: 0.9609 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01165: val_acc did not improve from 0.97561\n",
            "Epoch 1166/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.0334 - acc: 1.0000 - val_loss: 0.7721 - val_acc: 0.8049\n",
            "\n",
            "Epoch 01166: val_acc did not improve from 0.97561\n",
            "Epoch 1167/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.0594 - acc: 0.9750 - val_loss: 0.6574 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01167: val_acc did not improve from 0.97561\n",
            "Epoch 1168/2000\n",
            "5/5 [==============================] - 1s 258ms/step - loss: 0.1483 - acc: 0.9750 - val_loss: 0.7967 - val_acc: 0.8049\n",
            "\n",
            "Epoch 01168: val_acc did not improve from 0.97561\n",
            "Epoch 1169/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.0125 - acc: 1.0000 - val_loss: 0.9196 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01169: val_acc did not improve from 0.97561\n",
            "Epoch 1170/2000\n",
            "5/5 [==============================] - 1s 255ms/step - loss: 0.0329 - acc: 1.0000 - val_loss: 0.9637 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01170: val_acc did not improve from 0.97561\n",
            "Epoch 1171/2000\n",
            "5/5 [==============================] - 1s 258ms/step - loss: 0.0257 - acc: 1.0000 - val_loss: 0.9373 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01171: val_acc did not improve from 0.97561\n",
            "Epoch 1172/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.0808 - acc: 0.9750 - val_loss: 0.8322 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01172: val_acc did not improve from 0.97561\n",
            "Epoch 1173/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.0513 - acc: 0.9750 - val_loss: 0.8709 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01173: val_acc did not improve from 0.97561\n",
            "Epoch 1174/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.4660 - acc: 0.9000 - val_loss: 0.2813 - val_acc: 0.9024\n",
            "\n",
            "Epoch 01174: val_acc did not improve from 0.97561\n",
            "Epoch 1175/2000\n",
            "5/5 [==============================] - 1s 273ms/step - loss: 0.0995 - acc: 0.9500 - val_loss: 0.2324 - val_acc: 0.9268\n",
            "\n",
            "Epoch 01175: val_acc did not improve from 0.97561\n",
            "Epoch 1176/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.0902 - acc: 0.9500 - val_loss: 0.2610 - val_acc: 0.9268\n",
            "\n",
            "Epoch 01176: val_acc did not improve from 0.97561\n",
            "Epoch 1177/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.1055 - acc: 0.9750 - val_loss: 0.1592 - val_acc: 0.9512\n",
            "\n",
            "Epoch 01177: val_acc did not improve from 0.97561\n",
            "Epoch 1178/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.0957 - acc: 0.9500 - val_loss: 0.4027 - val_acc: 0.9024\n",
            "\n",
            "Epoch 01178: val_acc did not improve from 0.97561\n",
            "Epoch 1179/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.0725 - acc: 0.9750 - val_loss: 0.7943 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01179: val_acc did not improve from 0.97561\n",
            "Epoch 1180/2000\n",
            "5/5 [==============================] - 1s 272ms/step - loss: 0.0226 - acc: 1.0000 - val_loss: 0.9931 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01180: val_acc did not improve from 0.97561\n",
            "Epoch 1181/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.0861 - acc: 0.9750 - val_loss: 1.2671 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01181: val_acc did not improve from 0.97561\n",
            "Epoch 1182/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.1302 - acc: 0.9750 - val_loss: 1.6412 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01182: val_acc did not improve from 0.97561\n",
            "Epoch 1183/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.1919 - acc: 0.9500 - val_loss: 1.6546 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01183: val_acc did not improve from 0.97561\n",
            "Epoch 1184/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.0366 - acc: 1.0000 - val_loss: 1.7224 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01184: val_acc did not improve from 0.97561\n",
            "Epoch 1185/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.0959 - acc: 0.9750 - val_loss: 1.8197 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01185: val_acc did not improve from 0.97561\n",
            "Epoch 1186/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.3143 - acc: 0.8750 - val_loss: 0.8533 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01186: val_acc did not improve from 0.97561\n",
            "Epoch 1187/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.1224 - acc: 0.9750 - val_loss: 0.4413 - val_acc: 0.8049\n",
            "\n",
            "Epoch 01187: val_acc did not improve from 0.97561\n",
            "Epoch 1188/2000\n",
            "5/5 [==============================] - 1s 256ms/step - loss: 0.2003 - acc: 0.9250 - val_loss: 0.7330 - val_acc: 0.7073\n",
            "\n",
            "Epoch 01188: val_acc did not improve from 0.97561\n",
            "Epoch 1189/2000\n",
            "5/5 [==============================] - 1s 258ms/step - loss: 0.1187 - acc: 0.9250 - val_loss: 2.1290 - val_acc: 0.5610\n",
            "\n",
            "Epoch 01189: val_acc did not improve from 0.97561\n",
            "Epoch 1190/2000\n",
            "5/5 [==============================] - 1s 258ms/step - loss: 0.0658 - acc: 0.9750 - val_loss: 2.7565 - val_acc: 0.5122\n",
            "\n",
            "Epoch 01190: val_acc did not improve from 0.97561\n",
            "Epoch 1191/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.0623 - acc: 0.9750 - val_loss: 3.6290 - val_acc: 0.3902\n",
            "\n",
            "Epoch 01191: val_acc did not improve from 0.97561\n",
            "Epoch 1192/2000\n",
            "5/5 [==============================] - 1s 272ms/step - loss: 0.1318 - acc: 0.9750 - val_loss: 3.5050 - val_acc: 0.3902\n",
            "\n",
            "Epoch 01192: val_acc did not improve from 0.97561\n",
            "Epoch 1193/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.0568 - acc: 1.0000 - val_loss: 2.8606 - val_acc: 0.5366\n",
            "\n",
            "Epoch 01193: val_acc did not improve from 0.97561\n",
            "Epoch 1194/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.0668 - acc: 0.9750 - val_loss: 3.1535 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01194: val_acc did not improve from 0.97561\n",
            "Epoch 1195/2000\n",
            "5/5 [==============================] - 1s 271ms/step - loss: 0.0292 - acc: 1.0000 - val_loss: 3.4930 - val_acc: 0.4390\n",
            "\n",
            "Epoch 01195: val_acc did not improve from 0.97561\n",
            "Epoch 1196/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.1288 - acc: 0.9500 - val_loss: 3.8788 - val_acc: 0.3659\n",
            "\n",
            "Epoch 01196: val_acc did not improve from 0.97561\n",
            "Epoch 1197/2000\n",
            "5/5 [==============================] - 1s 271ms/step - loss: 0.0675 - acc: 0.9750 - val_loss: 3.8986 - val_acc: 0.3659\n",
            "\n",
            "Epoch 01197: val_acc did not improve from 0.97561\n",
            "Epoch 1198/2000\n",
            "5/5 [==============================] - 1s 272ms/step - loss: 0.0466 - acc: 0.9750 - val_loss: 0.9842 - val_acc: 0.7317\n",
            "\n",
            "Epoch 01198: val_acc did not improve from 0.97561\n",
            "Epoch 1199/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.0737 - acc: 0.9750 - val_loss: 0.2104 - val_acc: 0.9268\n",
            "\n",
            "Epoch 01199: val_acc did not improve from 0.97561\n",
            "Epoch 1200/2000\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 0.0426 - acc: 1.0000 - val_loss: 0.5417 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01200: val_acc did not improve from 0.97561\n",
            "Epoch 1201/2000\n",
            "5/5 [==============================] - 1s 272ms/step - loss: 0.0387 - acc: 0.9750 - val_loss: 0.3179 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01201: val_acc did not improve from 0.97561\n",
            "Epoch 1202/2000\n",
            "5/5 [==============================] - 1s 272ms/step - loss: 0.0759 - acc: 0.9750 - val_loss: 1.5190 - val_acc: 0.7317\n",
            "\n",
            "Epoch 01202: val_acc did not improve from 0.97561\n",
            "Epoch 1203/2000\n",
            "5/5 [==============================] - 1s 273ms/step - loss: 0.0435 - acc: 1.0000 - val_loss: 2.0433 - val_acc: 0.7073\n",
            "\n",
            "Epoch 01203: val_acc did not improve from 0.97561\n",
            "Epoch 1204/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.1465 - acc: 0.9250 - val_loss: 2.3081 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01204: val_acc did not improve from 0.97561\n",
            "Epoch 1205/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.0729 - acc: 0.9750 - val_loss: 2.4294 - val_acc: 0.6829\n",
            "\n",
            "Epoch 01205: val_acc did not improve from 0.97561\n",
            "Epoch 1206/2000\n",
            "5/5 [==============================] - 1s 274ms/step - loss: 0.0561 - acc: 0.9750 - val_loss: 2.5128 - val_acc: 0.6585\n",
            "\n",
            "Epoch 01206: val_acc did not improve from 0.97561\n",
            "Epoch 1207/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.0364 - acc: 1.0000 - val_loss: 2.2726 - val_acc: 0.6585\n",
            "\n",
            "Epoch 01207: val_acc did not improve from 0.97561\n",
            "Epoch 1208/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.1433 - acc: 0.9500 - val_loss: 1.9721 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01208: val_acc did not improve from 0.97561\n",
            "Epoch 1209/2000\n",
            "5/5 [==============================] - 1s 249ms/step - loss: 0.0779 - acc: 0.9750 - val_loss: 1.5119 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01209: val_acc did not improve from 0.97561\n",
            "Epoch 1210/2000\n",
            "5/5 [==============================] - 1s 244ms/step - loss: 0.2028 - acc: 0.9250 - val_loss: 1.0465 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01210: val_acc did not improve from 0.97561\n",
            "Epoch 1211/2000\n",
            "5/5 [==============================] - 1s 256ms/step - loss: 0.0797 - acc: 0.9750 - val_loss: 0.6840 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01211: val_acc did not improve from 0.97561\n",
            "Epoch 1212/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.0528 - acc: 0.9750 - val_loss: 0.5373 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01212: val_acc did not improve from 0.97561\n",
            "Epoch 1213/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.0833 - acc: 0.9500 - val_loss: 0.2288 - val_acc: 0.9268\n",
            "\n",
            "Epoch 01213: val_acc did not improve from 0.97561\n",
            "Epoch 1214/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.1852 - acc: 0.9250 - val_loss: 0.2445 - val_acc: 0.9024\n",
            "\n",
            "Epoch 01214: val_acc did not improve from 0.97561\n",
            "Epoch 1215/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.1865 - acc: 0.9250 - val_loss: 2.3719 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01215: val_acc did not improve from 0.97561\n",
            "Epoch 1216/2000\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 0.0568 - acc: 0.9750 - val_loss: 3.5939 - val_acc: 0.3171\n",
            "\n",
            "Epoch 01216: val_acc did not improve from 0.97561\n",
            "Epoch 1217/2000\n",
            "5/5 [==============================] - 1s 271ms/step - loss: 0.0767 - acc: 0.9750 - val_loss: 3.0793 - val_acc: 0.3415\n",
            "\n",
            "Epoch 01217: val_acc did not improve from 0.97561\n",
            "Epoch 1218/2000\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 0.0940 - acc: 0.9750 - val_loss: 0.9484 - val_acc: 0.6341\n",
            "\n",
            "Epoch 01218: val_acc did not improve from 0.97561\n",
            "Epoch 1219/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.0150 - acc: 1.0000 - val_loss: 0.7396 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01219: val_acc did not improve from 0.97561\n",
            "Epoch 1220/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.1549 - acc: 0.9500 - val_loss: 1.0750 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01220: val_acc did not improve from 0.97561\n",
            "Epoch 1221/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.0316 - acc: 1.0000 - val_loss: 1.0937 - val_acc: 0.8049\n",
            "\n",
            "Epoch 01221: val_acc did not improve from 0.97561\n",
            "Epoch 1222/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.0912 - acc: 0.9500 - val_loss: 0.9120 - val_acc: 0.8049\n",
            "\n",
            "Epoch 01222: val_acc did not improve from 0.97561\n",
            "Epoch 1223/2000\n",
            "5/5 [==============================] - 1s 256ms/step - loss: 0.0483 - acc: 0.9750 - val_loss: 0.8401 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01223: val_acc did not improve from 0.97561\n",
            "Epoch 1224/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.0895 - acc: 0.9750 - val_loss: 0.3817 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01224: val_acc did not improve from 0.97561\n",
            "Epoch 1225/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.0383 - acc: 1.0000 - val_loss: 0.2185 - val_acc: 0.9512\n",
            "\n",
            "Epoch 01225: val_acc did not improve from 0.97561\n",
            "Epoch 1226/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.0377 - acc: 1.0000 - val_loss: 0.2556 - val_acc: 0.9268\n",
            "\n",
            "Epoch 01226: val_acc did not improve from 0.97561\n",
            "Epoch 1227/2000\n",
            "5/5 [==============================] - 1s 255ms/step - loss: 0.0928 - acc: 0.9750 - val_loss: 1.4504 - val_acc: 0.6585\n",
            "\n",
            "Epoch 01227: val_acc did not improve from 0.97561\n",
            "Epoch 1228/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.0301 - acc: 1.0000 - val_loss: 4.0162 - val_acc: 0.3171\n",
            "\n",
            "Epoch 01228: val_acc did not improve from 0.97561\n",
            "Epoch 1229/2000\n",
            "5/5 [==============================] - 1s 250ms/step - loss: 0.1044 - acc: 0.9250 - val_loss: 3.9486 - val_acc: 0.3171\n",
            "\n",
            "Epoch 01229: val_acc did not improve from 0.97561\n",
            "Epoch 1230/2000\n",
            "5/5 [==============================] - 1s 253ms/step - loss: 0.0559 - acc: 0.9750 - val_loss: 3.7402 - val_acc: 0.4146\n",
            "\n",
            "Epoch 01230: val_acc did not improve from 0.97561\n",
            "Epoch 1231/2000\n",
            "5/5 [==============================] - 1s 258ms/step - loss: 0.0415 - acc: 1.0000 - val_loss: 1.9095 - val_acc: 0.5366\n",
            "\n",
            "Epoch 01231: val_acc did not improve from 0.97561\n",
            "Epoch 1232/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.0970 - acc: 0.9500 - val_loss: 2.6237 - val_acc: 0.5122\n",
            "\n",
            "Epoch 01232: val_acc did not improve from 0.97561\n",
            "Epoch 1233/2000\n",
            "5/5 [==============================] - 1s 248ms/step - loss: 0.0466 - acc: 1.0000 - val_loss: 3.3498 - val_acc: 0.3659\n",
            "\n",
            "Epoch 01233: val_acc did not improve from 0.97561\n",
            "Epoch 1234/2000\n",
            "5/5 [==============================] - 1s 244ms/step - loss: 0.0857 - acc: 0.9750 - val_loss: 2.3666 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01234: val_acc did not improve from 0.97561\n",
            "Epoch 1235/2000\n",
            "5/5 [==============================] - 1s 251ms/step - loss: 0.0314 - acc: 1.0000 - val_loss: 1.5153 - val_acc: 0.6098\n",
            "\n",
            "Epoch 01235: val_acc did not improve from 0.97561\n",
            "Epoch 1236/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.1202 - acc: 0.9750 - val_loss: 1.0813 - val_acc: 0.6341\n",
            "\n",
            "Epoch 01236: val_acc did not improve from 0.97561\n",
            "Epoch 1237/2000\n",
            "5/5 [==============================] - 1s 251ms/step - loss: 0.0163 - acc: 1.0000 - val_loss: 0.3991 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01237: val_acc did not improve from 0.97561\n",
            "Epoch 1238/2000\n",
            "5/5 [==============================] - 1s 249ms/step - loss: 0.2304 - acc: 0.9000 - val_loss: 0.5428 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01238: val_acc did not improve from 0.97561\n",
            "Epoch 1239/2000\n",
            "5/5 [==============================] - 1s 254ms/step - loss: 0.0958 - acc: 0.9250 - val_loss: 0.6529 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01239: val_acc did not improve from 0.97561\n",
            "Epoch 1240/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.0128 - acc: 1.0000 - val_loss: 0.3590 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01240: val_acc did not improve from 0.97561\n",
            "Epoch 1241/2000\n",
            "5/5 [==============================] - 1s 247ms/step - loss: 0.0315 - acc: 1.0000 - val_loss: 0.3783 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01241: val_acc did not improve from 0.97561\n",
            "Epoch 1242/2000\n",
            "5/5 [==============================] - 1s 246ms/step - loss: 0.2296 - acc: 0.8750 - val_loss: 0.1985 - val_acc: 0.9756\n",
            "\n",
            "Epoch 01242: val_acc did not improve from 0.97561\n",
            "Epoch 1243/2000\n",
            "5/5 [==============================] - 1s 254ms/step - loss: 0.0233 - acc: 1.0000 - val_loss: 0.1889 - val_acc: 0.9512\n",
            "\n",
            "Epoch 01243: val_acc did not improve from 0.97561\n",
            "Epoch 1244/2000\n",
            "5/5 [==============================] - 1s 251ms/step - loss: 0.0346 - acc: 1.0000 - val_loss: 0.1965 - val_acc: 0.9512\n",
            "\n",
            "Epoch 01244: val_acc did not improve from 0.97561\n",
            "Epoch 1245/2000\n",
            "5/5 [==============================] - 1s 250ms/step - loss: 0.2935 - acc: 0.8750 - val_loss: 4.4204 - val_acc: 0.3902\n",
            "\n",
            "Epoch 01245: val_acc did not improve from 0.97561\n",
            "Epoch 1246/2000\n",
            "5/5 [==============================] - 1s 246ms/step - loss: 0.0832 - acc: 0.9500 - val_loss: 6.2285 - val_acc: 0.3171\n",
            "\n",
            "Epoch 01246: val_acc did not improve from 0.97561\n",
            "Epoch 1247/2000\n",
            "5/5 [==============================] - 1s 252ms/step - loss: 0.1210 - acc: 0.9750 - val_loss: 6.2071 - val_acc: 0.3171\n",
            "\n",
            "Epoch 01247: val_acc did not improve from 0.97561\n",
            "Epoch 1248/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.0279 - acc: 1.0000 - val_loss: 2.8321 - val_acc: 0.5122\n",
            "\n",
            "Epoch 01248: val_acc did not improve from 0.97561\n",
            "Epoch 1249/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.0137 - acc: 1.0000 - val_loss: 0.5466 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01249: val_acc did not improve from 0.97561\n",
            "Epoch 1250/2000\n",
            "5/5 [==============================] - 1s 254ms/step - loss: 0.0467 - acc: 1.0000 - val_loss: 0.5076 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01250: val_acc did not improve from 0.97561\n",
            "Epoch 1251/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.1170 - acc: 0.9250 - val_loss: 1.3525 - val_acc: 0.5854\n",
            "\n",
            "Epoch 01251: val_acc did not improve from 0.97561\n",
            "Epoch 1252/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.0587 - acc: 0.9750 - val_loss: 2.9922 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01252: val_acc did not improve from 0.97561\n",
            "Epoch 1253/2000\n",
            "5/5 [==============================] - 1s 258ms/step - loss: 0.0449 - acc: 1.0000 - val_loss: 2.1493 - val_acc: 0.5122\n",
            "\n",
            "Epoch 01253: val_acc did not improve from 0.97561\n",
            "Epoch 1254/2000\n",
            "5/5 [==============================] - 1s 255ms/step - loss: 0.1905 - acc: 0.9250 - val_loss: 6.7869 - val_acc: 0.2927\n",
            "\n",
            "Epoch 01254: val_acc did not improve from 0.97561\n",
            "Epoch 1255/2000\n",
            "5/5 [==============================] - 1s 253ms/step - loss: 0.1813 - acc: 0.9250 - val_loss: 6.7023 - val_acc: 0.2439\n",
            "\n",
            "Epoch 01255: val_acc did not improve from 0.97561\n",
            "Epoch 1256/2000\n",
            "5/5 [==============================] - 1s 250ms/step - loss: 0.0657 - acc: 0.9750 - val_loss: 2.0117 - val_acc: 0.5122\n",
            "\n",
            "Epoch 01256: val_acc did not improve from 0.97561\n",
            "Epoch 1257/2000\n",
            "5/5 [==============================] - 1s 256ms/step - loss: 0.0709 - acc: 0.9750 - val_loss: 0.2342 - val_acc: 0.9268\n",
            "\n",
            "Epoch 01257: val_acc did not improve from 0.97561\n",
            "Epoch 1258/2000\n",
            "5/5 [==============================] - 1s 258ms/step - loss: 0.0233 - acc: 1.0000 - val_loss: 0.1789 - val_acc: 0.9268\n",
            "\n",
            "Epoch 01258: val_acc did not improve from 0.97561\n",
            "Epoch 1259/2000\n",
            "5/5 [==============================] - 1s 258ms/step - loss: 0.0256 - acc: 1.0000 - val_loss: 0.2306 - val_acc: 0.9268\n",
            "\n",
            "Epoch 01259: val_acc did not improve from 0.97561\n",
            "Epoch 1260/2000\n",
            "5/5 [==============================] - 1s 296ms/step - loss: 0.0580 - acc: 0.9750 - val_loss: 0.1451 - val_acc: 0.9512\n",
            "\n",
            "Epoch 01260: val_acc did not improve from 0.97561\n",
            "Epoch 1261/2000\n",
            "5/5 [==============================] - 2s 379ms/step - loss: 0.2634 - acc: 0.8750 - val_loss: 3.6005 - val_acc: 0.4634\n",
            "\n",
            "Epoch 01261: val_acc did not improve from 0.97561\n",
            "Epoch 1262/2000\n",
            "5/5 [==============================] - 2s 392ms/step - loss: 0.0373 - acc: 1.0000 - val_loss: 5.4450 - val_acc: 0.4634\n",
            "\n",
            "Epoch 01262: val_acc did not improve from 0.97561\n",
            "Epoch 1263/2000\n",
            "5/5 [==============================] - 2s 386ms/step - loss: 0.0656 - acc: 0.9750 - val_loss: 5.3552 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01263: val_acc did not improve from 0.97561\n",
            "Epoch 1264/2000\n",
            "5/5 [==============================] - 2s 389ms/step - loss: 0.1683 - acc: 0.9500 - val_loss: 3.7419 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01264: val_acc did not improve from 0.97561\n",
            "Epoch 1265/2000\n",
            "5/5 [==============================] - 2s 326ms/step - loss: 0.0284 - acc: 1.0000 - val_loss: 0.7363 - val_acc: 0.7317\n",
            "\n",
            "Epoch 01265: val_acc did not improve from 0.97561\n",
            "Epoch 1266/2000\n",
            "5/5 [==============================] - 1s 289ms/step - loss: 0.0436 - acc: 1.0000 - val_loss: 0.1556 - val_acc: 0.9512\n",
            "\n",
            "Epoch 01266: val_acc did not improve from 0.97561\n",
            "Epoch 1267/2000\n",
            "5/5 [==============================] - 1s 278ms/step - loss: 0.1208 - acc: 0.9750 - val_loss: 0.4120 - val_acc: 0.8780\n",
            "\n",
            "Epoch 01267: val_acc did not improve from 0.97561\n",
            "Epoch 1268/2000\n",
            "5/5 [==============================] - 1s 279ms/step - loss: 0.0507 - acc: 0.9750 - val_loss: 0.6764 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01268: val_acc did not improve from 0.97561\n",
            "Epoch 1269/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.0818 - acc: 0.9750 - val_loss: 0.2140 - val_acc: 0.9512\n",
            "\n",
            "Epoch 01269: val_acc did not improve from 0.97561\n",
            "Epoch 1270/2000\n",
            "5/5 [==============================] - 1s 255ms/step - loss: 0.0680 - acc: 0.9750 - val_loss: 6.2025 - val_acc: 0.2439\n",
            "\n",
            "Epoch 01270: val_acc did not improve from 0.97561\n",
            "Epoch 1271/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.2164 - acc: 0.9000 - val_loss: 3.5157 - val_acc: 0.5122\n",
            "\n",
            "Epoch 01271: val_acc did not improve from 0.97561\n",
            "Epoch 1272/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.1673 - acc: 0.9500 - val_loss: 1.9173 - val_acc: 0.5854\n",
            "\n",
            "Epoch 01272: val_acc did not improve from 0.97561\n",
            "Epoch 1273/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.0351 - acc: 0.9750 - val_loss: 3.6792 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01273: val_acc did not improve from 0.97561\n",
            "Epoch 1274/2000\n",
            "5/5 [==============================] - 1s 255ms/step - loss: 0.2517 - acc: 0.9500 - val_loss: 5.7227 - val_acc: 0.3171\n",
            "\n",
            "Epoch 01274: val_acc did not improve from 0.97561\n",
            "Epoch 1275/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.1395 - acc: 0.9500 - val_loss: 7.5055 - val_acc: 0.2683\n",
            "\n",
            "Epoch 01275: val_acc did not improve from 0.97561\n",
            "Epoch 1276/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.0756 - acc: 0.9750 - val_loss: 7.5294 - val_acc: 0.2683\n",
            "\n",
            "Epoch 01276: val_acc did not improve from 0.97561\n",
            "Epoch 1277/2000\n",
            "5/5 [==============================] - 1s 252ms/step - loss: 0.0962 - acc: 0.9750 - val_loss: 6.5115 - val_acc: 0.3171\n",
            "\n",
            "Epoch 01277: val_acc did not improve from 0.97561\n",
            "Epoch 1278/2000\n",
            "5/5 [==============================] - 1s 251ms/step - loss: 0.0309 - acc: 1.0000 - val_loss: 6.0310 - val_acc: 0.3171\n",
            "\n",
            "Epoch 01278: val_acc did not improve from 0.97561\n",
            "Epoch 1279/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.2998 - acc: 0.8500 - val_loss: 5.2823 - val_acc: 0.4146\n",
            "\n",
            "Epoch 01279: val_acc did not improve from 0.97561\n",
            "Epoch 1280/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.0806 - acc: 0.9750 - val_loss: 4.7466 - val_acc: 0.4146\n",
            "\n",
            "Epoch 01280: val_acc did not improve from 0.97561\n",
            "Epoch 1281/2000\n",
            "5/5 [==============================] - 1s 270ms/step - loss: 0.0356 - acc: 1.0000 - val_loss: 3.1999 - val_acc: 0.5366\n",
            "\n",
            "Epoch 01281: val_acc did not improve from 0.97561\n",
            "Epoch 1282/2000\n",
            "5/5 [==============================] - 1s 270ms/step - loss: 0.1901 - acc: 0.9250 - val_loss: 5.8456 - val_acc: 0.3171\n",
            "\n",
            "Epoch 01282: val_acc did not improve from 0.97561\n",
            "Epoch 1283/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.1635 - acc: 0.9250 - val_loss: 4.7486 - val_acc: 0.3415\n",
            "\n",
            "Epoch 01283: val_acc did not improve from 0.97561\n",
            "Epoch 1284/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.0606 - acc: 1.0000 - val_loss: 0.1575 - val_acc: 0.9512\n",
            "\n",
            "Epoch 01284: val_acc did not improve from 0.97561\n",
            "Epoch 1285/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.0416 - acc: 1.0000 - val_loss: 0.8160 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01285: val_acc did not improve from 0.97561\n",
            "Epoch 1286/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.0471 - acc: 0.9750 - val_loss: 0.8107 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01286: val_acc did not improve from 0.97561\n",
            "Epoch 1287/2000\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 0.0481 - acc: 1.0000 - val_loss: 0.9050 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01287: val_acc did not improve from 0.97561\n",
            "Epoch 1288/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.2641 - acc: 0.9000 - val_loss: 1.1479 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01288: val_acc did not improve from 0.97561\n",
            "Epoch 1289/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.0277 - acc: 1.0000 - val_loss: 1.1733 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01289: val_acc did not improve from 0.97561\n",
            "Epoch 1290/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.0441 - acc: 1.0000 - val_loss: 1.2482 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01290: val_acc did not improve from 0.97561\n",
            "Epoch 1291/2000\n",
            "5/5 [==============================] - 1s 275ms/step - loss: 0.0278 - acc: 1.0000 - val_loss: 1.3087 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01291: val_acc did not improve from 0.97561\n",
            "Epoch 1292/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.0816 - acc: 0.9750 - val_loss: 1.0869 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01292: val_acc did not improve from 0.97561\n",
            "Epoch 1293/2000\n",
            "5/5 [==============================] - 1s 242ms/step - loss: 0.1207 - acc: 0.9500 - val_loss: 0.7532 - val_acc: 0.8049\n",
            "\n",
            "Epoch 01293: val_acc did not improve from 0.97561\n",
            "Epoch 1294/2000\n",
            "5/5 [==============================] - 1s 247ms/step - loss: 0.0578 - acc: 0.9750 - val_loss: 0.7725 - val_acc: 0.8049\n",
            "\n",
            "Epoch 01294: val_acc did not improve from 0.97561\n",
            "Epoch 1295/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.2557 - acc: 0.9000 - val_loss: 0.7282 - val_acc: 0.8049\n",
            "\n",
            "Epoch 01295: val_acc did not improve from 0.97561\n",
            "Epoch 1296/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.6513 - acc: 0.8250 - val_loss: 0.1683 - val_acc: 0.9512\n",
            "\n",
            "Epoch 01296: val_acc did not improve from 0.97561\n",
            "Epoch 1297/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.1077 - acc: 0.9750 - val_loss: 0.1310 - val_acc: 0.9512\n",
            "\n",
            "Epoch 01297: val_acc did not improve from 0.97561\n",
            "Epoch 1298/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.1497 - acc: 0.9750 - val_loss: 1.4102 - val_acc: 0.6585\n",
            "\n",
            "Epoch 01298: val_acc did not improve from 0.97561\n",
            "Epoch 1299/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.0499 - acc: 0.9750 - val_loss: 0.3954 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01299: val_acc did not improve from 0.97561\n",
            "Epoch 1300/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.1491 - acc: 0.9250 - val_loss: 0.3215 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01300: val_acc did not improve from 0.97561\n",
            "Epoch 1301/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.0259 - acc: 1.0000 - val_loss: 0.3489 - val_acc: 0.8780\n",
            "\n",
            "Epoch 01301: val_acc did not improve from 0.97561\n",
            "Epoch 1302/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.0588 - acc: 0.9750 - val_loss: 0.6229 - val_acc: 0.6829\n",
            "\n",
            "Epoch 01302: val_acc did not improve from 0.97561\n",
            "Epoch 1303/2000\n",
            "5/5 [==============================] - 1s 256ms/step - loss: 0.1761 - acc: 0.9250 - val_loss: 0.6086 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01303: val_acc did not improve from 0.97561\n",
            "Epoch 1304/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.0330 - acc: 1.0000 - val_loss: 1.3426 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01304: val_acc did not improve from 0.97561\n",
            "Epoch 1305/2000\n",
            "5/5 [==============================] - 1s 245ms/step - loss: 0.0549 - acc: 0.9750 - val_loss: 1.1883 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01305: val_acc did not improve from 0.97561\n",
            "Epoch 1306/2000\n",
            "5/5 [==============================] - 1s 243ms/step - loss: 0.1668 - acc: 0.9250 - val_loss: 0.9055 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01306: val_acc did not improve from 0.97561\n",
            "Epoch 1307/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.0786 - acc: 0.9500 - val_loss: 0.2190 - val_acc: 0.9512\n",
            "\n",
            "Epoch 01307: val_acc did not improve from 0.97561\n",
            "Epoch 1308/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.0573 - acc: 0.9750 - val_loss: 5.5940 - val_acc: 0.2927\n",
            "\n",
            "Epoch 01308: val_acc did not improve from 0.97561\n",
            "Epoch 1309/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.0809 - acc: 1.0000 - val_loss: 6.9586 - val_acc: 0.2195\n",
            "\n",
            "Epoch 01309: val_acc did not improve from 0.97561\n",
            "Epoch 1310/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.1181 - acc: 0.9000 - val_loss: 2.0686 - val_acc: 0.5366\n",
            "\n",
            "Epoch 01310: val_acc did not improve from 0.97561\n",
            "Epoch 1311/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.1142 - acc: 0.9500 - val_loss: 0.1861 - val_acc: 0.9268\n",
            "\n",
            "Epoch 01311: val_acc did not improve from 0.97561\n",
            "Epoch 1312/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.0164 - acc: 1.0000 - val_loss: 0.3582 - val_acc: 0.9268\n",
            "\n",
            "Epoch 01312: val_acc did not improve from 0.97561\n",
            "Epoch 1313/2000\n",
            "5/5 [==============================] - 1s 256ms/step - loss: 0.0417 - acc: 0.9750 - val_loss: 0.5570 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01313: val_acc did not improve from 0.97561\n",
            "Epoch 1314/2000\n",
            "5/5 [==============================] - 1s 252ms/step - loss: 0.0359 - acc: 1.0000 - val_loss: 0.7039 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01314: val_acc did not improve from 0.97561\n",
            "Epoch 1315/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.1163 - acc: 0.9750 - val_loss: 0.4979 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01315: val_acc did not improve from 0.97561\n",
            "Epoch 1316/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.0343 - acc: 0.9750 - val_loss: 0.4112 - val_acc: 0.9024\n",
            "\n",
            "Epoch 01316: val_acc did not improve from 0.97561\n",
            "Epoch 1317/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.0343 - acc: 1.0000 - val_loss: 0.6014 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01317: val_acc did not improve from 0.97561\n",
            "Epoch 1318/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.1664 - acc: 0.9750 - val_loss: 0.3083 - val_acc: 0.9024\n",
            "\n",
            "Epoch 01318: val_acc did not improve from 0.97561\n",
            "Epoch 1319/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.0479 - acc: 1.0000 - val_loss: 0.5982 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01319: val_acc did not improve from 0.97561\n",
            "Epoch 1320/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.0381 - acc: 1.0000 - val_loss: 0.8260 - val_acc: 0.8049\n",
            "\n",
            "Epoch 01320: val_acc did not improve from 0.97561\n",
            "Epoch 1321/2000\n",
            "5/5 [==============================] - 1s 246ms/step - loss: 0.0803 - acc: 0.9750 - val_loss: 0.8960 - val_acc: 0.8049\n",
            "\n",
            "Epoch 01321: val_acc did not improve from 0.97561\n",
            "Epoch 1322/2000\n",
            "5/5 [==============================] - 1s 244ms/step - loss: 0.0858 - acc: 0.9750 - val_loss: 0.8322 - val_acc: 0.8049\n",
            "\n",
            "Epoch 01322: val_acc did not improve from 0.97561\n",
            "Epoch 1323/2000\n",
            "5/5 [==============================] - 1s 248ms/step - loss: 0.0535 - acc: 0.9750 - val_loss: 0.8215 - val_acc: 0.8049\n",
            "\n",
            "Epoch 01323: val_acc did not improve from 0.97561\n",
            "Epoch 1324/2000\n",
            "5/5 [==============================] - 1s 258ms/step - loss: 0.1138 - acc: 0.9500 - val_loss: 0.4558 - val_acc: 0.8780\n",
            "\n",
            "Epoch 01324: val_acc did not improve from 0.97561\n",
            "Epoch 1325/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.0119 - acc: 1.0000 - val_loss: 0.1964 - val_acc: 0.9512\n",
            "\n",
            "Epoch 01325: val_acc did not improve from 0.97561\n",
            "Epoch 1326/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.1956 - acc: 0.9250 - val_loss: 0.4584 - val_acc: 0.8049\n",
            "\n",
            "Epoch 01326: val_acc did not improve from 0.97561\n",
            "Epoch 1327/2000\n",
            "5/5 [==============================] - 1s 254ms/step - loss: 0.0722 - acc: 0.9750 - val_loss: 0.1760 - val_acc: 0.9512\n",
            "\n",
            "Epoch 01327: val_acc did not improve from 0.97561\n",
            "Epoch 1328/2000\n",
            "5/5 [==============================] - 1s 258ms/step - loss: 0.4257 - acc: 0.9000 - val_loss: 0.4630 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01328: val_acc did not improve from 0.97561\n",
            "Epoch 1329/2000\n",
            "5/5 [==============================] - 1s 250ms/step - loss: 0.0908 - acc: 0.9750 - val_loss: 2.5233 - val_acc: 0.5366\n",
            "\n",
            "Epoch 01329: val_acc did not improve from 0.97561\n",
            "Epoch 1330/2000\n",
            "5/5 [==============================] - 1s 243ms/step - loss: 0.0578 - acc: 1.0000 - val_loss: 2.6465 - val_acc: 0.5366\n",
            "\n",
            "Epoch 01330: val_acc did not improve from 0.97561\n",
            "Epoch 1331/2000\n",
            "5/5 [==============================] - 1s 253ms/step - loss: 0.1268 - acc: 0.9500 - val_loss: 2.4856 - val_acc: 0.5610\n",
            "\n",
            "Epoch 01331: val_acc did not improve from 0.97561\n",
            "Epoch 1332/2000\n",
            "5/5 [==============================] - 1s 271ms/step - loss: 0.1007 - acc: 0.9750 - val_loss: 2.7428 - val_acc: 0.5610\n",
            "\n",
            "Epoch 01332: val_acc did not improve from 0.97561\n",
            "Epoch 1333/2000\n",
            "5/5 [==============================] - 1s 276ms/step - loss: 0.0356 - acc: 1.0000 - val_loss: 1.7255 - val_acc: 0.6585\n",
            "\n",
            "Epoch 01333: val_acc did not improve from 0.97561\n",
            "Epoch 1334/2000\n",
            "5/5 [==============================] - 1s 279ms/step - loss: 0.1470 - acc: 0.9250 - val_loss: 0.3155 - val_acc: 0.9024\n",
            "\n",
            "Epoch 01334: val_acc did not improve from 0.97561\n",
            "Epoch 1335/2000\n",
            "5/5 [==============================] - 1s 275ms/step - loss: 0.0323 - acc: 1.0000 - val_loss: 1.3346 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01335: val_acc did not improve from 0.97561\n",
            "Epoch 1336/2000\n",
            "5/5 [==============================] - 1s 280ms/step - loss: 0.0329 - acc: 1.0000 - val_loss: 2.0354 - val_acc: 0.7317\n",
            "\n",
            "Epoch 01336: val_acc did not improve from 0.97561\n",
            "Epoch 1337/2000\n",
            "5/5 [==============================] - 1s 281ms/step - loss: 0.0657 - acc: 0.9750 - val_loss: 1.9430 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01337: val_acc did not improve from 0.97561\n",
            "Epoch 1338/2000\n",
            "5/5 [==============================] - 1s 280ms/step - loss: 0.0727 - acc: 0.9750 - val_loss: 2.3116 - val_acc: 0.6585\n",
            "\n",
            "Epoch 01338: val_acc did not improve from 0.97561\n",
            "Epoch 1339/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.0922 - acc: 0.9500 - val_loss: 3.4104 - val_acc: 0.5854\n",
            "\n",
            "Epoch 01339: val_acc did not improve from 0.97561\n",
            "Epoch 1340/2000\n",
            "5/5 [==============================] - 1s 253ms/step - loss: 0.1656 - acc: 0.9500 - val_loss: 2.6843 - val_acc: 0.6829\n",
            "\n",
            "Epoch 01340: val_acc did not improve from 0.97561\n",
            "Epoch 1341/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.0548 - acc: 0.9750 - val_loss: 2.4690 - val_acc: 0.6829\n",
            "\n",
            "Epoch 01341: val_acc did not improve from 0.97561\n",
            "Epoch 1342/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.1148 - acc: 0.9750 - val_loss: 1.8594 - val_acc: 0.7073\n",
            "\n",
            "Epoch 01342: val_acc did not improve from 0.97561\n",
            "Epoch 1343/2000\n",
            "5/5 [==============================] - 1s 255ms/step - loss: 0.0289 - acc: 1.0000 - val_loss: 0.8384 - val_acc: 0.8049\n",
            "\n",
            "Epoch 01343: val_acc did not improve from 0.97561\n",
            "Epoch 1344/2000\n",
            "5/5 [==============================] - 1s 253ms/step - loss: 0.0686 - acc: 0.9750 - val_loss: 0.2555 - val_acc: 0.9268\n",
            "\n",
            "Epoch 01344: val_acc did not improve from 0.97561\n",
            "Epoch 1345/2000\n",
            "5/5 [==============================] - 1s 251ms/step - loss: 0.0363 - acc: 1.0000 - val_loss: 0.1866 - val_acc: 0.9268\n",
            "\n",
            "Epoch 01345: val_acc did not improve from 0.97561\n",
            "Epoch 1346/2000\n",
            "5/5 [==============================] - 1s 253ms/step - loss: 0.0370 - acc: 1.0000 - val_loss: 2.0348 - val_acc: 0.6098\n",
            "\n",
            "Epoch 01346: val_acc did not improve from 0.97561\n",
            "Epoch 1347/2000\n",
            "5/5 [==============================] - 1s 252ms/step - loss: 0.1623 - acc: 0.9000 - val_loss: 0.3285 - val_acc: 0.8780\n",
            "\n",
            "Epoch 01347: val_acc did not improve from 0.97561\n",
            "Epoch 1348/2000\n",
            "5/5 [==============================] - 1s 251ms/step - loss: 0.0641 - acc: 0.9750 - val_loss: 0.2074 - val_acc: 0.9756\n",
            "\n",
            "Epoch 01348: val_acc did not improve from 0.97561\n",
            "Epoch 1349/2000\n",
            "5/5 [==============================] - 1s 250ms/step - loss: 0.0420 - acc: 1.0000 - val_loss: 0.1605 - val_acc: 0.9756\n",
            "\n",
            "Epoch 01349: val_acc did not improve from 0.97561\n",
            "Epoch 1350/2000\n",
            "5/5 [==============================] - 1s 243ms/step - loss: 0.0486 - acc: 1.0000 - val_loss: 0.1794 - val_acc: 0.9512\n",
            "\n",
            "Epoch 01350: val_acc did not improve from 0.97561\n",
            "Epoch 1351/2000\n",
            "5/5 [==============================] - 1s 245ms/step - loss: 0.0279 - acc: 1.0000 - val_loss: 0.2165 - val_acc: 0.9512\n",
            "\n",
            "Epoch 01351: val_acc did not improve from 0.97561\n",
            "Epoch 1352/2000\n",
            "5/5 [==============================] - 1s 244ms/step - loss: 0.0199 - acc: 1.0000 - val_loss: 0.2338 - val_acc: 0.9512\n",
            "\n",
            "Epoch 01352: val_acc did not improve from 0.97561\n",
            "Epoch 1353/2000\n",
            "5/5 [==============================] - 1s 250ms/step - loss: 0.0210 - acc: 1.0000 - val_loss: 0.2940 - val_acc: 0.9268\n",
            "\n",
            "Epoch 01353: val_acc did not improve from 0.97561\n",
            "Epoch 1354/2000\n",
            "5/5 [==============================] - 1s 249ms/step - loss: 0.0418 - acc: 0.9750 - val_loss: 0.2309 - val_acc: 0.9512\n",
            "\n",
            "Epoch 01354: val_acc did not improve from 0.97561\n",
            "Epoch 1355/2000\n",
            "5/5 [==============================] - 1s 251ms/step - loss: 0.0840 - acc: 0.9500 - val_loss: 1.3635 - val_acc: 0.6829\n",
            "\n",
            "Epoch 01355: val_acc did not improve from 0.97561\n",
            "Epoch 1356/2000\n",
            "5/5 [==============================] - 1s 252ms/step - loss: 0.0216 - acc: 1.0000 - val_loss: 2.8939 - val_acc: 0.5610\n",
            "\n",
            "Epoch 01356: val_acc did not improve from 0.97561\n",
            "Epoch 1357/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.1308 - acc: 0.9500 - val_loss: 4.6929 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01357: val_acc did not improve from 0.97561\n",
            "Epoch 1358/2000\n",
            "5/5 [==============================] - 1s 258ms/step - loss: 0.0713 - acc: 0.9750 - val_loss: 0.5824 - val_acc: 0.8049\n",
            "\n",
            "Epoch 01358: val_acc did not improve from 0.97561\n",
            "Epoch 1359/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.1126 - acc: 0.9750 - val_loss: 0.9359 - val_acc: 0.8049\n",
            "\n",
            "Epoch 01359: val_acc did not improve from 0.97561\n",
            "Epoch 1360/2000\n",
            "5/5 [==============================] - 1s 270ms/step - loss: 0.0647 - acc: 0.9750 - val_loss: 1.9559 - val_acc: 0.7317\n",
            "\n",
            "Epoch 01360: val_acc did not improve from 0.97561\n",
            "Epoch 1361/2000\n",
            "5/5 [==============================] - 1s 275ms/step - loss: 0.0671 - acc: 0.9750 - val_loss: 1.6637 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01361: val_acc did not improve from 0.97561\n",
            "Epoch 1362/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.0121 - acc: 1.0000 - val_loss: 0.4831 - val_acc: 0.8780\n",
            "\n",
            "Epoch 01362: val_acc did not improve from 0.97561\n",
            "Epoch 1363/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.1094 - acc: 0.9500 - val_loss: 4.9134 - val_acc: 0.3902\n",
            "\n",
            "Epoch 01363: val_acc did not improve from 0.97561\n",
            "Epoch 1364/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.0630 - acc: 1.0000 - val_loss: 5.4513 - val_acc: 0.2927\n",
            "\n",
            "Epoch 01364: val_acc did not improve from 0.97561\n",
            "Epoch 1365/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.2515 - acc: 0.9750 - val_loss: 2.3787 - val_acc: 0.5610\n",
            "\n",
            "Epoch 01365: val_acc did not improve from 0.97561\n",
            "Epoch 1366/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.1331 - acc: 0.9500 - val_loss: 0.2580 - val_acc: 0.9512\n",
            "\n",
            "Epoch 01366: val_acc did not improve from 0.97561\n",
            "Epoch 1367/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.2485 - acc: 0.9250 - val_loss: 0.2874 - val_acc: 0.9268\n",
            "\n",
            "Epoch 01367: val_acc did not improve from 0.97561\n",
            "Epoch 1368/2000\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 0.0242 - acc: 1.0000 - val_loss: 1.1065 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01368: val_acc did not improve from 0.97561\n",
            "Epoch 1369/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.1335 - acc: 0.9750 - val_loss: 0.6657 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01369: val_acc did not improve from 0.97561\n",
            "Epoch 1370/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.0120 - acc: 1.0000 - val_loss: 0.2671 - val_acc: 0.9268\n",
            "\n",
            "Epoch 01370: val_acc did not improve from 0.97561\n",
            "Epoch 1371/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.1977 - acc: 0.9500 - val_loss: 6.9564 - val_acc: 0.3659\n",
            "\n",
            "Epoch 01371: val_acc did not improve from 0.97561\n",
            "Epoch 1372/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.0155 - acc: 1.0000 - val_loss: 7.2001 - val_acc: 0.4146\n",
            "\n",
            "Epoch 01372: val_acc did not improve from 0.97561\n",
            "Epoch 1373/2000\n",
            "5/5 [==============================] - 1s 271ms/step - loss: 0.1246 - acc: 0.9500 - val_loss: 6.9397 - val_acc: 0.4390\n",
            "\n",
            "Epoch 01373: val_acc did not improve from 0.97561\n",
            "Epoch 1374/2000\n",
            "5/5 [==============================] - 1s 279ms/step - loss: 0.0654 - acc: 0.9750 - val_loss: 5.5146 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01374: val_acc did not improve from 0.97561\n",
            "Epoch 1375/2000\n",
            "5/5 [==============================] - 1s 272ms/step - loss: 0.1046 - acc: 0.9500 - val_loss: 4.6111 - val_acc: 0.5122\n",
            "\n",
            "Epoch 01375: val_acc did not improve from 0.97561\n",
            "Epoch 1376/2000\n",
            "5/5 [==============================] - 1s 272ms/step - loss: 0.0254 - acc: 1.0000 - val_loss: 1.0120 - val_acc: 0.6829\n",
            "\n",
            "Epoch 01376: val_acc did not improve from 0.97561\n",
            "Epoch 1377/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.0328 - acc: 1.0000 - val_loss: 0.2989 - val_acc: 0.9268\n",
            "\n",
            "Epoch 01377: val_acc did not improve from 0.97561\n",
            "Epoch 1378/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.0404 - acc: 1.0000 - val_loss: 0.2624 - val_acc: 0.9024\n",
            "\n",
            "Epoch 01378: val_acc did not improve from 0.97561\n",
            "Epoch 1379/2000\n",
            "5/5 [==============================] - 1s 256ms/step - loss: 0.0666 - acc: 0.9500 - val_loss: 0.1583 - val_acc: 0.9512\n",
            "\n",
            "Epoch 01379: val_acc did not improve from 0.97561\n",
            "Epoch 1380/2000\n",
            "5/5 [==============================] - 1s 258ms/step - loss: 0.0403 - acc: 1.0000 - val_loss: 1.1571 - val_acc: 0.6829\n",
            "\n",
            "Epoch 01380: val_acc did not improve from 0.97561\n",
            "Epoch 1381/2000\n",
            "5/5 [==============================] - 1s 251ms/step - loss: 0.0519 - acc: 0.9750 - val_loss: 0.1697 - val_acc: 0.9512\n",
            "\n",
            "Epoch 01381: val_acc did not improve from 0.97561\n",
            "Epoch 1382/2000\n",
            "5/5 [==============================] - 1s 251ms/step - loss: 0.0640 - acc: 0.9750 - val_loss: 0.9316 - val_acc: 0.8049\n",
            "\n",
            "Epoch 01382: val_acc did not improve from 0.97561\n",
            "Epoch 1383/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.2134 - acc: 0.9250 - val_loss: 1.7437 - val_acc: 0.7073\n",
            "\n",
            "Epoch 01383: val_acc did not improve from 0.97561\n",
            "Epoch 1384/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.0883 - acc: 0.9750 - val_loss: 1.5701 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01384: val_acc did not improve from 0.97561\n",
            "Epoch 1385/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.0974 - acc: 0.9750 - val_loss: 0.4950 - val_acc: 0.8049\n",
            "\n",
            "Epoch 01385: val_acc did not improve from 0.97561\n",
            "Epoch 1386/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.0529 - acc: 1.0000 - val_loss: 4.7949 - val_acc: 0.5122\n",
            "\n",
            "Epoch 01386: val_acc did not improve from 0.97561\n",
            "Epoch 1387/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.0748 - acc: 0.9750 - val_loss: 5.7221 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01387: val_acc did not improve from 0.97561\n",
            "Epoch 1388/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.0850 - acc: 0.9500 - val_loss: 2.0765 - val_acc: 0.6341\n",
            "\n",
            "Epoch 01388: val_acc did not improve from 0.97561\n",
            "Epoch 1389/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.3997 - val_acc: 0.9268\n",
            "\n",
            "Epoch 01389: val_acc did not improve from 0.97561\n",
            "Epoch 1390/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.3129 - acc: 0.9000 - val_loss: 1.1245 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01390: val_acc did not improve from 0.97561\n",
            "Epoch 1391/2000\n",
            "5/5 [==============================] - 1s 276ms/step - loss: 0.0527 - acc: 0.9750 - val_loss: 1.9114 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01391: val_acc did not improve from 0.97561\n",
            "Epoch 1392/2000\n",
            "5/5 [==============================] - 1s 275ms/step - loss: 0.0473 - acc: 1.0000 - val_loss: 2.7120 - val_acc: 0.7073\n",
            "\n",
            "Epoch 01392: val_acc did not improve from 0.97561\n",
            "Epoch 1393/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.1446 - acc: 0.9000 - val_loss: 2.1323 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01393: val_acc did not improve from 0.97561\n",
            "Epoch 1394/2000\n",
            "5/5 [==============================] - 1s 256ms/step - loss: 0.0952 - acc: 0.9750 - val_loss: 7.4310 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01394: val_acc did not improve from 0.97561\n",
            "Epoch 1395/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.0791 - acc: 0.9750 - val_loss: 8.0955 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01395: val_acc did not improve from 0.97561\n",
            "Epoch 1396/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.0354 - acc: 1.0000 - val_loss: 8.3567 - val_acc: 0.3659\n",
            "\n",
            "Epoch 01396: val_acc did not improve from 0.97561\n",
            "Epoch 1397/2000\n",
            "5/5 [==============================] - 1s 273ms/step - loss: 0.0222 - acc: 1.0000 - val_loss: 8.4855 - val_acc: 0.3171\n",
            "\n",
            "Epoch 01397: val_acc did not improve from 0.97561\n",
            "Epoch 1398/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.0408 - acc: 0.9750 - val_loss: 8.2005 - val_acc: 0.3659\n",
            "\n",
            "Epoch 01398: val_acc did not improve from 0.97561\n",
            "Epoch 1399/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.0864 - acc: 0.9500 - val_loss: 7.9251 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01399: val_acc did not improve from 0.97561\n",
            "Epoch 1400/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.0405 - acc: 1.0000 - val_loss: 7.9187 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01400: val_acc did not improve from 0.97561\n",
            "Epoch 1401/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.1633 - acc: 0.9250 - val_loss: 7.9364 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01401: val_acc did not improve from 0.97561\n",
            "Epoch 1402/2000\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 0.1620 - acc: 0.9500 - val_loss: 7.5222 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01402: val_acc did not improve from 0.97561\n",
            "Epoch 1403/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.0615 - acc: 0.9750 - val_loss: 3.3536 - val_acc: 0.5366\n",
            "\n",
            "Epoch 01403: val_acc did not improve from 0.97561\n",
            "Epoch 1404/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.1089 - acc: 0.9500 - val_loss: 2.3459 - val_acc: 0.5854\n",
            "\n",
            "Epoch 01404: val_acc did not improve from 0.97561\n",
            "Epoch 1405/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.0430 - acc: 0.9750 - val_loss: 4.7551 - val_acc: 0.5122\n",
            "\n",
            "Epoch 01405: val_acc did not improve from 0.97561\n",
            "Epoch 1406/2000\n",
            "5/5 [==============================] - 1s 253ms/step - loss: 0.0297 - acc: 1.0000 - val_loss: 6.9183 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01406: val_acc did not improve from 0.97561\n",
            "Epoch 1407/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.0411 - acc: 1.0000 - val_loss: 6.9704 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01407: val_acc did not improve from 0.97561\n",
            "Epoch 1408/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.0907 - acc: 0.9500 - val_loss: 6.5208 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01408: val_acc did not improve from 0.97561\n",
            "Epoch 1409/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.0358 - acc: 0.9750 - val_loss: 6.0588 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01409: val_acc did not improve from 0.97561\n",
            "Epoch 1410/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.1551 - acc: 0.9250 - val_loss: 5.0964 - val_acc: 0.5122\n",
            "\n",
            "Epoch 01410: val_acc did not improve from 0.97561\n",
            "Epoch 1411/2000\n",
            "5/5 [==============================] - 1s 258ms/step - loss: 0.0426 - acc: 0.9750 - val_loss: 4.8264 - val_acc: 0.5366\n",
            "\n",
            "Epoch 01411: val_acc did not improve from 0.97561\n",
            "Epoch 1412/2000\n",
            "5/5 [==============================] - 1s 255ms/step - loss: 0.0464 - acc: 1.0000 - val_loss: 4.4310 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01412: val_acc did not improve from 0.97561\n",
            "Epoch 1413/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.0133 - acc: 1.0000 - val_loss: 3.8492 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01413: val_acc did not improve from 0.97561\n",
            "Epoch 1414/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.1761 - acc: 0.9500 - val_loss: 5.6694 - val_acc: 0.4146\n",
            "\n",
            "Epoch 01414: val_acc did not improve from 0.97561\n",
            "Epoch 1415/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.1649 - acc: 0.9500 - val_loss: 7.0863 - val_acc: 0.3659\n",
            "\n",
            "Epoch 01415: val_acc did not improve from 0.97561\n",
            "Epoch 1416/2000\n",
            "5/5 [==============================] - 1s 270ms/step - loss: 0.0956 - acc: 0.9750 - val_loss: 7.4424 - val_acc: 0.4634\n",
            "\n",
            "Epoch 01416: val_acc did not improve from 0.97561\n",
            "Epoch 1417/2000\n",
            "5/5 [==============================] - 1s 276ms/step - loss: 0.0663 - acc: 0.9500 - val_loss: 5.9094 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01417: val_acc did not improve from 0.97561\n",
            "Epoch 1418/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.1056 - acc: 0.9750 - val_loss: 0.9049 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01418: val_acc did not improve from 0.97561\n",
            "Epoch 1419/2000\n",
            "5/5 [==============================] - 1s 255ms/step - loss: 0.0674 - acc: 1.0000 - val_loss: 0.7389 - val_acc: 0.7317\n",
            "\n",
            "Epoch 01419: val_acc did not improve from 0.97561\n",
            "Epoch 1420/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.0580 - acc: 0.9750 - val_loss: 0.5660 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01420: val_acc did not improve from 0.97561\n",
            "Epoch 1421/2000\n",
            "5/5 [==============================] - 1s 245ms/step - loss: 0.0544 - acc: 1.0000 - val_loss: 0.2305 - val_acc: 0.9024\n",
            "\n",
            "Epoch 01421: val_acc did not improve from 0.97561\n",
            "Epoch 1422/2000\n",
            "5/5 [==============================] - 1s 242ms/step - loss: 0.0500 - acc: 0.9750 - val_loss: 0.9417 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01422: val_acc did not improve from 0.97561\n",
            "Epoch 1423/2000\n",
            "5/5 [==============================] - 1s 253ms/step - loss: 0.0538 - acc: 0.9750 - val_loss: 0.6062 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01423: val_acc did not improve from 0.97561\n",
            "Epoch 1424/2000\n",
            "5/5 [==============================] - 1s 254ms/step - loss: 0.1703 - acc: 0.9250 - val_loss: 0.3220 - val_acc: 0.9024\n",
            "\n",
            "Epoch 01424: val_acc did not improve from 0.97561\n",
            "Epoch 1425/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.0344 - acc: 1.0000 - val_loss: 0.3869 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01425: val_acc did not improve from 0.97561\n",
            "Epoch 1426/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.1139 - acc: 0.9750 - val_loss: 2.0373 - val_acc: 0.6098\n",
            "\n",
            "Epoch 01426: val_acc did not improve from 0.97561\n",
            "Epoch 1427/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.0660 - acc: 1.0000 - val_loss: 0.1745 - val_acc: 0.9512\n",
            "\n",
            "Epoch 01427: val_acc did not improve from 0.97561\n",
            "Epoch 1428/2000\n",
            "5/5 [==============================] - 1s 272ms/step - loss: 0.0394 - acc: 0.9750 - val_loss: 0.4711 - val_acc: 0.8780\n",
            "\n",
            "Epoch 01428: val_acc did not improve from 0.97561\n",
            "Epoch 1429/2000\n",
            "5/5 [==============================] - 1s 276ms/step - loss: 0.0539 - acc: 0.9750 - val_loss: 0.4980 - val_acc: 0.8780\n",
            "\n",
            "Epoch 01429: val_acc did not improve from 0.97561\n",
            "Epoch 1430/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.0465 - acc: 0.9750 - val_loss: 0.3790 - val_acc: 0.9024\n",
            "\n",
            "Epoch 01430: val_acc did not improve from 0.97561\n",
            "Epoch 1431/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.4169 - val_acc: 0.8780\n",
            "\n",
            "Epoch 01431: val_acc did not improve from 0.97561\n",
            "Epoch 1432/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.0204 - acc: 1.0000 - val_loss: 0.5312 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01432: val_acc did not improve from 0.97561\n",
            "Epoch 1433/2000\n",
            "5/5 [==============================] - 1s 250ms/step - loss: 0.0274 - acc: 1.0000 - val_loss: 0.7557 - val_acc: 0.8049\n",
            "\n",
            "Epoch 01433: val_acc did not improve from 0.97561\n",
            "Epoch 1434/2000\n",
            "5/5 [==============================] - 1s 244ms/step - loss: 0.0539 - acc: 0.9750 - val_loss: 0.6121 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01434: val_acc did not improve from 0.97561\n",
            "Epoch 1435/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.3698 - acc: 0.8750 - val_loss: 0.2424 - val_acc: 0.8780\n",
            "\n",
            "Epoch 01435: val_acc did not improve from 0.97561\n",
            "Epoch 1436/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.1599 - acc: 0.9250 - val_loss: 1.3893 - val_acc: 0.7073\n",
            "\n",
            "Epoch 01436: val_acc did not improve from 0.97561\n",
            "Epoch 1437/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.1529 - acc: 0.9750 - val_loss: 1.4958 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01437: val_acc did not improve from 0.97561\n",
            "Epoch 1438/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.0851 - acc: 0.9750 - val_loss: 1.9023 - val_acc: 0.7073\n",
            "\n",
            "Epoch 01438: val_acc did not improve from 0.97561\n",
            "Epoch 1439/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.1281 - acc: 0.9250 - val_loss: 0.6155 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01439: val_acc did not improve from 0.97561\n",
            "Epoch 1440/2000\n",
            "5/5 [==============================] - 1s 277ms/step - loss: 0.0496 - acc: 1.0000 - val_loss: 2.4891 - val_acc: 0.3415\n",
            "\n",
            "Epoch 01440: val_acc did not improve from 0.97561\n",
            "Epoch 1441/2000\n",
            "5/5 [==============================] - 1s 270ms/step - loss: 0.0989 - acc: 0.9500 - val_loss: 2.3282 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01441: val_acc did not improve from 0.97561\n",
            "Epoch 1442/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.0187 - acc: 1.0000 - val_loss: 2.1713 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01442: val_acc did not improve from 0.97561\n",
            "Epoch 1443/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.2321 - acc: 0.9000 - val_loss: 0.7746 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01443: val_acc did not improve from 0.97561\n",
            "Epoch 1444/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.3312 - acc: 0.9250 - val_loss: 0.8660 - val_acc: 0.7073\n",
            "\n",
            "Epoch 01444: val_acc did not improve from 0.97561\n",
            "Epoch 1445/2000\n",
            "5/5 [==============================] - 1s 256ms/step - loss: 0.0797 - acc: 0.9750 - val_loss: 6.2332 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01445: val_acc did not improve from 0.97561\n",
            "Epoch 1446/2000\n",
            "5/5 [==============================] - 1s 255ms/step - loss: 0.0450 - acc: 1.0000 - val_loss: 6.8741 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01446: val_acc did not improve from 0.97561\n",
            "Epoch 1447/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.0743 - acc: 0.9750 - val_loss: 7.0400 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01447: val_acc did not improve from 0.97561\n",
            "Epoch 1448/2000\n",
            "5/5 [==============================] - 1s 256ms/step - loss: 0.1383 - acc: 0.9250 - val_loss: 6.8233 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01448: val_acc did not improve from 0.97561\n",
            "Epoch 1449/2000\n",
            "5/5 [==============================] - 1s 251ms/step - loss: 0.1721 - acc: 0.9250 - val_loss: 6.5782 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01449: val_acc did not improve from 0.97561\n",
            "Epoch 1450/2000\n",
            "5/5 [==============================] - 1s 246ms/step - loss: 0.0322 - acc: 1.0000 - val_loss: 6.4879 - val_acc: 0.4146\n",
            "\n",
            "Epoch 01450: val_acc did not improve from 0.97561\n",
            "Epoch 1451/2000\n",
            "5/5 [==============================] - 1s 253ms/step - loss: 0.0735 - acc: 0.9750 - val_loss: 5.2679 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01451: val_acc did not improve from 0.97561\n",
            "Epoch 1452/2000\n",
            "5/5 [==============================] - 1s 258ms/step - loss: 0.0310 - acc: 1.0000 - val_loss: 3.8904 - val_acc: 0.5122\n",
            "\n",
            "Epoch 01452: val_acc did not improve from 0.97561\n",
            "Epoch 1453/2000\n",
            "5/5 [==============================] - 1s 247ms/step - loss: 0.0551 - acc: 1.0000 - val_loss: 0.7593 - val_acc: 0.7073\n",
            "\n",
            "Epoch 01453: val_acc did not improve from 0.97561\n",
            "Epoch 1454/2000\n",
            "5/5 [==============================] - 1s 246ms/step - loss: 0.0556 - acc: 0.9750 - val_loss: 0.3249 - val_acc: 0.8780\n",
            "\n",
            "Epoch 01454: val_acc did not improve from 0.97561\n",
            "Epoch 1455/2000\n",
            "5/5 [==============================] - 1s 258ms/step - loss: 0.0464 - acc: 0.9750 - val_loss: 0.5929 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01455: val_acc did not improve from 0.97561\n",
            "Epoch 1456/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.1185 - acc: 0.9250 - val_loss: 0.7017 - val_acc: 0.8049\n",
            "\n",
            "Epoch 01456: val_acc did not improve from 0.97561\n",
            "Epoch 1457/2000\n",
            "5/5 [==============================] - 1s 251ms/step - loss: 0.1658 - acc: 0.9500 - val_loss: 0.7393 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01457: val_acc did not improve from 0.97561\n",
            "Epoch 1458/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.1946 - acc: 0.9250 - val_loss: 0.8203 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01458: val_acc did not improve from 0.97561\n",
            "Epoch 1459/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.0282 - acc: 1.0000 - val_loss: 0.6919 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01459: val_acc did not improve from 0.97561\n",
            "Epoch 1460/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.1120 - acc: 0.9500 - val_loss: 0.6011 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01460: val_acc did not improve from 0.97561\n",
            "Epoch 1461/2000\n",
            "5/5 [==============================] - 1s 253ms/step - loss: 0.0376 - acc: 1.0000 - val_loss: 1.1689 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01461: val_acc did not improve from 0.97561\n",
            "Epoch 1462/2000\n",
            "5/5 [==============================] - 1s 254ms/step - loss: 0.1753 - acc: 0.9250 - val_loss: 1.0721 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01462: val_acc did not improve from 0.97561\n",
            "Epoch 1463/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.2004 - acc: 0.9250 - val_loss: 0.8043 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01463: val_acc did not improve from 0.97561\n",
            "Epoch 1464/2000\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 0.5861 - acc: 0.8250 - val_loss: 2.2067 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01464: val_acc did not improve from 0.97561\n",
            "Epoch 1465/2000\n",
            "5/5 [==============================] - 1s 272ms/step - loss: 0.0324 - acc: 1.0000 - val_loss: 4.1436 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01465: val_acc did not improve from 0.97561\n",
            "Epoch 1466/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.0751 - acc: 0.9750 - val_loss: 4.1207 - val_acc: 0.5366\n",
            "\n",
            "Epoch 01466: val_acc did not improve from 0.97561\n",
            "Epoch 1467/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.0700 - acc: 0.9750 - val_loss: 3.5133 - val_acc: 0.5610\n",
            "\n",
            "Epoch 01467: val_acc did not improve from 0.97561\n",
            "Epoch 1468/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.2894 - acc: 0.8500 - val_loss: 2.8230 - val_acc: 0.6585\n",
            "\n",
            "Epoch 01468: val_acc did not improve from 0.97561\n",
            "Epoch 1469/2000\n",
            "5/5 [==============================] - 1s 255ms/step - loss: 0.0686 - acc: 0.9750 - val_loss: 2.7186 - val_acc: 0.7317\n",
            "\n",
            "Epoch 01469: val_acc did not improve from 0.97561\n",
            "Epoch 1470/2000\n",
            "5/5 [==============================] - 1s 253ms/step - loss: 0.0608 - acc: 0.9750 - val_loss: 2.4037 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01470: val_acc did not improve from 0.97561\n",
            "Epoch 1471/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.3004 - acc: 0.8500 - val_loss: 1.8945 - val_acc: 0.6829\n",
            "\n",
            "Epoch 01471: val_acc did not improve from 0.97561\n",
            "Epoch 1472/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.1018 - acc: 0.9500 - val_loss: 0.3471 - val_acc: 0.8780\n",
            "\n",
            "Epoch 01472: val_acc did not improve from 0.97561\n",
            "Epoch 1473/2000\n",
            "5/5 [==============================] - 1s 275ms/step - loss: 0.0585 - acc: 0.9750 - val_loss: 2.0917 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01473: val_acc did not improve from 0.97561\n",
            "Epoch 1474/2000\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 0.0649 - acc: 1.0000 - val_loss: 0.7986 - val_acc: 0.7317\n",
            "\n",
            "Epoch 01474: val_acc did not improve from 0.97561\n",
            "Epoch 1475/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.0624 - acc: 0.9750 - val_loss: 0.9009 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01475: val_acc did not improve from 0.97561\n",
            "Epoch 1476/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.0377 - acc: 1.0000 - val_loss: 1.7020 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01476: val_acc did not improve from 0.97561\n",
            "Epoch 1477/2000\n",
            "5/5 [==============================] - 1s 251ms/step - loss: 0.0494 - acc: 1.0000 - val_loss: 1.8538 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01477: val_acc did not improve from 0.97561\n",
            "Epoch 1478/2000\n",
            "5/5 [==============================] - 1s 249ms/step - loss: 0.0214 - acc: 1.0000 - val_loss: 1.7747 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01478: val_acc did not improve from 0.97561\n",
            "Epoch 1479/2000\n",
            "5/5 [==============================] - 1s 258ms/step - loss: 0.1220 - acc: 0.9750 - val_loss: 1.3299 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01479: val_acc did not improve from 0.97561\n",
            "Epoch 1480/2000\n",
            "5/5 [==============================] - 1s 258ms/step - loss: 0.0743 - acc: 0.9500 - val_loss: 1.3012 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01480: val_acc did not improve from 0.97561\n",
            "Epoch 1481/2000\n",
            "5/5 [==============================] - 1s 255ms/step - loss: 0.0428 - acc: 1.0000 - val_loss: 1.2242 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01481: val_acc did not improve from 0.97561\n",
            "Epoch 1482/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.1557 - acc: 0.9500 - val_loss: 1.1418 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01482: val_acc did not improve from 0.97561\n",
            "Epoch 1483/2000\n",
            "5/5 [==============================] - 1s 254ms/step - loss: 0.0267 - acc: 1.0000 - val_loss: 0.3050 - val_acc: 0.9024\n",
            "\n",
            "Epoch 01483: val_acc did not improve from 0.97561\n",
            "Epoch 1484/2000\n",
            "5/5 [==============================] - 1s 256ms/step - loss: 0.1018 - acc: 0.9750 - val_loss: 0.2010 - val_acc: 0.9512\n",
            "\n",
            "Epoch 01484: val_acc did not improve from 0.97561\n",
            "Epoch 1485/2000\n",
            "5/5 [==============================] - 1s 247ms/step - loss: 0.0241 - acc: 1.0000 - val_loss: 0.3061 - val_acc: 0.8780\n",
            "\n",
            "Epoch 01485: val_acc did not improve from 0.97561\n",
            "Epoch 1486/2000\n",
            "5/5 [==============================] - 1s 252ms/step - loss: 0.1178 - acc: 0.9250 - val_loss: 0.4585 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01486: val_acc did not improve from 0.97561\n",
            "Epoch 1487/2000\n",
            "5/5 [==============================] - 1s 255ms/step - loss: 0.2082 - acc: 0.9500 - val_loss: 0.8699 - val_acc: 0.8049\n",
            "\n",
            "Epoch 01487: val_acc did not improve from 0.97561\n",
            "Epoch 1488/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.0437 - acc: 1.0000 - val_loss: 0.8101 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01488: val_acc did not improve from 0.97561\n",
            "Epoch 1489/2000\n",
            "5/5 [==============================] - 1s 251ms/step - loss: 0.0761 - acc: 0.9500 - val_loss: 0.8388 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01489: val_acc did not improve from 0.97561\n",
            "Epoch 1490/2000\n",
            "5/5 [==============================] - 1s 255ms/step - loss: 0.0671 - acc: 0.9750 - val_loss: 0.1395 - val_acc: 0.9756\n",
            "\n",
            "Epoch 01490: val_acc did not improve from 0.97561\n",
            "Epoch 1491/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.0995 - acc: 0.9500 - val_loss: 3.9468 - val_acc: 0.2439\n",
            "\n",
            "Epoch 01491: val_acc did not improve from 0.97561\n",
            "Epoch 1492/2000\n",
            "5/5 [==============================] - 1s 270ms/step - loss: 0.2741 - acc: 0.8750 - val_loss: 0.1578 - val_acc: 0.9512\n",
            "\n",
            "Epoch 01492: val_acc did not improve from 0.97561\n",
            "Epoch 1493/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.3597 - acc: 0.8750 - val_loss: 1.0676 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01493: val_acc did not improve from 0.97561\n",
            "Epoch 1494/2000\n",
            "5/5 [==============================] - 1s 256ms/step - loss: 0.0819 - acc: 0.9750 - val_loss: 1.5775 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01494: val_acc did not improve from 0.97561\n",
            "Epoch 1495/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.4756 - acc: 0.8250 - val_loss: 0.6837 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01495: val_acc did not improve from 0.97561\n",
            "Epoch 1496/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.0978 - acc: 0.9750 - val_loss: 0.7304 - val_acc: 0.7317\n",
            "\n",
            "Epoch 01496: val_acc did not improve from 0.97561\n",
            "Epoch 1497/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.0720 - acc: 0.9750 - val_loss: 1.9020 - val_acc: 0.5854\n",
            "\n",
            "Epoch 01497: val_acc did not improve from 0.97561\n",
            "Epoch 1498/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.1191 - acc: 0.9250 - val_loss: 6.8817 - val_acc: 0.3171\n",
            "\n",
            "Epoch 01498: val_acc did not improve from 0.97561\n",
            "Epoch 1499/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.0395 - acc: 0.9750 - val_loss: 6.1410 - val_acc: 0.3415\n",
            "\n",
            "Epoch 01499: val_acc did not improve from 0.97561\n",
            "Epoch 1500/2000\n",
            "5/5 [==============================] - 1s 270ms/step - loss: 0.3116 - acc: 0.9500 - val_loss: 5.0822 - val_acc: 0.3415\n",
            "\n",
            "Epoch 01500: val_acc did not improve from 0.97561\n",
            "Epoch 1501/2000\n",
            "5/5 [==============================] - 1s 278ms/step - loss: 0.1602 - acc: 0.9500 - val_loss: 1.8139 - val_acc: 0.6098\n",
            "\n",
            "Epoch 01501: val_acc did not improve from 0.97561\n",
            "Epoch 1502/2000\n",
            "5/5 [==============================] - 1s 279ms/step - loss: 0.0868 - acc: 0.9750 - val_loss: 0.3509 - val_acc: 0.9024\n",
            "\n",
            "Epoch 01502: val_acc did not improve from 0.97561\n",
            "Epoch 1503/2000\n",
            "5/5 [==============================] - 1s 280ms/step - loss: 0.0233 - acc: 1.0000 - val_loss: 0.1309 - val_acc: 0.9512\n",
            "\n",
            "Epoch 01503: val_acc did not improve from 0.97561\n",
            "Epoch 1504/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.1800 - acc: 0.9500 - val_loss: 3.0476 - val_acc: 0.5366\n",
            "\n",
            "Epoch 01504: val_acc did not improve from 0.97561\n",
            "Epoch 1505/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.1672 - acc: 0.9250 - val_loss: 3.4604 - val_acc: 0.5122\n",
            "\n",
            "Epoch 01505: val_acc did not improve from 0.97561\n",
            "Epoch 1506/2000\n",
            "5/5 [==============================] - 1s 255ms/step - loss: 0.0733 - acc: 0.9500 - val_loss: 0.2924 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01506: val_acc did not improve from 0.97561\n",
            "Epoch 1507/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.0270 - acc: 1.0000 - val_loss: 0.3593 - val_acc: 0.9024\n",
            "\n",
            "Epoch 01507: val_acc did not improve from 0.97561\n",
            "Epoch 1508/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.0198 - acc: 1.0000 - val_loss: 0.6938 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01508: val_acc did not improve from 0.97561\n",
            "Epoch 1509/2000\n",
            "5/5 [==============================] - 1s 277ms/step - loss: 0.1334 - acc: 0.9500 - val_loss: 0.4552 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01509: val_acc did not improve from 0.97561\n",
            "Epoch 1510/2000\n",
            "5/5 [==============================] - 1s 273ms/step - loss: 0.0296 - acc: 1.0000 - val_loss: 0.6073 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01510: val_acc did not improve from 0.97561\n",
            "Epoch 1511/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.0145 - acc: 1.0000 - val_loss: 0.9286 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01511: val_acc did not improve from 0.97561\n",
            "Epoch 1512/2000\n",
            "5/5 [==============================] - 1s 258ms/step - loss: 0.4030 - acc: 0.8750 - val_loss: 2.8513 - val_acc: 0.5122\n",
            "\n",
            "Epoch 01512: val_acc did not improve from 0.97561\n",
            "Epoch 1513/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.1768 - acc: 0.9250 - val_loss: 7.5382 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01513: val_acc did not improve from 0.97561\n",
            "Epoch 1514/2000\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 0.0654 - acc: 0.9750 - val_loss: 7.5693 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01514: val_acc did not improve from 0.97561\n",
            "Epoch 1515/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.0593 - acc: 0.9750 - val_loss: 7.6954 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01515: val_acc did not improve from 0.97561\n",
            "Epoch 1516/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.0345 - acc: 1.0000 - val_loss: 7.6985 - val_acc: 0.3902\n",
            "\n",
            "Epoch 01516: val_acc did not improve from 0.97561\n",
            "Epoch 1517/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.0699 - acc: 0.9750 - val_loss: 7.4023 - val_acc: 0.3902\n",
            "\n",
            "Epoch 01517: val_acc did not improve from 0.97561\n",
            "Epoch 1518/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.0228 - acc: 1.0000 - val_loss: 6.8815 - val_acc: 0.4146\n",
            "\n",
            "Epoch 01518: val_acc did not improve from 0.97561\n",
            "Epoch 1519/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.2952 - acc: 0.9000 - val_loss: 6.5797 - val_acc: 0.4146\n",
            "\n",
            "Epoch 01519: val_acc did not improve from 0.97561\n",
            "Epoch 1520/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.0815 - acc: 0.9500 - val_loss: 5.8283 - val_acc: 0.4146\n",
            "\n",
            "Epoch 01520: val_acc did not improve from 0.97561\n",
            "Epoch 1521/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.0431 - acc: 1.0000 - val_loss: 4.6153 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01521: val_acc did not improve from 0.97561\n",
            "Epoch 1522/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.1041 - acc: 0.9500 - val_loss: 3.2394 - val_acc: 0.5122\n",
            "\n",
            "Epoch 01522: val_acc did not improve from 0.97561\n",
            "Epoch 1523/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.1678 - acc: 0.9250 - val_loss: 4.6486 - val_acc: 0.2927\n",
            "\n",
            "Epoch 01523: val_acc did not improve from 0.97561\n",
            "Epoch 1524/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.0666 - acc: 0.9750 - val_loss: 8.7793 - val_acc: 0.2195\n",
            "\n",
            "Epoch 01524: val_acc did not improve from 0.97561\n",
            "Epoch 1525/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.2367 - acc: 0.9250 - val_loss: 6.7461 - val_acc: 0.2927\n",
            "\n",
            "Epoch 01525: val_acc did not improve from 0.97561\n",
            "Epoch 1526/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.4369 - acc: 0.8500 - val_loss: 0.2641 - val_acc: 0.9268\n",
            "\n",
            "Epoch 01526: val_acc did not improve from 0.97561\n",
            "Epoch 1527/2000\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 0.1539 - acc: 0.9250 - val_loss: 3.2918 - val_acc: 0.6341\n",
            "\n",
            "Epoch 01527: val_acc did not improve from 0.97561\n",
            "Epoch 1528/2000\n",
            "5/5 [==============================] - 1s 275ms/step - loss: 0.3170 - acc: 0.9000 - val_loss: 1.6115 - val_acc: 0.6341\n",
            "\n",
            "Epoch 01528: val_acc did not improve from 0.97561\n",
            "Epoch 1529/2000\n",
            "5/5 [==============================] - 1s 276ms/step - loss: 0.0953 - acc: 0.9750 - val_loss: 6.2896 - val_acc: 0.3171\n",
            "\n",
            "Epoch 01529: val_acc did not improve from 0.97561\n",
            "Epoch 1530/2000\n",
            "5/5 [==============================] - 1s 275ms/step - loss: 0.2979 - acc: 0.9000 - val_loss: 6.0748 - val_acc: 0.2439\n",
            "\n",
            "Epoch 01530: val_acc did not improve from 0.97561\n",
            "Epoch 1531/2000\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 0.0717 - acc: 0.9750 - val_loss: 4.5925 - val_acc: 0.3171\n",
            "\n",
            "Epoch 01531: val_acc did not improve from 0.97561\n",
            "Epoch 1532/2000\n",
            "5/5 [==============================] - 1s 270ms/step - loss: 0.0201 - acc: 1.0000 - val_loss: 3.3259 - val_acc: 0.3659\n",
            "\n",
            "Epoch 01532: val_acc did not improve from 0.97561\n",
            "Epoch 1533/2000\n",
            "5/5 [==============================] - 1s 273ms/step - loss: 0.1847 - acc: 0.8750 - val_loss: 0.4616 - val_acc: 0.8049\n",
            "\n",
            "Epoch 01533: val_acc did not improve from 0.97561\n",
            "Epoch 1534/2000\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 0.1410 - acc: 0.9750 - val_loss: 0.8969 - val_acc: 0.6585\n",
            "\n",
            "Epoch 01534: val_acc did not improve from 0.97561\n",
            "Epoch 1535/2000\n",
            "5/5 [==============================] - 1s 273ms/step - loss: 0.0756 - acc: 0.9500 - val_loss: 1.0735 - val_acc: 0.7073\n",
            "\n",
            "Epoch 01535: val_acc did not improve from 0.97561\n",
            "Epoch 1536/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.0311 - acc: 0.9750 - val_loss: 0.7260 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01536: val_acc did not improve from 0.97561\n",
            "Epoch 1537/2000\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 0.0128 - acc: 1.0000 - val_loss: 1.0460 - val_acc: 0.6585\n",
            "\n",
            "Epoch 01537: val_acc did not improve from 0.97561\n",
            "Epoch 1538/2000\n",
            "5/5 [==============================] - 1s 270ms/step - loss: 0.0596 - acc: 0.9750 - val_loss: 0.8687 - val_acc: 0.7073\n",
            "\n",
            "Epoch 01538: val_acc did not improve from 0.97561\n",
            "Epoch 1539/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.0210 - acc: 1.0000 - val_loss: 0.7544 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01539: val_acc did not improve from 0.97561\n",
            "Epoch 1540/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.0413 - acc: 0.9750 - val_loss: 0.5660 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01540: val_acc did not improve from 0.97561\n",
            "Epoch 1541/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.1568 - acc: 0.9000 - val_loss: 0.1392 - val_acc: 0.9512\n",
            "\n",
            "Epoch 01541: val_acc did not improve from 0.97561\n",
            "Epoch 1542/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.0414 - acc: 1.0000 - val_loss: 0.1980 - val_acc: 0.9268\n",
            "\n",
            "Epoch 01542: val_acc did not improve from 0.97561\n",
            "Epoch 1543/2000\n",
            "5/5 [==============================] - 1s 271ms/step - loss: 0.0730 - acc: 0.9750 - val_loss: 0.3726 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01543: val_acc did not improve from 0.97561\n",
            "Epoch 1544/2000\n",
            "5/5 [==============================] - 1s 270ms/step - loss: 0.0236 - acc: 1.0000 - val_loss: 0.1643 - val_acc: 0.9268\n",
            "\n",
            "Epoch 01544: val_acc did not improve from 0.97561\n",
            "Epoch 1545/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.2562 - acc: 0.9250 - val_loss: 2.0987 - val_acc: 0.5122\n",
            "\n",
            "Epoch 01545: val_acc did not improve from 0.97561\n",
            "Epoch 1546/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.0285 - acc: 1.0000 - val_loss: 1.7954 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01546: val_acc did not improve from 0.97561\n",
            "Epoch 1547/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.2236 - acc: 0.9000 - val_loss: 1.9726 - val_acc: 0.6829\n",
            "\n",
            "Epoch 01547: val_acc did not improve from 0.97561\n",
            "Epoch 1548/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.0237 - acc: 1.0000 - val_loss: 2.0812 - val_acc: 0.6098\n",
            "\n",
            "Epoch 01548: val_acc did not improve from 0.97561\n",
            "Epoch 1549/2000\n",
            "5/5 [==============================] - 1s 243ms/step - loss: 0.0507 - acc: 1.0000 - val_loss: 3.0457 - val_acc: 0.6341\n",
            "\n",
            "Epoch 01549: val_acc did not improve from 0.97561\n",
            "Epoch 1550/2000\n",
            "5/5 [==============================] - 1s 249ms/step - loss: 0.2037 - acc: 0.8500 - val_loss: 1.4220 - val_acc: 0.6829\n",
            "\n",
            "Epoch 01550: val_acc did not improve from 0.97561\n",
            "Epoch 1551/2000\n",
            "5/5 [==============================] - 1s 253ms/step - loss: 0.0657 - acc: 0.9750 - val_loss: 6.1024 - val_acc: 0.3171\n",
            "\n",
            "Epoch 01551: val_acc did not improve from 0.97561\n",
            "Epoch 1552/2000\n",
            "5/5 [==============================] - 1s 253ms/step - loss: 0.1081 - acc: 0.9250 - val_loss: 5.9223 - val_acc: 0.3902\n",
            "\n",
            "Epoch 01552: val_acc did not improve from 0.97561\n",
            "Epoch 1553/2000\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 0.1854 - acc: 0.9500 - val_loss: 5.3866 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01553: val_acc did not improve from 0.97561\n",
            "Epoch 1554/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.1280 - acc: 0.9750 - val_loss: 4.4681 - val_acc: 0.5122\n",
            "\n",
            "Epoch 01554: val_acc did not improve from 0.97561\n",
            "Epoch 1555/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.0243 - acc: 1.0000 - val_loss: 3.6981 - val_acc: 0.5366\n",
            "\n",
            "Epoch 01555: val_acc did not improve from 0.97561\n",
            "Epoch 1556/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.0241 - acc: 1.0000 - val_loss: 1.8929 - val_acc: 0.6585\n",
            "\n",
            "Epoch 01556: val_acc did not improve from 0.97561\n",
            "Epoch 1557/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.1113 - acc: 0.9750 - val_loss: 0.9696 - val_acc: 0.6829\n",
            "\n",
            "Epoch 01557: val_acc did not improve from 0.97561\n",
            "Epoch 1558/2000\n",
            "5/5 [==============================] - 1s 258ms/step - loss: 0.1178 - acc: 0.9250 - val_loss: 3.3811 - val_acc: 0.5122\n",
            "\n",
            "Epoch 01558: val_acc did not improve from 0.97561\n",
            "Epoch 1559/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.0886 - acc: 0.9750 - val_loss: 5.3645 - val_acc: 0.3171\n",
            "\n",
            "Epoch 01559: val_acc did not improve from 0.97561\n",
            "Epoch 1560/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.1767 - acc: 0.9250 - val_loss: 7.1699 - val_acc: 0.2683\n",
            "\n",
            "Epoch 01560: val_acc did not improve from 0.97561\n",
            "Epoch 1561/2000\n",
            "5/5 [==============================] - 1s 273ms/step - loss: 0.0698 - acc: 1.0000 - val_loss: 6.2132 - val_acc: 0.2439\n",
            "\n",
            "Epoch 01561: val_acc did not improve from 0.97561\n",
            "Epoch 1562/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.1636 - acc: 0.9250 - val_loss: 5.9641 - val_acc: 0.2683\n",
            "\n",
            "Epoch 01562: val_acc did not improve from 0.97561\n",
            "Epoch 1563/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.1644 - acc: 0.9500 - val_loss: 4.8548 - val_acc: 0.3659\n",
            "\n",
            "Epoch 01563: val_acc did not improve from 0.97561\n",
            "Epoch 1564/2000\n",
            "5/5 [==============================] - 1s 258ms/step - loss: 0.1211 - acc: 0.9750 - val_loss: 3.3887 - val_acc: 0.4634\n",
            "\n",
            "Epoch 01564: val_acc did not improve from 0.97561\n",
            "Epoch 1565/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.0441 - acc: 1.0000 - val_loss: 0.4963 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01565: val_acc did not improve from 0.97561\n",
            "Epoch 1566/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.0915 - acc: 0.9500 - val_loss: 0.2187 - val_acc: 0.9268\n",
            "\n",
            "Epoch 01566: val_acc did not improve from 0.97561\n",
            "Epoch 1567/2000\n",
            "5/5 [==============================] - 1s 258ms/step - loss: 0.0591 - acc: 0.9750 - val_loss: 0.3340 - val_acc: 0.9024\n",
            "\n",
            "Epoch 01567: val_acc did not improve from 0.97561\n",
            "Epoch 1568/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.0703 - acc: 0.9750 - val_loss: 0.2485 - val_acc: 0.9268\n",
            "\n",
            "Epoch 01568: val_acc did not improve from 0.97561\n",
            "Epoch 1569/2000\n",
            "5/5 [==============================] - 1s 270ms/step - loss: 0.0368 - acc: 1.0000 - val_loss: 0.2508 - val_acc: 0.9268\n",
            "\n",
            "Epoch 01569: val_acc did not improve from 0.97561\n",
            "Epoch 1570/2000\n",
            "5/5 [==============================] - 1s 280ms/step - loss: 0.0885 - acc: 0.9500 - val_loss: 0.4308 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01570: val_acc did not improve from 0.97561\n",
            "Epoch 1571/2000\n",
            "5/5 [==============================] - 1s 281ms/step - loss: 0.0982 - acc: 0.9500 - val_loss: 0.7127 - val_acc: 0.8049\n",
            "\n",
            "Epoch 01571: val_acc did not improve from 0.97561\n",
            "Epoch 1572/2000\n",
            "5/5 [==============================] - 1s 279ms/step - loss: 0.0650 - acc: 0.9750 - val_loss: 0.7631 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01572: val_acc did not improve from 0.97561\n",
            "Epoch 1573/2000\n",
            "5/5 [==============================] - 1s 277ms/step - loss: 0.0707 - acc: 0.9750 - val_loss: 0.6519 - val_acc: 0.8049\n",
            "\n",
            "Epoch 01573: val_acc did not improve from 0.97561\n",
            "Epoch 1574/2000\n",
            "5/5 [==============================] - 1s 278ms/step - loss: 0.0530 - acc: 0.9750 - val_loss: 0.2365 - val_acc: 0.9268\n",
            "\n",
            "Epoch 01574: val_acc did not improve from 0.97561\n",
            "Epoch 1575/2000\n",
            "5/5 [==============================] - 1s 272ms/step - loss: 0.0406 - acc: 0.9750 - val_loss: 0.1800 - val_acc: 0.9268\n",
            "\n",
            "Epoch 01575: val_acc did not improve from 0.97561\n",
            "Epoch 1576/2000\n",
            "5/5 [==============================] - 1s 279ms/step - loss: 0.0764 - acc: 0.9500 - val_loss: 0.2512 - val_acc: 0.9268\n",
            "\n",
            "Epoch 01576: val_acc did not improve from 0.97561\n",
            "Epoch 1577/2000\n",
            "5/5 [==============================] - 1s 271ms/step - loss: 0.0263 - acc: 1.0000 - val_loss: 0.4927 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01577: val_acc did not improve from 0.97561\n",
            "Epoch 1578/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.0361 - acc: 1.0000 - val_loss: 0.6116 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01578: val_acc did not improve from 0.97561\n",
            "Epoch 1579/2000\n",
            "5/5 [==============================] - 1s 271ms/step - loss: 0.0280 - acc: 1.0000 - val_loss: 0.5249 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01579: val_acc did not improve from 0.97561\n",
            "Epoch 1580/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.1147 - acc: 0.9500 - val_loss: 0.6381 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01580: val_acc did not improve from 0.97561\n",
            "Epoch 1581/2000\n",
            "5/5 [==============================] - 1s 256ms/step - loss: 0.0812 - acc: 0.9750 - val_loss: 1.1584 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01581: val_acc did not improve from 0.97561\n",
            "Epoch 1582/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.1373 - acc: 0.9500 - val_loss: 0.7816 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01582: val_acc did not improve from 0.97561\n",
            "Epoch 1583/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.1107 - acc: 0.9750 - val_loss: 2.9376 - val_acc: 0.3659\n",
            "\n",
            "Epoch 01583: val_acc did not improve from 0.97561\n",
            "Epoch 1584/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.1904 - acc: 0.9500 - val_loss: 4.7652 - val_acc: 0.2927\n",
            "\n",
            "Epoch 01584: val_acc did not improve from 0.97561\n",
            "Epoch 1585/2000\n",
            "5/5 [==============================] - 1s 251ms/step - loss: 0.2326 - acc: 0.9250 - val_loss: 5.1111 - val_acc: 0.2927\n",
            "\n",
            "Epoch 01585: val_acc did not improve from 0.97561\n",
            "Epoch 1586/2000\n",
            "5/5 [==============================] - 1s 247ms/step - loss: 0.0595 - acc: 0.9750 - val_loss: 4.8468 - val_acc: 0.3902\n",
            "\n",
            "Epoch 01586: val_acc did not improve from 0.97561\n",
            "Epoch 1587/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.1588 - acc: 0.9500 - val_loss: 5.0104 - val_acc: 0.3415\n",
            "\n",
            "Epoch 01587: val_acc did not improve from 0.97561\n",
            "Epoch 1588/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.0438 - acc: 0.9750 - val_loss: 4.2320 - val_acc: 0.3415\n",
            "\n",
            "Epoch 01588: val_acc did not improve from 0.97561\n",
            "Epoch 1589/2000\n",
            "5/5 [==============================] - 1s 274ms/step - loss: 0.2036 - acc: 0.9000 - val_loss: 0.4661 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01589: val_acc did not improve from 0.97561\n",
            "Epoch 1590/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.0862 - acc: 0.9500 - val_loss: 1.0010 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01590: val_acc did not improve from 0.97561\n",
            "Epoch 1591/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.1167 - acc: 0.9500 - val_loss: 1.0343 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01591: val_acc did not improve from 0.97561\n",
            "Epoch 1592/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.0287 - acc: 1.0000 - val_loss: 0.7631 - val_acc: 0.8049\n",
            "\n",
            "Epoch 01592: val_acc did not improve from 0.97561\n",
            "Epoch 1593/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.0691 - acc: 0.9750 - val_loss: 0.5713 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01593: val_acc did not improve from 0.97561\n",
            "Epoch 1594/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.0084 - acc: 1.0000 - val_loss: 0.6609 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01594: val_acc did not improve from 0.97561\n",
            "Epoch 1595/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.2549 - acc: 0.9250 - val_loss: 0.6842 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01595: val_acc did not improve from 0.97561\n",
            "Epoch 1596/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.2061 - acc: 0.9000 - val_loss: 0.7491 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01596: val_acc did not improve from 0.97561\n",
            "Epoch 1597/2000\n",
            "5/5 [==============================] - 1s 251ms/step - loss: 0.1071 - acc: 0.9750 - val_loss: 1.2727 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01597: val_acc did not improve from 0.97561\n",
            "Epoch 1598/2000\n",
            "5/5 [==============================] - 1s 250ms/step - loss: 0.0281 - acc: 1.0000 - val_loss: 1.8371 - val_acc: 0.7073\n",
            "\n",
            "Epoch 01598: val_acc did not improve from 0.97561\n",
            "Epoch 1599/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.0252 - acc: 1.0000 - val_loss: 2.2584 - val_acc: 0.7073\n",
            "\n",
            "Epoch 01599: val_acc did not improve from 0.97561\n",
            "Epoch 1600/2000\n",
            "5/5 [==============================] - 1s 270ms/step - loss: 0.2101 - acc: 0.8750 - val_loss: 2.4103 - val_acc: 0.7317\n",
            "\n",
            "Epoch 01600: val_acc did not improve from 0.97561\n",
            "Epoch 1601/2000\n",
            "5/5 [==============================] - 1s 271ms/step - loss: 0.0593 - acc: 0.9750 - val_loss: 3.0419 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01601: val_acc did not improve from 0.97561\n",
            "Epoch 1602/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.1840 - acc: 0.9500 - val_loss: 1.3136 - val_acc: 0.6585\n",
            "\n",
            "Epoch 01602: val_acc did not improve from 0.97561\n",
            "Epoch 1603/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.1020 - acc: 0.9750 - val_loss: 2.2048 - val_acc: 0.6585\n",
            "\n",
            "Epoch 01603: val_acc did not improve from 0.97561\n",
            "Epoch 1604/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.0399 - acc: 1.0000 - val_loss: 2.4195 - val_acc: 0.6098\n",
            "\n",
            "Epoch 01604: val_acc did not improve from 0.97561\n",
            "Epoch 1605/2000\n",
            "5/5 [==============================] - 1s 254ms/step - loss: 0.0911 - acc: 0.9750 - val_loss: 1.9913 - val_acc: 0.7073\n",
            "\n",
            "Epoch 01605: val_acc did not improve from 0.97561\n",
            "Epoch 1606/2000\n",
            "5/5 [==============================] - 1s 253ms/step - loss: 0.1123 - acc: 0.9500 - val_loss: 2.3214 - val_acc: 0.6341\n",
            "\n",
            "Epoch 01606: val_acc did not improve from 0.97561\n",
            "Epoch 1607/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.0220 - acc: 1.0000 - val_loss: 1.9353 - val_acc: 0.6585\n",
            "\n",
            "Epoch 01607: val_acc did not improve from 0.97561\n",
            "Epoch 1608/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.0462 - acc: 1.0000 - val_loss: 1.8469 - val_acc: 0.6585\n",
            "\n",
            "Epoch 01608: val_acc did not improve from 0.97561\n",
            "Epoch 1609/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.0526 - acc: 1.0000 - val_loss: 1.0616 - val_acc: 0.7317\n",
            "\n",
            "Epoch 01609: val_acc did not improve from 0.97561\n",
            "Epoch 1610/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.0255 - acc: 1.0000 - val_loss: 1.0771 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01610: val_acc did not improve from 0.97561\n",
            "Epoch 1611/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.0298 - acc: 1.0000 - val_loss: 1.0034 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01611: val_acc did not improve from 0.97561\n",
            "Epoch 1612/2000\n",
            "5/5 [==============================] - 1s 273ms/step - loss: 0.0504 - acc: 1.0000 - val_loss: 0.7268 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01612: val_acc did not improve from 0.97561\n",
            "Epoch 1613/2000\n",
            "5/5 [==============================] - 1s 255ms/step - loss: 0.1294 - acc: 0.9500 - val_loss: 0.5900 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01613: val_acc did not improve from 0.97561\n",
            "Epoch 1614/2000\n",
            "5/5 [==============================] - 1s 253ms/step - loss: 0.0177 - acc: 1.0000 - val_loss: 0.5843 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01614: val_acc did not improve from 0.97561\n",
            "Epoch 1615/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.0755 - acc: 0.9750 - val_loss: 0.4014 - val_acc: 0.8780\n",
            "\n",
            "Epoch 01615: val_acc did not improve from 0.97561\n",
            "Epoch 1616/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.0327 - acc: 1.0000 - val_loss: 0.3726 - val_acc: 0.8780\n",
            "\n",
            "Epoch 01616: val_acc did not improve from 0.97561\n",
            "Epoch 1617/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.0237 - acc: 1.0000 - val_loss: 0.3405 - val_acc: 0.8780\n",
            "\n",
            "Epoch 01617: val_acc did not improve from 0.97561\n",
            "Epoch 1618/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.0293 - acc: 1.0000 - val_loss: 0.2851 - val_acc: 0.8780\n",
            "\n",
            "Epoch 01618: val_acc did not improve from 0.97561\n",
            "Epoch 1619/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.0244 - acc: 1.0000 - val_loss: 0.3288 - val_acc: 0.8780\n",
            "\n",
            "Epoch 01619: val_acc did not improve from 0.97561\n",
            "Epoch 1620/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.0253 - acc: 1.0000 - val_loss: 0.4171 - val_acc: 0.8780\n",
            "\n",
            "Epoch 01620: val_acc did not improve from 0.97561\n",
            "Epoch 1621/2000\n",
            "5/5 [==============================] - 1s 254ms/step - loss: 0.0676 - acc: 0.9750 - val_loss: 0.4834 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01621: val_acc did not improve from 0.97561\n",
            "Epoch 1622/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.0161 - acc: 1.0000 - val_loss: 0.8531 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01622: val_acc did not improve from 0.97561\n",
            "Epoch 1623/2000\n",
            "5/5 [==============================] - 1s 273ms/step - loss: 0.1053 - acc: 0.9750 - val_loss: 0.2581 - val_acc: 0.9268\n",
            "\n",
            "Epoch 01623: val_acc did not improve from 0.97561\n",
            "Epoch 1624/2000\n",
            "5/5 [==============================] - 1s 278ms/step - loss: 0.0678 - acc: 0.9750 - val_loss: 7.3252 - val_acc: 0.2683\n",
            "\n",
            "Epoch 01624: val_acc did not improve from 0.97561\n",
            "Epoch 1625/2000\n",
            "5/5 [==============================] - 1s 272ms/step - loss: 0.1304 - acc: 0.9500 - val_loss: 8.5918 - val_acc: 0.2195\n",
            "\n",
            "Epoch 01625: val_acc did not improve from 0.97561\n",
            "Epoch 1626/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.1559 - acc: 0.9500 - val_loss: 7.9745 - val_acc: 0.2439\n",
            "\n",
            "Epoch 01626: val_acc did not improve from 0.97561\n",
            "Epoch 1627/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.0764 - acc: 0.9750 - val_loss: 1.1180 - val_acc: 0.6829\n",
            "\n",
            "Epoch 01627: val_acc did not improve from 0.97561\n",
            "Epoch 1628/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.0590 - acc: 0.9750 - val_loss: 1.6644 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01628: val_acc did not improve from 0.97561\n",
            "Epoch 1629/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.0054 - acc: 1.0000 - val_loss: 2.0371 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01629: val_acc did not improve from 0.97561\n",
            "Epoch 1630/2000\n",
            "5/5 [==============================] - 1s 256ms/step - loss: 0.0286 - acc: 1.0000 - val_loss: 2.4590 - val_acc: 0.6829\n",
            "\n",
            "Epoch 01630: val_acc did not improve from 0.97561\n",
            "Epoch 1631/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.0906 - acc: 0.9500 - val_loss: 2.4576 - val_acc: 0.6829\n",
            "\n",
            "Epoch 01631: val_acc did not improve from 0.97561\n",
            "Epoch 1632/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.0694 - acc: 0.9750 - val_loss: 1.7700 - val_acc: 0.7317\n",
            "\n",
            "Epoch 01632: val_acc did not improve from 0.97561\n",
            "Epoch 1633/2000\n",
            "5/5 [==============================] - 1s 258ms/step - loss: 0.1128 - acc: 0.9750 - val_loss: 1.3899 - val_acc: 0.7073\n",
            "\n",
            "Epoch 01633: val_acc did not improve from 0.97561\n",
            "Epoch 1634/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.0201 - acc: 1.0000 - val_loss: 1.1656 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01634: val_acc did not improve from 0.97561\n",
            "Epoch 1635/2000\n",
            "5/5 [==============================] - 1s 258ms/step - loss: 0.0400 - acc: 1.0000 - val_loss: 0.7364 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01635: val_acc did not improve from 0.97561\n",
            "Epoch 1636/2000\n",
            "5/5 [==============================] - 1s 254ms/step - loss: 0.1339 - acc: 0.9500 - val_loss: 0.6562 - val_acc: 0.8049\n",
            "\n",
            "Epoch 01636: val_acc did not improve from 0.97561\n",
            "Epoch 1637/2000\n",
            "5/5 [==============================] - 1s 246ms/step - loss: 0.0878 - acc: 0.9750 - val_loss: 3.5587 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01637: val_acc did not improve from 0.97561\n",
            "Epoch 1638/2000\n",
            "5/5 [==============================] - 1s 247ms/step - loss: 0.0375 - acc: 1.0000 - val_loss: 3.6591 - val_acc: 0.5122\n",
            "\n",
            "Epoch 01638: val_acc did not improve from 0.97561\n",
            "Epoch 1639/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.0272 - acc: 1.0000 - val_loss: 1.9867 - val_acc: 0.5610\n",
            "\n",
            "Epoch 01639: val_acc did not improve from 0.97561\n",
            "Epoch 1640/2000\n",
            "5/5 [==============================] - 1s 270ms/step - loss: 0.0729 - acc: 0.9750 - val_loss: 0.7014 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01640: val_acc did not improve from 0.97561\n",
            "Epoch 1641/2000\n",
            "5/5 [==============================] - 1s 255ms/step - loss: 0.0284 - acc: 1.0000 - val_loss: 0.7663 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01641: val_acc did not improve from 0.97561\n",
            "Epoch 1642/2000\n",
            "5/5 [==============================] - 1s 254ms/step - loss: 0.1756 - acc: 0.9000 - val_loss: 2.8105 - val_acc: 0.5366\n",
            "\n",
            "Epoch 01642: val_acc did not improve from 0.97561\n",
            "Epoch 1643/2000\n",
            "5/5 [==============================] - 1s 252ms/step - loss: 0.0099 - acc: 1.0000 - val_loss: 5.8651 - val_acc: 0.4390\n",
            "\n",
            "Epoch 01643: val_acc did not improve from 0.97561\n",
            "Epoch 1644/2000\n",
            "5/5 [==============================] - 1s 254ms/step - loss: 0.1691 - acc: 0.9000 - val_loss: 6.4318 - val_acc: 0.3902\n",
            "\n",
            "Epoch 01644: val_acc did not improve from 0.97561\n",
            "Epoch 1645/2000\n",
            "5/5 [==============================] - 1s 250ms/step - loss: 0.0557 - acc: 0.9750 - val_loss: 4.5676 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01645: val_acc did not improve from 0.97561\n",
            "Epoch 1646/2000\n",
            "5/5 [==============================] - 1s 248ms/step - loss: 0.0682 - acc: 1.0000 - val_loss: 1.0006 - val_acc: 0.7073\n",
            "\n",
            "Epoch 01646: val_acc did not improve from 0.97561\n",
            "Epoch 1647/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.1933 - acc: 0.9250 - val_loss: 0.5193 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01647: val_acc did not improve from 0.97561\n",
            "Epoch 1648/2000\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 0.0669 - acc: 0.9750 - val_loss: 0.2734 - val_acc: 0.8780\n",
            "\n",
            "Epoch 01648: val_acc did not improve from 0.97561\n",
            "Epoch 1649/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.1071 - acc: 0.9750 - val_loss: 7.9818 - val_acc: 0.2927\n",
            "\n",
            "Epoch 01649: val_acc did not improve from 0.97561\n",
            "Epoch 1650/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.2680 - acc: 0.9500 - val_loss: 9.6663 - val_acc: 0.2195\n",
            "\n",
            "Epoch 01650: val_acc did not improve from 0.97561\n",
            "Epoch 1651/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.0151 - acc: 1.0000 - val_loss: 10.4138 - val_acc: 0.2195\n",
            "\n",
            "Epoch 01651: val_acc did not improve from 0.97561\n",
            "Epoch 1652/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.0814 - acc: 0.9750 - val_loss: 10.5075 - val_acc: 0.2195\n",
            "\n",
            "Epoch 01652: val_acc did not improve from 0.97561\n",
            "Epoch 1653/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.0713 - acc: 0.9750 - val_loss: 9.2776 - val_acc: 0.2439\n",
            "\n",
            "Epoch 01653: val_acc did not improve from 0.97561\n",
            "Epoch 1654/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.0186 - acc: 1.0000 - val_loss: 8.1968 - val_acc: 0.2927\n",
            "\n",
            "Epoch 01654: val_acc did not improve from 0.97561\n",
            "Epoch 1655/2000\n",
            "5/5 [==============================] - 1s 258ms/step - loss: 0.0117 - acc: 1.0000 - val_loss: 7.2558 - val_acc: 0.3171\n",
            "\n",
            "Epoch 01655: val_acc did not improve from 0.97561\n",
            "Epoch 1656/2000\n",
            "5/5 [==============================] - 1s 258ms/step - loss: 0.0284 - acc: 1.0000 - val_loss: 6.6136 - val_acc: 0.3415\n",
            "\n",
            "Epoch 01656: val_acc did not improve from 0.97561\n",
            "Epoch 1657/2000\n",
            "5/5 [==============================] - 1s 249ms/step - loss: 0.1407 - acc: 0.9500 - val_loss: 7.8605 - val_acc: 0.2927\n",
            "\n",
            "Epoch 01657: val_acc did not improve from 0.97561\n",
            "Epoch 1658/2000\n",
            "5/5 [==============================] - 1s 249ms/step - loss: 0.0375 - acc: 0.9750 - val_loss: 8.0854 - val_acc: 0.2927\n",
            "\n",
            "Epoch 01658: val_acc did not improve from 0.97561\n",
            "Epoch 1659/2000\n",
            "5/5 [==============================] - 1s 255ms/step - loss: 0.0276 - acc: 1.0000 - val_loss: 8.5175 - val_acc: 0.2927\n",
            "\n",
            "Epoch 01659: val_acc did not improve from 0.97561\n",
            "Epoch 1660/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.0601 - acc: 0.9500 - val_loss: 8.9859 - val_acc: 0.2439\n",
            "\n",
            "Epoch 01660: val_acc did not improve from 0.97561\n",
            "Epoch 1661/2000\n",
            "5/5 [==============================] - 1s 243ms/step - loss: 0.0361 - acc: 1.0000 - val_loss: 9.2928 - val_acc: 0.2195\n",
            "\n",
            "Epoch 01661: val_acc did not improve from 0.97561\n",
            "Epoch 1662/2000\n",
            "5/5 [==============================] - 1s 244ms/step - loss: 0.0667 - acc: 0.9500 - val_loss: 9.0063 - val_acc: 0.2195\n",
            "\n",
            "Epoch 01662: val_acc did not improve from 0.97561\n",
            "Epoch 1663/2000\n",
            "5/5 [==============================] - 1s 242ms/step - loss: 0.0238 - acc: 1.0000 - val_loss: 8.1418 - val_acc: 0.2439\n",
            "\n",
            "Epoch 01663: val_acc did not improve from 0.97561\n",
            "Epoch 1664/2000\n",
            "5/5 [==============================] - 1s 246ms/step - loss: 0.0630 - acc: 0.9500 - val_loss: 0.3034 - val_acc: 0.8780\n",
            "\n",
            "Epoch 01664: val_acc did not improve from 0.97561\n",
            "Epoch 1665/2000\n",
            "5/5 [==============================] - 1s 252ms/step - loss: 0.0691 - acc: 0.9500 - val_loss: 0.5910 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01665: val_acc did not improve from 0.97561\n",
            "Epoch 1666/2000\n",
            "5/5 [==============================] - 1s 251ms/step - loss: 0.4199 - acc: 0.9000 - val_loss: 0.2947 - val_acc: 0.9268\n",
            "\n",
            "Epoch 01666: val_acc did not improve from 0.97561\n",
            "Epoch 1667/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.1988 - acc: 0.9250 - val_loss: 4.8600 - val_acc: 0.2927\n",
            "\n",
            "Epoch 01667: val_acc did not improve from 0.97561\n",
            "Epoch 1668/2000\n",
            "5/5 [==============================] - 1s 273ms/step - loss: 0.0624 - acc: 0.9750 - val_loss: 6.0322 - val_acc: 0.2683\n",
            "\n",
            "Epoch 01668: val_acc did not improve from 0.97561\n",
            "Epoch 1669/2000\n",
            "5/5 [==============================] - 1s 273ms/step - loss: 0.0223 - acc: 1.0000 - val_loss: 3.5646 - val_acc: 0.3659\n",
            "\n",
            "Epoch 01669: val_acc did not improve from 0.97561\n",
            "Epoch 1670/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.0150 - acc: 1.0000 - val_loss: 1.5312 - val_acc: 0.6098\n",
            "\n",
            "Epoch 01670: val_acc did not improve from 0.97561\n",
            "Epoch 1671/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.0534 - acc: 0.9750 - val_loss: 0.3677 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01671: val_acc did not improve from 0.97561\n",
            "Epoch 1672/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.0132 - acc: 1.0000 - val_loss: 0.1053 - val_acc: 0.9512\n",
            "\n",
            "Epoch 01672: val_acc did not improve from 0.97561\n",
            "Epoch 1673/2000\n",
            "5/5 [==============================] - 1s 246ms/step - loss: 0.0924 - acc: 0.9250 - val_loss: 0.3965 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01673: val_acc did not improve from 0.97561\n",
            "Epoch 1674/2000\n",
            "5/5 [==============================] - 1s 245ms/step - loss: 0.0500 - acc: 0.9750 - val_loss: 1.1574 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01674: val_acc did not improve from 0.97561\n",
            "Epoch 1675/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.0085 - acc: 1.0000 - val_loss: 1.5681 - val_acc: 0.7317\n",
            "\n",
            "Epoch 01675: val_acc did not improve from 0.97561\n",
            "Epoch 1676/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.0099 - acc: 1.0000 - val_loss: 1.8105 - val_acc: 0.7073\n",
            "\n",
            "Epoch 01676: val_acc did not improve from 0.97561\n",
            "Epoch 1677/2000\n",
            "5/5 [==============================] - 1s 255ms/step - loss: 0.0328 - acc: 1.0000 - val_loss: 1.7447 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01677: val_acc did not improve from 0.97561\n",
            "Epoch 1678/2000\n",
            "5/5 [==============================] - 1s 255ms/step - loss: 0.0482 - acc: 0.9750 - val_loss: 1.6242 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01678: val_acc did not improve from 0.97561\n",
            "Epoch 1679/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.0311 - acc: 1.0000 - val_loss: 1.3243 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01679: val_acc did not improve from 0.97561\n",
            "Epoch 1680/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.0268 - acc: 1.0000 - val_loss: 0.8836 - val_acc: 0.8049\n",
            "\n",
            "Epoch 01680: val_acc did not improve from 0.97561\n",
            "Epoch 1681/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.0281 - acc: 1.0000 - val_loss: 0.5719 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01681: val_acc did not improve from 0.97561\n",
            "Epoch 1682/2000\n",
            "5/5 [==============================] - 1s 271ms/step - loss: 0.0210 - acc: 1.0000 - val_loss: 0.4346 - val_acc: 0.8780\n",
            "\n",
            "Epoch 01682: val_acc did not improve from 0.97561\n",
            "Epoch 1683/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.0152 - acc: 1.0000 - val_loss: 0.3766 - val_acc: 0.9024\n",
            "\n",
            "Epoch 01683: val_acc did not improve from 0.97561\n",
            "Epoch 1684/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.1435 - acc: 0.9500 - val_loss: 0.2185 - val_acc: 0.9268\n",
            "\n",
            "Epoch 01684: val_acc did not improve from 0.97561\n",
            "Epoch 1685/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.0878 - acc: 0.9500 - val_loss: 1.7256 - val_acc: 0.5854\n",
            "\n",
            "Epoch 01685: val_acc did not improve from 0.97561\n",
            "Epoch 1686/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.0633 - acc: 0.9750 - val_loss: 5.4024 - val_acc: 0.3171\n",
            "\n",
            "Epoch 01686: val_acc did not improve from 0.97561\n",
            "Epoch 1687/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.0611 - acc: 0.9750 - val_loss: 2.0802 - val_acc: 0.5366\n",
            "\n",
            "Epoch 01687: val_acc did not improve from 0.97561\n",
            "Epoch 1688/2000\n",
            "5/5 [==============================] - 1s 255ms/step - loss: 0.0741 - acc: 0.9750 - val_loss: 0.2088 - val_acc: 0.8780\n",
            "\n",
            "Epoch 01688: val_acc did not improve from 0.97561\n",
            "Epoch 1689/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.0994 - acc: 0.9750 - val_loss: 0.1267 - val_acc: 0.9756\n",
            "\n",
            "Epoch 01689: val_acc did not improve from 0.97561\n",
            "Epoch 1690/2000\n",
            "5/5 [==============================] - 1s 258ms/step - loss: 0.0587 - acc: 1.0000 - val_loss: 0.6818 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01690: val_acc did not improve from 0.97561\n",
            "Epoch 1691/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.2188 - acc: 0.9000 - val_loss: 4.3554 - val_acc: 0.4634\n",
            "\n",
            "Epoch 01691: val_acc did not improve from 0.97561\n",
            "Epoch 1692/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.0429 - acc: 0.9750 - val_loss: 4.7744 - val_acc: 0.4634\n",
            "\n",
            "Epoch 01692: val_acc did not improve from 0.97561\n",
            "Epoch 1693/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.0823 - acc: 0.9750 - val_loss: 3.4212 - val_acc: 0.5122\n",
            "\n",
            "Epoch 01693: val_acc did not improve from 0.97561\n",
            "Epoch 1694/2000\n",
            "5/5 [==============================] - 1s 272ms/step - loss: 0.0221 - acc: 1.0000 - val_loss: 0.4763 - val_acc: 0.8780\n",
            "\n",
            "Epoch 01694: val_acc did not improve from 0.97561\n",
            "Epoch 1695/2000\n",
            "5/5 [==============================] - 1s 275ms/step - loss: 0.0305 - acc: 1.0000 - val_loss: 1.0739 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01695: val_acc did not improve from 0.97561\n",
            "Epoch 1696/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.0307 - acc: 0.9750 - val_loss: 1.2963 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01696: val_acc did not improve from 0.97561\n",
            "Epoch 1697/2000\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 0.0347 - acc: 1.0000 - val_loss: 1.3650 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01697: val_acc did not improve from 0.97561\n",
            "Epoch 1698/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.0302 - acc: 1.0000 - val_loss: 1.5057 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01698: val_acc did not improve from 0.97561\n",
            "Epoch 1699/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.0561 - acc: 0.9750 - val_loss: 1.3882 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01699: val_acc did not improve from 0.97561\n",
            "Epoch 1700/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.0284 - acc: 1.0000 - val_loss: 1.3950 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01700: val_acc did not improve from 0.97561\n",
            "Epoch 1701/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.0129 - acc: 1.0000 - val_loss: 1.4224 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01701: val_acc did not improve from 0.97561\n",
            "Epoch 1702/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 1.4532 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01702: val_acc did not improve from 0.97561\n",
            "Epoch 1703/2000\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 0.0605 - acc: 0.9750 - val_loss: 1.4093 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01703: val_acc did not improve from 0.97561\n",
            "Epoch 1704/2000\n",
            "5/5 [==============================] - 1s 270ms/step - loss: 0.0483 - acc: 0.9750 - val_loss: 1.4015 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01704: val_acc did not improve from 0.97561\n",
            "Epoch 1705/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.0229 - acc: 1.0000 - val_loss: 1.4020 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01705: val_acc did not improve from 0.97561\n",
            "Epoch 1706/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.0330 - acc: 1.0000 - val_loss: 1.9962 - val_acc: 0.7073\n",
            "\n",
            "Epoch 01706: val_acc did not improve from 0.97561\n",
            "Epoch 1707/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.0271 - acc: 1.0000 - val_loss: 2.3447 - val_acc: 0.6585\n",
            "\n",
            "Epoch 01707: val_acc did not improve from 0.97561\n",
            "Epoch 1708/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.0899 - acc: 0.9500 - val_loss: 1.1445 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01708: val_acc did not improve from 0.97561\n",
            "Epoch 1709/2000\n",
            "5/5 [==============================] - 1s 241ms/step - loss: 0.0401 - acc: 1.0000 - val_loss: 0.4572 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01709: val_acc did not improve from 0.97561\n",
            "Epoch 1710/2000\n",
            "5/5 [==============================] - 1s 242ms/step - loss: 0.0315 - acc: 1.0000 - val_loss: 1.0511 - val_acc: 0.6829\n",
            "\n",
            "Epoch 01710: val_acc did not improve from 0.97561\n",
            "Epoch 1711/2000\n",
            "5/5 [==============================] - 1s 248ms/step - loss: 0.0576 - acc: 0.9750 - val_loss: 2.8564 - val_acc: 0.5122\n",
            "\n",
            "Epoch 01711: val_acc did not improve from 0.97561\n",
            "Epoch 1712/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.0409 - acc: 1.0000 - val_loss: 0.2972 - val_acc: 0.9268\n",
            "\n",
            "Epoch 01712: val_acc did not improve from 0.97561\n",
            "Epoch 1713/2000\n",
            "5/5 [==============================] - 1s 273ms/step - loss: 0.0773 - acc: 0.9500 - val_loss: 0.6387 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01713: val_acc did not improve from 0.97561\n",
            "Epoch 1714/2000\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 0.0568 - acc: 0.9750 - val_loss: 0.9287 - val_acc: 0.7317\n",
            "\n",
            "Epoch 01714: val_acc did not improve from 0.97561\n",
            "Epoch 1715/2000\n",
            "5/5 [==============================] - 1s 272ms/step - loss: 0.1203 - acc: 0.9500 - val_loss: 0.6458 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01715: val_acc did not improve from 0.97561\n",
            "Epoch 1716/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.0229 - acc: 1.0000 - val_loss: 0.7478 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01716: val_acc did not improve from 0.97561\n",
            "Epoch 1717/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.0415 - acc: 1.0000 - val_loss: 0.5426 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01717: val_acc did not improve from 0.97561\n",
            "Epoch 1718/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.0644 - acc: 0.9750 - val_loss: 0.2861 - val_acc: 0.9268\n",
            "\n",
            "Epoch 01718: val_acc did not improve from 0.97561\n",
            "Epoch 1719/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.0190 - acc: 1.0000 - val_loss: 0.3556 - val_acc: 0.9024\n",
            "\n",
            "Epoch 01719: val_acc did not improve from 0.97561\n",
            "Epoch 1720/2000\n",
            "5/5 [==============================] - 1s 273ms/step - loss: 0.2753 - acc: 0.9250 - val_loss: 0.6469 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01720: val_acc did not improve from 0.97561\n",
            "Epoch 1721/2000\n",
            "5/5 [==============================] - 1s 276ms/step - loss: 0.0220 - acc: 1.0000 - val_loss: 1.1579 - val_acc: 0.6829\n",
            "\n",
            "Epoch 01721: val_acc did not improve from 0.97561\n",
            "Epoch 1722/2000\n",
            "5/5 [==============================] - 1s 274ms/step - loss: 0.1233 - acc: 0.9500 - val_loss: 0.2142 - val_acc: 0.9024\n",
            "\n",
            "Epoch 01722: val_acc did not improve from 0.97561\n",
            "Epoch 1723/2000\n",
            "5/5 [==============================] - 1s 278ms/step - loss: 0.0222 - acc: 1.0000 - val_loss: 0.1705 - val_acc: 0.9512\n",
            "\n",
            "Epoch 01723: val_acc did not improve from 0.97561\n",
            "Epoch 1724/2000\n",
            "5/5 [==============================] - 1s 279ms/step - loss: 0.0689 - acc: 0.9750 - val_loss: 0.2518 - val_acc: 0.9268\n",
            "\n",
            "Epoch 01724: val_acc did not improve from 0.97561\n",
            "Epoch 1725/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.0217 - acc: 1.0000 - val_loss: 0.4721 - val_acc: 0.8049\n",
            "\n",
            "Epoch 01725: val_acc did not improve from 0.97561\n",
            "Epoch 1726/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.4936 - val_acc: 0.8049\n",
            "\n",
            "Epoch 01726: val_acc did not improve from 0.97561\n",
            "Epoch 1727/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.0298 - acc: 0.9750 - val_loss: 1.9731 - val_acc: 0.5610\n",
            "\n",
            "Epoch 01727: val_acc did not improve from 0.97561\n",
            "Epoch 1728/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.3315 - acc: 0.9500 - val_loss: 6.8973 - val_acc: 0.4390\n",
            "\n",
            "Epoch 01728: val_acc did not improve from 0.97561\n",
            "Epoch 1729/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.1661 - acc: 0.9250 - val_loss: 7.2573 - val_acc: 0.4146\n",
            "\n",
            "Epoch 01729: val_acc did not improve from 0.97561\n",
            "Epoch 1730/2000\n",
            "5/5 [==============================] - 1s 275ms/step - loss: 0.0317 - acc: 1.0000 - val_loss: 7.1405 - val_acc: 0.4390\n",
            "\n",
            "Epoch 01730: val_acc did not improve from 0.97561\n",
            "Epoch 1731/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.0333 - acc: 1.0000 - val_loss: 7.3282 - val_acc: 0.4390\n",
            "\n",
            "Epoch 01731: val_acc did not improve from 0.97561\n",
            "Epoch 1732/2000\n",
            "5/5 [==============================] - 1s 270ms/step - loss: 0.2157 - acc: 0.9250 - val_loss: 8.8288 - val_acc: 0.2683\n",
            "\n",
            "Epoch 01732: val_acc did not improve from 0.97561\n",
            "Epoch 1733/2000\n",
            "5/5 [==============================] - 1s 274ms/step - loss: 0.2668 - acc: 0.9250 - val_loss: 9.5102 - val_acc: 0.2195\n",
            "\n",
            "Epoch 01733: val_acc did not improve from 0.97561\n",
            "Epoch 1734/2000\n",
            "5/5 [==============================] - 1s 277ms/step - loss: 0.2829 - acc: 0.9250 - val_loss: 8.4394 - val_acc: 0.2683\n",
            "\n",
            "Epoch 01734: val_acc did not improve from 0.97561\n",
            "Epoch 1735/2000\n",
            "5/5 [==============================] - 1s 271ms/step - loss: 0.0325 - acc: 1.0000 - val_loss: 7.4710 - val_acc: 0.3171\n",
            "\n",
            "Epoch 01735: val_acc did not improve from 0.97561\n",
            "Epoch 1736/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.3995 - acc: 0.9000 - val_loss: 8.0119 - val_acc: 0.2439\n",
            "\n",
            "Epoch 01736: val_acc did not improve from 0.97561\n",
            "Epoch 1737/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.1027 - acc: 0.9500 - val_loss: 9.8368 - val_acc: 0.2439\n",
            "\n",
            "Epoch 01737: val_acc did not improve from 0.97561\n",
            "Epoch 1738/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.0485 - acc: 1.0000 - val_loss: 10.3623 - val_acc: 0.2195\n",
            "\n",
            "Epoch 01738: val_acc did not improve from 0.97561\n",
            "Epoch 1739/2000\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 0.1250 - acc: 0.9750 - val_loss: 9.5653 - val_acc: 0.2439\n",
            "\n",
            "Epoch 01739: val_acc did not improve from 0.97561\n",
            "Epoch 1740/2000\n",
            "5/5 [==============================] - 1s 270ms/step - loss: 0.0552 - acc: 1.0000 - val_loss: 8.1067 - val_acc: 0.2683\n",
            "\n",
            "Epoch 01740: val_acc did not improve from 0.97561\n",
            "Epoch 1741/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.1399 - acc: 0.9750 - val_loss: 7.9637 - val_acc: 0.2683\n",
            "\n",
            "Epoch 01741: val_acc did not improve from 0.97561\n",
            "Epoch 1742/2000\n",
            "5/5 [==============================] - 1s 272ms/step - loss: 0.3592 - acc: 0.9250 - val_loss: 8.4850 - val_acc: 0.2439\n",
            "\n",
            "Epoch 01742: val_acc did not improve from 0.97561\n",
            "Epoch 1743/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.0568 - acc: 0.9750 - val_loss: 9.0703 - val_acc: 0.2195\n",
            "\n",
            "Epoch 01743: val_acc did not improve from 0.97561\n",
            "Epoch 1744/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.0864 - acc: 0.9750 - val_loss: 9.0665 - val_acc: 0.2195\n",
            "\n",
            "Epoch 01744: val_acc did not improve from 0.97561\n",
            "Epoch 1745/2000\n",
            "5/5 [==============================] - 1s 272ms/step - loss: 0.0532 - acc: 1.0000 - val_loss: 8.4132 - val_acc: 0.2195\n",
            "\n",
            "Epoch 01745: val_acc did not improve from 0.97561\n",
            "Epoch 1746/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.1804 - acc: 0.9500 - val_loss: 0.6546 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01746: val_acc did not improve from 0.97561\n",
            "Epoch 1747/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.0497 - acc: 0.9750 - val_loss: 1.6710 - val_acc: 0.7073\n",
            "\n",
            "Epoch 01747: val_acc did not improve from 0.97561\n",
            "Epoch 1748/2000\n",
            "5/5 [==============================] - 1s 258ms/step - loss: 0.0840 - acc: 0.9750 - val_loss: 1.8489 - val_acc: 0.7073\n",
            "\n",
            "Epoch 01748: val_acc did not improve from 0.97561\n",
            "Epoch 1749/2000\n",
            "5/5 [==============================] - 1s 254ms/step - loss: 0.0363 - acc: 1.0000 - val_loss: 1.9741 - val_acc: 0.7317\n",
            "\n",
            "Epoch 01749: val_acc did not improve from 0.97561\n",
            "Epoch 1750/2000\n",
            "5/5 [==============================] - 1s 251ms/step - loss: 0.0943 - acc: 0.9500 - val_loss: 2.0740 - val_acc: 0.7073\n",
            "\n",
            "Epoch 01750: val_acc did not improve from 0.97561\n",
            "Epoch 1751/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.0670 - acc: 0.9750 - val_loss: 2.2393 - val_acc: 0.6341\n",
            "\n",
            "Epoch 01751: val_acc did not improve from 0.97561\n",
            "Epoch 1752/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.0608 - acc: 0.9750 - val_loss: 2.0973 - val_acc: 0.7073\n",
            "\n",
            "Epoch 01752: val_acc did not improve from 0.97561\n",
            "Epoch 1753/2000\n",
            "5/5 [==============================] - 1s 277ms/step - loss: 0.0534 - acc: 1.0000 - val_loss: 0.6997 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01753: val_acc did not improve from 0.97561\n",
            "Epoch 1754/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.0226 - acc: 1.0000 - val_loss: 0.3137 - val_acc: 0.9268\n",
            "\n",
            "Epoch 01754: val_acc did not improve from 0.97561\n",
            "Epoch 1755/2000\n",
            "5/5 [==============================] - 1s 271ms/step - loss: 0.0830 - acc: 0.9500 - val_loss: 0.3092 - val_acc: 0.9024\n",
            "\n",
            "Epoch 01755: val_acc did not improve from 0.97561\n",
            "Epoch 1756/2000\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 0.0151 - acc: 1.0000 - val_loss: 0.1944 - val_acc: 0.9512\n",
            "\n",
            "Epoch 01756: val_acc did not improve from 0.97561\n",
            "Epoch 1757/2000\n",
            "5/5 [==============================] - 1s 275ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.1646 - val_acc: 0.9512\n",
            "\n",
            "Epoch 01757: val_acc did not improve from 0.97561\n",
            "Epoch 1758/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.0257 - acc: 1.0000 - val_loss: 0.1856 - val_acc: 0.9268\n",
            "\n",
            "Epoch 01758: val_acc did not improve from 0.97561\n",
            "Epoch 1759/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.0554 - acc: 0.9750 - val_loss: 0.7571 - val_acc: 0.8049\n",
            "\n",
            "Epoch 01759: val_acc did not improve from 0.97561\n",
            "Epoch 1760/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.0724 - acc: 0.9500 - val_loss: 1.3116 - val_acc: 0.6585\n",
            "\n",
            "Epoch 01760: val_acc did not improve from 0.97561\n",
            "Epoch 1761/2000\n",
            "5/5 [==============================] - 1s 258ms/step - loss: 0.0193 - acc: 1.0000 - val_loss: 0.3946 - val_acc: 0.8780\n",
            "\n",
            "Epoch 01761: val_acc did not improve from 0.97561\n",
            "Epoch 1762/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.0141 - acc: 1.0000 - val_loss: 0.7817 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01762: val_acc did not improve from 0.97561\n",
            "Epoch 1763/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.0143 - acc: 1.0000 - val_loss: 0.8829 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01763: val_acc did not improve from 0.97561\n",
            "Epoch 1764/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.0940 - acc: 0.9750 - val_loss: 0.7586 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01764: val_acc did not improve from 0.97561\n",
            "Epoch 1765/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.7493 - val_acc: 0.8049\n",
            "\n",
            "Epoch 01765: val_acc did not improve from 0.97561\n",
            "Epoch 1766/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.0254 - acc: 1.0000 - val_loss: 0.7845 - val_acc: 0.8049\n",
            "\n",
            "Epoch 01766: val_acc did not improve from 0.97561\n",
            "Epoch 1767/2000\n",
            "5/5 [==============================] - 1s 255ms/step - loss: 0.0603 - acc: 0.9750 - val_loss: 0.6324 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01767: val_acc did not improve from 0.97561\n",
            "Epoch 1768/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.0242 - acc: 1.0000 - val_loss: 0.7306 - val_acc: 0.8049\n",
            "\n",
            "Epoch 01768: val_acc did not improve from 0.97561\n",
            "Epoch 1769/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.0219 - acc: 1.0000 - val_loss: 0.7635 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01769: val_acc did not improve from 0.97561\n",
            "Epoch 1770/2000\n",
            "5/5 [==============================] - 1s 271ms/step - loss: 0.0422 - acc: 0.9750 - val_loss: 0.8452 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01770: val_acc did not improve from 0.97561\n",
            "Epoch 1771/2000\n",
            "5/5 [==============================] - 1s 272ms/step - loss: 0.1962 - acc: 0.9250 - val_loss: 1.1263 - val_acc: 0.7317\n",
            "\n",
            "Epoch 01771: val_acc did not improve from 0.97561\n",
            "Epoch 1772/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.0727 - acc: 0.9750 - val_loss: 1.0944 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01772: val_acc did not improve from 0.97561\n",
            "Epoch 1773/2000\n",
            "5/5 [==============================] - 1s 246ms/step - loss: 0.0306 - acc: 1.0000 - val_loss: 0.9551 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01773: val_acc did not improve from 0.97561\n",
            "Epoch 1774/2000\n",
            "5/5 [==============================] - 1s 246ms/step - loss: 0.0420 - acc: 1.0000 - val_loss: 0.7359 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01774: val_acc did not improve from 0.97561\n",
            "Epoch 1775/2000\n",
            "5/5 [==============================] - 1s 253ms/step - loss: 0.0388 - acc: 0.9750 - val_loss: 0.4846 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01775: val_acc did not improve from 0.97561\n",
            "Epoch 1776/2000\n",
            "5/5 [==============================] - 1s 248ms/step - loss: 0.1059 - acc: 0.9500 - val_loss: 0.8583 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01776: val_acc did not improve from 0.97561\n",
            "Epoch 1777/2000\n",
            "5/5 [==============================] - 1s 255ms/step - loss: 0.0374 - acc: 1.0000 - val_loss: 1.1501 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01777: val_acc did not improve from 0.97561\n",
            "Epoch 1778/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.0248 - acc: 1.0000 - val_loss: 1.3442 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01778: val_acc did not improve from 0.97561\n",
            "Epoch 1779/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.0904 - acc: 0.9500 - val_loss: 1.5410 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01779: val_acc did not improve from 0.97561\n",
            "Epoch 1780/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.0523 - acc: 0.9750 - val_loss: 2.3837 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01780: val_acc did not improve from 0.97561\n",
            "Epoch 1781/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.0272 - acc: 1.0000 - val_loss: 2.1515 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01781: val_acc did not improve from 0.97561\n",
            "Epoch 1782/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.0865 - acc: 0.9750 - val_loss: 1.1211 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01782: val_acc did not improve from 0.97561\n",
            "Epoch 1783/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.0407 - acc: 0.9750 - val_loss: 7.9873 - val_acc: 0.2927\n",
            "\n",
            "Epoch 01783: val_acc did not improve from 0.97561\n",
            "Epoch 1784/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.0946 - acc: 0.9250 - val_loss: 9.3213 - val_acc: 0.2439\n",
            "\n",
            "Epoch 01784: val_acc did not improve from 0.97561\n",
            "Epoch 1785/2000\n",
            "5/5 [==============================] - 1s 250ms/step - loss: 0.0924 - acc: 0.9750 - val_loss: 9.4513 - val_acc: 0.2439\n",
            "\n",
            "Epoch 01785: val_acc did not improve from 0.97561\n",
            "Epoch 1786/2000\n",
            "5/5 [==============================] - 1s 248ms/step - loss: 0.0830 - acc: 0.9750 - val_loss: 8.2407 - val_acc: 0.2927\n",
            "\n",
            "Epoch 01786: val_acc did not improve from 0.97561\n",
            "Epoch 1787/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.0594 - acc: 0.9750 - val_loss: 7.4049 - val_acc: 0.4146\n",
            "\n",
            "Epoch 01787: val_acc did not improve from 0.97561\n",
            "Epoch 1788/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.0361 - acc: 0.9750 - val_loss: 7.1627 - val_acc: 0.3415\n",
            "\n",
            "Epoch 01788: val_acc did not improve from 0.97561\n",
            "Epoch 1789/2000\n",
            "5/5 [==============================] - 1s 253ms/step - loss: 0.2478 - acc: 0.9000 - val_loss: 7.1944 - val_acc: 0.4634\n",
            "\n",
            "Epoch 01789: val_acc did not improve from 0.97561\n",
            "Epoch 1790/2000\n",
            "5/5 [==============================] - 1s 253ms/step - loss: 0.0315 - acc: 1.0000 - val_loss: 7.0933 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01790: val_acc did not improve from 0.97561\n",
            "Epoch 1791/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.0258 - acc: 1.0000 - val_loss: 7.1552 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01791: val_acc did not improve from 0.97561\n",
            "Epoch 1792/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.0219 - acc: 1.0000 - val_loss: 7.3326 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01792: val_acc did not improve from 0.97561\n",
            "Epoch 1793/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.0083 - acc: 1.0000 - val_loss: 7.4079 - val_acc: 0.4634\n",
            "\n",
            "Epoch 01793: val_acc did not improve from 0.97561\n",
            "Epoch 1794/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.0378 - acc: 1.0000 - val_loss: 7.4020 - val_acc: 0.4634\n",
            "\n",
            "Epoch 01794: val_acc did not improve from 0.97561\n",
            "Epoch 1795/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.1217 - acc: 0.9500 - val_loss: 6.7319 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01795: val_acc did not improve from 0.97561\n",
            "Epoch 1796/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.0362 - acc: 0.9750 - val_loss: 4.8412 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01796: val_acc did not improve from 0.97561\n",
            "Epoch 1797/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.0468 - acc: 0.9750 - val_loss: 4.0570 - val_acc: 0.5122\n",
            "\n",
            "Epoch 01797: val_acc did not improve from 0.97561\n",
            "Epoch 1798/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.0242 - acc: 1.0000 - val_loss: 4.1914 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01798: val_acc did not improve from 0.97561\n",
            "Epoch 1799/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.0682 - acc: 0.9750 - val_loss: 5.6436 - val_acc: 0.4390\n",
            "\n",
            "Epoch 01799: val_acc did not improve from 0.97561\n",
            "Epoch 1800/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.0919 - acc: 0.9500 - val_loss: 5.8507 - val_acc: 0.3415\n",
            "\n",
            "Epoch 01800: val_acc did not improve from 0.97561\n",
            "Epoch 1801/2000\n",
            "5/5 [==============================] - 1s 244ms/step - loss: 0.0310 - acc: 1.0000 - val_loss: 2.4805 - val_acc: 0.5366\n",
            "\n",
            "Epoch 01801: val_acc did not improve from 0.97561\n",
            "Epoch 1802/2000\n",
            "5/5 [==============================] - 1s 244ms/step - loss: 0.1645 - acc: 0.9250 - val_loss: 0.2543 - val_acc: 0.9268\n",
            "\n",
            "Epoch 01802: val_acc did not improve from 0.97561\n",
            "Epoch 1803/2000\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 0.1575 - acc: 0.9750 - val_loss: 0.1878 - val_acc: 0.9268\n",
            "\n",
            "Epoch 01803: val_acc did not improve from 0.97561\n",
            "Epoch 1804/2000\n",
            "5/5 [==============================] - 1s 279ms/step - loss: 0.0576 - acc: 0.9500 - val_loss: 2.8838 - val_acc: 0.5122\n",
            "\n",
            "Epoch 01804: val_acc did not improve from 0.97561\n",
            "Epoch 1805/2000\n",
            "5/5 [==============================] - 1s 280ms/step - loss: 0.0674 - acc: 0.9750 - val_loss: 5.9005 - val_acc: 0.2195\n",
            "\n",
            "Epoch 01805: val_acc did not improve from 0.97561\n",
            "Epoch 1806/2000\n",
            "5/5 [==============================] - 1s 286ms/step - loss: 0.0948 - acc: 0.9500 - val_loss: 5.1614 - val_acc: 0.2683\n",
            "\n",
            "Epoch 01806: val_acc did not improve from 0.97561\n",
            "Epoch 1807/2000\n",
            "5/5 [==============================] - 1s 287ms/step - loss: 0.2535 - acc: 0.8500 - val_loss: 1.7655 - val_acc: 0.6585\n",
            "\n",
            "Epoch 01807: val_acc did not improve from 0.97561\n",
            "Epoch 1808/2000\n",
            "5/5 [==============================] - 1s 289ms/step - loss: 0.0357 - acc: 0.9750 - val_loss: 0.3945 - val_acc: 0.8780\n",
            "\n",
            "Epoch 01808: val_acc did not improve from 0.97561\n",
            "Epoch 1809/2000\n",
            "5/5 [==============================] - 1s 295ms/step - loss: 0.1223 - acc: 0.9250 - val_loss: 0.5597 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01809: val_acc did not improve from 0.97561\n",
            "Epoch 1810/2000\n",
            "5/5 [==============================] - 1s 295ms/step - loss: 0.0473 - acc: 1.0000 - val_loss: 0.6195 - val_acc: 0.8049\n",
            "\n",
            "Epoch 01810: val_acc did not improve from 0.97561\n",
            "Epoch 1811/2000\n",
            "5/5 [==============================] - 1s 281ms/step - loss: 0.0397 - acc: 0.9750 - val_loss: 0.6270 - val_acc: 0.8049\n",
            "\n",
            "Epoch 01811: val_acc did not improve from 0.97561\n",
            "Epoch 1812/2000\n",
            "5/5 [==============================] - 1s 290ms/step - loss: 0.0342 - acc: 1.0000 - val_loss: 0.5825 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01812: val_acc did not improve from 0.97561\n",
            "Epoch 1813/2000\n",
            "5/5 [==============================] - 1s 277ms/step - loss: 0.0582 - acc: 1.0000 - val_loss: 0.5959 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01813: val_acc did not improve from 0.97561\n",
            "Epoch 1814/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.0254 - acc: 1.0000 - val_loss: 0.5573 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01814: val_acc did not improve from 0.97561\n",
            "Epoch 1815/2000\n",
            "5/5 [==============================] - 1s 256ms/step - loss: 0.0113 - acc: 1.0000 - val_loss: 0.4825 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01815: val_acc did not improve from 0.97561\n",
            "Epoch 1816/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.0534 - acc: 0.9750 - val_loss: 0.2320 - val_acc: 0.9268\n",
            "\n",
            "Epoch 01816: val_acc did not improve from 0.97561\n",
            "Epoch 1817/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.0133 - acc: 1.0000 - val_loss: 0.3749 - val_acc: 0.9024\n",
            "\n",
            "Epoch 01817: val_acc did not improve from 0.97561\n",
            "Epoch 1818/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.1155 - acc: 0.9500 - val_loss: 0.3233 - val_acc: 0.9024\n",
            "\n",
            "Epoch 01818: val_acc did not improve from 0.97561\n",
            "Epoch 1819/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.0115 - acc: 1.0000 - val_loss: 0.3549 - val_acc: 0.8780\n",
            "\n",
            "Epoch 01819: val_acc did not improve from 0.97561\n",
            "Epoch 1820/2000\n",
            "5/5 [==============================] - 1s 270ms/step - loss: 0.0804 - acc: 0.9250 - val_loss: 0.6799 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01820: val_acc did not improve from 0.97561\n",
            "Epoch 1821/2000\n",
            "5/5 [==============================] - 1s 273ms/step - loss: 0.0273 - acc: 1.0000 - val_loss: 1.0725 - val_acc: 0.8049\n",
            "\n",
            "Epoch 01821: val_acc did not improve from 0.97561\n",
            "Epoch 1822/2000\n",
            "5/5 [==============================] - 1s 274ms/step - loss: 0.1062 - acc: 0.9250 - val_loss: 1.4354 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01822: val_acc did not improve from 0.97561\n",
            "Epoch 1823/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.0077 - acc: 1.0000 - val_loss: 1.7958 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01823: val_acc did not improve from 0.97561\n",
            "Epoch 1824/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.0386 - acc: 0.9750 - val_loss: 2.0043 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01824: val_acc did not improve from 0.97561\n",
            "Epoch 1825/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.0399 - acc: 0.9750 - val_loss: 1.4330 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01825: val_acc did not improve from 0.97561\n",
            "Epoch 1826/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.0146 - acc: 1.0000 - val_loss: 1.1797 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01826: val_acc did not improve from 0.97561\n",
            "Epoch 1827/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.0524 - acc: 0.9750 - val_loss: 1.0051 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01827: val_acc did not improve from 0.97561\n",
            "Epoch 1828/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.0157 - acc: 1.0000 - val_loss: 0.9494 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01828: val_acc did not improve from 0.97561\n",
            "Epoch 1829/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.1843 - acc: 0.9250 - val_loss: 1.2125 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01829: val_acc did not improve from 0.97561\n",
            "Epoch 1830/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.0508 - acc: 0.9750 - val_loss: 1.7385 - val_acc: 0.6341\n",
            "\n",
            "Epoch 01830: val_acc did not improve from 0.97561\n",
            "Epoch 1831/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.0945 - acc: 0.9500 - val_loss: 2.4715 - val_acc: 0.6585\n",
            "\n",
            "Epoch 01831: val_acc did not improve from 0.97561\n",
            "Epoch 1832/2000\n",
            "5/5 [==============================] - 1s 270ms/step - loss: 0.0054 - acc: 1.0000 - val_loss: 2.6676 - val_acc: 0.6098\n",
            "\n",
            "Epoch 01832: val_acc did not improve from 0.97561\n",
            "Epoch 1833/2000\n",
            "5/5 [==============================] - 1s 254ms/step - loss: 0.0471 - acc: 1.0000 - val_loss: 2.7901 - val_acc: 0.5854\n",
            "\n",
            "Epoch 01833: val_acc did not improve from 0.97561\n",
            "Epoch 1834/2000\n",
            "5/5 [==============================] - 1s 254ms/step - loss: 0.1473 - acc: 0.9500 - val_loss: 1.9283 - val_acc: 0.7073\n",
            "\n",
            "Epoch 01834: val_acc did not improve from 0.97561\n",
            "Epoch 1835/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.0151 - acc: 1.0000 - val_loss: 2.4164 - val_acc: 0.7317\n",
            "\n",
            "Epoch 01835: val_acc did not improve from 0.97561\n",
            "Epoch 1836/2000\n",
            "5/5 [==============================] - 1s 251ms/step - loss: 0.0108 - acc: 1.0000 - val_loss: 2.4811 - val_acc: 0.7317\n",
            "\n",
            "Epoch 01836: val_acc did not improve from 0.97561\n",
            "Epoch 1837/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.0746 - acc: 0.9750 - val_loss: 2.3900 - val_acc: 0.7317\n",
            "\n",
            "Epoch 01837: val_acc did not improve from 0.97561\n",
            "Epoch 1838/2000\n",
            "5/5 [==============================] - 1s 255ms/step - loss: 0.1346 - acc: 0.9500 - val_loss: 0.6055 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01838: val_acc did not improve from 0.97561\n",
            "Epoch 1839/2000\n",
            "5/5 [==============================] - 1s 256ms/step - loss: 0.0263 - acc: 1.0000 - val_loss: 0.3327 - val_acc: 0.9268\n",
            "\n",
            "Epoch 01839: val_acc did not improve from 0.97561\n",
            "Epoch 1840/2000\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 0.0323 - acc: 1.0000 - val_loss: 0.4735 - val_acc: 0.8780\n",
            "\n",
            "Epoch 01840: val_acc did not improve from 0.97561\n",
            "Epoch 1841/2000\n",
            "5/5 [==============================] - 1s 272ms/step - loss: 0.0219 - acc: 1.0000 - val_loss: 0.4994 - val_acc: 0.8780\n",
            "\n",
            "Epoch 01841: val_acc did not improve from 0.97561\n",
            "Epoch 1842/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.0172 - acc: 1.0000 - val_loss: 0.7174 - val_acc: 0.9024\n",
            "\n",
            "Epoch 01842: val_acc did not improve from 0.97561\n",
            "Epoch 1843/2000\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 0.0938 - acc: 0.9750 - val_loss: 0.4341 - val_acc: 0.9024\n",
            "\n",
            "Epoch 01843: val_acc did not improve from 0.97561\n",
            "Epoch 1844/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.0415 - acc: 1.0000 - val_loss: 0.9306 - val_acc: 0.8049\n",
            "\n",
            "Epoch 01844: val_acc did not improve from 0.97561\n",
            "Epoch 1845/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.0836 - acc: 0.9750 - val_loss: 1.3081 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01845: val_acc did not improve from 0.97561\n",
            "Epoch 1846/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.0403 - acc: 0.9750 - val_loss: 1.6048 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01846: val_acc did not improve from 0.97561\n",
            "Epoch 1847/2000\n",
            "5/5 [==============================] - 1s 273ms/step - loss: 0.0201 - acc: 1.0000 - val_loss: 1.6448 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01847: val_acc did not improve from 0.97561\n",
            "Epoch 1848/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.0329 - acc: 1.0000 - val_loss: 1.5023 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01848: val_acc did not improve from 0.97561\n",
            "Epoch 1849/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.0270 - acc: 1.0000 - val_loss: 1.2351 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01849: val_acc did not improve from 0.97561\n",
            "Epoch 1850/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.0156 - acc: 1.0000 - val_loss: 0.9665 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01850: val_acc did not improve from 0.97561\n",
            "Epoch 1851/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.0122 - acc: 1.0000 - val_loss: 0.6423 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01851: val_acc did not improve from 0.97561\n",
            "Epoch 1852/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.0531 - acc: 0.9500 - val_loss: 0.5564 - val_acc: 0.8780\n",
            "\n",
            "Epoch 01852: val_acc did not improve from 0.97561\n",
            "Epoch 1853/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.0353 - acc: 1.0000 - val_loss: 0.3816 - val_acc: 0.9024\n",
            "\n",
            "Epoch 01853: val_acc did not improve from 0.97561\n",
            "Epoch 1854/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.0589 - acc: 0.9750 - val_loss: 0.3247 - val_acc: 0.9024\n",
            "\n",
            "Epoch 01854: val_acc did not improve from 0.97561\n",
            "Epoch 1855/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.0420 - acc: 1.0000 - val_loss: 0.6920 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01855: val_acc did not improve from 0.97561\n",
            "Epoch 1856/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.0621 - acc: 0.9750 - val_loss: 0.7241 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01856: val_acc did not improve from 0.97561\n",
            "Epoch 1857/2000\n",
            "5/5 [==============================] - 1s 252ms/step - loss: 0.0127 - acc: 1.0000 - val_loss: 0.7133 - val_acc: 0.7317\n",
            "\n",
            "Epoch 01857: val_acc did not improve from 0.97561\n",
            "Epoch 1858/2000\n",
            "5/5 [==============================] - 1s 247ms/step - loss: 0.1030 - acc: 0.9500 - val_loss: 1.3722 - val_acc: 0.6585\n",
            "\n",
            "Epoch 01858: val_acc did not improve from 0.97561\n",
            "Epoch 1859/2000\n",
            "5/5 [==============================] - 1s 251ms/step - loss: 0.0259 - acc: 1.0000 - val_loss: 1.9684 - val_acc: 0.5610\n",
            "\n",
            "Epoch 01859: val_acc did not improve from 0.97561\n",
            "Epoch 1860/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.0121 - acc: 1.0000 - val_loss: 1.3504 - val_acc: 0.6341\n",
            "\n",
            "Epoch 01860: val_acc did not improve from 0.97561\n",
            "Epoch 1861/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.0948 - acc: 0.9500 - val_loss: 0.1859 - val_acc: 0.9268\n",
            "\n",
            "Epoch 01861: val_acc did not improve from 0.97561\n",
            "Epoch 1862/2000\n",
            "5/5 [==============================] - 1s 251ms/step - loss: 0.0137 - acc: 1.0000 - val_loss: 0.5322 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01862: val_acc did not improve from 0.97561\n",
            "Epoch 1863/2000\n",
            "5/5 [==============================] - 1s 256ms/step - loss: 0.1223 - acc: 0.9250 - val_loss: 7.9735 - val_acc: 0.2439\n",
            "\n",
            "Epoch 01863: val_acc did not improve from 0.97561\n",
            "Epoch 1864/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.2386 - acc: 0.9000 - val_loss: 9.0798 - val_acc: 0.2195\n",
            "\n",
            "Epoch 01864: val_acc did not improve from 0.97561\n",
            "Epoch 1865/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.0421 - acc: 0.9750 - val_loss: 9.2687 - val_acc: 0.2195\n",
            "\n",
            "Epoch 01865: val_acc did not improve from 0.97561\n",
            "Epoch 1866/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.0377 - acc: 1.0000 - val_loss: 8.5125 - val_acc: 0.2439\n",
            "\n",
            "Epoch 01866: val_acc did not improve from 0.97561\n",
            "Epoch 1867/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.0720 - acc: 0.9750 - val_loss: 6.8838 - val_acc: 0.2683\n",
            "\n",
            "Epoch 01867: val_acc did not improve from 0.97561\n",
            "Epoch 1868/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.0238 - acc: 1.0000 - val_loss: 6.1311 - val_acc: 0.2927\n",
            "\n",
            "Epoch 01868: val_acc did not improve from 0.97561\n",
            "Epoch 1869/2000\n",
            "5/5 [==============================] - 1s 251ms/step - loss: 0.0303 - acc: 0.9750 - val_loss: 6.0449 - val_acc: 0.3415\n",
            "\n",
            "Epoch 01869: val_acc did not improve from 0.97561\n",
            "Epoch 1870/2000\n",
            "5/5 [==============================] - 1s 253ms/step - loss: 0.0626 - acc: 0.9750 - val_loss: 7.4880 - val_acc: 0.2683\n",
            "\n",
            "Epoch 01870: val_acc did not improve from 0.97561\n",
            "Epoch 1871/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.1069 - acc: 0.9500 - val_loss: 7.5001 - val_acc: 0.2683\n",
            "\n",
            "Epoch 01871: val_acc did not improve from 0.97561\n",
            "Epoch 1872/2000\n",
            "5/5 [==============================] - 1s 270ms/step - loss: 0.0311 - acc: 1.0000 - val_loss: 5.9531 - val_acc: 0.2927\n",
            "\n",
            "Epoch 01872: val_acc did not improve from 0.97561\n",
            "Epoch 1873/2000\n",
            "5/5 [==============================] - 1s 253ms/step - loss: 0.0624 - acc: 0.9750 - val_loss: 3.2107 - val_acc: 0.5122\n",
            "\n",
            "Epoch 01873: val_acc did not improve from 0.97561\n",
            "Epoch 1874/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.0423 - acc: 0.9750 - val_loss: 0.5625 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01874: val_acc did not improve from 0.97561\n",
            "Epoch 1875/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.0366 - acc: 0.9750 - val_loss: 0.4314 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01875: val_acc did not improve from 0.97561\n",
            "Epoch 1876/2000\n",
            "5/5 [==============================] - 1s 270ms/step - loss: 0.0488 - acc: 1.0000 - val_loss: 0.5198 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01876: val_acc did not improve from 0.97561\n",
            "Epoch 1877/2000\n",
            "5/5 [==============================] - 1s 253ms/step - loss: 0.0778 - acc: 0.9500 - val_loss: 0.5170 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01877: val_acc did not improve from 0.97561\n",
            "Epoch 1878/2000\n",
            "5/5 [==============================] - 1s 248ms/step - loss: 0.2264 - acc: 0.9250 - val_loss: 1.9648 - val_acc: 0.7317\n",
            "\n",
            "Epoch 01878: val_acc did not improve from 0.97561\n",
            "Epoch 1879/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.3313 - acc: 0.9250 - val_loss: 1.5175 - val_acc: 0.6098\n",
            "\n",
            "Epoch 01879: val_acc did not improve from 0.97561\n",
            "Epoch 1880/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.0367 - acc: 1.0000 - val_loss: 1.7277 - val_acc: 0.6829\n",
            "\n",
            "Epoch 01880: val_acc did not improve from 0.97561\n",
            "Epoch 1881/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.0201 - acc: 1.0000 - val_loss: 4.5238 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01881: val_acc did not improve from 0.97561\n",
            "Epoch 1882/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.0596 - acc: 0.9750 - val_loss: 4.6715 - val_acc: 0.5122\n",
            "\n",
            "Epoch 01882: val_acc did not improve from 0.97561\n",
            "Epoch 1883/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.0214 - acc: 1.0000 - val_loss: 3.9169 - val_acc: 0.5122\n",
            "\n",
            "Epoch 01883: val_acc did not improve from 0.97561\n",
            "Epoch 1884/2000\n",
            "5/5 [==============================] - 1s 270ms/step - loss: 0.0483 - acc: 0.9750 - val_loss: 3.6171 - val_acc: 0.5122\n",
            "\n",
            "Epoch 01884: val_acc did not improve from 0.97561\n",
            "Epoch 1885/2000\n",
            "5/5 [==============================] - 1s 250ms/step - loss: 0.0254 - acc: 1.0000 - val_loss: 2.4159 - val_acc: 0.5610\n",
            "\n",
            "Epoch 01885: val_acc did not improve from 0.97561\n",
            "Epoch 1886/2000\n",
            "5/5 [==============================] - 1s 250ms/step - loss: 0.0578 - acc: 0.9500 - val_loss: 0.4234 - val_acc: 0.9024\n",
            "\n",
            "Epoch 01886: val_acc did not improve from 0.97561\n",
            "Epoch 1887/2000\n",
            "5/5 [==============================] - 1s 260ms/step - loss: 0.0298 - acc: 1.0000 - val_loss: 0.8974 - val_acc: 0.8049\n",
            "\n",
            "Epoch 01887: val_acc did not improve from 0.97561\n",
            "Epoch 1888/2000\n",
            "5/5 [==============================] - 1s 270ms/step - loss: 0.1014 - acc: 0.9500 - val_loss: 1.8876 - val_acc: 0.6829\n",
            "\n",
            "Epoch 01888: val_acc did not improve from 0.97561\n",
            "Epoch 1889/2000\n",
            "5/5 [==============================] - 1s 271ms/step - loss: 0.0601 - acc: 0.9750 - val_loss: 2.9856 - val_acc: 0.6341\n",
            "\n",
            "Epoch 01889: val_acc did not improve from 0.97561\n",
            "Epoch 1890/2000\n",
            "5/5 [==============================] - 1s 275ms/step - loss: 0.0233 - acc: 1.0000 - val_loss: 1.5672 - val_acc: 0.7317\n",
            "\n",
            "Epoch 01890: val_acc did not improve from 0.97561\n",
            "Epoch 1891/2000\n",
            "5/5 [==============================] - 1s 270ms/step - loss: 0.1306 - acc: 0.9500 - val_loss: 1.9902 - val_acc: 0.6829\n",
            "\n",
            "Epoch 01891: val_acc did not improve from 0.97561\n",
            "Epoch 1892/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.0273 - acc: 1.0000 - val_loss: 3.1440 - val_acc: 0.6585\n",
            "\n",
            "Epoch 01892: val_acc did not improve from 0.97561\n",
            "Epoch 1893/2000\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 0.1117 - acc: 0.9500 - val_loss: 5.0927 - val_acc: 0.5610\n",
            "\n",
            "Epoch 01893: val_acc did not improve from 0.97561\n",
            "Epoch 1894/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.0499 - acc: 0.9750 - val_loss: 4.6054 - val_acc: 0.6585\n",
            "\n",
            "Epoch 01894: val_acc did not improve from 0.97561\n",
            "Epoch 1895/2000\n",
            "5/5 [==============================] - 1s 255ms/step - loss: 0.0154 - acc: 1.0000 - val_loss: 4.2634 - val_acc: 0.5854\n",
            "\n",
            "Epoch 01895: val_acc did not improve from 0.97561\n",
            "Epoch 1896/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.0347 - acc: 1.0000 - val_loss: 4.2648 - val_acc: 0.5854\n",
            "\n",
            "Epoch 01896: val_acc did not improve from 0.97561\n",
            "Epoch 1897/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.1007 - acc: 0.9500 - val_loss: 4.6670 - val_acc: 0.6585\n",
            "\n",
            "Epoch 01897: val_acc did not improve from 0.97561\n",
            "Epoch 1898/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.0933 - acc: 0.9500 - val_loss: 4.7810 - val_acc: 0.6585\n",
            "\n",
            "Epoch 01898: val_acc did not improve from 0.97561\n",
            "Epoch 1899/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.0238 - acc: 1.0000 - val_loss: 6.4131 - val_acc: 0.4390\n",
            "\n",
            "Epoch 01899: val_acc did not improve from 0.97561\n",
            "Epoch 1900/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.2051 - acc: 0.8750 - val_loss: 9.7406 - val_acc: 0.2195\n",
            "\n",
            "Epoch 01900: val_acc did not improve from 0.97561\n",
            "Epoch 1901/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.3129 - acc: 0.9250 - val_loss: 10.2559 - val_acc: 0.2195\n",
            "\n",
            "Epoch 01901: val_acc did not improve from 0.97561\n",
            "Epoch 1902/2000\n",
            "5/5 [==============================] - 1s 275ms/step - loss: 0.0240 - acc: 1.0000 - val_loss: 10.6248 - val_acc: 0.2195\n",
            "\n",
            "Epoch 01902: val_acc did not improve from 0.97561\n",
            "Epoch 1903/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.1707 - acc: 0.9250 - val_loss: 11.0514 - val_acc: 0.2195\n",
            "\n",
            "Epoch 01903: val_acc did not improve from 0.97561\n",
            "Epoch 1904/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.0642 - acc: 0.9750 - val_loss: 11.0398 - val_acc: 0.2195\n",
            "\n",
            "Epoch 01904: val_acc did not improve from 0.97561\n",
            "Epoch 1905/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.1727 - acc: 0.9250 - val_loss: 9.4074 - val_acc: 0.2439\n",
            "\n",
            "Epoch 01905: val_acc did not improve from 0.97561\n",
            "Epoch 1906/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.1228 - acc: 0.9500 - val_loss: 8.3321 - val_acc: 0.3659\n",
            "\n",
            "Epoch 01906: val_acc did not improve from 0.97561\n",
            "Epoch 1907/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.0801 - acc: 0.9750 - val_loss: 8.1085 - val_acc: 0.4146\n",
            "\n",
            "Epoch 01907: val_acc did not improve from 0.97561\n",
            "Epoch 1908/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.0560 - acc: 0.9750 - val_loss: 7.9916 - val_acc: 0.4390\n",
            "\n",
            "Epoch 01908: val_acc did not improve from 0.97561\n",
            "Epoch 1909/2000\n",
            "5/5 [==============================] - 1s 272ms/step - loss: 0.1368 - acc: 0.9500 - val_loss: 8.0559 - val_acc: 0.3659\n",
            "\n",
            "Epoch 01909: val_acc did not improve from 0.97561\n",
            "Epoch 1910/2000\n",
            "5/5 [==============================] - 1s 270ms/step - loss: 0.0292 - acc: 1.0000 - val_loss: 8.8223 - val_acc: 0.2439\n",
            "\n",
            "Epoch 01910: val_acc did not improve from 0.97561\n",
            "Epoch 1911/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.0238 - acc: 1.0000 - val_loss: 9.7899 - val_acc: 0.2195\n",
            "\n",
            "Epoch 01911: val_acc did not improve from 0.97561\n",
            "Epoch 1912/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.0894 - acc: 0.9750 - val_loss: 8.9094 - val_acc: 0.2439\n",
            "\n",
            "Epoch 01912: val_acc did not improve from 0.97561\n",
            "Epoch 1913/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.0092 - acc: 1.0000 - val_loss: 8.4757 - val_acc: 0.2927\n",
            "\n",
            "Epoch 01913: val_acc did not improve from 0.97561\n",
            "Epoch 1914/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.0798 - acc: 0.9750 - val_loss: 8.1716 - val_acc: 0.2927\n",
            "\n",
            "Epoch 01914: val_acc did not improve from 0.97561\n",
            "Epoch 1915/2000\n",
            "5/5 [==============================] - 1s 272ms/step - loss: 0.3495 - acc: 0.8500 - val_loss: 8.7492 - val_acc: 0.2439\n",
            "\n",
            "Epoch 01915: val_acc did not improve from 0.97561\n",
            "Epoch 1916/2000\n",
            "5/5 [==============================] - 1s 271ms/step - loss: 0.1246 - acc: 0.9500 - val_loss: 6.6181 - val_acc: 0.4634\n",
            "\n",
            "Epoch 01916: val_acc did not improve from 0.97561\n",
            "Epoch 1917/2000\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 0.0722 - acc: 0.9750 - val_loss: 0.3547 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01917: val_acc did not improve from 0.97561\n",
            "Epoch 1918/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.0669 - acc: 0.9500 - val_loss: 0.4408 - val_acc: 0.8780\n",
            "\n",
            "Epoch 01918: val_acc did not improve from 0.97561\n",
            "Epoch 1919/2000\n",
            "5/5 [==============================] - 1s 254ms/step - loss: 0.0191 - acc: 1.0000 - val_loss: 1.1178 - val_acc: 0.7317\n",
            "\n",
            "Epoch 01919: val_acc did not improve from 0.97561\n",
            "Epoch 1920/2000\n",
            "5/5 [==============================] - 1s 258ms/step - loss: 0.1712 - acc: 0.9250 - val_loss: 1.0598 - val_acc: 0.7317\n",
            "\n",
            "Epoch 01920: val_acc did not improve from 0.97561\n",
            "Epoch 1921/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.0351 - acc: 1.0000 - val_loss: 0.7876 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01921: val_acc did not improve from 0.97561\n",
            "Epoch 1922/2000\n",
            "5/5 [==============================] - 1s 254ms/step - loss: 0.1113 - acc: 0.9750 - val_loss: 0.6095 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01922: val_acc did not improve from 0.97561\n",
            "Epoch 1923/2000\n",
            "5/5 [==============================] - 1s 252ms/step - loss: 0.1069 - acc: 0.9250 - val_loss: 0.2044 - val_acc: 0.9512\n",
            "\n",
            "Epoch 01923: val_acc did not improve from 0.97561\n",
            "Epoch 1924/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.0488 - acc: 1.0000 - val_loss: 0.4078 - val_acc: 0.8780\n",
            "\n",
            "Epoch 01924: val_acc did not improve from 0.97561\n",
            "Epoch 1925/2000\n",
            "5/5 [==============================] - 1s 248ms/step - loss: 0.0727 - acc: 1.0000 - val_loss: 0.7962 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01925: val_acc did not improve from 0.97561\n",
            "Epoch 1926/2000\n",
            "5/5 [==============================] - 1s 247ms/step - loss: 0.3520 - acc: 0.9250 - val_loss: 1.1336 - val_acc: 0.7317\n",
            "\n",
            "Epoch 01926: val_acc did not improve from 0.97561\n",
            "Epoch 1927/2000\n",
            "5/5 [==============================] - 1s 256ms/step - loss: 0.1048 - acc: 0.9750 - val_loss: 1.1956 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01927: val_acc did not improve from 0.97561\n",
            "Epoch 1928/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.1114 - acc: 0.9500 - val_loss: 1.6518 - val_acc: 0.6585\n",
            "\n",
            "Epoch 01928: val_acc did not improve from 0.97561\n",
            "Epoch 1929/2000\n",
            "5/5 [==============================] - 1s 256ms/step - loss: 0.0772 - acc: 1.0000 - val_loss: 1.4009 - val_acc: 0.7073\n",
            "\n",
            "Epoch 01929: val_acc did not improve from 0.97561\n",
            "Epoch 1930/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.0824 - acc: 0.9500 - val_loss: 1.0668 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01930: val_acc did not improve from 0.97561\n",
            "Epoch 1931/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.0816 - acc: 0.9750 - val_loss: 1.0752 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01931: val_acc did not improve from 0.97561\n",
            "Epoch 1932/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.0723 - acc: 0.9500 - val_loss: 1.9326 - val_acc: 0.7073\n",
            "\n",
            "Epoch 01932: val_acc did not improve from 0.97561\n",
            "Epoch 1933/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.0209 - acc: 1.0000 - val_loss: 2.9792 - val_acc: 0.6341\n",
            "\n",
            "Epoch 01933: val_acc did not improve from 0.97561\n",
            "Epoch 1934/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.1732 - acc: 0.9500 - val_loss: 3.6664 - val_acc: 0.5854\n",
            "\n",
            "Epoch 01934: val_acc did not improve from 0.97561\n",
            "Epoch 1935/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.1472 - acc: 0.9750 - val_loss: 3.2377 - val_acc: 0.5122\n",
            "\n",
            "Epoch 01935: val_acc did not improve from 0.97561\n",
            "Epoch 1936/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.1091 - acc: 0.9500 - val_loss: 3.2097 - val_acc: 0.4146\n",
            "\n",
            "Epoch 01936: val_acc did not improve from 0.97561\n",
            "Epoch 1937/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.1323 - acc: 0.9250 - val_loss: 2.7696 - val_acc: 0.5122\n",
            "\n",
            "Epoch 01937: val_acc did not improve from 0.97561\n",
            "Epoch 1938/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.0501 - acc: 0.9750 - val_loss: 2.1601 - val_acc: 0.6341\n",
            "\n",
            "Epoch 01938: val_acc did not improve from 0.97561\n",
            "Epoch 1939/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.1517 - acc: 0.9250 - val_loss: 2.5286 - val_acc: 0.5366\n",
            "\n",
            "Epoch 01939: val_acc did not improve from 0.97561\n",
            "Epoch 1940/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.0333 - acc: 1.0000 - val_loss: 2.6984 - val_acc: 0.5366\n",
            "\n",
            "Epoch 01940: val_acc did not improve from 0.97561\n",
            "Epoch 1941/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.0546 - acc: 1.0000 - val_loss: 3.0568 - val_acc: 0.5854\n",
            "\n",
            "Epoch 01941: val_acc did not improve from 0.97561\n",
            "Epoch 1942/2000\n",
            "5/5 [==============================] - 1s 256ms/step - loss: 0.1445 - acc: 0.9500 - val_loss: 3.2402 - val_acc: 0.6098\n",
            "\n",
            "Epoch 01942: val_acc did not improve from 0.97561\n",
            "Epoch 1943/2000\n",
            "5/5 [==============================] - 1s 255ms/step - loss: 0.3735 - acc: 0.8750 - val_loss: 3.3190 - val_acc: 0.5610\n",
            "\n",
            "Epoch 01943: val_acc did not improve from 0.97561\n",
            "Epoch 1944/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.0285 - acc: 0.9750 - val_loss: 3.3669 - val_acc: 0.6585\n",
            "\n",
            "Epoch 01944: val_acc did not improve from 0.97561\n",
            "Epoch 1945/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.0853 - acc: 0.9500 - val_loss: 2.5728 - val_acc: 0.6585\n",
            "\n",
            "Epoch 01945: val_acc did not improve from 0.97561\n",
            "Epoch 1946/2000\n",
            "5/5 [==============================] - 1s 271ms/step - loss: 0.1509 - acc: 0.9250 - val_loss: 1.2287 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01946: val_acc did not improve from 0.97561\n",
            "Epoch 1947/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.0709 - acc: 0.9500 - val_loss: 3.8171 - val_acc: 0.5366\n",
            "\n",
            "Epoch 01947: val_acc did not improve from 0.97561\n",
            "Epoch 1948/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.2600 - acc: 0.9250 - val_loss: 0.9611 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01948: val_acc did not improve from 0.97561\n",
            "Epoch 1949/2000\n",
            "5/5 [==============================] - 1s 253ms/step - loss: 0.0417 - acc: 1.0000 - val_loss: 0.5000 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01949: val_acc did not improve from 0.97561\n",
            "Epoch 1950/2000\n",
            "5/5 [==============================] - 1s 249ms/step - loss: 0.0386 - acc: 1.0000 - val_loss: 1.7383 - val_acc: 0.6829\n",
            "\n",
            "Epoch 01950: val_acc did not improve from 0.97561\n",
            "Epoch 1951/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.0535 - acc: 0.9750 - val_loss: 2.8629 - val_acc: 0.5610\n",
            "\n",
            "Epoch 01951: val_acc did not improve from 0.97561\n",
            "Epoch 1952/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.0501 - acc: 0.9750 - val_loss: 3.9262 - val_acc: 0.5122\n",
            "\n",
            "Epoch 01952: val_acc did not improve from 0.97561\n",
            "Epoch 1953/2000\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 0.0088 - acc: 1.0000 - val_loss: 5.1796 - val_acc: 0.3415\n",
            "\n",
            "Epoch 01953: val_acc did not improve from 0.97561\n",
            "Epoch 1954/2000\n",
            "5/5 [==============================] - 1s 272ms/step - loss: 0.0823 - acc: 0.9750 - val_loss: 5.4132 - val_acc: 0.3415\n",
            "\n",
            "Epoch 01954: val_acc did not improve from 0.97561\n",
            "Epoch 1955/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.0499 - acc: 0.9750 - val_loss: 4.6590 - val_acc: 0.3902\n",
            "\n",
            "Epoch 01955: val_acc did not improve from 0.97561\n",
            "Epoch 1956/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.0938 - acc: 0.9750 - val_loss: 3.9843 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01956: val_acc did not improve from 0.97561\n",
            "Epoch 1957/2000\n",
            "5/5 [==============================] - 1s 256ms/step - loss: 0.0247 - acc: 1.0000 - val_loss: 3.4964 - val_acc: 0.5122\n",
            "\n",
            "Epoch 01957: val_acc did not improve from 0.97561\n",
            "Epoch 1958/2000\n",
            "5/5 [==============================] - 1s 266ms/step - loss: 0.0180 - acc: 1.0000 - val_loss: 1.7928 - val_acc: 0.6585\n",
            "\n",
            "Epoch 01958: val_acc did not improve from 0.97561\n",
            "Epoch 1959/2000\n",
            "5/5 [==============================] - 2s 328ms/step - loss: 0.0498 - acc: 0.9750 - val_loss: 2.7977 - val_acc: 0.5610\n",
            "\n",
            "Epoch 01959: val_acc did not improve from 0.97561\n",
            "Epoch 1960/2000\n",
            "5/5 [==============================] - 1s 298ms/step - loss: 0.0508 - acc: 1.0000 - val_loss: 2.4677 - val_acc: 0.5854\n",
            "\n",
            "Epoch 01960: val_acc did not improve from 0.97561\n",
            "Epoch 1961/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.0264 - acc: 1.0000 - val_loss: 3.0969 - val_acc: 0.5122\n",
            "\n",
            "Epoch 01961: val_acc did not improve from 0.97561\n",
            "Epoch 1962/2000\n",
            "5/5 [==============================] - 1s 258ms/step - loss: 0.0901 - acc: 0.9750 - val_loss: 2.9587 - val_acc: 0.5366\n",
            "\n",
            "Epoch 01962: val_acc did not improve from 0.97561\n",
            "Epoch 1963/2000\n",
            "5/5 [==============================] - 1s 261ms/step - loss: 0.1177 - acc: 0.9750 - val_loss: 1.2037 - val_acc: 0.6829\n",
            "\n",
            "Epoch 01963: val_acc did not improve from 0.97561\n",
            "Epoch 1964/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.0148 - acc: 1.0000 - val_loss: 0.5387 - val_acc: 0.8780\n",
            "\n",
            "Epoch 01964: val_acc did not improve from 0.97561\n",
            "Epoch 1965/2000\n",
            "5/5 [==============================] - 1s 265ms/step - loss: 0.2057 - acc: 0.8750 - val_loss: 0.4231 - val_acc: 0.9024\n",
            "\n",
            "Epoch 01965: val_acc did not improve from 0.97561\n",
            "Epoch 1966/2000\n",
            "5/5 [==============================] - 1s 255ms/step - loss: 0.0118 - acc: 1.0000 - val_loss: 0.3554 - val_acc: 0.9024\n",
            "\n",
            "Epoch 01966: val_acc did not improve from 0.97561\n",
            "Epoch 1967/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.0233 - acc: 1.0000 - val_loss: 0.5344 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01967: val_acc did not improve from 0.97561\n",
            "Epoch 1968/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.0645 - acc: 0.9750 - val_loss: 0.6264 - val_acc: 0.8537\n",
            "\n",
            "Epoch 01968: val_acc did not improve from 0.97561\n",
            "Epoch 1969/2000\n",
            "5/5 [==============================] - 1s 249ms/step - loss: 0.0493 - acc: 0.9750 - val_loss: 0.4510 - val_acc: 0.8293\n",
            "\n",
            "Epoch 01969: val_acc did not improve from 0.97561\n",
            "Epoch 1970/2000\n",
            "5/5 [==============================] - 1s 249ms/step - loss: 0.1751 - acc: 0.9500 - val_loss: 0.4519 - val_acc: 0.9024\n",
            "\n",
            "Epoch 01970: val_acc did not improve from 0.97561\n",
            "Epoch 1971/2000\n",
            "5/5 [==============================] - 1s 251ms/step - loss: 0.0203 - acc: 1.0000 - val_loss: 1.0989 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01971: val_acc did not improve from 0.97561\n",
            "Epoch 1972/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.0770 - acc: 0.9750 - val_loss: 1.2933 - val_acc: 0.7073\n",
            "\n",
            "Epoch 01972: val_acc did not improve from 0.97561\n",
            "Epoch 1973/2000\n",
            "5/5 [==============================] - 1s 244ms/step - loss: 0.0486 - acc: 0.9750 - val_loss: 2.0945 - val_acc: 0.5610\n",
            "\n",
            "Epoch 01973: val_acc did not improve from 0.97561\n",
            "Epoch 1974/2000\n",
            "5/5 [==============================] - 1s 249ms/step - loss: 0.0129 - acc: 1.0000 - val_loss: 2.9631 - val_acc: 0.4634\n",
            "\n",
            "Epoch 01974: val_acc did not improve from 0.97561\n",
            "Epoch 1975/2000\n",
            "5/5 [==============================] - 1s 246ms/step - loss: 0.0119 - acc: 1.0000 - val_loss: 3.5150 - val_acc: 0.4634\n",
            "\n",
            "Epoch 01975: val_acc did not improve from 0.97561\n",
            "Epoch 1976/2000\n",
            "5/5 [==============================] - 1s 267ms/step - loss: 0.0347 - acc: 1.0000 - val_loss: 3.5125 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01976: val_acc did not improve from 0.97561\n",
            "Epoch 1977/2000\n",
            "5/5 [==============================] - 1s 258ms/step - loss: 0.0568 - acc: 1.0000 - val_loss: 2.7944 - val_acc: 0.6341\n",
            "\n",
            "Epoch 01977: val_acc did not improve from 0.97561\n",
            "Epoch 1978/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.0297 - acc: 1.0000 - val_loss: 2.1604 - val_acc: 0.7073\n",
            "\n",
            "Epoch 01978: val_acc did not improve from 0.97561\n",
            "Epoch 1979/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.0161 - acc: 1.0000 - val_loss: 1.6346 - val_acc: 0.7805\n",
            "\n",
            "Epoch 01979: val_acc did not improve from 0.97561\n",
            "Epoch 1980/2000\n",
            "5/5 [==============================] - 1s 275ms/step - loss: 0.0326 - acc: 1.0000 - val_loss: 1.6264 - val_acc: 0.7073\n",
            "\n",
            "Epoch 01980: val_acc did not improve from 0.97561\n",
            "Epoch 1981/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.0551 - acc: 0.9750 - val_loss: 2.0450 - val_acc: 0.5122\n",
            "\n",
            "Epoch 01981: val_acc did not improve from 0.97561\n",
            "Epoch 1982/2000\n",
            "5/5 [==============================] - 1s 253ms/step - loss: 0.0121 - acc: 1.0000 - val_loss: 2.7838 - val_acc: 0.4390\n",
            "\n",
            "Epoch 01982: val_acc did not improve from 0.97561\n",
            "Epoch 1983/2000\n",
            "5/5 [==============================] - 1s 270ms/step - loss: 0.0214 - acc: 1.0000 - val_loss: 2.8636 - val_acc: 0.3902\n",
            "\n",
            "Epoch 01983: val_acc did not improve from 0.97561\n",
            "Epoch 1984/2000\n",
            "5/5 [==============================] - 1s 271ms/step - loss: 0.0262 - acc: 1.0000 - val_loss: 2.6933 - val_acc: 0.3902\n",
            "\n",
            "Epoch 01984: val_acc did not improve from 0.97561\n",
            "Epoch 1985/2000\n",
            "5/5 [==============================] - 1s 256ms/step - loss: 0.0142 - acc: 1.0000 - val_loss: 2.3672 - val_acc: 0.4634\n",
            "\n",
            "Epoch 01985: val_acc did not improve from 0.97561\n",
            "Epoch 1986/2000\n",
            "5/5 [==============================] - 1s 256ms/step - loss: 0.0567 - acc: 0.9750 - val_loss: 1.1389 - val_acc: 0.6341\n",
            "\n",
            "Epoch 01986: val_acc did not improve from 0.97561\n",
            "Epoch 1987/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.1226 - acc: 0.9750 - val_loss: 1.5606 - val_acc: 0.5366\n",
            "\n",
            "Epoch 01987: val_acc did not improve from 0.97561\n",
            "Epoch 1988/2000\n",
            "5/5 [==============================] - 1s 258ms/step - loss: 0.0069 - acc: 1.0000 - val_loss: 2.9553 - val_acc: 0.3902\n",
            "\n",
            "Epoch 01988: val_acc did not improve from 0.97561\n",
            "Epoch 1989/2000\n",
            "5/5 [==============================] - 1s 247ms/step - loss: 0.2635 - acc: 0.9250 - val_loss: 4.7948 - val_acc: 0.5122\n",
            "\n",
            "Epoch 01989: val_acc did not improve from 0.97561\n",
            "Epoch 1990/2000\n",
            "5/5 [==============================] - 1s 245ms/step - loss: 0.0189 - acc: 1.0000 - val_loss: 8.0129 - val_acc: 0.4390\n",
            "\n",
            "Epoch 01990: val_acc did not improve from 0.97561\n",
            "Epoch 1991/2000\n",
            "5/5 [==============================] - 1s 254ms/step - loss: 0.1660 - acc: 0.9250 - val_loss: 7.5135 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01991: val_acc did not improve from 0.97561\n",
            "Epoch 1992/2000\n",
            "5/5 [==============================] - 1s 257ms/step - loss: 0.0753 - acc: 0.9750 - val_loss: 6.9702 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01992: val_acc did not improve from 0.97561\n",
            "Epoch 1993/2000\n",
            "5/5 [==============================] - 1s 242ms/step - loss: 0.0088 - acc: 1.0000 - val_loss: 6.0861 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01993: val_acc did not improve from 0.97561\n",
            "Epoch 1994/2000\n",
            "5/5 [==============================] - 1s 247ms/step - loss: 0.1624 - acc: 0.9250 - val_loss: 6.2366 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01994: val_acc did not improve from 0.97561\n",
            "Epoch 1995/2000\n",
            "5/5 [==============================] - 1s 264ms/step - loss: 0.0159 - acc: 1.0000 - val_loss: 5.5712 - val_acc: 0.4878\n",
            "\n",
            "Epoch 01995: val_acc did not improve from 0.97561\n",
            "Epoch 1996/2000\n",
            "5/5 [==============================] - 1s 259ms/step - loss: 0.0237 - acc: 1.0000 - val_loss: 3.5968 - val_acc: 0.5122\n",
            "\n",
            "Epoch 01996: val_acc did not improve from 0.97561\n",
            "Epoch 1997/2000\n",
            "5/5 [==============================] - 1s 262ms/step - loss: 0.0735 - acc: 0.9500 - val_loss: 0.9666 - val_acc: 0.7317\n",
            "\n",
            "Epoch 01997: val_acc did not improve from 0.97561\n",
            "Epoch 1998/2000\n",
            "5/5 [==============================] - 1s 263ms/step - loss: 0.0242 - acc: 1.0000 - val_loss: 0.9010 - val_acc: 0.7073\n",
            "\n",
            "Epoch 01998: val_acc did not improve from 0.97561\n",
            "Epoch 1999/2000\n",
            "5/5 [==============================] - 1s 256ms/step - loss: 0.0082 - acc: 1.0000 - val_loss: 1.3137 - val_acc: 0.7561\n",
            "\n",
            "Epoch 01999: val_acc did not improve from 0.97561\n",
            "Epoch 2000/2000\n",
            "5/5 [==============================] - 1s 268ms/step - loss: 0.0298 - acc: 1.0000 - val_loss: 1.3092 - val_acc: 0.7561\n",
            "\n",
            "Epoch 02000: val_acc did not improve from 0.97561\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6yS9kL-o1XK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b45dba79-1195-47f6-f061-4a3f257dab36"
      },
      "source": [
        "# evaluate model\n",
        "_seg, acc_seg = model.evaluate(testX_seg, testY_seg, verbose=0)\n",
        "print('acc is> %.3f' % (acc_seg * 100.0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "acc is> 75.610\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMjlI-8qTbix",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "87a96520-516e-4c13-db93-fafa2184015c"
      },
      "source": [
        "seg_model = load_model(pathModelSave_seg)\n",
        "_seg, acc_seg = seg_model.evaluate(testX_seg, testY_seg, verbose=0)\n",
        "print('acc is> %.3f' % (acc_seg * 100.0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "acc is> 97.561\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaCPRkMeTxIp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "64371331-0fff-40d6-eb83-f42c75f78fd2"
      },
      "source": [
        "# confusion matrix plotting\n",
        "model = load_model(pathModelSave_seg)\n",
        "\n",
        "y_pred = model.predict(testX)\n",
        "y_pred = np.rint(y_pred.argmax(axis=1))\n",
        "y_pred = y_pred.tolist()\n",
        "\n",
        "testY_ = np.rint(testY_)\n",
        "testY_ = testY_.tolist()\n",
        "\n",
        "y_true = convert_string_label(testY_)\n",
        "y_predicted = convert_string_label(y_pred)\n",
        "\n",
        "cnf_matrix = confusion_matrix(y_true, y_predicted, labels=['Healthy', 'Mild', 'Severe'])\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix, classes=['Healthy', 'Mild', 'Severe'], title='Confusion matrix, without normalization')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT4AAAEYCAYAAADFzZobAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01QJ7LLgLdQL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c396660d-44d3-4607-e321-16fd3c8862b6"
      },
      "source": [
        "# learning curves\n",
        "summarize_diagnostics(history_seg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAACSCAYAAABc4pECAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAACSCAYAAABLwAHLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHBGjjxAhQoQcR8ToI0SIECHH8f+2PFROaOEibgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNcOB3xhjasY/v+hyqkcDKs8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lohxgzNvKxG8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "35e31483-1c8d-4c7b-be24-41e580e9ea46"
      },
      "source": [
        "predict_imgs('/content/drive/My Drive/datasets/alien_test_leaves_seg/healthy/', 'healthy', pathModelSave_seg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 96/96 [00:18<00:00,  5.16it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "time to predict(96,)images is: 8.486170999999956\n",
            "65.06% Healthy\n",
            "61.90% Healthy\n",
            "72.62% Healthy\n",
            "70.12% Healthy\n",
            "98.35% Healthy\n",
            "95.63% Healthy\n",
            "92.49% Healthy\n",
            "94.38% Healthy\n",
            "95.73% Healthy\n",
            "93.95% Healthy\n",
            "97.70% Healthy\n",
            "95.28% Healthy\n",
            "87.99% Healthy\n",
            "94.18% Healthy\n",
            "67.56% Healthy\n",
            "84.41% Healthy\n",
            "82.59% Healthy\n",
            "91.35% Healthy\n",
            "95.82% Healthy\n",
            "92.82% Healthy\n",
            "55.09% Healthy\n",
            "89.83% Healthy\n",
            "90.40% Healthy\n",
            "95.14% Healthy\n",
            "98.35% Healthy\n",
            "96.99% Healthy\n",
            "96.93% Healthy\n",
            "97.60% Healthy\n",
            "94.61% Healthy\n",
            "94.16% Healthy\n",
            "96.04% Healthy\n",
            "97.70% Healthy\n",
            "97.41% Healthy\n",
            "95.35% Healthy\n",
            "96.71% Healthy\n",
            "95.21% Healthy\n",
            "86.74% Healthy\n",
            "94.21% Healthy\n",
            "94.85% Healthy\n",
            "94.97% Healthy\n",
            "92.71% Healthy\n",
            "93.58% Healthy\n",
            "82.89% Healthy\n",
            "81.32% Healthy\n",
            "58.08% Healthy\n",
            "67.09% Healthy\n",
            "59.67% Healthy\n",
            "61.90% Healthy\n",
            "55.65% Healthy\n",
            "55.70% Healthy\n",
            "98.78% Healthy\n",
            "97.28% Healthy\n",
            "97.85% Healthy\n",
            "96.91% Healthy\n",
            "99.19% Healthy\n",
            "98.76% Healthy\n",
            "93.45% Healthy\n",
            "93.74% Healthy\n",
            "82.34% Healthy\n",
            "90.26% Healthy\n",
            "97.83% Healthy\n",
            "95.84% Healthy\n",
            "95.95% Healthy\n",
            "96.43% Healthy\n",
            "97.21% Healthy\n",
            "97.31% Healthy\n",
            "91.54% Healthy\n",
            "79.61% Healthy\n",
            "92.70% Healthy\n",
            "96.08% Healthy\n",
            "98.28% Healthy\n",
            "96.08% Healthy\n",
            "81.71% Healthy\n",
            "94.43% Healthy\n",
            "94.29% Healthy\n",
            "92.41% Healthy\n",
            "95.55% Healthy\n",
            "97.73% Healthy\n",
            "84.55% Healthy\n",
            "88.41% Healthy\n",
            "91.66% Healthy\n",
            "81.84% Healthy\n",
            "71.27% Healthy\n",
            "75.78% Healthy\n",
            "94.66% Healthy\n",
            "91.14% Healthy\n",
            "74.11% Healthy\n",
            "92.18% Healthy\n",
            "78.30% Healthy\n",
            "73.31% Healthy\n",
            "82.40% Healthy\n",
            "86.75% Healthy\n",
            "95.43% Healthy\n",
            "97.47% Healthy\n",
            "76.37% Healthy\n",
            "77.00% Healthy\n",
            "total healthy images: 96\n",
            "Pridicted Healthy: 96\n",
            "Pridicted Mild: 0\n",
            "Pridicted Severe: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6jkWhr2qDku",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f630cdc2-13ef-4480-bd44-55283c234e85"
      },
      "source": [
        "predict_imgs('/content/drive/My Drive/datasets/alien_test_leaves_seg/mild/', 'mild', pathModelSave_seg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 229/229 [00:56<00:00,  4.06it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "time to predict(229,)images is: 20.61457200000001\n",
            "89.19% Mild\n",
            "85.29% Mild\n",
            "79.26% Mild\n",
            "68.30% Mild\n",
            "88.11% Mild\n",
            "69.01% Mild\n",
            "82.72% Mild\n",
            "70.16% Mild\n",
            "94.53% Mild\n",
            "99.52% Mild\n",
            "96.04% Mild\n",
            "89.92% Mild\n",
            "93.65% Mild\n",
            "93.08% Mild\n",
            "81.52% Mild\n",
            "59.29% Mild\n",
            "95.43% Mild\n",
            "88.97% Mild\n",
            "87.73% Mild\n",
            "80.21% Mild\n",
            "94.01% Mild\n",
            "96.97% Mild\n",
            "65.96% Mild\n",
            "82.01% Mild\n",
            "78.96% Mild\n",
            "71.63% Mild\n",
            "88.25% Mild\n",
            "84.92% Mild\n",
            "91.82% Mild\n",
            "86.93% Mild\n",
            "89.66% Mild\n",
            "81.03% Mild\n",
            "54.60% Mild\n",
            "51.04% Mild\n",
            "56.31% Severe\n",
            "49.36% Severe\n",
            "60.46% Mild\n",
            "49.28% Mild\n",
            "70.93% Mild\n",
            "66.95% Mild\n",
            "79.58% Mild\n",
            "70.05% Mild\n",
            "89.54% Mild\n",
            "90.64% Mild\n",
            "79.00% Mild\n",
            "69.68% Mild\n",
            "80.67% Mild\n",
            "79.90% Mild\n",
            "97.09% Mild\n",
            "86.60% Mild\n",
            "74.65% Mild\n",
            "70.52% Mild\n",
            "77.46% Mild\n",
            "74.82% Mild\n",
            "84.91% Mild\n",
            "84.90% Mild\n",
            "73.41% Mild\n",
            "79.80% Mild\n",
            "87.01% Mild\n",
            "81.51% Mild\n",
            "87.37% Mild\n",
            "83.37% Mild\n",
            "92.30% Mild\n",
            "85.76% Mild\n",
            "87.59% Mild\n",
            "81.46% Mild\n",
            "92.26% Mild\n",
            "86.88% Mild\n",
            "96.02% Mild\n",
            "91.11% Mild\n",
            "92.95% Mild\n",
            "88.42% Mild\n",
            "96.29% Mild\n",
            "92.82% Mild\n",
            "96.86% Mild\n",
            "78.82% Mild\n",
            "97.12% Mild\n",
            "90.88% Mild\n",
            "96.50% Mild\n",
            "90.22% Mild\n",
            "81.05% Mild\n",
            "79.88% Mild\n",
            "85.10% Mild\n",
            "74.60% Mild\n",
            "78.73% Mild\n",
            "79.19% Mild\n",
            "71.45% Mild\n",
            "88.75% Mild\n",
            "70.10% Severe\n",
            "72.21% Severe\n",
            "66.80% Mild\n",
            "63.72% Mild\n",
            "94.16% Mild\n",
            "93.31% Mild\n",
            "96.01% Mild\n",
            "70.98% Healthy\n",
            "96.33% Mild\n",
            "50.79% Healthy\n",
            "95.07% Mild\n",
            "82.35% Mild\n",
            "49.74% Mild\n",
            "93.69% Mild\n",
            "86.75% Mild\n",
            "89.77% Mild\n",
            "81.23% Mild\n",
            "92.61% Mild\n",
            "87.78% Mild\n",
            "94.42% Mild\n",
            "90.46% Mild\n",
            "50.30% Mild\n",
            "54.00% Severe\n",
            "79.48% Mild\n",
            "89.90% Mild\n",
            "86.52% Mild\n",
            "93.63% Mild\n",
            "89.80% Mild\n",
            "94.61% Mild\n",
            "88.45% Mild\n",
            "92.46% Mild\n",
            "84.46% Mild\n",
            "92.13% Mild\n",
            "48.30% Mild\n",
            "93.57% Mild\n",
            "87.39% Mild\n",
            "95.95% Mild\n",
            "89.36% Mild\n",
            "92.22% Mild\n",
            "86.98% Mild\n",
            "95.37% Mild\n",
            "87.30% Mild\n",
            "85.83% Mild\n",
            "89.76% Mild\n",
            "83.68% Mild\n",
            "87.40% Mild\n",
            "65.69% Mild\n",
            "97.57% Mild\n",
            "92.93% Mild\n",
            "96.73% Mild\n",
            "91.56% Mild\n",
            "96.74% Mild\n",
            "91.59% Mild\n",
            "96.48% Mild\n",
            "88.47% Mild\n",
            "97.03% Mild\n",
            "81.48% Severe\n",
            "95.91% Mild\n",
            "90.41% Mild\n",
            "97.23% Mild\n",
            "86.03% Mild\n",
            "98.08% Mild\n",
            "87.12% Mild\n",
            "97.46% Mild\n",
            "87.26% Mild\n",
            "96.16% Mild\n",
            "68.30% Mild\n",
            "87.62% Mild\n",
            "69.46% Mild\n",
            "96.38% Mild\n",
            "93.82% Mild\n",
            "97.69% Mild\n",
            "92.62% Mild\n",
            "95.83% Mild\n",
            "90.22% Mild\n",
            "91.07% Mild\n",
            "68.13% Mild\n",
            "90.76% Mild\n",
            "56.07% Mild\n",
            "97.46% Mild\n",
            "58.35% Mild\n",
            "96.53% Mild\n",
            "95.72% Mild\n",
            "81.73% Mild\n",
            "64.14% Mild\n",
            "61.32% Healthy\n",
            "91.19% Mild\n",
            "74.75% Mild\n",
            "97.66% Mild\n",
            "90.13% Mild\n",
            "95.92% Mild\n",
            "80.31% Mild\n",
            "83.42% Mild\n",
            "94.59% Mild\n",
            "91.39% Mild\n",
            "95.22% Mild\n",
            "88.67% Mild\n",
            "98.15% Mild\n",
            "77.81% Mild\n",
            "61.43% Mild\n",
            "52.92% Healthy\n",
            "88.03% Mild\n",
            "50.99% Mild\n",
            "94.80% Mild\n",
            "79.26% Mild\n",
            "97.31% Mild\n",
            "48.77% Mild\n",
            "97.46% Mild\n",
            "77.31% Mild\n",
            "97.86% Mild\n",
            "86.64% Mild\n",
            "97.36% Mild\n",
            "88.28% Mild\n",
            "94.36% Mild\n",
            "77.94% Mild\n",
            "95.51% Mild\n",
            "76.01% Mild\n",
            "94.92% Mild\n",
            "70.26% Mild\n",
            "85.75% Mild\n",
            "52.68% Mild\n",
            "83.21% Mild\n",
            "48.63% Mild\n",
            "53.32% Mild\n",
            "84.70% Healthy\n",
            "95.75% Mild\n",
            "64.38% Healthy\n",
            "97.98% Mild\n",
            "91.11% Mild\n",
            "97.40% Mild\n",
            "93.29% Mild\n",
            "96.93% Mild\n",
            "82.77% Mild\n",
            "85.20% Mild\n",
            "80.15% Mild\n",
            "51.71% Severe\n",
            "53.90% Mild\n",
            "93.93% Mild\n",
            "84.76% Mild\n",
            "73.45% Severe\n",
            "64.72% Severe\n",
            "total mild images: 229\n",
            "Pridicted Healthy: 6\n",
            "Pridicted Mild: 214\n",
            "Pridicted Severe: 9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCa_UW7QqEPk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "29bbb3d0-cb1e-4e86-e2de-183362735135"
      },
      "source": [
        "predict_imgs('/content/drive/My Drive/datasets/alien_test_leaves_seg/severe/', 'severe', pathModelSave_seg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 108/108 [00:20<00:00,  5.21it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "time to predict(108,)images is: 9.598357000000021\n",
            "93.98% Severe\n",
            "91.66% Severe\n",
            "94.64% Severe\n",
            "95.69% Severe\n",
            "96.80% Severe\n",
            "94.43% Severe\n",
            "61.95% Severe\n",
            "50.57% Mild\n",
            "80.27% Severe\n",
            "87.70% Severe\n",
            "91.33% Severe\n",
            "91.10% Severe\n",
            "86.89% Severe\n",
            "84.28% Severe\n",
            "76.58% Severe\n",
            "96.55% Severe\n",
            "95.56% Severe\n",
            "95.35% Severe\n",
            "95.09% Severe\n",
            "94.60% Severe\n",
            "92.82% Severe\n",
            "87.45% Severe\n",
            "94.04% Severe\n",
            "91.50% Severe\n",
            "92.88% Mild\n",
            "85.45% Mild\n",
            "47.01% Mild\n",
            "46.06% Mild\n",
            "52.18% Severe\n",
            "52.20% Severe\n",
            "81.96% Severe\n",
            "65.02% Severe\n",
            "84.22% Severe\n",
            "72.15% Severe\n",
            "63.40% Severe\n",
            "60.89% Severe\n",
            "77.91% Severe\n",
            "52.40% Severe\n",
            "92.77% Severe\n",
            "93.72% Severe\n",
            "50.59% Mild\n",
            "58.59% Severe\n",
            "86.27% Severe\n",
            "90.94% Severe\n",
            "66.58% Severe\n",
            "77.87% Severe\n",
            "59.77% Mild\n",
            "54.22% Mild\n",
            "81.83% Severe\n",
            "84.12% Severe\n",
            "72.87% Severe\n",
            "75.68% Severe\n",
            "89.87% Severe\n",
            "92.05% Severe\n",
            "94.35% Severe\n",
            "94.36% Severe\n",
            "88.21% Severe\n",
            "90.19% Severe\n",
            "92.29% Severe\n",
            "93.98% Severe\n",
            "93.04% Severe\n",
            "92.76% Severe\n",
            "93.47% Severe\n",
            "95.95% Severe\n",
            "85.58% Severe\n",
            "72.30% Severe\n",
            "92.19% Severe\n",
            "89.35% Severe\n",
            "88.84% Severe\n",
            "80.95% Severe\n",
            "95.89% Severe\n",
            "96.83% Severe\n",
            "33.87% Mild\n",
            "50.40% Healthy\n",
            "57.87% Severe\n",
            "52.94% Mild\n",
            "68.35% Severe\n",
            "67.70% Severe\n",
            "75.94% Severe\n",
            "73.32% Severe\n",
            "69.45% Severe\n",
            "49.52% Mild\n",
            "67.72% Mild\n",
            "81.10% Severe\n",
            "73.22% Severe\n",
            "66.74% Severe\n",
            "62.43% Severe\n",
            "91.93% Severe\n",
            "88.11% Severe\n",
            "62.94% Severe\n",
            "89.90% Severe\n",
            "89.24% Severe\n",
            "86.95% Severe\n",
            "83.65% Severe\n",
            "55.32% Severe\n",
            "70.94% Mild\n",
            "82.26% Severe\n",
            "90.33% Severe\n",
            "65.88% Severe\n",
            "60.38% Severe\n",
            "77.30% Mild\n",
            "71.19% Mild\n",
            "95.50% Severe\n",
            "92.13% Severe\n",
            "95.06% Severe\n",
            "95.84% Severe\n",
            "96.65% Severe\n",
            "97.47% Severe\n",
            "total severe images: 108\n",
            "Pridicted Healthy: 1\n",
            "Pridicted Mild: 15\n",
            "Pridicted Severe: 92\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmT322QpqFBn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "17fbde4c-31e7-49d3-c88b-3a3fc8a7571a"
      },
      "source": [
        "predict_imgs('/content/drive/My Drive/datasets/alien_test_leaves_ori/different/', 'different', pathModelSave_seg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 13/13 [00:00<00:00, 90.86it/s] \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "time to predict(13,)images is: 1.3690159999999878\n",
            "98.67% Mild\n",
            "98.09% Mild\n",
            "97.80% Mild\n",
            "99.27% Severe\n",
            "52.34% Mild\n",
            "99.99% Severe\n",
            "99.65% Healthy\n",
            "49.22% Mild\n",
            "77.29% Healthy\n",
            "100.00% Healthy\n",
            "99.99% Healthy\n",
            "99.19% Healthy\n",
            "99.71% Healthy\n",
            "total different images: 13\n",
            "Pridicted Healthy: 6\n",
            "Pridicted Mild: 5\n",
            "Pridicted Severe: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAMYfvhZ6Svz"
      },
      "source": [
        "**acc is> 92.683** with 64x64 image size and initial input size<br>\n",
        "**acc is> 75.610** with 128x128 image size and initial input size: took total 48 minutes to train on 10 epoches"
      ]
    }
  ]
}